{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "from newspaper import Article\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import os\n",
    "\n",
    "#from scrape_and_extract import *\n",
    "#from scrape_and_extract import extract_pdf_pages, extract_chapter, scrape_article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'document_type': 'research_paper',\n",
       " 'title': 'Dark Patterns at Scale: Findings from a Crawl of 11K Shopping Websites',\n",
       " 'author': 'Arunesh Mathur, Gunes Acar, Michael J. Friedman, Elena Lucherini, Jonathan Mayer, Marshini Chetty, and Arvind Narayanan',\n",
       " 'source': 'raw_syllabi\\\\master_courses\\\\Human_computer_interaction\\\\pdf_material\\\\Mathur-2019-Dark-patterns-at-scale.pdf',\n",
       " 'date_published': '2019-09-23',\n",
       " 'keywords': 'Dark Patterns; Consumer Protection; Deceptive Content; Nudging; Manipulation',\n",
       " 'flag': '',\n",
       " 'text': '81 Dark Patterns at Scale: Findings from a Crawl of 11K Shopping Websites ARUNESH MATHUR, Princeton University, USA GUNES ACAR, Princeton University, USA MICHAEL J. FRIEDMAN, Princeton University, USA ELENA LUCHERINI, Princeton University, USA JONATHAN MAYER, Princeton University, USA MARSHINI CHETTY, University of Chicago, USA ARVIND NARAYANAN, Princeton University, USA Dark patterns are user interface design choices that benefit an online service by coercing, steering, or deceiving users into making unintended and potentially harmful decisions. We present automated techniques that enable experts to identify dark patterns on a large set of websites. Using these techniques, we study shopping websites, which often use dark patterns to influence users into making more purchases or disclosing more information than they would otherwise. Analyzing ∼ 53K product pages from ∼ 11K shopping websites, we discover 1,818 dark pattern instances, together representing 15 types and 7 broader categories. We examine these dark patterns for deceptive practices, and find 183 websites that engage in such practices. We also uncover 22 third-party entities that offer dark patterns as a turnkey solution. Finally, we develop a taxonomy of dark pattern characteristics that describes the underlying influence of the dark patterns and their potential harm on user decision-making. Based on our findings, we make recommendations for stakeholders including researchers and regulators to study, mitigate, and minimize the use of these patterns. CCS Concepts: • Human-centered computing → Empirical studies in HCI ; HCI theory, concepts and models ; • Social and professional topics → Consumer products policy ; • Information systems → Browsers . Additional Key Words and Phrases: Dark Patterns; Consumer Protection; Deceptive Content; Nudging; Manipulation ACM Reference Format: Arunesh Mathur, Gunes Acar, Michael J. Friedman, Elena Lucherini, Jonathan Mayer, Marshini Chetty, and Arvind Narayanan. 2019. Dark Patterns at Scale: Findings from a Crawl of 11K Shopping Websites. Proc. ACM Hum.-Comput. Interact. 3, CSCW, Article 81 (November 2019), 32 pages. https://doi.org/10.1145/3359183 Authors’ addresses: Arunesh Mathur, Princeton University, 304 Sherrerd Hall, Princeton, NJ, 08544, USA, amathur@cs. princeton.edu; Gunes Acar, Princeton University, 320 Sherrerd Hall, Princeton, NJ, 08544, USA, gunes@princeton.edu; Michael J. Friedman, Princeton University, 35 Olden Street, Princeton, NJ, 08544, USA, mjf4@princeton.edu; Elena Lucherini, Princeton University, 312 Sherrerd Hall, Princeton, NJ, 08544, USA, elucherini@cs.princeton.edu; Jonathan Mayer, Princeton University, 307 Sherrerd Hall, Princeton, NJ, 08544, USA, jonathan.mayer@princeton.edu; Marshini Chetty, University of Chicago, 355 John Crerar Library, Chicago, IL, 60637, USA, marshini@uchicago.edu; Arvind Narayanan, Princeton University, 308 Sherrerd Hall, Princeton, NJ, 08544, USA, arvindn@cs.princeton.edu. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. © 2019 Copyright held by the owner/author(s). Publication rights licensed to ACM. 2573-0142/2019/11-ART81 $15.00 https://doi.org/10.1145/3359183 Proc. ACM Hum.-Comput. Interact., Vol. 3, No. CSCW, Article 81. Publication date: November 2019. arXiv:1907.07032v2  [cs.HC]  20 Sep 2019 \\n81:2 Arunesh Mathur et al. 1 INTRODUCTION Dark patterns [ 32 , 48 ] are user interface design choices that benefit an online service by coercing, steering, or deceiving users into making decisions that, if fully informed and capable of selecting alternatives, they might not make. Such interface design is an increasingly common occurrence on digital platforms including social media websites [ 46 ], shopping websites [ 32 ], mobile apps [ 5 , 31 ], and video games [ 85 ]. At best, dark patterns annoy and frustrate users. At worst, they can mislead and deceive users, e.g., by causing financial loss [ 1 , 2 ], tricking users into giving up vast amounts of personal data [ 46 ], or inducing compulsive and addictive behavior in adults [ 74 ] and children [ 21 ]. While prior work [ 31 , 32 , 38 , 48 ] has provided taxonomies to describe the existing types of dark patterns, there is no large-scale evidence documenting their prevalence, or a systematic and descriptive investigation of how the different types of dark patterns harm users. Collecting this information would allow us to first examine where, how often, and the technical means by which dark patterns appear; second, it would allow us to compare and contrast how various dark patterns influence users. In doing so, we can develop countermeasures against dark patterns to both inform users and protect them from such patterns. Further, given that many of these patterns are potentially unlawful, we can also aid regulatory agencies in addressing and mitigating their use. In this paper, we present an automated approach that enables experts to identify dark patterns at scale on the web. Our approach relies on (1) a web crawler, built on top of OpenWPM [ 25 , 40 ]—a web privacy measurement platform—to simulate a user browsing experience and identify user interface elements; (2) text clustering to extract all user interface designs from the resulting data; and (3) inspecting the resulting clusters for instances of dark patterns. We also develop a taxonomy so that researchers can share descriptive and comparative terminology to explain how dark patterns subvert user decision-making and lead to harm. We base this taxonomy on the characteristics of dark patterns as well as the cognitive biases they exploit in users. While our automated approach generalizes, we focus this study on shopping websites, which are used by an overwhelming majority of people worldwide [ 41 ]. Dark patterns found on these websites trick users into signing up for recurring subscriptions and making unwanted purchases, resulting in concrete financial loss. We use our web crawler to visit the ∼ 11K most popular shopping websites worldwide, create a large data set of dark patterns, and document their prevalence. Our data set contains several new instances and variations of previously documented dark patterns [ 32 , 48 ]. Finally, we use our taxonomy of dark pattern characteristics to classify and describe the patterns we discover. We have five main findings: • We discovered 1,818 instances of dark patterns on shopping websites, which together repre- sent 15 types of dark patterns and 7 broad categories. • These 1,818 dark patterns were found on 1,254 of the ∼ 11K shopping websites ( ∼ 11.1%) in our data set. Shopping websites that were more popular, according to Alexa rankings [ 9 ], were more likely to feature dark patterns. These numbers represent a lower bound on the total number of dark patterns on these websites, since our automated approach only examined text-based user interfaces on a sample of product pages per website. • In using our taxonomy to classify the dark patterns in our data set, we discovered that the majority are covert , deceptive , and information hiding in nature. Further, many patterns exploit cognitive biases, such as the default and framing effects. These characteristics and biases collectively describe the consumer psychology underpinnings of the dark patterns we identified. • We uncovered 234 instances of dark patterns—across 183 websites—that exhibit deceptive behavior. We highlight the types of dark patterns we encountered that rely on deception. Proc. ACM Hum.-Comput. Interact., Vol. 3, No. CSCW, Article 81. Publication date: November 2019. \\nDark Patterns at Scale 81:3 • We identified 22 third-party entities that provide shopping websites with the ability to create and implement dark patterns on their sites. Two of these entities openly advertised practices that enable deceptive messages. Through this study, we make the following contributions: • We contribute automated measurement techniques that enable expert analysts to discover new or revisit existing instances of dark patterns on the web. As part of this contribution, we make our web crawler and associated technical artifacts available on GitHub 1 . These can be used to conduct longitudinal measurements on shopping websites or be re-purposed for use on other types of websites (e.g., travel and ticket booking websites). • We create a data set and measure the prevalence of dark patterns on 11K shopping websites. We make this data set of dark patterns and our automated techniques publicly available 2 to help researchers, journalists, and regulators raise awareness of dark patterns [ 21 ], and to help develop user-facing tools to combat these patterns. • We contribute a novel descriptive taxonomy that provides precise terminology to characterize how each dark pattern works. This taxonomy can aid researchers and regulators to better understand and compare the underlying influence and harmful effects of dark patterns. • We document the third-party entities that enable dark patterns on websites. This list of third parties can be used by existing tracker and ad-blocking extensions (e.g., Ghostery, 3 Adblock Plus 4 ) to limit their use on websites. 2 RELATED WORK 2.1 Online Shopping and Influencing User Behavior Starting with Hanson and Kysar, numerous scholars have examined how companies abuse users’ cognitive limitations and biases for profit, a practice they call market manipulation [ 50 ]. For instance, studies have shown that users make different decisions from the same information based on how it is framed [ 80 , 81 ], giving readily accessible information greater weight [ 79 ], and becoming susceptible to impulsively changing their decision the longer the reward from their decision is delayed [ 28 ]. Some argue that because users are not always capable of acting in their own best interests, some forms of ‘paternalism’—a term referring to the regulation or curation of the user’s options—may be acceptable [ 78 ]. However, determining the kinds of curation that are acceptable is less straightforward, particularly without documenting the practices that already exist. More recently, Calo has argued that market manipulation is exacerbated by digital marketplaces since they posses capabilities that increase the chance of user harm culminating in financial loss, loss of privacy, and the ability to make independent decisions [ 34 ]. For example, unlike brick-and- mortar stores, digital marketplaces can capture and retain user behavior information, design and mediate user interaction, and proactively reach out to users. Other studies have suggested that certain elements in shopping websites can influence impulse buying behavior [ 60 , 86 ]. For instance, perceived scarcity, social influence (e.g., ‘social proof’—informing users of others’ behavior—and shopping with others [ 33 , 61 ]) can all lead to higher spending. More recently, Moser et al. conducted a study [ 65 ] to measure the prevalence of elements that encourage impulse buying. They identified 64 such elements—e.g., product reviews/ratings, discounts, and quick add-to cart buttons—by manually scraping 200 shopping websites. 1 https://github.com/aruneshmathur/dark-patterns 2 https://webtransparency.cs.princeton.edu/dark-patterns 3 https://ghostery.com 4 https://adblockplus.com Proc. ACM Hum.-Comput. Interact., Vol. 3, No. CSCW, Article 81. Publication date: November 2019. \\n81:4 Arunesh Mathur et al. 2.2 Dark Patterns in User Interface Design Coined by Brignull in 2010, dark patterns is a catch-all term for how user interface design can be used to adversely influence users and their decision-making abilities. Brignull described dark patterns as ‘tricks used in websites and apps that make you buy or sign up for things that you didn’t mean to’, and he created a taxonomy of dark patterns using examples from shopping and travel websites to help raise user awareness. The taxonomy documented patterns such as ‘Bait and Switch’ (the user sets out to do one thing, but a different, undesirable thing happens instead), and ‘Confirmshaming’ (using shame tactics to steer the user into making a choice). 2.2.1 Dark Pattern Taxonomies. A growing number of studies have expanded on Brignull’s orig- inal taxonomy more systematically to advance our understanding of dark patterns. Conti and Sobiesk [ 38 ] were the first to create a taxonomy of malicious interface design techniques, which they defined as interfaces that manipulate, exploit, or attack users. While their taxonomy contains no examples and details on how the authors created the taxonomy are limited, it contains sev- eral categories that overlap with Brignull’s dark patterns, including ‘Confusion’ (asking the user questions or providing information that they do not understand) and ‘Obfuscation’ (hiding desired information and interface elements). More recently, Bösch et al. [ 31 ] presented a similar, alternative breakdown of privacy-specific dark patterns as ‘Dark Strategies’, uncovering new patterns: ‘Forced Registration’ (requiring account registration to access some functionality) and ‘Hidden Legalese Stipulations’ (hiding malicious information in lengthy terms and conditions). Finally, Gray et al. [ 48 ] presented a broader categorization of Brignull’s taxonomy and collapsed many patterns into categories such as ‘Nagging’ (repeatedly making the same request to the user) and ‘Obstruction’ (preventing the user from accessing functionality). While these taxonomies have focused on the web, researchers have also begun to examine dark patterns in specific application domains. For instance, Lewis [ 57 ] analyzed design patterns in the context of web and mobile applications and games, and codified those patterns that have been successful in making apps ‘irresistible’, such as ‘Pay To Skip’ (in-app purchases that skip levels of a game). In another instance, Greenberg et al. [ 49 ] analyzed dark patterns and ‘antipatterns’— interface designs with unintentional side-effects on user behavior—that leverage users’ spatial relationship with digital devices. They introduced patterns such as ‘Captive Audience’ (inserting unrelated activities such as an advertisement during users’ daily activities) and ‘Attention Grabber’ (visual effects that compete for users’ attention). Finally, Mathur et al. [ 63 ] discovered that most affiliate marketing on social media platforms such as YouTube and Pinterest is not disclosed to users (the ‘Disguised Ads’ dark pattern). 2.2.2 Dark Patterns and User Decision-making. A growing body of work has drawn connections between dark patterns and various theories of human decision-making in an attempt to explain how dark patterns work and cause harm to users. Xiao and Benbasat [ 84 ] proposed a theoretical model for how users are affected by deceptive marketing practices in online shopping, including affective mechanisms (psychological or emotional motivations) and cognitive mechanisms (perceptions about a product). In another instance, Bösch et al. [ 31 ] used Kahneman’s Dual process theory [ 79 ] which describes how humans have two modes of thinking—‘System 1’ (unconscious, automatic, possibly less rational) and ‘System 2’ (conscious, rational)—and noted how ‘Dark Strategies’ exploit users’ System 1 thinking to get them to make a decision desired by the designer. Lastly, Lewis [ 57 ] linked each of the dark patterns described in his book to Reiss’s Desires, a popular theory of psychological motivators [ 72 ]. Finally, a recent study by the Norwegian Consumer Council (Frobrukerrådet) [ 46 ] examined how interface designs on Google, Facebook, and Windows 10 make Proc. ACM Hum.-Comput. Interact., Vol. 3, No. CSCW, Article 81. Publication date: November 2019. \\nDark Patterns at Scale 81:5 it hard for users to exercise privacy-friendly options. The study highlighted the default options and framing statements that enable such dark patterns. 2.3 Comparison to Prior Work Our study differs from prior work in two ways. First, while prior work has largely focused on creating taxonomies of the types of dark patterns either based on anecdotal data [ 31 , 32 ] or data collected from users’ submissions [ 38 , 48 ], we provide large-scale evidence documenting the presence and prevalence of dark patterns in the wild. Automated measurements of this kind have proven useful in discovering various privacy and security issues on the web—including third-party tracking [ 25 , 40 ] and detecting vulnerabilities of remote third-party JavaScript libraries [ 68 ]—by documenting how and on which websites these issues manifest, thus enabling practical solutions to counter them. Second, we expand on the insight offered by prior work about how dark patterns affect users. We develop a comprehensive taxonomy of dark pattern characteristics (Section 3) that concretely explains the underlying influence and harmful effects of each dark pattern. Finally, while prior work has shed light on impulse buying on shopping websites, the focus of our work is on dark patterns. While there is some overlap between certain types of dark patterns and impulse buying features of shopping websites [ 65 ], the majority of impulse buying elements are not dark patterns. For instance, offering returns and exchanges for products, or showing multiple images of a product [ 65 ] do not constitute dark patterns: even though they play a role in persuading users into purchasing products, they do not fundamentally subvert user decision-making in a manner that benefits shopping websites and retailers. 3 A TAXONOMY OF DARK PATTERN CHARACTERISTICS Our taxonomy explains how dark patterns affects user decision-making based on their charac- teristics as well as the cognitive biases in users—deviations from rational behavior justified by some ‘biased’ line of reasoning [ 51 ]—they exploit to their advantage. We ground this taxonomy in the literature on online manipulation [ 34 , 77 , 83 ] and by studying the types of dark patterns highlighted in previous work [32, 48]. Our taxonomy consists of the following five dimensions: • Asymmetric : Does the user interface design impose unequal weights or burdens on the available choices presented to the user in the interface? 5 For instance, a website may present a prominent button to accept cookies on the web but make the opt-out button less visible, or even hide it in another page. • Covert : Is the effect of the user interface design choice hidden from users? That is, does the interface design to steer users into making specific purchases without their knowledge? For instance, a website may leverage the decoy effect [ 52 ] cognitive bias, in which an additional choice—the decoy—is introduced to make certain other choices seem more appealing. Users may fail to recognize the decoy’s presence is merely to influence their decision making, making its effect covert. • Deceptive : Does the user interface design induce false beliefs either through affirmative misstatements, misleading statements, or omissions? For instance, a website may offer a discount to users that appears to be limited-time, but actually repeats when the user refreshes the website’s page. Users may be aware that the website is trying to offer them a discount; however, they may not realize that they do not have a limited time to take advantage of the deal. This false belief affects users’ decision-making i.e., they may act differently if they knew that the sale is recurring. 5 We narrow the scope of asymmetry to only refer to explicit choices in the interface. Proc. ACM Hum.-Comput. Interact., Vol. 3, No. CSCW, Article 81. Publication date: November 2019. \\n81:6 Arunesh Mathur et al. • Hides Information : Does the user interface obscure or delay the presentation of necessary information to the user? For instance, a website may not disclose additional charges for a product to the user until the very end of their checkout. • Restrictive : Does the user interface restrict the set of choices available to users? For instance, a website may only allow users to sign up for an account with existing social media accounts so they can gather more information about them. Many types of dark patterns operate by exploiting cognitive biases in users. In Section 5, we draw an explicit connection between each type of dark pattern we encounter and the cognitive biases it exploits. The biases we refer to in our findings are: (1) Anchoring Effect [ 79 ]: The tendency of individuals to overly rely on an initial piece of information—the ‘anchor’—in future decisions. (2) Bandwagon Effect [ 75 ]: The tendency of individuals to value something more because others seem to value it. (3) Default Effect [ 54 ]: The tendency of individuals to stick with options that are assigned to them by default due to inertia. (4) Framing Effect [ 80 ]: The tendency of individuals to reach different decisions from the same information depending on how it is presented. (5) Scarcity Bias [ 64 ]: The tendency of individuals to place a higher value on things that are scarce. (6) Sunk Cost Fallacy [ 29 ]: The tendency of individuals to continue an action if they have invested resources into it, even if that action might make them worse off. 4 METHOD Dark patterns may manifest in several different locations inside websites, and they can rely heavily upon interface manipulation, such as changing the hierarchy of interface elements or prioritizing certain options over others using different colors. However, many dark patterns are often present on users’ primary interaction paths in an online service or website (e.g., when purchasing a product on a shopping website, or when a game is paused after a level is completed). Further, multiple instances of a type of dark pattern share common traits such as the text they display (e.g., in the ‘Confirmshaming’ dark pattern—which tries to shame the user into making a particular choice— many messages begin with No thanks ). Our technique relies on automating the primary interaction path of websites, extracting textual interface elements present in this path, and finally, grouping and organizing these—using clustering—for an expert analyst to sift through. While our method generalizes to different types of websites, we focus on shopping websites in this study. We designed a web crawler capable of navigating users’ primary interaction path on shopping websites: making a product purchase. Our crawler aligned closely with how an ordinary user would browse and make purchases on shopping websites: discover pages containing products on a website, add these products to the cart, and check out. We describe these steps, and the data we collected during each visit to a website below. Figure 1 illustrates an overview of our method. We note that only analyzing textual information in this manner restricts the set of dark patterns we can discover, making our findings a lower bound on the dark patterns employed by shopping websites. We leave detecting other kinds of dark patterns—those that are enabled using style, color, and other non-textual features—to future work, and we discuss possible approaches in Section 6. 4.1 Creating a Corpus of Shopping Websites We used the following criteria to evaluate existing lists of popular shopping websites, and, eventually, construct our own: (1) the list must be representative of the most popular shopping websites globally, Proc. ACM Hum.-Comput. Interact., Vol. 3, No. CSCW, Article 81. Publication date: November 2019. \\nDark Patterns at Scale 81:7 and (2) the list must consist of shopping websites in English so that we would have the means to analyze the data collected from the websites. We retrieved a list of popular websites worldwide from Alexa using the Top Sites API [ 9 ]. Alexa is a web traffic analysis company that ranks and categorizes websites based on statistics it collects from users of its toolbar. We used the Top Sites list because it is more stable and is based on monthly traffic and not daily rank, which fluctuates often [ 73 ] The list contained 361,102 websites in total, ordered by popularity rank. 6 We evaluated two website classification services to extract shopping websites from this list of the most popular websites: Alexa Web Information Service [ 10 ] and WebShrinker [ 23 ]. We evaluated the classification accuracy of these services using a random sample of 500 websites from our list of 361K websites, which we manually labeled as ‘shopping’ or ‘not shopping’. We considered a website to be a shopping website if it was offering a product for purchase. Of the 500 websites in our sample, we labeled 57 as ‘shopping’ and 443 as ‘not shopping’. We then evaluated the performance of both classifiers against this ground truth. Table 3 in the Appendix summarizes the classifiers’ results. Compared to Webshrinker, Alexa’s classifications performed poorly on our sample of websites (classification accuracy: 89% vs. 94%), with a strikingly high false negative rate (93% vs. 18%). Although Webshrinker had a slightly higher false positive rate (0.2% vs. 0.4%), we used methods to determine and remove these false positives as we describe in Section 4.2.1. We subsequently used Webshrinker to classify our list of 361K websites, obtaining a list of 46,569 shopping websites. To filter out non-English websites, we downloaded home pages of each site using Selenium [ 8 ] and ran language detection on texts extracted from the pages using the polyglot Python library [ 4 ]. Our final data set contained 19,455 English language shopping websites. We created this filtered list in August 2018. 4.2 Data Collection with a Website Crawl We conducted all our crawls from the Princeton University campus using two off-the-shelf com- puters, both equipped with 16G of memory and quad-core CPUs. Our crawler’s exploration of each shopping website mimicked a typical user’s primary interaction path on a shopping website— starting with one of its product pages. Therefore, the first step in our website crawl was to determine ways to automatically identify product URLs from shopping websites. 4.2.1 Discovering Product URLs on Shopping Websites. To effectively extract product URLs from shopping websites, we iteratively designed and built a Selenium-based web crawler that contained a classifier capable of distinguishing product URLs from non-product URLs. At first, we build a naïve depth-first crawler that, upon visiting a website’s home page, determined the various URLs on the page, selected one URL at random, and then repeated this process from the selected URL. Using this crawler, we assembled a data set of several thousand URLs from visiting a random sample of 100 websites from our data set of 19K shopping websites. We manually labeled a sample of these URLs either as ‘product’ or ‘non-product’ URLs, and created a balanced data set containing 714 labeled URLs in total. We trained a Logistic Regression classifier on this data set of labeled URLs using the SGDClassifier class from scikit-learn [ 71 ]. We extracted several relevant features from this data set of URLs, in- cluding the length of a URL, the length of its path, the number of forward slashes and hyphens in 6 We did not use Alexa’s list of Top/Shopping websites [ 22 ] because of two issues. First, its criteria of categorization are not fully disclosed. Second, most of the websites in the list had an average monthly rank > 500,000, which we did not consider to be representative of the most popular websites worldwide. Proc. ACM Hum.-Comput. Interact., Vol. 3, No. CSCW, Article 81. Publication date: November 2019. \\n81:8 Arunesh Mathur et al. 361 K Websites From Alexa Top Sites 47 K Shopping Websites Webshrinker Classiﬁer polyglot Language Classiﬁer 19 K English Shopping Websites Corpus CreaDon Data CollecDon Product Page Crawler 53 K Product Pages From 11 K Shopping Websites Checkout Crawler • 13 M Segments • HTTP Requests & Responses • HAR Files • HTML Sources • Page Screenshots Data Analysis Hierarchical Clustering using HDBSCAN Manual ExaminaDon Dark PaSerns Fig. 1. Overview of the shopping website corpus creation, data collection using crawling, and data analysis using hierarchical clustering stages. its path, and whether its path contained the words ‘product’ or ‘category’. We used 90% of the URLs for training and obtained an 83% average classification accuracy using five-fold cross validation. We embedded this classifier into our original Selenium-based web crawler to help guide its crawl. As a result, rather than selecting and visiting URLs at random, the crawler first used the classifier to rank the URLs on a page by likelihood of being product URLs, and then visited the URL with the highest likelihood. The crawler declared a URL as product if its page contained an ‘Add to cart’ or similar button. We detected this button by assigning a weighted score to visible HTML elements on a page based on their size, color, and whether they matched certain regular expressions (e.g., ‘Add to bag|cart|tote|...’). This check also helped us weed out any false positives that may have resulted from the classification of shopping websites using Webshrinker (Section 4.1). We tuned the crawler’s search process to keep its crawl tractable. The crawler returned to the home page after flagging a product URL. It did not visit a given URL more than two times to avoid exploring the same URLs, and it stopped after visiting 100 URLs or spending 15 minutes on a site. We determined these termination limits by running test crawls on random samples of shopping websites. Finally, we opted to extract no more than five product pages from each shopping website. To evaluate our crawler’s performance, we randomly sampled 100 shopping websites from our corpus of 19K shopping websites and examined the product URLs the crawler returned for each of these websites. For 86 of those 100 websites, our crawler successfully extracted and returned legitimate product pages where they were present, and it returned no product pages where there Proc. ACM Hum.-Comput. Interact., Vol. 3, No. CSCW, Article 81. Publication date: November 2019. \\nDark Patterns at Scale 81:9 were not any. For the remaining 14 websites, the crawler either timed out because the website was no longer reachable, the website included a step that the crawler could not handle (e.g., the website required selecting a country of origin), or the ‘Add to cart’ button was incorrectly detected. We then used the crawler on all of the 19K shopping websites, and in total we gathered 53,180 product pages from 11,286 shopping websites. 4.2.2 Simulating Product Purchase Flows. To simulate a user’s typical shopping flow—which in- cluded selecting certain product options (e.g., size or color), adding the product to the cart, viewing the cart, and checking out—we designed and built an interactive ‘checkout crawler’. We based our checkout crawler on OpenWPM, a fully instrumented browser platform that is designed to conduct large-scale privacy and web-tracking measurement studies [ 40 ]. We extended OpenWPM in a number of ways to interact with the product pages we collected previously, including identifying various interface elements using scoring functions similar to the ones we described in Section 4.2. Each of these functions would output the most likely ‘Add to cart’ buttons, ‘View cart’ buttons, and ‘Checkout’ buttons, which the crawler would click in–order across multiple pages. Because websites do not follow uniform HTML markup and design, our crawler needed to account for a variety of design alternatives and edge cases to simulate user interaction, such as dismissing popup dialogs, and identifying and interacting with product options (e.g., selecting a size and color for a t-shirt) to add a product to cart. We collected three types of data during this crawl for each product page. First, we saved the page source on visit. Second, we took screenshots each time the state of the page changed (e.g., clicking a button or selecting a product option). Third, we extended OpenWPM’s HTTP instrumentation to store HTTP Archive (HAR) [ 13 ]) files for each crawled page since HAR files are not limited to HTTP headers and contain full response contents that can be used for further analysis. To evaluate our crawler’s performance, we randomly sampled 100 product pages from the crawl in Section 4.2.1 and examined whether our crawler was able to simulate a user’s shopping flow. In 66 of the 100 pages, our crawler reached the checkout page successfully. In 14 of the remaining 34, the crawler was able to add the product to cart but it was unable to proceed to the cart page; most often this was the result of complex product interaction (e.g., selecting the dimensions of a rug), which our crawler was not designed to perform. In the remaining 20 cases, either we produced Selenium exceptions, or failed to discover cart and checkout buttons. We then used the crawler on all of the 53K product pages. We divided the 53K product URLs into two equal-length lists to reduce the total crawling time. These crawls took approximately 90 hours to complete. 4.2.3 Capturing Meaningful Text Using Page Segmentation. The checkout crawler divided all the pages it visited into meaningful page segments to help discover dark patterns. These segments can be thought of as ‘building blocks’ of web pages, representing meaningful smaller sections of a web page. These formed the basic units for our data analysis and clustering. We defined segments as visible HTML elements that contained no other block-level elements [ 6 ] and contained at least one text element—that is, elements of type TEXT_NODE [ 19 ]. However, since websites may use a virtually endless variety of markup and designs, we iteratively developed our segmentation algorithm, testing it on samples of shopping websites and accounting for possible edge cases. Algorithm 1 and Figure 11 in the Appendix detail the segmentation algorithm and illustrate its output for one web page, respectively. Before segmenting each web page, the crawler waited for the page to load completely, also accounting for the time needed for popup dialogs to appear. However, web pages may also display text from subsequent user interactions, and with dynamically loaded content (e.g., a countdown timer). To capture possible segments from such updates to the web page during a crawl—no matter how minor or transient—we integrated the Mutation Summary [ 3 ] library into our checkout crawler. Proc. ACM Hum.-Comput. Interact., Vol. 3, No. CSCW, Article 81. Publication date: November 2019. \\n81:10 Arunesh Mathur et al. The Mutation Summary library combines DOM MutationObserver events [ 18 ] into compound event summaries that are easy to process. When the checkout crawler received a new Mutation Summary representing updates to the page, it segmented (Algorithm 1) this summary and stored the resulting segments. For each segment, we stored its HTML Element type, its element text (via innerText ), its dimensions and coordinates on the page, and its style including its text and background colors. Our crawls resulted in ∼ 13 million segments across the 53K product URL pages. 4.3 Data Analysis with Clustering We employed hierarchical clustering to discover dark patterns from the data set of segments. Our use of clustering was not to discover a set of latent constructs in the data but rather to organize the segments in a manner that would be conducive to scanning, making it easier for an expert analyst to sift through the clusters for possible dark patterns. 4.3.1 Data Preprocessing. Many of the ∼ 13 million segments collected during our crawls were duplicates, such as multiple ‘Add to cart’ segments across multiple websites. Since we only used text-based features for our analyses, we retained unique pieces of text across the websites in our data set (e.g., one segment containing the text ‘Add to cart’ across all the websites in our data set). We also replaced all numbers with a placeholder before performing this process to further reduce duplicates. This preprocessing reduced the set of segments by 90% to ∼ 1.3 million segments. 4.3.2 Feature Representations and Hierarchical Clustering. Before performing clustering, we trans- formed the text segments into a Bag of Words (BoW) representation. Each entry in the resulting BoW matrix ( M ij ) indicated the number of times token j appeared in segment i . 7 We filtered all stop words 8 and punctuation—except currency symbols, since these are indicative of product price—from the list of tokens, and further only retained tokens that appeared in at least 100 segments. This resulted in a vocabulary of 10,133 tokens. Given this large size of our vocabulary—and thus the dimensions of the segment-token matrix— we performed Principal Component Analysis (PCA) on the BoW matrix. We retained 3 components from the PCA, which together captured more than 95% of the variance in the data. We used the Hierarchical Density-Based Spatial Clustering of Applications with Noise (HDB- SCAN) algorithm [ 35 ] implemented in the HDBSCAN Python library [ 14 ] to extract clusters from this data. We chose HDBSCAN over other clustering algorithms since it is robust to noise in the data, and it allows us to vary the minimum size of the clusters ( min_cluster_size ). We varied a total of four passes at clustering: two min_cluster_size values (5 and 10) × two distance metrics (Manhattan distance or L1 norm, and Euclidean distance or L2 norm). We picked sufficiently small values for the min_cluster_size parameter to keep the size of the noise cluster small and to avoid coercing segments into one cluster. The clustering output across the BoW input was nearly the same. As expected, a min_cluster_size of 10 resulted in a larger noise cluster compared to a min_cluster_size of 5—but only marginally larger regardless of the distance metric. However, since the min_cluster_size of 10 produced significantly fewer clusters, we picked its output over the others. It contained 10,277 clusters. 7 We did not use the Term Frequency-Inverse Document Frequency (TF-IDF) representation as upon clustering, it resulted in anywhere between 70%-75% of the segments being classified as noise. We believe this may have been because of the incorrect IDF scaling factor since the segments were not all drawn from a pool of independent observations—i.e., multiple segments originated from the same website 8 Using Python NLTK [30] Proc. ACM Hum.-Comput. Interact., Vol. 3, No. CSCW, Article 81. Publication date: November 2019. \\nDark Patterns at Scale 81:11 Alexa rank % Websites with >= 1 Dark Pattern 0e+00 1e+05 2e+05 3e+05 4e+05 0 5 10 15 20 Fig. 2. Distribution of the dark patterns we discovered over the Alexa rank of the websites. Each bin indicates the percentage of shopping websites in that bin that contained at least one dark pattern. 4.3.3 Examining and Analyzing the Clusters. Once the clustering was complete, we made two passes through the data. The goal of pass one was to include clusters that contained any segments that might manifest as dark patterns. In this pass, one researcher scanned the clusters and identified possible clusters of interest, recording all those clusters that represented specific types of user interfaces (e.g., login choices, cart totals), website characteristics (e.g., stock notifications), and product options (e.g., small/medium/large) that generally appear on shopping websites. This step filtered down the clusters from 10,277 to 1,768. In pass two, we extracted all the websites that corresponded to these segments for further examination. The research team used the literature on dark patterns [ 32 , 48 , 69 ] and impulse buying [ 65 ], and media coverage of high-pressure sales and marketing tactics (e.g., [ 15 ]) to create a shared understanding of possible dark patterns using the examples cited in these works to guide our thinking. In order to validate the coding of clusters, two researchers examined a sample of 200 of the 1,768 clusters, and recorded any dark patterns they encountered. The researchers also examined each website’s set of screenshots and visited the websites to gain context and additional information surrounding the segments (e.g., discovering practices associated with the flagged pattern). To measure agreement between the researchers, we computed Cohen’s kappa between the segments that were recorded—resulting in a score of 0.74. The team discussed and resolved all disagreements, and one researcher then examined the remaining clusters in the same manner. The team then discussed the resulting dark patterns, and iteratively grouped them into types and broader categories. 4.4 Detecting Deceptive Dark Patterns We further examined many of the dynamic dark patterns—those patterns that displayed transient values (e.g., a countdown timer)—for deceptive practices. To this end, we used our checkout crawler to ‘monitor’ the websites containing dark patterns of interest once every four hours for a period of five days. We combined this data with several dark pattern-specific heuristics—which we describe in the following sections—to uncover instances of deceptive practices. 5 FINDINGS In total, we discovered 1,818 instances of dark patterns from 1,254 ( ∼ 11.1%) websites in our data set of 11K shopping websites. Given that (1) our crawler only explored the product pages, cart pages, and checkout pages of websites, (2) our analyses only took text-based user interfaces into Proc. ACM Hum.-Comput. Interact., Vol. 3, No. CSCW, Article 81. Publication date: November 2019. \\n81:12 Arunesh Mathur et al. Table 1. Categories and types of dark patterns along with their description, prevalence, and definitions. Legend: = Always, G# = Sometimes, # = Never Category Type Description # Instances # Websites Asymmetric? Covert? Deceptive? Hides Info? Restrictive? Cognitive Biases Sneaking Sneak into Basket Adding additional products to users’ shop- ping carts without their consent 7 7 # # G # # Default Effect Hidden Costs Revealing previously undisclosed charges to users right before they make a purchase 5 5 # # G # # Sunk Cost Fallacy Hidden Subscription Charging users a recurring fee under the pretense of a one-time fee or a free trial 14 13 # # G # # None Urgency Countdown Timer Indicating to users that a deal or discount will expire using a counting-down timer 393 361 # G # G # # # Scarcity Bias Limited-time Message Indicating to users that a deal or sale will expire will expire soon without specifying a deadline 88 84 # G # # # Scarcity Bias Misdirection Confirmshaming Using language and emotion (shame) to steer users away from making a certain choice 169 164 # # # # Framing Effect Visual Interference Using style and visual presentation to steer users to or away from certain choices 25 24 G # G # # # Anchoring & Fram- ing Effect Trick Questions Using confusing language to steer users into making certain choices 9 9 # # # Default & Framing Effect Pressured Selling Pre-selecting more expensive variations of a product, or pressuring the user to accept the more expensive variations of a product and related products 67 62 G # G # # # # Anchoring & Default Effect, Scarcity Bias Social Proof Activity Message Informing the user about the activity on the website (e.g., purchases, views, visits) 313 264 # G # G # # # Bandwagon Effect Testimonials Testimonials on a product page whose ori- gin is unclear 12 12 # # G # # # Bandwagon Effect Scarcity Low-stock Message Indicating to users that limited quantities of a product are available, increasing its de- sirability 632 581 # G # G # G # # Scarcity Bias High-demand Message Indicating to users that a product is in high- demand and likely to sell out soon, increas- ing its desirability 47 43 # G # # # # Scarcity Bias Obstruction Hard to Cancel Making it easy for the user to sign up for a service but hard to cancel it 31 31 # # # G # None Forced Action Forced Enrollment Coercing users to create accounts or share their information to complete their tasks 6 6 # # # None account, this number represents a lower-bound estimate of the prevalence of dark patterns. We divide our discussion of the findings by first illustrating the categories of dark patterns revealed by our analyses, and then by describing our findings on the ecosystem of third-parties that enable dark patterns. Proc. ACM Hum.-Comput. Interact., Vol. 3, No. CSCW, Article 81. Publication date: November 2019. \\nDark Patterns at Scale 81:13 5.1 Categories of Dark Patterns Our analyses revealed 15 types of dark patterns contained in 7 broader categories. Where applicable, we use the dark pattern labels proposed by Gray et al. [ 48 ] and Brignull [ 32 ] to describe these types and categories. Table 1 summarizes our findings, highlighting the number of separate instances of dark patterns found for each type. Figure 2 shows the distribution of the websites containing dark patterns over their Alexa ranks. The distribution suggests that dark patterns are more likely to appear on popular websites (Spear- man’s Rho = -0.62, p < 0 . 0001). In the following sections, we describe the various categories and types of dark patterns we discovered. 5.1.1 Sneaking. Coined by Gray et al. in their taxonomy [ 48 ], ‘Sneaking’ refers to the category of dark patterns that attempt to misrepresent user actions, or hide/delay information that, if made available to users, they would likely object to. We observed three types of the Sneaking dark pattern: Sneak into Basket [ 32 ], Hidden Costs [ 32 ], and Hidden Subscription (Brignull’s Forced Continuity [32]) on 23 shopping websites. Figure 3 highlights instances of these three types. Sneak into Basket . The ‘Sneak into Basket’ dark pattern adds additional products to users’ shopping carts without their consent, often promoting the added products as ‘bonuses’ and ‘neces- sary’. Sneak into Basket exploits the default effect cognitive bias in users, with the website behind it hoping that users will stick with the products it adds to cart. One instance of Sneak into Basket is shown in Figure 3a, where adding a bouquet of flowers to the shopping cart on avasflowers.net also adds a greeting card. In another instance on laptopoutlet.co.uk —not shown in the figure— adding an electronic product, such as a laptop, to the shopping cart also adds product insurance. Other websites, such as cellularoutfitter.com , add additional products (e.g., a USB charger) to the shopping cart using pre-selected checkboxes. While such checkboxes could be deselected by a vigilant user, the additional products would be added by default in the absence of any intervention. In our data set, we found a total of 7 instances of the Sneak into Basket dark pattern. Using our taxonomy of dark pattern characteristics, we classify Sneak into Basket as at least partially deceptive (it incorrectly represents the nature of the action of adding an item to the shopping cart) and information hiding (it deliberately disguises how the additional products were added to cart from users) in nature. However, it is not covert : users can visibly see and realize that the website included additional products to their shopping carts. Hidden Costs . The ‘Hidden Costs’ dark pattern reveals new, additional, and often unusually high charges to users just before they are about to complete a purchase. Examples of such charges include ‘service fees’ or ‘handling costs’. Often these charges are only revealed at the end of a checkout process, after the user has already filled out shipping/billing information, and consented to terms of use. The Hidden Costs dark pattern exploits the sunk cost fallacy cognitive bias: users are likely to feel so invested in the process that they justify the additional charges by completing the purchase to not waste their effort. Figure 3b shows the Hidden Costs dark pattern on proflowers.com , where the ‘Care & Handling’ charge of $2.99 is revealed immediately before confirming the order. In our data set, we found a total of 5 instances of the Hidden Costs dark pattern. Using our taxonomy of dark pattern characteristics, we classify Hidden Costs as at least partially deceptive (it relies on minimizing and delaying information from users), and thus also information hiding in nature. Like Sneak into Basket, Hidden Costs is not covert : users can visibly see and realize that the website included additional charges. Hidden Subscription . The ‘Hidden Subscription’ dark pattern charges users a recurring fee under the pretense of a one-time fee or a free trial. Often, if at all, users become aware of the Proc. ACM Hum.-Comput. Interact., Vol. 3, No. CSCW, Article 81. Publication date: November 2019. \\n81:14 Arunesh Mathur et al. (a) Sneak into Basket on avasflowers.net . Despite requesting no greeting cards, one worth $3.99 is automati- cally added. (b) Hidden Costs on proflowers .com . The Care & Handling charge ($2.99) is disclosed on the last step. (c) Hidden Subscription on wsjwine.com . Left: The website fails to disclose that the Advantage service is an annual subscription worth $89 unless the user clicks on Learn More . Right: The service in cart. Fig. 3. Three types of the Sneaking category of dark patterns. recurring fee once they are charged several days or months after their purchase. For instance, we discovered that wsjwine.com offers users an Advantage service which appears to be a one-time payment of $89 but renews annually, as shown in Figure 3c. Further, Hidden Subscription often appears with the ‘Hard to Cancel’ dark pattern—which we describe in Section 5.1.6—thereby making the recurring charges harder to cancel than signing up for them. In our data set, we found a total of 14 instances of Hidden Subscription dark pattern. Using our taxonomy of dark pattern characteristics, we classify Hidden Subscription as at least partially deceptive (it misleads users about the nature of the initial offer) and information hiding (it withholds information about the recurring fees from users) in nature. 5.1.2 Urgency. ‘Urgency’ refers to the category of dark patterns that impose a deadline on a sale or deal, thereby accelerating user decision-making and purchases [ 27 , 37 , 53 , 69 ]. Urgency dark patterns exploit the scarcity bias in users—making discounts and offers more desirable than they would otherwise be, and signaling that inaction would result in losing out on potential savings. These dark patterns create a potent ‘fear of missing out’ effect particularly when combined with the Social Proof (Section 5.1.4) and Scarcity (Section 5.1.5) dark patterns. We observed two types of the Urgency dark pattern: Countdown Timers and Limited-time Messages on 437 shopping websites across their product, cart, and checkout pages. In product pages, these indicated deadlines about site-wide sales and coupons, sales on specific products, or shipping deadlines; in cart pages, they indicated deadlines about product reservation (e.g., ‘Your cart will expire in 10:00 minutes, please check out now’) and coupons, urging users to complete their purchase. Figure 4 highlights instances of these two types. Proc. ACM Hum.-Comput. Interact., Vol. 3, No. CSCW, Article 81. Publication date: November 2019. \\nDark Patterns at Scale 81:15 (a) Countdown Timer on mattressfirm.com . The header displays a Flash Sale where the majority of discounted products remain the same on a day-to-day basis. (b) Countdown Timer on justfab.com . The offer is available even after the timer expires. (c) Limited-time Message on chicwish.com . The website claims the sale will end ‘soon’ without stating a deadline. Fig. 4. Two types of the Urgency category of dark patterns. Countdown Timers . The ‘Countdown Timer’ dark pattern is a dynamic indicator of a deadline, counting down until the deadline expires. Figures 4a and 4b show the Countdown Timer dark pattern on mattressfirm.com and justfab.com , respectively. One indicates the deadline for a recurring Flash Sale , the other a Member Exclusive . In our data set, we found a total of 393 instances of the Countdown Timer dark pattern. Deceptive Countdown Timers. Using the visit-and-record method described in Section 4.4, we examined the countdown timers in our data set for deceptive practices. We stitched the screenshots of each countdown timer from the repeated visits of our crawler to a website into a video, and viewed the resulting videos to observe the behavior of the timers. We considered a countdown timer deceptive if (1) the timer reset after timeout with the same offer still valid, or (2) the timer expired but the offer it claimed was expiring was still valid even following expiration. In our data set, we discovered a total of 157 instances of deceptive Countdown Timers on 140 shopping websites. One such example is shown in Figure 4b on justfab.com , where the advertised offer remains valid even after the countdown timer of 60 minutes expires. Using our taxonomy of dark pattern characteristics, we classify Countdown Timers as partially covert (it creates a heightened sense of immediacy, unbeknownst to at least some users), and sometimes deceptive (it can mislead users into believing an offer is expiring when in reality it is not) in nature. Limited-time Messages . Unlike Countdown Timers, the ‘Limited-time Message’ dark pattern is a static urgency message without an accompanying deadline. By not stating the deadline, websites withhold information from users, and thus misrepresent the nature of the offer [ 20 ]. Figure 4c shows an instance of the Limited-time Message dark pattern on chicwish.com , where the advertised sale is stated to end ‘soon’ with no mention of the end date. For every such instance we discovered, we verified that the shopping website made no disclosure about the accompanying deadline (e.g., in Proc. ACM Hum.-Comput. Interact., Vol. 3, No. CSCW, Article 81. Publication date: November 2019. \\n81:16 Arunesh Mathur et al. (a) Confirmshaming on radioshack.com . The option to dismiss the popup is framed to shame the user into avoiding it. (b) Visual Interference on greenfingers.com . The option to opt out of marketing communication is grayed, making it seem un- available even though it can be clicked. (c) Trick Questions on newbalance.co.uk . Opting out of marketing communication requires ticking the checkbox. (d) Pressured Selling on 1800flowers.com . The most expensive product is the default. Fig. 5. Four types of the Misdirection category of dark patterns. the fine print and in the terms of sale pages). In our data set, we discovered a total of 88 instances of the Limited-time Message dark pattern. Using our taxonomy of dark pattern characteristics, we classify Limited-time Messages as at least partially covert (similar to Countdown Timers), and information hiding (unlike Countdown Timers, they do not reveal the deadline in their offers) in nature. 5.1.3 Misdirection. The ‘Misdirection’ category of dark patterns uses visuals, language, and emo- tion to steer users toward or away from making a particular choice. Misdirection functions by exploiting different affective mechanisms and cognitive biases in users without actually restricting the set of choices available to users. Our version of the Misdirection dark pattern is inspired by Brignull’s original Misdirection dark pattern [ 32 ]. However, while Brignull considered Misdirection to occur exclusively using stylistic and visual manipulation, we take a broader view of the term, also including Misdirection caused by language and emotional manipulation. We observed four types of the Misdirection dark pattern: Confirmshaming [ 32 ], Trick Ques- tions [ 32 ], Visual Interference [ 48 ], and Pressured Selling on 244 shopping websites. Figure 5 highlights instances of these four types. Confirmshaming . Coined by Brignull [ 32 ], the ‘Confirmshaming’ dark pattern uses language and emotion to steer users away from making a certain choice. Confirmshaming appeared most often in popup dialogs that solicited users’ email addresses in exchange for a discount, where the option to decline the offer—which the website did not want users to select—was framed as a shameful choice. Examples of such framing included ‘No thanks, I like paying full price’, ‘No thanks, I hate saving money’, and ‘No thanks, I hate fun & games’. By framing the negative option as such, the Confirmshaming dark pattern exploits the framing effect cognitive bias in users and shame, a powerful behavior change agent [ 58 ]. Figure 5a shows one instance of the Confirmshaming dark pattern on radioshack.com . In our data set, we found a total of 169 such instances. Proc. ACM Hum.-Comput. Interact., Vol. 3, No. CSCW, Article 81. Publication date: November 2019. \\nDark Patterns at Scale 81:17 Using our taxonomy of dark pattern characteristics, we classify Confirmshaming as asymmetric (the opt-out choice shames users into avoiding it) in nature. However, Confirmshaming is not covert , since users can visibly see and realize that the design is attempting to influence their choice. Visual Interference . The ‘Visual Interference’ dark pattern uses style and visual presentation to influence users into making certain choices over others (Brignull’s original description of Misdirection [ 32 ]). Although we excluded style information in our clustering analysis, we extracted these patterns as a consequence of examining the text the patterns displayed. In some instances, websites used the Visual Interference dark pattern to make certain courses of action more prominent over others. For example, the subscription offering on exposedskincare.com is stylistically more prominent and emphasized than the non-subscription offering. In other instances, websites used visual effects on textual descriptions to inflate the discounts available for products. For example, websites such as dyson.co.uk and justfab.com offered free gifts to users, and then used these gifts to inflate the savings on users’ purchases in the checkout page—even when the originally selected product was not on discount. In one instance on greenfingers.com , we discovered that the option to decline marketing communication is greyed out, creating an illusion that the option is unavailable or disabled even though it can be clicked, as shown in Figure 5b. In our data set, we found a total of 25 instances of the Visual Interference dark pattern. Using our taxonomy of dark pattern characteristics, we classify Visual Interference as sometimes asymmetric (in some instances it creates unequal choices, steering users into one choice over the other), covert (users may not realize the effect the visual presentation has had on their choice), and sometimes deceptive (e.g., when a website presents users with a ‘lucky draw’ from a list of potential deals, but the draw process is deterministic unbeknownst to users) in nature. Trick Questions . Also originating from Brignull’s taxonomy [ 32 ], the ‘Trick Questions’ dark pattern uses confusing language to steer users into making certain choices. Like Confirmshaming, Trick Questions attempt to overcome users’ propensity to opt out of marketing and promotional messages by subtly inverting the entire opt-out process. Most often, websites achieved this effect by introducing confusing double negatives (e.g., ‘Uncheck the box if you prefer not to receive email updates’), or by using negatives to alter expected courses of action, such as checking a box to opt out (e.g., ‘We would like to send you emails. If you do not wish to be contacted via email, please ensure that the box is not checked’). We note here that we only considered an opt-out choice as a Trick Question dark pattern when it was misleading, such as when the user has to check a box and the text began with an affirmative statement about the undesirable practice (e.g., ‘We want to send you marketing email...’) since these would more likely be missed by users as opposed to ones that began with the opt-out choice (e.g., ‘Please tick here to opt-out of...’). 9 Trick Questions exploits the default and framing effect cognitive biases in users, who become more susceptible to a choice they erroneously believe is aligned with their preferences. Figure 5c shows one instance of Trick Questions on newbalance.co.uk . In our data set, we found a total of 9 such instances, occurring most often during the checkout process when collecting user information to complete purchases. Using our taxonomy of dark pattern characteristics, we classify Trick Questions as asymmetric (opting out is more burdensome than opting in) and covert (users fail to understand the effect of their choice as a consequence of the confusing language) in nature. 9 We note that while Gray et al. [ 48 ] consider the latter as Trick Questions, we do not take that stance. However, we do consider all opt-out messages as concerning. We discovered 23 instances of opt-out choices that did not begin with an affirmative statement in total. Proc. ACM Hum.-Comput. Interact., Vol. 3, No. CSCW, Article 81. Publication date: November 2019. \\n81:18 Arunesh Mathur et al. Pressured Selling . The ‘Pressured Selling’ dark pattern refers to defaults or often high-pressure tactics that steer users into purchasing a more expensive version of a product ( upselling ) or into purchasing related products ( cross-selling ). The Pressured Selling dark pattern exploits a variety of different cognitive biases, such as the default effect, the anchoring effect, and the scarcity bias to drive user purchasing behavior. Figure 5d shows one such instance on 1800flowers.com , where the largest flower bouquet is selected by default. The dark pattern makes the most expensive option the point of comparison—an ‘anchor’—and thus increases the probability of users overlooking the least expensive option [ 70 ]. In another instance, on fashionworld.co.uk , the website opened popup dialogs that the user had to explicitly decline immediately after adding a product to cart. These dialogs urged users to buy more ‘Hot sellers’, ‘Deals’, and ‘Bundled’ products. In our data set, we found a total of 67 instances of the Pressured Selling dark pattern. Using our taxonomy of dark pattern characteristics, we classify Pressured Selling as sometimes asymmetric (it pushes users towards accepting more expensive product options) and at least partially covert (users fail to realize that they have purchased a more expensive product than they would have, had they been defaulted with the least expensive product to begin with) in nature. 5.1.4 Social Proof. According to the social proof principle, individuals determine the correct action and behavior for themselves in a given situation by examining the action and behavior of others [ 37 , 69 ]. The ‘Social Proof’ dark pattern uses this influence to accelerate user decision-making and purchases, exploiting the bandwagon effect cognitive bias to its advantage. Studies have shown that individuals are more likely to impulse buy when shopping with their peers and families [61]. We observed two types of the Social Proof dark pattern: Activity Notifications and Testimonials of Uncertain Origin on 275 websites across their product and cart pages. In all these instances, the Social Proof messages indicated other users’ activities and experiences shopping for products and items. Figure 6 highlights instances of these two types. Activity Notifications . The ‘Activity Notification’ dark pattern is a transient, often recurring and attention grabbing message that appears on product pages indicating the activity of other users. These can be grouped into different categories: dynamic and periodic messages that indicated other users just bought a product (e.g., ‘Abigail from Michigan just bought a new stereo system’); static or dynamic text to indicate how many users have a specific item in their cart (e.g., ‘35 people added this item to cart’); and similar text to indicate how many users have viewed a product (e.g., ‘90 people have viewed this product’). Figures 6a, 6b, and 6c highlight three instances of Activity Notification on tkmaxx.com , thredup.com , and jcpenney.com , respectively. In our data set, we found a total of 313 such instances. Deceptive Activity Notifications. We examined the Activity Notification messages in our data set for deceptive practices. To facilitate our analysis, we manually inspected the page source of each shopping website that displayed these notifications to verify their integrity. We ignored all those notifications that were generated server-side since we had limited insight into how and whether they were truly deceptive. We considered an instance of Activity Notification to be deceptive if the content it displayed—including any names, locations statistics, counts—was falsely generated or made misleading statements. In our data set, we discovered a total of 29 instances of deceptive Activity Notifications on 20 shopping websites. The majority of these websites generated their deceptive notifications in a random fashion (e.g., using a random number generator to indicate the number of users who are ‘currently viewing’ a product) and others hard-coded previously generated notifications, meaning they never changed. One notable case was thredup.com as shown in Figure 6b, where the website Proc. ACM Hum.-Comput. Interact., Vol. 3, No. CSCW, Article 81. Publication date: November 2019. \\nDark Patterns at Scale 81:19 (a) Activity Notification on tkmaxx.com . The message indi- cates how many people added the product to the cart in the last 72 hours. (b) Activity Notification on thredup.com . The message always signals products as if they were sold recently (‘just saved’), even in the case of old purchases. (c) Activity Notification on jcpenney.com . The message indicates the number of people who viewed the product in the 24 hours along with the quantity left in stock. (d) Testimonials of Uncertain Origin on coolhockey.com . We found the same tes- timonials on ealerjerseys.com with dif- ferent customer names. Fig. 6. Two types of the Social Proof category of dark patterns. generated messages based on fictitious names and locations for an unvarying list of products that was always indicated to be ‘just sold’. Using our taxonomy of dark pattern characteristics, we classify Activity Notifications as partially covert (in instances where the notifications are site-wide for example, users may fail to understand their effect on their choices) and sometimes deceptive (the content of notifications can be deceptively generated or misleading) in nature. Testimonials of Uncertain Origin . The ‘Testimonials of Uncertain Origin’ dark pattern refers to the use of customer testimonials whose origin or how they were sourced and created is not clearly specified. For each instance of this dark pattern, we made two attempts to validate its origin. First, we inspected the website to check if it contained a form to submit testimonials. Second, we performed exact searches of the testimonials on a search engine ( google.com ) to check if they appeared on other websites. Figure 6d shows one instance on coolhockey.com , where we found the same set of testimonials on ealerjerseys.com with different customer names attached to them. In our data set, we found a total of 12 instances of this pattern. 5.1.5 Scarcity. ‘Scarcity’ refers to the category of dark patterns that signal the limited availability or high demand of a product, thus increasing its perceived value and desirability [ 37 , 55 , 62 , 69 ]. We observed two types of the Scarcity dark pattern: ‘Low-stock Messages’ and ‘High-demand Messages’ on 609 shopping websites across their product and cart pages. In both pages, they indicated the limited availability of a product or that a product was in high demand and thus likely to become unavailable soon. Figure 7 highlights instances of these two types. Proc. ACM Hum.-Comput. Interact., Vol. 3, No. CSCW, Article 81. Publication date: November 2019. \\n81:20 Arunesh Mathur et al. (a) Low-stock Message on 6pm.com . Left: Choosing product options shows Only 3 left in stock . Right: The out-of-stock product makes it seem that it just sold out. (b) Low-stock on orthofeet .com . Appears for all products. (c) High-demand Message on fashionnova.com . The message appears for all products in the cart. Fig. 7. Two types of the Scarcity category of dark patterns. Low-stock Messages . The ‘Low-stock Message’ dark pattern signals to users about limited quantities of a product. Figure 7a shows an instance of this pattern on 6pm.com , displaying the precise quantity in stock. In our data set, we found a total of 632 instances of the Low-stock Message dark pattern. However, not all of these instances displayed stock quantities. 49 of these instances only indicated that stock was limited or low, without displaying the exact quantity, resulting in uncertainty, increased desirability of products, and impulse buying behavior in users. Figure 7b shows one such instance on orthofeet.com . Deceptive Low-stock Messages. We examined all the Low-stock Message dark patterns for de- ceptive practices using the method described in Section 4.4. From the resulting data, we ignored those websites whose stock amounts remained the same between visits, reasoning that those are unlikely to be indicative of deceptive practices. We then manually examined the remaining sites and identified how the stock information was generated. In our data set, we discovered a total of 17 instances of deceptive Low-stock Messages on 17 shopping websites. On further examination, we observed that 16 of these sites decremented stock amounts in a recurring, deterministic pattern according to a schedule, and the one remaining site ( forwardrevive.com ) randomly generated stock values on page load. Exactly 8 of these sites used third-party JavaScript libraries to generate the stock values, such as Hurrify [ 17 ] and Booster [ 11 ]. Both of these are popular plugins for Shopify—one of the largest e-Commerce companies—based websites. The remaining websites injected stock amounts through first-party JavaScript or HTML. Besides the use—or non-use—of numeric data and deception, Low-stock Messages can be con- cerning in other ways. For example, we observed that several websites, such as 6pm.com and orthofeet.com , displayed Low-stock Messages for nearly all their products—stating ‘Only X left’ and ‘Hurry, limited quantities left!’ respectively. The former, in particular, showed a ‘Sorry, this is out of stock. You just missed it’ popup dialog for every product that was sold out, even if it had already been out of stock in the previous days. Proc. ACM Hum.-Comput. Interact., Vol. 3, No. CSCW, Article 81. Publication date: November 2019. \\nDark Patterns at Scale 81:21 (a) Hard to Cancel on sportsmanguide.com . The website only discloses in the terms PDF file that canceling the recurring service requires calling customer service. (b) Hard to Cancel on savagex.com . The website discloses upfront that the recurring service can only be canceled through customer care. Fig. 8. The Hard to Cancel type from the Obstruction category of dark patterns. Using our taxonomy of dark pattern characteristics, we classify Low-stock Messages as partially covert (it creates a heightened sense of impulse buying, unbeknownst to users), sometimes deceptive (it can mislead users into believing a product is low on stock when in reality it is not, creating false scarcity), and sometimes information hiding (in some instances, it does not explicitly specify the stock quantities at hand) in nature. High-demand Messages . The ‘High-demand Message’ dark pattern signals to users that a product is in high demand, implying that it is likely to sell out soon. Figure 7c shows one such instance on fashionnova.com on the cart page, indicating that the products in the cart are selling out quickly. In our data set, we found a total of 47 instances of the High-demand dark pattern; 38 of these instances appeared consistently, regardless of the product displayed on the website, or regardless of the items in cart. As with Low-stock Messages, we classify High-demand Messages as partially covert . 5.1.6 Obstruction. ‘Obstruction’, coined by Gray et al. [ 48 ], refers to the category of dark patterns that make a certain action harder than it should be in order to dissuade users from taking that action. We observed one type of the Obstruction dark pattern: ‘Hard to Cancel’—a pattern similar to Brignull’s Roach Motel dark pattern [ 32 ]—on 31 websites. Obstruction makes it easy for users to sign up for recurring subscriptions and memberships, but it makes it hard for them to subsequently cancel the subscriptions. More often than not, shopping websites did not disclose upfront to users that canceling the subscription or membership could not be completed in the same manner they signed up for the memberships in the first place. For example, as shown in Figure 8a, sportsmansguide.com pro- motes a ‘buyer’s club’ discount membership price and makes it easy for users to sign up for the annual recurring membership, as they are under the impression they can ‘cancel anytime.’ However, sportsmansguide.com ’s terms of service reveal that the membership can only be cancelled by call- ing their customer service. In rare instances, as shown in Figure 8b, websites such as savagex.com disclosed upfront that cancellation required calling customer service. Using our taxonomy of dark pattern characteristics, we classify Hard to Cancel as restrictive (it limits the choices users can exercise to cancel their services) in nature. In cases where websites do Proc. ACM Hum.-Comput. Interact., Vol. 3, No. CSCW, Article 81. Publication date: November 2019. \\n81:22 Arunesh Mathur et al. (a) Forced Enrollment on musiciansfriend.com . Agreeing to the terms of use also requires agreeing to receive emails and promotions. (b) Forced Enrollment on therealreal.com . Browsing the website requires creating an account even without making a purchase. Fig. 9. The Forced Enrollment type from the Forced Action category of dark patterns. not disclose their cancellation policies upfront, Hard to Cancel also becomes information hiding (it fails to inform users about how cancellation is harder than signing up) in nature. 5.1.7 Forced Action. ‘Forced Action’ refers to the category of dark patterns—originally proposed by Gray et al. [ 48 ]—that require users to take certain additional and tangential actions to complete their tasks. We observed one type of the Forced Action dark pattern, ‘Forced Enrollment’, on 6 websites. This type of dark pattern explicitly coerces users into signing up for marketing communication, or creates accounts to surrender users’ information. By using the Forced Enrollment dark pattern, online services and websites collected more information about their users than they might otherwise consent to—resulting from an all-or-nothing proposition. On four out of six websites, the Forced Enrollment dark pattern manifested as a checkbox in the user interface, requiring users to simultaneously consent to the terms of service and to receiving marketing emails as part of the consent process. Figure 9a shows one such instance on musiciansfriend.com . In another instance of the Forced Enrollment on therealreal.com —as shown in Figure 9b—the website displayed a popup dialog that prevented users from viewing product offerings on the website without creating an account—even if users eventually decide against making a purchase. Using our taxonomy of dark pattern characteristics, we classify Forced Enrollment as asymmetric (it requires competing the additional, tangential tasks, creating unequal choices) and restrictive (it mandates enrolling in marketing communication or creating accounts) in nature. 5.2 Dark Patterns as A Third-Party Service: A Case Study Of Social Proof Activity Notifications In many instances, third-party entities—i.e., organizations and companies other than the shopping websites themselves—were responsible for creating and presenting dark patterns on behalf of the shopping websites. We observed this frequently to be the case for one dark pattern in particular: Social Proof Activity Notifications (Section 5.1.4). In this section, we shed light on the ecosystem of third parties that enable Social Proof Activity Notifications, using our starting point as the list of websites in our data set that displayed such Activity Notifications. 5.2.1 Detecting Third-party Entities. In order to detect third-party entities, it is sufficient to uncover scripts that are served from third-party domains and are responsible for creating Social Proof Proc. ACM Hum.-Comput. Interact., Vol. 3, No. CSCW, Article 81. Publication date: November 2019. \\nDark Patterns at Scale 81:23 Activity Notifications. However, automatically attributing certain interface elements and webpage modifications to third-party scripts constitutes a more challenging task because modern browsers do not expose any means to attribute DOM changes (e.g. displaying a popup dialog) to particular scripts. Further, web pages may be modified by several different first and third-party scripts in the same visit, making attribution trickier. To overcome this challenge, we employed a combination of automated and manual analyses. We used the following observation: when a third-party entity displays an Activity Notification on a shopping website, its content should be included in the HTTP response received from this third party’s servers on that website. For example, if the notification states ‘Jane from Washington, DC just purchased this product’, looking up the customer name and location—in this case ‘Jane’ and ‘Washington, DC’—in the HAR file for that website should reveal the end point of the server that issued the notification. Thus, for all notifications of this kind, we extracted the name and location pairs from the content, searched the HAR files for these pairs; where successful, we recorded the HTTP endpoints corresponding to the third-parties. We then manually verified these endpoints and determined the responsible entities by using the WHOIS database, visiting the script domains and using search engines to uncover the company identities and websites. Where this analysis failed to return an HTTP endpoint from the HAR files, and for all other kinds of Social Proof Activity Notification (e.g., ‘This product was added to cart 10 times in the last day’), we manually visited the websites containing the message to determine the responsible third parties. We sped up this analysis using Google Chrome Developer Tool’s ‘DOM change breakpoints’ feature [16], which helped us easily determine the responsible entities. Having determined the third-party entities, we measured their prevalence across all the shopping websites in our data set. To do so, we searched the HTTP request data from checkout crawls for the third-party domains we identified. Finally, as a reference point, we also determined their prevalence on the web—beyond shopping websites—using the latest publicly available crawl data (November 2018) from the Princeton Web Census Project [ 7 , 40 ]. This public project documents the prevalence of third-party scripts using periodic scans of home pages of Alexa top million sites and is available for external researchers to use. 5.2.2 The Ecosystem Of Third-party Entities. Table 2 summarizes our findings. We discovered a total of 22 third-party entities, embedded in 1,066 of the 11K shopping websites in our data set, and in 7,769 of the Alexa top million websites. We note that the prevalence figures from the Princeton Web Census Project data should be taken as a lower bound since their crawls are limited to home pages of websites. This difference in prevalence is particularly visible for certain third-party entities like Qubit and Taggstar, where their prevalence is higher in our data set compared to the Web Census data. By manually examining websites that contained these third parties, we discovered that many shopping websites only embedded them in their product—and not home—pages, presumably for functionality and performance reasons. We learned that many third-party entities offered a variety of services for shopping websites, including plugins for popular e-commerce platforms such as Shopify 10 and Woocommerce 11 . To better understand the nature and capabilities of each third-party entity, we examined any publicly available marketing materials on their websites. Broadly, we could classify the third-party entities into two groups. The first group exclusively provided Social Proof Activity Notifications integration as a service. The second group provided a wider array of marketing services that often enabled other types of dark patterns; most commonly 10 https://shopify.com 11 https://woocommerce.com Proc. ACM Hum.-Comput. Interact., Vol. 3, No. CSCW, Article 81. Publication date: November 2019. \\n81:24 Arunesh Mathur et al. Table 2. List and prevalence of Social Proof Activity Notifications enabling third-party entities in our data set of 11K shopping websites and the home pages of Alexa top million websites [ 7 ]. Where available, we list additional dark patterns the third parties claim to offer. Nice/Bizzy, Woocommerce Notification, Boost, and Amasty are Shopify, Woocommerce, Wordpress and Magento plugins respectively. Third-party Entity Prevalence Additional Dark Patterns # Shopping Websites # Alexa Top Million Beeketing 406 4,151 Pressured Selling, Urgency, Scarcity Dynamic Yield 114 416 Urgency Yieldify 111 323 Urgency, Scarcity Fomo 91 663 – Fresh Relevance 86 208 Urgency Insider 52 484 Scarcity, Urgency Bizzy 33 213 – ConvertCart 31 62 – Taggstar 27 4 Scarcity, Urgency Qubit 25 73 Pressured Selling, Scarcity, Urgency Exponea 18 180 Urgency, Scarcity Recently 14 66 – Proof 11 508 – Fera 11 132 Pressured Selling, Scarcity, Urgency Nice 10 80 – Woocommerce Notification 10 61 – Bunting 5 17 Urgency, Scarcity Credibly 4 67 – Convertize 3 58 Scarcity, Urgency LeanConvert 2 0 – Boost 1 3 – Amasty 1 0 Pressured Selling, Scarcity, Urgency these were Scarcity and Urgency dark patterns. We list all these additional dark pattern capabilities in the rightmost column of Table 2. Many of the third-parties advertised practices that appeared to be—and sometimes unambiguously were—manipulative: ‘[p]lay upon [customers’] fear of missing out by showing shoppers which products are creating a buzz on your website’ (Fresh Relevance), ‘[c]reate a sense of urgency to boost conversions and speed up sales cycles with Price Alert Web Push’ (Insider), ‘[t]ake advantage of impulse purchases or encourage visitors over shipping thresholds’ (Qubit). Further, Qubit also advertised Social Proof Activity Notifications that could be tailored to users’ preferences and backgrounds. In some instances, we found that third parties openly advertised the deceptive capabilities of their products. For example, Boost dedicated a web page—titled ‘Fake it till you make it’—to describing how it could help create fake orders [ 12 ]. Woocommerce Notification—a Woocommerce platform plugin—also advertised that it could create fake social proof messages: ‘[t]he plugin will create fake orders of the selected products’ [ 24 ]. Interestingly, certain third parties (Fomo, Proof, and Boost) used Activity Notifications on their websites to promote their own products. Finally, we also discovered that some of these deceptive practices resulted in e-commerce plat- forms taking action against third-party entities. For instance, Beeketing’s—the most popular third Proc. ACM Hum.-Comput. Interact., Vol. 3, No. CSCW, Article 81. Publication date: November 2019. \\nDark Patterns at Scale 81:25 This is an instance of Dark Pattern called ‘Countdown Timer’. The timer might be fake. Click to learn more. Fig. 10. Mockup of a possible browser extension that can be developed using our data set. The extension flags instances of dark patterns with a red warning icon. By hovering over the icon, the user can learn more about the specific pattern. party provider in our data set—‘Sales Pop’ Shopify plugin was temporarily removed from Shopify in an effort to crack down on deceptive practices [ 67 , 76 ]. The plugin had allowed websites to create fake Activity Notifications by entering fabricated sales data. In summary, we discovered that third party entities widely enable dark patterns on shopping websites. Furthermore, some of these third-parties even advertised the deceptive use of their services. 6 DISCUSSION 6.1 Dark Patterns and Implications For Consumers Many dark patterns constitute manipulative and deceptive practices that past work has shown users are increasingly becoming aware of [ 36 ]. Our current data set of dark patterns, comprising of screenshots and text segments, can be used to build countermeasures to help users make more informed decisions even in the presence of dark patterns. One such countermeasure could be a public-facing website that scores shopping websites based on their use of dark patterns. Our data set can also enable the development of browser extensions that automatically detect and flag dark patterns (e.g., shopping websites, as shown in Figure 10). Such a tool could be augmented to flag dark patterns on websites not in our data set through users’ submissions, through community- generated and maintained lists (similar to how ad blockers work [ 26 ]), or through trained machine learning classifiers. Eventually, such tools could be integrated into browsers themselves. For example, in recent years, Firefox and Safari have shown interest in integrating tools that promote consumer privacy (e.g., features to block web tracking by default [ 66 , 82 ]). However, finding the right incentives for browser vendors to implement these solutions might be challenging in the context of dark patterns, since they might be wary of policing content on the web. Finally, future studies could leverage our descriptive and comparative taxonomy of dark pattern characteristics to better understand their effects on users, as well as to ascertain which dark patterns are considered most egregious by users (e.g., by means of users studies). 6.2 Implications for Consumer Protection Policy and Retailers Our results demonstrate that a number of shopping websites use deceptive dark patterns, involving affirmative and false representations to consumers. We also found 22 different third-party entities that enable the creation of Social Proof Activity Notification dark patterns. Some of these entities promote blatantly deceptive practices and provide the infrastructure for retailers to use these Proc. ACM Hum.-Comput. Interact., Vol. 3, No. CSCW, Article 81. Publication date: November 2019. \\n81:26 Arunesh Mathur et al. practices to influence consumer behavior for profit. These practices are unambiguously unlawful in the United States (under Section 5 of the Federal Trade Commission Act and similar state laws [ 45 ]), and the European Union (under the Unfair Commercial Practices Directive and similar member state laws [42]). We also find practices that are unlawful in a smaller set of jurisdictions. In the European Union, businesses are bound by an array of affirmative disclosure and independent consent requirements in the Consumer Rights Directive [ 43 ]. Websites that use the Sneaking dark patterns (Sneak into Basket, Hidden Subscription, and Hidden Costs) on European Union consumers are likely in violation of the Directive. Furthermore, user consent obtained through Trick Questions and Visual Interference dark patterns do not constitute freely given, informed and active consent as required by the General Data Protection Regulation (GDPR) [ 44 ]. In fact, the Norwegian Consumer Council filed a GDPR complaint against Google in 2018, arguing that Google used dark patterns to manipulate users into turning on the ‘Location History’ feature on Android, and thus enabling constant location tracking [47]. In addition to demonstrating specific instances of unlawful business practices, we contribute a new approach for regulatory agencies and other consumer protection stakeholders (e.g., journalists and civil society groups) to detect dark patterns. The crawling and clustering methodology that we developed is readily generalizable, and it radically reduces the difficulty of discovering and measuring dark patterns at web scale. Furthermore, our data set of third-party entities which provide the infrastructure to enable certain deceptive dark patterns can be used by regulators as a starting point to inform policy and regulation around what kinds of practices should be allowable in the context online shopping. 6.3 Dark Patterns and Future Studies At Scale We created automated techniques that can be used to conduct measurements of dark patterns at web scale. Researchers can extend our tools and infrastructure to document the presence of dark patterns other types of websites (e.g., travel and ticket booking websites) by building a crawler that traverses users’ primary interaction paths on those websites. Researchers can also extend our techniques to measure dark patterns that are not inherently dark because of the text they display but because they take advantage of visual elements. For example, urgency can be created by a blinking timer; similarly, Hidden Subscriptions can make the default option (e.g., subscribing to a paid service) visually more appealing and noticeable than its alternative (e.g., not subscribing). One starting point to detect such interfaces could be to incorporate style and color as features for clustering, or even use the design mining literature [ 39 , 56 , 59 ] to analyze specific types of interfaces (e.g., page headers) in isolation. Finally, researchers can leverage our descriptive taxonomy of dark pattern characteristics to study and analyze dark patterns in other domains, such as emails and mobile applications. 6.4 Limitations Our research has several limitations. First, we only take into account text-based dark patterns and, therefore, leave out those that are inherently visual (e.g., using font size or color to emphasize one part of the text more than another). Second, many of the dark patterns we document are derived from the existing dark patterns literature. However, some of these are exist in a gray area, and in those cases determining whether a dark pattern is deliberately misleading or not can sometimes be hard to discern. Opinions of dark patterns may also vary between and among experts and users (e.g., countdown timers to indicate when to order to be eligible for free shipping). Clarifying this gray area and establishing the degree to which these patterns are perceived as manipulative by users can be further investigated by future user studies. Third, in Section 3 we drew connections between Proc. ACM Hum.-Comput. Interact., Vol. 3, No. CSCW, Article 81. Publication date: November 2019. \\nDark Patterns at Scale 81:27 each type of dark pattern and a set of cognitive biases it exploits. However, these connections may be more nuanced or complex. For example, not all individuals may be equally susceptible to these cognitive biases; some individuals may be more susceptible to one kind over another. Fourth, during our crawls we experienced a small number of Selenium crashes, which did not allow us to either retrieve product pages or complete data collection on certain websites. Fifth, while the crawler was mostly effective in simulating user actions, it failed to complete the product purchase flow on some websites (see Section 4). Sixth, and finally, we only crawled product pages and checkout pages, missing out on dark patterns commonly present in other pages, such as the home page, product search, and account creation pages. Many dark patterns also appear after purchase (e.g., upselling) which our crawler fails to capture because we do not make purchases. Future studies could consider collecting these kinds of dark patterns from users. 7 CONCLUSION In this paper, we developed automated techniques to study dark patterns on the web at scale. By simulating user actions on the ∼ 11K most popular shopping websites, we collected text and screenshots of these websites to identify their use of dark patterns. We defined and characterized these dark patterns, describing how they affect users’ decisions by linking our definitions to the cognitive biases leveraged by dark patterns. We found at least one instance of dark pattern on approximately 11.1% of the examined websites. Notably, 183 of the websites displayed deceptive messages. Furthermore, we observed that dark patterns are more likely to appear on popular websites. Finally, we discovered that dark patterns are often enabled by third-party entities, of which we identify 22; two of these advertise practices that enable deceptive patterns. Based on these findings, we suggest that future work focuses on empirically evaluating the effects of dark patterns on user behavior, developing countermeasures against dark patterns so that users have a fair and transparent experience, and extending our work to discover dark patterns in other domains. ACKNOWLEDGMENTS We are grateful to Mihir Kshirsagar, Finn Myrstad, Vincent Toubiana, and Joe Calandrino for feedback on this paper.'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open(r'processed_syllabi\\Human_computer_interaction\\scraped_data\\dark_patterns_at_scale_findings_from_a_crawl_of_11k_shopping_websites.json', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_html_soup(url):\n",
    "    \"\"\"Fetches HTML content and returns a BeautifulSoup object.\"\"\"\n",
    "    response = requests.get(url, headers={\"User-Agent\": \"Mozilla/5.0\"})\n",
    "    if response.status_code == 200:\n",
    "        return BeautifulSoup(response.text, \"html.parser\")\n",
    "    else:\n",
    "        print(f\"⚠️ Failed to fetch page: {url}\")\n",
    "        return None\n",
    "\n",
    "def extract_author(article, soup):\n",
    "    \"\"\"Attempts to extract the author using Newspaper3k first, then BeautifulSoup.\"\"\"\n",
    "    author = article.authors if article.authors else []\n",
    "    \n",
    "    # If Newspaper3k fails, try manual extraction with BeautifulSoup\n",
    "    if not author and soup:\n",
    "        author_tag = soup.find(\"meta\", attrs={\"name\": \"author\"})  # Many sites store author here\n",
    "        if author_tag:\n",
    "            author = [author_tag[\"content\"].strip()]\n",
    "        else:\n",
    "            author_div = soup.find(\"div\", class_=re.compile(r\"author\", re.IGNORECASE))\n",
    "            if author_div:\n",
    "                author = [author_div.text.strip()]\n",
    "\n",
    "    return author[0] if author else \"Unknown\"\n",
    "\n",
    "def extract_date(article, soup):\n",
    "    \"\"\"Attempts to extract the publication date using Newspaper3k first, then BeautifulSoup.\"\"\"\n",
    "    date_published = str(article.publish_date) if article.publish_date else \"Unknown\"\n",
    "\n",
    "    if date_published == \"Unknown\" and soup:\n",
    "        time_tag = soup.find(\"time\")  # Many sites use <time> tag\n",
    "        if time_tag:\n",
    "            date_published = time_tag.text.strip()\n",
    "        else:\n",
    "            date_meta = soup.find(\"meta\", attrs={\"property\": \"article:published_time\"})  # OpenGraph format\n",
    "            if date_meta:\n",
    "                date_published = date_meta[\"content\"]\n",
    "\n",
    "    return date_published if date_published != \"\" else \"Unknown\"\n",
    "\n",
    "def scrape_article(url):\n",
    "    \"\"\"Scrapes an online article, extracts metadata and text, and structures it in JSON format.\"\"\"\n",
    "\n",
    "    soup = get_html_soup(url)\n",
    "    article = Article(url)\n",
    "    article.download()\n",
    "    article.parse()\n",
    "\n",
    "    # Extract metadata\n",
    "    author = extract_author(article, soup)\n",
    "    date_published = extract_date(article, soup)\n",
    "\n",
    "    # Prepare data structure\n",
    "    data = {\n",
    "        \"document_type\": \"blog_post\",\n",
    "        \"title\": article.title if article.title else \"Untitled\",\n",
    "        \"author\": author,\n",
    "        \"source_url\": url,\n",
    "        \"date_published\": date_published,\n",
    "        \"sections\": []\n",
    "    }\n",
    "\n",
    "    # Extract subheadings & text sections\n",
    "    subheadings = soup.find_all([\"h2\", \"h3\"]) if soup else []\n",
    "    content = article.text.split(\"\\n\")  \n",
    "    section = {\"subheading\": \"Introduction\", \"text\": \"\"}\n",
    "\n",
    "    for paragraph in content:\n",
    "        if any(heading.text.strip() in paragraph for heading in subheadings):\n",
    "            data[\"sections\"].append(section)\n",
    "            section = {\"subheading\": paragraph.strip(), \"text\": \"\"}\n",
    "        else:\n",
    "            section[\"text\"] += paragraph.strip() + \" \"\n",
    "\n",
    "    data[\"sections\"].append(section)\n",
    "\n",
    "    print(data)\n",
    "    print(article.title)\n",
    "\n",
    "    return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'document_type': 'blog_post',\n",
       " 'title': 'Human Computer Interaction - brief intro',\n",
       " 'author': 'Unknown',\n",
       " 'source_url': 'https://www.interaction-design.org/literature/book/the-encyclopedia-of-human-computer-interaction-2nd-ed/human-computer-interaction-brief-intro',\n",
       " 'date_published': 'Unknown',\n",
       " 'sections': [{'subheading': 'Introduction',\n",
       "   'text': 'Human-computer interaction (HCI) is an area of research and practice that emerged in the early 1980s, initially as a specialty area in computer science embracing cognitive science and human factors engineering. HCI has expanded rapidly and steadily for three decades, attracting professionals from many other disciplines and incorporating diverse concepts and approaches. To a considerable extent, HCI now aggregates a collection of semi-autonomous fields of research and practice in human-centered informatics. However, the continuing synthesis of disparate conceptions and approaches to science and practice in HCI has produced a dramatic example of how different epistemologies and paradigms can be reconciled and integrated in a vibrant and productive intellectual project.  '},\n",
       "  {'subheading': '2.1 Where HCI came from',\n",
       "   'text': ' Until the late 1970s, the only humans who interacted with computers were information technology professionals and dedicated hobbyists. This changed disruptively with the emergence of personal computing in the later 1970s. Personal computing, including both personal software (productivity applications, such as text editors and spreadsheets, and interactive computer games) and personal computer platforms (operating systems, programming languages, and hardware), made everyone in the world a potential computer user, and vividly highlighted the deficiencies of computers with respect to usability for those who wanted to use computers as tools.  Author/Copyright holder: Steven Weyhrich. Copyright terms and licence: All Rights Reserved. Reproduced with permission. See section \"Exceptions\" in the copyright terms below.  Author/Copyright holder: Courtesy of Grubitzsch (geb. Raphael), Waltraud. Copyright terms and licence:CC-Att-SA-3 (Creative Commons Attribution-ShareAlike 3.0)  Figure 2.1 A-B: Personal computing rapidly pushed computer use into the general population, starting in the later 1970s. However, the non-professional computer user was often subjected to arcane commands and system dialogs.  The challenge of personal computing became manifest at an opportune time. The broad project of cognitive science, which incorporated cognitive psychology, artificial intelligence, linguistics, cognitive anthropology, and the philosophy of mind, had formed at the end of the 1970s. Part of the programme of cognitive science was to articulate systematic and scientifically informed applications to be known as \"cognitive engineering\". Thus, at just the point when personal computing presented the practical need for HCI, cognitive science presented people, concepts, skills, and a vision for addressing such needs through an ambitious synthesis of science and engineering. HCI was one of the first examples of cognitive engineering.  Author/Copyright holder: Card, Moran and Newell. Copyright terms and licence: All Rights Reserved. Reproduced with permission. See section \"Exceptions\" in the copyright terms below.  Figure 2.2: The Model Human Processor was an early cognitive engineering model intended to help developers apply principles from cognitive psychology.  This was facilitated by analogous developments in engineering and design areas adjacent to HCI, and in fact often overlapping HCI, notably human factors engineering and documentation development. Human factors had developed empirical and task-analytic techniques for evaluating human-system interactions in domains such as aviation and manufacturing, and was moving to address interactive system contexts in which human operators regularly exerted greater problem-solving discretion. Documentation development was moving beyond its traditional role of producing systematic technical descriptions toward a cognitive approach incorporating theories of writing, reading, and media, with empirical user testing. Documents and other information needed to be usable also.  Author/Copyright holder: MIT Press. Copyright terms and licence: All Rights Reserved. Reproduced with permission. See section \"Exceptions\" in the copyright terms below.  Figure 2.3: Minimalist information emphasized supporting goal-directed activity in a domain. Instead of topic hierarchies and structured practice, it emphasized succinct support for self-directed action and for recognizing and recovering from error.  Other historically fortuitous developments contributed to the establishment of HCI. Software engineering, mired in unmanageable software complexity in the 1970s (the “software crisis”), was starting to focus on nonfunctional requirements, including usability and maintainability, and on empirical software development processes that relied heavily on iterative prototyping and empirical testing. Computer graphics and information retrieval had emerged in the 1970s, and rapidly came to recognize that interactive systems were the key to progressing beyond early achievements. All these threads of development in computer science pointed to the same conclusion: The way forward for computing entailed understanding and better empowering users. These diverse forces of need and opportunity converged around 1980, focusing a huge burst of human energy, and creating a highly visible interdisciplinary project.  '},\n",
       "  {'subheading': '2.2 From cabal to community',\n",
       "   'text': ' The original and abiding technical focus of HCI was and is the concept of usability. This concept was originally articulated somewhat naively in the slogan \"easy to learn, easy to use\". The blunt simplicity of this conceptualization gave HCI an edgy and prominent identity in computing. It served to hold the field together, and to help it influence computer science and technology development more broadly and effectively. However, inside HCI the concept of usability has been re-articulated and reconstructed almost continually, and has become increasingly rich and intriguingly problematic. Usability now often subsumes qualities like fun, well being, collective efficacy, aesthetic tension, enhanced creativity, flow, support for human development, and others. A more dynamic view of usability is one of a programmatic objective that should and will continue to develop as our ability to reach further toward it improves.  Author/Copyright holder: ©. Copyright terms and licence: All Rights Reserved. Used without permission under the Fair Use Doctrine (as permission could not be obtained). See the \"Exceptions\" section (and subsection \"allRightsReserved-UsedWithoutPermission\") on the page copyright notice.  Figure 2.4: Usability is an emergent quality that reflects the grasp and the reach of HCI. Contemporary users want more from a system than merely “ease of use”.  Although the original academic home for HCI was computer science, and its original focus was on personal productivity applications, mainly text editing and spreadsheets, the field has constantly diversified and outgrown all boundaries. It quickly expanded to encompass visualization, information systems, collaborative systems, the system development process, and many areas of design. HCI is taught now in many departments/faculties that address information technology, including psychology, design, communication studies, cognitive science, information science, science and technology studies, geographical sciences, management information systems, and industrial, manufacturing, and systems engineering. HCI research and practice draws upon and integrates all of these perspectives.  A result of this growth is that HCI is now less singularly focused with respect to core concepts and methods, problem areas and assumptions about infrastructures, applications, and types of users. Indeed, it no longer makes sense to regard HCI as a specialty of computer science; HCI has grown to be broader, larger and much more diverse than computer science itself. HCI expanded from its initial focus on individual and generic user behavior to include social and organizational computing, accessibility for the elderly, the cognitively and physically impaired, and for all people, and for the widest possible spectrum of human experiences and activities. It expanded from desktop office applications to include games, learning and education, commerce, health and medical applications, emergency planning and response, and systems to support collaboration and community. It expanded from early graphical user interfaces to include myriad interaction techniques and devices, multi-modal interactions, tool support for model-based user interface specification, and a host of emerging ubiquitous, handheld and context-aware interactions.  There is no unified concept of an HCI professional. In the 1980s, the cognitive science side of HCI was sometimes contrasted with the software tools and user interface side of HCI. The landscape of core HCI concepts and skills is far more differentiated and complex now. HCI academic programs train many different types of professionals: user experience designers, interaction designers, user interface designers, application designers, usability engineers, user interface developers, application developers, technical communicators/online information designers, and more. And indeed, many of the sub-communities of HCI are themselves quite diverse. For example, ubiquitous computing (aka ubicomp) is subarea of HCI, but it is also a superordinate area integrating several distinguishable subareas, for example mobile computing, geo-spatial information systems, in-vehicle systems, community informatics, distributed systems, handhelds, wearable devices, ambient intelligence, sensor networks, and specialized views of usability evaluation, programming tools and techniques, and application infrastructures. The relationship between ubiquitous computing and HCI is paradigmatic: HCI is the name for a community of communities.  Author/Copyright holder: User Experience Professionals Association. Copyright terms and licence: All Rights Reserved. Reproduced with permission. See section \"Exceptions\" in the copyright terms below.      Author/Copyright holder: Envis Precisely. Copyright terms and licence: All Rights Reserved. Reproduced with permission. See section \"Exceptions\" in the copyright terms below.  Figure 2.5 A-B: Two visualizations of the variety of disciplinary knowledge and skills involved in contemporary design of human-computer interactions  Indeed, the principle that HCI is a community of communities is now a point of definition codified, for example, in the organization of major HCI conferences and journals. The integrating element across HCI communities continues to be a close linkage of critical analysis of usability, broadly understood, with development of novel technology and applications. This is the defining identity commitment of the HCI community. It has allowed HCI to successfully cultivate respect for the diversity of skills and concepts that underlie innovative technology development, and to regularly transcend disciplinary obstacles. In the early 1980s, HCI was a small and focused specialty area. It was a cabal trying to establish what was then a heretical view of computing. Today, HCI is a vast and multifaceted community, bound by the evolving concept of usability, and the integrating commitment to value human activity and experience as the primary driver in technology.  '},\n",
       "  {'subheading': '2.3 Beyond the desktop',\n",
       "   'text': ' Given the contemporary shape of HCI, it is important to remember that its origins are personal productivity interactions bound to the desktop, such as word processing and spreadsheets. Indeed, one of biggest design ideas of the early 1980s was the so-called messy desk metaphor, popularized by the Apple Macintosh: Files and folders were displayed as icons that could be, and were scattered around the display surface. The messy desktop was a perfect incubator for the developing paradigm of graphical user interfaces. Perhaps it wasn’t quite as easy to learn and easy to use as claimed, but people everywhere were soon double clicking, dragging windows and icons around their displays, and losing track of things on their desktop interfaces just as they did on their physical desktops. It was surely a stark contrast to the immediately prior teletype metaphor of Unix, in which all interactions were accomplished by typing commands.  Author/Copyright holder: Unknown (pending investigation). Copyright terms and licence: Unknown (pending investigation). See section \"Exceptions\" in the copyright terms below.  Figure 2.6: The early Macintosh desktop metaphor: Icons scattered on the desktop depict documents and functions, which can be selected and accessed (as System Disk in the example)  Even though it can definitely be argued that the desktop metaphor was superficial, or perhaps under-exploited as a design paradigm, it captured imaginations of designers and the public. These were new possibilities for many people in 1980, pundits speculated about how they might change office work. Indeed, the tsunami of desktop designs challenged, sometimes threatened the expertise and work practices of office workers. Today they are in the cultural background. Children learn these concepts and skills routinely.  As HCI developed, it moved beyond the desktop in three distinct senses. First, the desktop metaphor proved to be more limited than it first seemed. It’s fine to directly represent a couple dozen digital objects as icons, but this approach quickly leads to clutter, and is not very useful for people with thousands of personal files and folders. Through the mid-1990s, HCI professionals and everyone else realized that search is a more fundamental paradigm than browsing for finding things in a user interface. Ironically though, when early World Wide Web pages emerged in the mid-1990s, they not only dropped the messy desktop metaphor, but for the most part dropped graphical interactions entirely. And still they were seen as a breakthrough in usability (of course, the direct contrast was to Unix-style tools like ftp and telnet). The design approach of displaying and directly interacting with data objects as icons has not disappeared, but it is no longer a hegemonic design concept.  Author/Copyright holder: Unknown (pending investigation). Copyright terms and licence: Unknown (pending investigation). See section \"Exceptions\" in the copyright terms below.  Figure 2.7: The early popularity of messy desktops for personal information spaces does not scale.  The second sense in which HCI moved beyond the desktop was through the growing influence of the Internet on computing and on society. Starting in the mid-1980s, email emerged as one of the most important HCI applications, but ironically, email made computers and networks into communication channels; people were not interacting with computers, they were interacting with other people through computers. Tools and applications to support collaborative activity now include instant messaging, wikis, blogs, online forums, social networking, social bookmarking and tagging services, media spaces and other collaborative workspaces, recommender and collaborative filtering systems, and a wide variety of online groups and communities. New paradigms and mechanisms for collective activity have emerged including online auctions, reputation systems, soft sensors, and crowd sourcing. This area of HCI, now often called social computing, is one of the most rapidly developing.  Author/Copyright holder: ©. Copyright terms and licence: All Rights Reserved. Used without permission under the Fair Use Doctrine (as permission could not be obtained). See the \"Exceptions\" section (and subsection \"allRightsReserved-UsedWithoutPermission\") on the page copyright notice.  Author/Copyright holder: Courtesy of Larry Ewing. Copyright terms and licence: CC-Att-3 (Creative Commons Attribution 3.0 Unported).  Author/Copyright holder: GitHub Inc. Copyright terms and licence: All Rights Reserved. Used without permission under the Fair Use Doctrine (as permission could not be obtained). See the \"Exceptions\" section (and subsection \"allRightsReserved-UsedWithoutPermission\") on the page copyright notice.  Figure 2.8 A-B-C: A huge and expanding variety of social network services are part of everyday computing experiences for many people. Online communities, such as Linux communities and GitHub, employ social computing to produce high-quality knowledge work.  The third way that HCI moved beyond the desktop was through the continual, and occasionally explosive diversification in the ecology of computing devices. Before desktop applications were consolidated, new kinds of device contexts emerged, notably laptops, which began to appear in the early 1980s, and handhelds, which began to appear in the mid-1980s. One frontier today is ubiquitous computing: The pervasive incorporation of computing into human habitats — cars, home appliances, furniture, clothing, and so forth. Desktop computing is still very important, though the desktop habitat has been transformed by the wide use of laptops. To a considerable extent, the desktop itself has moved off the desktop.  Author/Copyright holder: Courtesy of Andrew Stern. Copyright terms and licence: CC-Att-SA-3 (Creative Commons Attribution-ShareAlike 3.0)  Author/Copyright holder: Courtesy of United States Federal Government. Copyright terms and licence: pd (Public Domain (information that is common property and contains no original authorship)).  Author/Copyright holder: Unknown (pending investigation). Copyright terms and licence: Unknown (pending investigation). See section \"Exceptions\" in the copyright terms below.  Figure 2.9 A-B-C: Computing moved off the desktop to be everywhere all the time. Computers are in phones, cars, meeting rooms, and coffee shops.  The focus of HCI has moved beyond the desktop, and its focus will continue to move. HCI is a technology area, and it is ineluctably driven to frontiers of technology and application possibility. The special value and contribution of HCI is that it will investigate, develop, and harness those new areas of possibility not merely as technologies or designs, but as means for enhancing human activity and experience.  '},\n",
       "  {'subheading': '2.4 The task-artifact cycle',\n",
       "   'text': ' The movement of HCI off the desktop is a large-scale example of a pattern of technology development that is replicated throughout HCI at many levels of analysis. HCI addresses the dynamic co-evolution of the activities people engage in and experience, and the artifacts — such as interactive tools and environments — that mediate those activities. HCI is about understanding and critically evaluating the interactive technologies people use and experience. But it is also about how those interactions evolve as people appropriate technologies, as their expectations, concepts and skills develop, and as they articulate new needs, new interests, and new visions and agendas for interactive technology.  Reciprocally, HCI is about understanding contemporary human practices and aspirations, including how those activities are embodied, elaborated, but also perhaps limited by current infrastructures and tools. HCI is about understanding practices and activity specifically as requirements and design possibilities envisioning and bringing into being new technology, new tools and environments. It is about exploring design spaces, and realizing new systems and devices through the co-evolution of activity and artifacts, the task-artifact cycle.  Author/Copyright holder: Courtesy of John M. Carroll. Copyright terms and licence: CC-Att-SA-3 (Creative Commons Attribution-ShareAlike 3.0)  Figure 2.10: Human activities implicitly articulate needs, preferences and design visions. Artifacts are designed in response, but inevitably do more than merely respond. Through the course of their adoption and appropriation, new designs provide new possibilities for action and interaction. Ultimately, this activity articulates further human needs, preferences, and design visions.  Understanding HCI as inscribed in a co-evolution of activity and technological artifacts is useful. Most simply, it reminds us what HCI is like, that all of the infrastructure of HCI, including its concepts, methods, focal problems, and stirring successes will always be in flux. Moreover, because the co-evolution of activity and artifacts is shaped by a cascade of contingent initiatives across a diverse collection of actors, there is no reason to expect HCI to be convergent, or predictable. This is not to say progress in HCI is random or arbitrary, just that it is more like world history than it is like physics. One could see this quite optimistically: Individual and collective initiative shapes what HCI is, but not the laws of physics.  Author/Copyright holder: Palo Alto Research Center Incorporated (PARC) - a Xerox company. Copyright terms and licence: All Rights Reserved. Reproduced with permission. See section \"Exceptions\" in the copyright terms below.  Figure 2.11: Smalltalk was a programming language and environment project in Xerox Palo Alto Research Center in the 1970s. The work of a handful of people, it became the direct antecedent for the modern graphical user interface.  A second implication of the task-artifact cycle is that continual exploration of new applications and application domains, new designs and design paradigms, new experiences, and new activities should remain highly prized in HCI. We may have the sense that we know where we are going today, but given the apparent rate of co-evolution in activity and artifacts, our effective look-ahead is probably less than we think. Moreover, since we are in effect constructing a future trajectory, and not just finding it, the cost of missteps is high. The co-evolution of activity and artifacts evidences strong hysteresis, that is to say, effects of past co-evolutionary adjustments persist far into the future. For example, many people struggle every day with operating systems and core productivity applications whose designs were evolutionary reactions to misanalyses from two or more decades ago. Of course, it is impossible to always be right with respect to values and criteria that will emerge and coalesce in the future, but we should at least be mindful that very consequential missteps are possible.  Author/Copyright holder: Unknown (pending investigation). Copyright terms and licence: Unknown (pending investigation). See section \"Exceptions\" in the copyright terms below.  Author/Copyright holder: Unknown (pending investigation). Copyright terms and licence: Unknown (pending investigation). See section \"Exceptions\" in the copyright terms below.  Figure 2.12 A-B: The Drift Table is an interactive coffee table; aerial views of England and Wales are displayed the porthole on top; placing and moving objects on the table causes the aerial imagery to scroll. This design is intended to provoke reaction and challenge thinking about domestic technologies.  The remedy is to consider many alternatives at every point in the progression. It is vitally important to have lots of work exploring possible experiences and activities, for example, on design and experience probes and prototypes. If we focus too strongly on the affordances of currently embodied technology we are too easily and uncritically accepting constraints that will limit contemporary HCI as well as all future trajectories.  Author/Copyright holder: Apple Computer, Inc. Copyright terms and licence: All Rights Reserved. Used without permission under the Fair Use Doctrine (as permission could not be obtained). See the \"Exceptions\" section (and subsection \"allRightsReserved-UsedWithoutPermission\") on the page copyright notice.  Author/Copyright holder: Courtesy of Antonio Zugaldia. Copyright terms and licence: CC-Att-SA-2 (Creative Commons Attribution-ShareAlike 2.0 Unported).  Figure 2.13 A-B: Siri, the speech-based intelligent assistant for Apple’s iPhone, and the augmented reality glasses of Goggle’s Project Glass are recent examples of technology visions being turned into everyday HCI experiences.  HCI is not fundamentally about the laws of nature. Rather, it manages innovation to ensure that human values and human priorities are advanced, and not diminished through new technology. This is what created HCI; this is what led HCI off the desktop; it will continue to lead HCI to new regions of technology-mediated human possibility. This is why usability is an open-ended concept, and can never be reduced to a fixed checklist.  '},\n",
       "  {'subheading': '2.5 A caldron of theory',\n",
       "   'text': ' The contingent trajectory of HCI as a project in transforming human activity and experience through design has nonetheless remained closely integrated with the application and development of theory in the social and cognitive sciences. Even though, and to some extent because the technologies and human activities at issue in HCI are continually co-evolving, the domain has served as a laboratory and incubator for theory. The origin of HCI as an early case study in cognitive engineering had an imprinting effect on the character of the endeavor. From the very start, the models, theories and frameworks developed and used in HCI were pursued as contributions to science: HCI has enriched every theory it has appropriated. For example, the GOMS (Goals, Operations, Methods, Selection rules) model, the earliest native theory in HCI, was a more comprehensive cognitive model than had been attempted elsewhere in cognitive science and engineering; the model human processor included simple aspects of perception, attention, short-term memory operations, planning, and motor behavior in a single model. But GOMS was also a practical tool, articulating the dual criteria of scientific contribution plus engineering and design efficacy that has become the culture of theory and application in HCI.  Author/Copyright holder: Bonnie E. John. Copyright terms and licence: All Rights Reserved. Reproduced with permission. See section \"Exceptions\" in the copyright terms below.  Author/Copyright holder: Bonnie E. John. Copyright terms and licence: All Rights Reserved. Reproduced with permission. See section \"Exceptions\" in the copyright terms below.  Figure 2.14 A-B: CogTool analyzes demonstrations of user tasks to produce a model of the cognitive processes underlying task performance; from this model it predicts expert performance times for the tasks.  The focus of theory development and application has moved throughout the history of HCI, as the focus of the co-evolution of activities and artifacts has moved.?á Thus, the early information processing-based psychological theories, like GOMS, were employed to model the cognition and behavior of individuals interacting with keyboards, simple displays, and pointing devices. This initial conception of HCI theory was broadened as interactions became more varied and applications became richer. For example, perceptual theories were marshaled to explain how objects are recognized in a graphical display, mental model theories were appropriated to explain the role of concepts — like the messy desktop metaphor — in shaping interactions, active user theories were developed to explain how and why users learn and making sense of interactions. In each case, however, these elaborations were both scientific advances and bases for better tools and design practices.  This dialectic of theory and application has continued in HCI. It is easy to identify a dozen or so major currents of theory, which themselves can by grouped (roughly) into three eras: theories that view human-computer interaction as information processing, theories that view interaction as the initiative of agents pursuing projects, and theories that view interaction as socially and materially embedded in rich contexts. To some extent, the sequence of theories can be understood as a convergence of scientific opportunity and application need: Codifying and using relatively austere models made it clear what richer views of people and interaction could be articulated and what they could contribute; at the same time, personal devices became portals for interaction in the social and physical world, requiring richer theoretical frameworks for analysis and design.  Author/Copyright holder: Unknown (pending investigation). Copyright terms and licence: Unknown (pending investigation). See section \"Exceptions\" in the copyright terms below.  Figure 2.15: Through the past three decades, a series of theoretical paradigms emerged to address the expanding ambitions of HCI research, design, and product development. Successive theories both challenged and enriched prior conception of people and interaction. All of these theories are still relevant and still in use today in HCI.  The sequence of theories and eras is of course somewhat idealized. People still work on GOMS models; indeed, all of the major models, theories and frameworks that ever were employed in HCI are still in current use. Indeed, they continue to develop as the context of the field develops. GOMS today is more a niche model than a paradigm for HCI, but has recently been applied in research on smart phone designs and human-robot interactions.  The challenge of integrating, or at least better coordinating descriptive and explanatory science goals with prescriptive and constructive design goals is abiding in HCI. There are at least three ongoing directions — traditional application of ever-broader and deeper basic theories, development of local, sometimes domain dependent proto-theories within particular design domains, and the use of design rationale as a mediating level of description between basic science and design practice.  '},\n",
       "  {'subheading': '2.6 Implications of HCI for science, practice, and epistemology',\n",
       "   'text': ' One of the most significant achievements of HCI is its evolving model of the integration of research and practice. Initially this model was articulated as a reciprocal relation between cognitive science and cognitive engineering. Later, it ambitiously incorporated a diverse science foundation, notably social and organizational psychology, Activity Theory, distributed cognition, and sociology, and a ethnographic approaches human activity, including the activities of design and technology development and appropriation. Currently, the model is incorporating design practices and research across a broad spectrum, for example, theorizing user experience and ecological sustainability. In these developments, HCI provides a blueprint for a mutual relation between science and practice that is unprecedented.  Although HCI was always talked about as a design science or as pursuing guidance for designers, this was construed at first as a boundary, with HCI research and design as separate contributing areas of professional expertise. Throughout the 1990s, however, HCI directly assimilated, and eventually itself spawned, a series of design communities. At first, this was a merely ecumenical acceptance of methods and techniques laying those of beyond those of science and engineering. But this outreach impulse coincided with substantial advances in user interface technologies that shifted much of the potential proprietary value of user interfaces into graphical design and much richer ontologies of user experience.  Somewhat ironically, designers were welcomed into the HCI community just in time to help remake it as a design discipline. A large part of this transformation was the creation of design disciplines and issues that did not exist before. For example, user experience design and interaction design were not imported into HCI, but rather were among the first exports from HCI to the design world. Similarly, analysis of the productive tensions between creativity and rationale in design required a design field like HCI in which it is essential that designs have an internal logic, and can be systematically evaluated and maintained, yet at the same time provoke new experiences and insights.?á Design is currently the facet of HCI in most rapid flux. It seems likely that more new design proto-disciplines will emerge from HCI during the next decade.  No one can accuse HCI of resting on laurels. Conceptions of how underlying science informs and is informed by the worlds of practice and activity have evolved continually in HCI since its inception. Throughout the development of HCI, paradigm-changing scientific and epistemological revisions were deliberately embraced by a field that was, by any measure, succeeding intellectually and practically. The result has been an increasingly fragmented and complex field that has continued to succeed even more. This example contradicts the Kuhnian view of how intellectual projects develop through paradigms that are eventually overthrown. The continuing success of the HCI community in moving its meta-project forward thus has profound implications, not only for human-centered informatics, but for epistemology.  '},\n",
       "  {'subheading': '2.7 Pointers: How to learn more',\n",
       "   'text': \" In these “pointers” I have listed general background references to the discussion above, specific references to points made in the text, and reference to other chapters in the Encyclopedia of Human-Computer Interaction (Interaction-Design.org). I have organized the pointers by section, so the next six sections (below) echo the six major section headings in the paper itself (above).  2.7.1 Where HCI came from  There are many highly readable descriptions of the disciplinary landscape in which early HCI developed:  1980 volume of the journal Cognitive Science provides a vivid picture of the foundations of cognitive science as they were being built (http://csjarchive.cogsci.rpi.edu/1980v04/index.html);  F. Brooks’ book The Mythical Man-Month (1975, Addison-Wesley) is an insightful analysis of software engineering, and the original source for the idea that iterative prototyping is inevitable in the design and development of complex software;  J. Foley and A. van Dam’s book Computer Graphics (1982, Addison Wesley) describes the early field of computer graphics as a root of what would become human-computer interaction.  Vivid primary information about the founding of HCI - the proceedings of the 1982 US Bureau of Standards Conference in Gaithersburg, Maryland, are available in the ACM Digital Library at http://dl.acm.org/citation.cfm?id=800049  Several histories of HCI have been published:  Carroll, J.M. (1997) Human-Computer Interaction: Psychology as a science of design. Annual Review of Psychology, 48, 61-83.?á (Co-published (slightly revised) in International Journal of Human-Computer Studies, 46, 501-522).  Grudin, J. (2012) A Moving Target: The evolution of Human-computer Interaction. In J. Jacko (Ed.), Human-computer interaction handbook: Fundamentals, evolving technologies, and emerging applications. (3rd edition). Taylor & Francis.  Myers, B.A. (1998) A Brief History of Human Computer Interaction Technology. ACM interactions. Vol. 5, no. 2, March. pp. 44-54.  The leading HCI textbooks also include some discussion of history (see below).  2.7.2 From cabal to community  There is some dispute as to how to address the evolution of usability. In this overview, I take a historical view that the concept itself is evolving, analogous to way physics has treated its fundamental concepts, such as gravity and mass. See also  Carroll, J.M. (2004) Beyond fun. ACM interactions, 11(5), 38-40.  The ACM Special Interest Group on Computer-Human Interaction (SIGCHI), and its CHI Conference, one of the most general and significant HCI conferences, now is explicitly organized into communities that manage pieces of the technical program (http://www.sigchi.org/communities). In fall of 2012, these communities included CCaA (Creativity, Cognition and Art), CSCW (Computer-Supported Cooperative Work), EICS (Engineering Interactive Computer Systems), HCI and Sustainability, HCI Education, HCI4D (HCI for Development), Heritage Matters, Latin American HCI, Pattern Languages and HCI, Research-practice Interaction, UbiComp (Ubiquitous Computing), and UIST (User Interface Software and Tools).  An even more diverse view of HCI can be appreciated by investigating HCI activities and interest groups embedded in professional communities other than ACM: the Design Research Society (designresearchsociety.org), the Association for Information Systems (sighci.org), the Human Factors and Ergonomics Society (hfes.org), the Society for Technical Communication (stc.org), the AIGA (aiga.org), International Communication Association (icahdq.org), the Interaction Design Association (https://www.ixda.org/), the IEEE Professional Communication Society (pcs.ieee.org), the European Association of Work and Organizational Psychology (eawop2013.org), and many others.  Further relevant material in the Encyclopedia of Human-Computer Interaction can be found in chapters 1, 3, 8, 13, 15, 19, 21, and 22.  2.7.3 Beyond the desktop  A classic discussion of the desktop metaphor is Apple Human Interface Guidelines: Apple & Raskin, J. (1992). Macintosh Human Interface Guidelines. Addison-Wesley Professional. ISBN 0-201-62216-5.  An early critique of the Macintosh user interface paradigm is:  Gentner, D. and Nielsen, J. (1996) The Anti-Mac interface, Communications of the ACM 39, 8 (August), 70-82.  The emergence of collaboration, mobility, and new types of user devices and interactions as major themes driving “HCI beyond the desktop” are discussed widely, of course; here are some starting points:  Horn, D.B., Finholt, T.A., Birnholtz, J.P., Motwani, D. and Jayaraman, S. (2004) Six degrees of jonathan grudin: a social network analysis of the evolution and impact of CSCW research. In Proceedings of the 2004 ACM conference on Computer supported cooperative work (CSCW '04). ACM, New York, NY, USA, 582-591.  Luff, P. and Heath, C. (1998) Mobility in collaboration. In Proceedings of the 1998 ACM conference on Computer supported cooperative work (CSCW '98). ACM, New York, NY, USA, 305-314.  Shaer, O. and Hornecker, E. (2010) Tangible User Interfaces: Past, Present, and Future Directions. Found. Trends Hum.-Comput. Interact. 3, 1-2 (January), 1-137.  Waller V. and Johnston, R.B. (2009) Making ubiquitous computing available. Commun. ACM 52, 10 (October 2009), 127-130.  Further relevant material in the Encyclopedia of Human-Computer Interaction can be found in chapters 4, 14, 23, and 27.  2.7.4 The task-artifact cycle  I use the term “task-artifact cycle” here, as originally introduced in a 1991 paper with Wendy Kellogg and Mary Beth Rosson, though think “activity” better conveys what I mean than “task”. Not surprisingly, the terminology of the task-artifact cycle is itself an example of how HCI shifts under its own foundations; see  Carroll, J.M., Kellogg, W.A., & Rosson, M.B. (1991) The task-artifact cycle.?á In J.M. Carroll (Ed.),?á Designing Interaction: Psychology at the human-computer interface. ?áNew York: Cambridge University Press, pages 74-102.  A good reference for the history of the Smalltalk project is  Kay, A.C. (1996) The early history of Smalltalk. In History of programming languages---II, Thomas J. Bergin, Jr. and Richard G. Gibson, Jr. (Eds.). ACM, New York, NY, USA 511-598.  For more discussion of the drift table project, see  Boucher, A. and Gaver, W. 2006. Developing the drift table. interactions 13, 1 (January 2006), 24-27.  For more discussion of the general point being emphasized through the example of the drift table, see  Sengers, P. and W. Gaver, W. (2006) Staying open to interpretation: engaging multiple meanings in design and evaluation. In Proceedings of the 6th conference on Designing Interactive systems (DIS '06). ACM, New York, NY, USA, 99-108.  Further relevant material in the Encyclopedia of Human-Computer Interaction can be found in chapters 7, 12, 14, and 20.  2.7.5 A caldron of theory  I edited a book of theory overviews (Carroll, 2003), referenced below. It is available online (http://www.sciencedirect.com/science/book/9781558608085). I am currently curating theory overviews in the Synthesis Lectures on Human-Centered Informatics (http://www.morganclaypool.com/toc/hci/1/1).  John, B.E. (2011) Using predictive human performance models to inspire and support UI design recommendations. In Proceedings of the 2011 annual conference on Human factors in computing systems (CHI '11). ACM, New York, NY, USA, 983-986.  Further relevant material in the Encyclopedia of Human-Computer Interaction can be found in chapters 5, 6, 9, 11, 16, 1 7, 24, 25, 26, and 28.  2.7.6 Implications of HCI for science practice and epistemology  The work I refer to on creativity and design rationale is collected in a book, Carroll (2012), reference below. A nice example, I think, of the theoretical multi-vocality I describe in this section can be appreciated by contrasting these three treatments of aesthetics in HCI design (all are published in the Synthesis Lectures on Human-Centered Informatics, http://www.morganclaypool.com/toc/hci/1/1):  Hassenzahl, M. (2010). Experience Design: Technology for All the Right Reasons.  Sutcliffe, A. (2009) Designing for User Engagement: Aesthetic and Attractive User Interfaces  Wright, P. and McCarthy, J. (2010) Experience-Centered Design: Designers, Users, and Communities in Dialogue.  My reference to Kuhn regarding the development of science and knowledge is:  Kuhn, T.S. (1962) The Structure of Scientific Revolutions. Chicago: University of Chicago Press.  Kuhn, T.S. (1977) The Essential Tension: Selected Studies in Scientific Tradition and Change. Chicago and London: University of Chicago Press.  2.7.7 Textbooks  The number of important monographs is just too large to list, so I have concentrated in the list below on a few significant textbooks. Readers should also check the HCI Bibliography, the HCC Education Digital Library, the ACM Digital Library, and the Synthesis Series of lectures on human-centered informatics. These are the three most comprehensive textbooks:  Dix, A.J., Finlay, J.E., Abowd, G.D. and Beale, R. (2003). Human-Computer Interaction (3rd Edition). Prentice Hall  Rogers, Y., Sharp, H. and Preece, J.J. (2011) Interaction Design: Beyond Human-Computer Interaction (3rd ed.). John Wiley and Sons  Shneiderman, B. and Plaisant, C. (2009). Designing the User Interface: Strategies for Effective Human-Computer Interaction (5th ed.). Addison-Wesley  Several texts present more specialized views of HCI. Carroll (2003) collected a set of introductory papers on major theories used in HCI. L??wgren and Stolterman (2007) present a design perspective on HCI. Rosson and Carroll (2002) emphasize a software engineering view of HCI using a set of case studies to convey an engineering process view of usability. Tidwell (2011) presents a pattern-based approach to user interface design.  Carroll, John M. (ed.) (2003). HCI Models, Theories, and Frameworks: Toward a Multidisciplinary Science. Morgan Kaufmann  L??wgren, J. and Stolterman, E. (2007) Thoughtful Interaction Design: A Design Perspective on Information Technology. MIT Press.  Rosson, M.B. and Carroll, J.M. (2002). Usability Engineering: Scenario-Based Development of Human Computer Interaction. Morgan Kaufmann.  Tidwell, J. (2011) Designing Interfaces (2nd ed.). O’Reilly Media.  2.7.8 Journals  The leading general journal for HCI is the ACM Transactions on Computer-Human Interaction. However, there are many other well-established journals of roughly equivalent quality: Human-Computer Interaction (emphasizes design research), Interacting With Computers, International Journal of Human-Computer Studies, Behaviour and Information Technology, International Journal of Human-Computer Interaction, Journal of Computer-Supported Cooperative Work. Recently, Association for Information Systems has initiated a Transactions on Human-Computer Interaction.Morgan-Claypool publishes a monograph series, Synthesis Lectures on Human-Centered Informatics.  My personal perspectives on the emergence and development of HCI are elaborated in several other articles, monographs, and introductions to edited books:  Carroll, J.M. ?á(1995)?á Introduction: The scenario perspective on system development.?á In Carroll, J.M. (Ed.), Scenario-based design: Envisioning work and technology in system development. New York: John Wiley & Sons, pp 1-17.  Carroll, John M. (1997) Human-Computer Interaction: Psychology as a Science of Design. Annual Review of Psychology, 48, 61-83.?á Co-published (slightly revised) in International Journal of Human-Computer Studies, 46(4), 501-522  Carroll, J.M. (1998) Reconstructing minimalism. In J.M. Carroll (Ed.) Minimalism beyond?á “The Nurnberg Funnel”. M.I.T. Press  Carroll, J.M. (2000)?á Making use: Scenario-based design of human-computer interactions.?á MIT Press.?á Japanese edition published in 2003 by Kyoritsu Publishing; translated by Professor Kentaro Go.  Carroll, John M. (2002). Human-Computer Interaction. In: (ed.), MacMillan Encyclopedia of Cognitive Science. Macmillan-Nature Publishing Group.  Carroll, John M. (2004). Beyond fun. Interactions, 11(5), 38-40  Carroll, J.M. (2010) Narrating the Future: Scenarios and the Cult of Specification. In Selber, S. (Ed.), Rhetorics And Technologies: New directions in writing and communication. University of South Carolina Press, pp. 134-147.  Carroll, J.M. (2010). Conceptualizing a possible discipline of Human-Computer Interaction. Interacting with Computers, 22, 3-12.  Carroll, J.M. (2012) The neighborhood in the Internet: Design research projects in community informatics. Routledge.  Carroll, J.M. (2012) Creativity and Rationale: The Essential Tension, in J.M. Carroll (Ed.) Creativity and rationale: Enhancing human experience by design. Springer, pages 1-10.  2.7.9 Relevant Conference Series  2.7.9.1 CHI - Human Factors in Computing Systems  20112010200920082007200620052004200320022001200019991998199719961995199419931992199119901989198819871986198519831982  2.7.9.2 ECSCW - European Conference on Computer Supported Cooperative Work  200920072003200320012001199919971995199319911989  2.7.9.3 CSCW - Conference On Computer-Supported Cooperative Work  201220122012201120102008200620042004200220001998199619941992199019881986  2.7.9.4 UIST - Symposium on User Interface Software and Technology  20122012201120102009200820072007200720062005200420032003200220012000199919981997199619951994199319921991199019891988  2.7.9.5 NordiCHI - Nordic conference on human-computer interaction  20102008200620042002200220002000  2.7.9.6 BCSHCI People and Computers  2012201020092008200620062005200420032002200120001998199719961995199419931992199119891988198719861985  2.7.9.7 SIGGROUP - Conference on Supporting Group Work  2010200920072005200320011999199719951993199119901988198619841982  2.7.9.8 DIS - Designing Interactive Systems  201220102008200620042002200019971995  Next conference is coming up 08 Jun 2016 in Brisbane, Australia  2.7.9.9 CC - Creativity and Cognition  201120092007200520021999  \"},\n",
       "  {'subheading': '2.8 References',\n",
       "   'text': ' Myers, Brad A. (1998): A Brief History of Human-Computer Interaction Technology. In Interactions, 5 (2) pp. 44-54 '}]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example usage\n",
    "url = \"https://www.interaction-design.org/literature/book/the-encyclopedia-of-human-computer-interaction-2nd-ed/human-computer-interaction-brief-intro\"\n",
    "scrape_article(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CORRECTIONS_FILE = \"processed_syllabi/metadata_corrections.json\"\n",
    "\n",
    "def sanitize_filename(title):\n",
    "    \"\"\"Removes invalid filename characters and replaces spaces with underscores.\"\"\"\n",
    "    return re.sub(r'[<>:\"/\\\\|?*]', '', title).replace(' ', '_')\n",
    "\n",
    "def load_metadata_corrections():\n",
    "    \"\"\"Loads manually corrected metadata from a JSON file or creates an empty one if missing.\"\"\"\n",
    "    if not os.path.exists(CORRECTIONS_FILE):\n",
    "        with open(CORRECTIONS_FILE, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump({}, f, indent=4, ensure_ascii=False)  # Initialize empty JSON\n",
    "    with open(CORRECTIONS_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def save_metadata_corrections(corrections):\n",
    "    \"\"\"Saves full metadata for error spotting and manual corrections.\"\"\"\n",
    "    with open(CORRECTIONS_FILE, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(corrections, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "def process_course_syllabi(course_name):\n",
    "    \"\"\"Reads URLs & PDFs from a links.txt file and processes them.\"\"\"\n",
    "    raw_path = f\"raw_syllabi/master_courses/{course_name}/materials_paths_test.txt\" # test file\n",
    "    output_folder = f\"processed_syllabi/{course_name}/\"\n",
    "    \n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    \n",
    "    # Load existing metadata corrections\n",
    "    metadata_corrections = load_metadata_corrections()\n",
    "\n",
    "    with open(raw_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "            if not line or line.startswith(\"#\"):\n",
    "                continue\n",
    "\n",
    "            article_data = None\n",
    "            \n",
    "            # Process online articles\n",
    "            if line.startswith(\"http\"):  \n",
    "                print(f\"🔗 Scraping article: {line}\")\n",
    "                article_data = scrape_article(line)\n",
    "\n",
    "            \"\"\"\n",
    "            elif \"pages=\" in line:  # Process PDFs with page ranges\n",
    "                pdf_path, pages = line.split(\" pages=\")\n",
    "                page_range = range(*map(int, pages.split(\"-\")))\n",
    "                output_pdf = f\"{output_folder}{os.path.basename(pdf_path).replace('.pdf', '_extracted.pdf')}\"\n",
    "                extract_pdf_pages(pdf_path.strip(), output_pdf, page_range)\n",
    "\n",
    "\n",
    "            \"\"\"\n",
    "\n",
    "            if not article_data:\n",
    "                print(f\"⚠️ Skipping {line} (Extraction failed)\")\n",
    "                continue\n",
    "\n",
    "\n",
    "            # specify title and course name for meta data\n",
    "            title = sanitize_filename(article_data.get(\"title\", \"Untitled\"))\n",
    "            article_data[\"course\"] = course_name\n",
    "            filename = f\"{output_folder}{title}.json\"\n",
    "\n",
    "            # Check if manual corrections exist and apply them\n",
    "            file_key = f\"{course_name}/{os.path.basename(filename)}\"\n",
    "            print(file_key)\n",
    "            if file_key in metadata_corrections:\n",
    "                corrected_metadata = metadata_corrections[file_key]\n",
    "                article_data.update(corrected_metadata)  # Merge corrected fields\n",
    "            \n",
    "            \n",
    "            # Save extracted data as JSON\n",
    "            with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "                json.dump(article_data, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "            # Store extracted metadata in corrections log if it's missing\n",
    "            if file_key not in metadata_corrections:\n",
    "                metadata_corrections[file_key] = {\n",
    "                    \"course\": course_name,\n",
    "                    \"title\": article_data.get(\"title\", \"Untitled\"),\n",
    "                    \"author\": article_data.get(\"author\", \"Unknown\"),\n",
    "                    \"date_published\": article_data.get(\"date_published\", \"Unknown\")\n",
    "                }\n",
    "                save_metadata_corrections(metadata_corrections)\n",
    "\n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔗 Scraping article: https://www.nngroup.com/articles/minimize-cognitive-load/\n",
      "Human_computer_interaction/Minimize_Cognitive_Load_to_Maximize_Usability.json\n",
      "🔗 Scraping article: https://www.nngroup.com/articles/mental-models/\n",
      "Human_computer_interaction/Mental_Models_and_User_Experience_Design.json\n",
      "🔗 Scraping article: https://imotions.com/blog/learning/best-practice/eye-tracking/\n",
      "Human_computer_interaction/Eye_Tracking_The_Complete_Pocket_Guide.json\n",
      "🔗 Scraping article: https://maitraudit.medium.com/a-complete-guide-for-eye-tracking-testing-in-ux-research-a3f95d617590\n",
      "Human_computer_interaction/A_complete_guide_for_Eye-Tracking_testing_in_UX_Research.json\n",
      "⚠️ Skipping raw_syllabi\\master_courses\\Human_computer_interaction\\pdf_material\\Laws of UX.pdf pages=1-12 (Extraction failed)\n",
      "⚠️ Skipping raw_syllabi\\master_courses\\Human_computer_interaction\\pdf_material\\Laws of UX.pdf pages=13-22 (Extraction failed)\n",
      "⚠️ Skipping raw_syllabi\\master_courses\\Human_computer_interaction\\pdf_material\\Measuring the User Experience.pdf chapter=\"Eye Tracking\" (Extraction failed)\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "process_course_syllabi(\"Human_computer_interaction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# syllabus lists specific pages\n",
    "\n",
    "import fitz  # PyMuPDF\n",
    "\n",
    "def extract_pdf_pages(pdf_path, output_path, page_range):\n",
    "    \"\"\"Extracts specific pages from a PDF.\"\"\"\n",
    "    doc = fitz.open(pdf_path)\n",
    "    new_pdf = fitz.open()\n",
    "    \n",
    "    for page_num in page_range:\n",
    "        if page_num < len(doc):  # Avoid out-of-range errors\n",
    "            new_pdf.insert_pdf(doc, from_page=page_num, to_page=page_num)\n",
    "\n",
    "    new_pdf.save(output_path)\n",
    "    print(f\"✅ Extracted pages saved to {output_path}\")\n",
    "\n",
    "\n",
    "# syllabus lists chapters, and pdf has structured heading\n",
    "\n",
    "def extract_chapter(pdf_path, keyword, output_path):\n",
    "    \"\"\"Extracts pages containing a chapter title keyword.\"\"\"\n",
    "    doc = fitz.open(pdf_path)\n",
    "    new_pdf = fitz.open()\n",
    "\n",
    "    for page_num in range(len(doc)):\n",
    "        text = doc[page_num].get_text(\"text\")\n",
    "        if keyword.lower() in text.lower():  # Check if chapter keyword is in the page\n",
    "            new_pdf.insert_pdf(doc, from_page=page_num, to_page=page_num + 5)  # Assume chapters span ~5 pages\n",
    "\n",
    "    new_pdf.save(output_path)\n",
    "    print(f\"✅ Extracted chapter saved to {output_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Extracted pages saved to processed_syllabi/Human_computer_interaction/clipped_pdfs/page13-22.pdf\n"
     ]
    }
   ],
   "source": [
    "from scrape_and_extract import *\n",
    "from scrape_and_extract import extract_pdf_pages, extract_chapter, scrape_article\n",
    "\n",
    "# Example usage\n",
    "extract_pdf_pages(\"raw_syllabi/master_courses/Human_computer_interaction/pdf_material/Laws of UX.pdf\", \"processed_syllabi/Human_computer_interaction/clipped_pdfs/page13-22.pdf\", range(13, 22))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Extracted chapter saved to processed_syllabi/Human_computer_interaction/clipped_pdfs/page_chapter.pdf\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "extract_chapter(\"raw_syllabi/master_courses/Human_computer_interaction/pdf_material/Laws of UX.pdf\", \"Jakob's Law\", \"processed_syllabi/Human_computer_interaction/clipped_pdfs/page_chapter.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dark Patterns at Scale: Findings from a Crawl of 11K Shopping Websites\n",
      "Arunesh Mathur, Gunes Acar, Michael J. Friedman, Elena Lucherini, Jonathan Mayer, Marshini Chetty, and Arvind Narayanan\n",
      "-  Human-centered computing  ->  Empirical studies in HCI.HCI theory, concepts and models.-  Social and professional topics  ->  Consumer products policy.-  Information systems  ->  Browsers.\n",
      "LaTeX with acmart 2019/04/22 v1.60 Typesetting articles for the Association for Computing Machinery and hyperref 2016/06/24 v6.83q Hypertext links for LaTeX\n",
      "pdfTeX-1.40.17\n",
      "2019-09-23 00:22:01+00:00\n",
      "2019-09-23 00:22:01+00:00\n"
     ]
    }
   ],
   "source": [
    "from pypdf import PdfReader\n",
    "\n",
    "reader = PdfReader(r\"raw_syllabi\\master_courses\\Human_computer_interaction\\pdf_material\\Laws of UX.pdf\")\n",
    "reader = PdfReader(r\"raw_syllabi\\master_courses\\Human_computer_interaction\\pdf_material\\Mathur-2019-Dark-patterns-at-scale.pdf\")\n",
    "meta = reader.metadata\n",
    "\n",
    "# All of the following could be None!\n",
    "print(meta.title)\n",
    "print(meta.author)\n",
    "print(meta.subject)\n",
    "print(meta.creator)\n",
    "print(meta.producer)\n",
    "print(meta.creation_date)\n",
    "print(meta.modification_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymupdf  # PyMuPDF\n",
    "import pypdf\n",
    "import re\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def extract_pdf_metadata(pdf_path):\n",
    "    \"\"\"Extracts metadata (title, author, date) from a PDF file.\"\"\"\n",
    "    title, author, date_published = \"Unknown\", \"Unknown\", \"Unknown\"\n",
    "\n",
    "    try:\n",
    "        with open(pdf_path, \"rb\") as f:\n",
    "            pdf_reader = pypdf.PdfReader(f)\n",
    "            metadata = pdf_reader.metadata or {}\n",
    "\n",
    "            if metadata:\n",
    "                # Print all metadata keys for debugging\n",
    "                for key, value in metadata.items():\n",
    "                    print(f\"   pypdf* {key}: {value}\")\n",
    "\n",
    "            title = metadata.get(\"/Title\", \"Unknown\")\n",
    "            author = metadata.get(\"/Author\", \"Unknown\")\n",
    "            date_published = metadata.get(\"/CreationDate\", \"Unknown\")\n",
    "            keywords = metadata.get(\"/Keywords\", \"Unavailable\")\n",
    "            \n",
    "            # format date correctly - YYYY-MM-DD format\n",
    "            if date_published.startswith(\"D:\"):\n",
    "                date_published = f\"{date_published[2:6]}-{date_published[6:8]}-{date_published[8:10]}\"\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting metadata with PyPDF: {e}\")\n",
    "\n",
    "    return title.strip(), author.strip(), date_published.strip(), keywords.strip()\n",
    "\n",
    "\n",
    "def pymupdf_extract_pdf_metadata(pdf_path):\n",
    "    \"\"\"Extracts metadata (title, author, date) from a PDF file.\"\"\"\n",
    "    title, author, date_published = \"Unknown\", \"Unknown\", \"Unknown\"\n",
    "\n",
    "    try:\n",
    "        with open(pdf_path, \"rb\") as f:\n",
    "            pdf_reader = pymupdf.open(f)\n",
    "            metadata = pdf_reader.metadata or {}\n",
    "\n",
    "            if metadata:\n",
    "                # Print all metadata keys for debugging\n",
    "                for key, value in metadata.items():\n",
    "                    print(f\"   pymupdf* {key}: {value}\")\n",
    "\n",
    "            title = metadata.get(\"/title\", \"Unknown\")\n",
    "            author = metadata.get(\"/author\", \"Unknown\")\n",
    "            date_published = metadata.get(\"/creationDate\", \"Unknown\")\n",
    "            keywords = metadata.get(\"/keywords\", \"Unavailable\")\n",
    "            \n",
    "            # format date correctly - YYYY-MM-DD format\n",
    "            if date_published.startswith(\"D:\"):\n",
    "                date_published = f\"{date_published[2:6]}-{date_published[6:8]}-{date_published[8:10]}\"\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting metadata with PyPDF: {e}\")\n",
    "\n",
    "    return title.strip(), author.strip(), date_published.strip(), keywords.strip()\n",
    "\n",
    "def adjust_page_range(page_range, true_page_1):\n",
    "    \"\"\"\n",
    "    Adjusts the page range based on a manually specified 'true' page 1.\n",
    "    - If true_page_1 = 15 and requested range is (1, 12), \n",
    "      actual PDF pages are (15, 26).\n",
    "    \"\"\"\n",
    "    if not page_range or true_page_1 is None:\n",
    "        return None  # No adjustments needed\n",
    "\n",
    "    start, end = page_range\n",
    "\n",
    "    # Compute actual PDF pages (zero-indexed for fitz)\n",
    "    adjusted_start = (start - 1) + (true_page_1 - 1)\n",
    "    adjusted_end = (end - 1) + (true_page_1 - 1)\n",
    "\n",
    "    return (adjusted_start, adjusted_end)\n",
    "\n",
    "def extract_pdf_text(pdf_path, page_range=None, true_page_1=None):\n",
    "    \"\"\"Extracts text from a PDF, adjusting for true page 1 and distinguishing sections.\"\"\"\n",
    "    try:\n",
    "        doc = pymupdf.open(pdf_path)\n",
    "        extracted_sections = []\n",
    "        adjusted_range = adjust_page_range(page_range, true_page_1)\n",
    "        #print(f\"True Page 1: {true_page_1}, Requested Pages: {page_range}\")\n",
    "        #print(f\"Adjusted Pages: {adjusted_range}, FitZ Total Pages: {len(doc)}\")\n",
    "\n",
    "        # Get pages in adjusted range (or full doc if no range)\n",
    "        page_numbers = range(len(doc)) if adjusted_range is None else range(adjusted_range[0], adjusted_range[1] + 1)\n",
    "\n",
    "        current_section = {\"subheading\": \"Introduction\", \"text\": \"\"}\n",
    "\n",
    "        for page_num in page_numbers:\n",
    "            page = doc[page_num]\n",
    "            blocks = page.get_text(\"blocks\")  # Get text as blocks to detect headings\n",
    "\n",
    "            for block in sorted(blocks, key=lambda b: b[1]):  # Sort by y-coordinate (top to bottom)\n",
    "                text = block[4].strip()\n",
    "\n",
    "                if not text:\n",
    "                    continue  # Skip empty blocks\n",
    "                \n",
    "                # Detect headings based on text formatting\n",
    "                if text.isupper() or len(text) < 40:  \n",
    "                    # If previous section has content, save it\n",
    "                    if current_section[\"text\"].strip():\n",
    "                        extracted_sections.append(current_section)\n",
    "                    \n",
    "                    # Start new section\n",
    "                    current_section = {\"subheading\": text, \"text\": \"\"}\n",
    "                else:\n",
    "                    current_section[\"text\"] += \" \" + text  # Append text to current section\n",
    "            \n",
    "        # Append the last section\n",
    "        if current_section[\"text\"].strip():\n",
    "            extracted_sections.append(current_section)\n",
    "\n",
    "        return extracted_sections\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting text from {pdf_path}: {e}\")\n",
    "        return []\n",
    "\n",
    "\n",
    "def scrape_pdf(pdf_path, page_range=None, true_page_1=None):\n",
    "    \"\"\"\n",
    "    Extracts metadata and structured text from a PDF.\n",
    "    - Books: Uses true page 1 and page range\n",
    "    - Research Papers: Extracts full text as sections\n",
    "    \"\"\"\n",
    "    title, author, date_published, keywords = extract_pdf_metadata(pdf_path)\n",
    "    #title, author, date_published, keywords = pymupdf_extract_pdf_metadata(pdf_path)\n",
    "    sections = extract_pdf_text(pdf_path, page_range, true_page_1)\n",
    "\n",
    "    # title can't be unknown, to not override. fallback to file name\n",
    "    if title == 'Unknown':\n",
    "        title = Path(pdf_path).stem\n",
    "\n",
    "    return {\n",
    "        \"document_type\": \"book\" if page_range else \"research_paper\",\n",
    "        \"title\": title,\n",
    "        \"author\": author,\n",
    "        \"source\": pdf_path,\n",
    "        \"date_published\": date_published,\n",
    "        \"keywords\": keywords,\n",
    "        \"sections\": sections,\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page 14: average font size = 9.66\n",
      "Block text: Dark Patterns at Scale 81:15\n",
      "Block avg size: 7.97, Page avg: 9.66\n",
      "Block text: (a) Countdown Timer on mattressfirm.com . The header displays a Flash Sale where the majority of discounted products remain the same on a day-to-day basis.\n",
      "Block avg size: 8.99, Page avg: 9.66\n",
      "Block text: (b) Countdown Timer on justfab.com . The offer is available even after the timer expires.\n",
      "Block avg size: 8.97, Page avg: 9.66\n",
      "Block text: (c) Limited-time Message on chicwish.com . The website claims the sale will end ‘soon’ without stating a deadline.\n",
      "Block avg size: 8.90, Page avg: 9.66\n",
      "Block text: Fig. 4. Two types of the Urgency category of dark patterns.\n",
      "Block avg size: 8.97, Page avg: 9.66\n",
      "Block text: Countdown Timers . The ‘Countdown Timer’ dark pattern is a dynamic indicator of a deadline, counting down until the deadline expires. Figures 4a and 4b show the Countdown Timer dark pattern on mattressfirm.com and justfab.com , respectively. One indicates the deadline for a recurring Flash Sale , the other a Member Exclusive . In our data set, we found a total of 393 instances of the Countdown Timer dark pattern.\n",
      "Block avg size: 9.94, Page avg: 9.66\n",
      "Block text: Deceptive Countdown Timers. Using the visit-and-record method described in Section 4.4, we examined the countdown timers in our data set for deceptive practices. We stitched the screenshots of each countdown timer from the repeated visits of our crawler to a website into a video, and viewed the resulting videos to observe the behavior of the timers. We considered a countdown timer deceptive if (1) the timer reset after timeout with the same offer still valid, or (2) the timer expired but the offer it claimed was expiring was still valid even following expiration. In our data set, we discovered a total of 157 instances of deceptive Countdown Timers on 140 shopping websites. One such example is shown in Figure 4b on justfab.com , where the advertised offer remains valid even after the countdown timer of 60 minutes expires. Using our taxonomy of dark pattern characteristics, we classify Countdown Timers as partially covert (it creates a heightened sense of immediacy, unbeknownst to at least some users), and sometimes deceptive (it can mislead users into believing an offer is expiring when in reality it is not) in nature.\n",
      "Block avg size: 10.00, Page avg: 9.66\n",
      "Block text: Limited-time Messages . Unlike Countdown Timers, the ‘Limited-time Message’ dark pattern is a static urgency message without an accompanying deadline. By not stating the deadline, websites withhold information from users, and thus misrepresent the nature of the offer [ 20 ]. Figure 4c shows an instance of the Limited-time Message dark pattern on chicwish.com , where the advertised sale is stated to end ‘soon’ with no mention of the end date. For every such instance we discovered, we verified that the shopping website made no disclosure about the accompanying deadline (e.g., in\n",
      "Block avg size: 9.90, Page avg: 9.66\n",
      "Page 15: average font size = 9.59\n",
      "Block text: 81:16 Arunesh Mathur et al.\n",
      "Block avg size: 7.97, Page avg: 9.59\n",
      "Block text: (a) Confirmshaming on radioshack.com . The option to dismiss the popup is framed to shame the user into avoiding it.\n",
      "Block avg size: 8.91, Page avg: 9.59\n",
      "Block text: (b) Visual Interference on greenfingers.com . The option to opt out of marketing communication is grayed, making it seem un- available even though it can be clicked.\n",
      "Block avg size: 8.94, Page avg: 9.59\n",
      "Block text: (c) Trick Questions on newbalance.co.uk . Opting out of marketing communication requires ticking the checkbox.\n",
      "Block avg size: 9.01, Page avg: 9.59\n",
      "Block text: (d) Pressured Selling on 1800flowers.com . The most expensive product is the default.\n",
      "Block avg size: 9.04, Page avg: 9.59\n",
      "Block text: Fig. 5. Four types of the Misdirection category of dark patterns.\n",
      "Block avg size: 8.97, Page avg: 9.59\n",
      "Block text: the fine print and in the terms of sale pages). In our data set, we discovered a total of 88 instances of the Limited-time Message dark pattern. Using our taxonomy of dark pattern characteristics, we classify Limited-time Messages as at least partially covert (similar to Countdown Timers), and information hiding (unlike Countdown Timers, they do not reveal the deadline in their offers) in nature.\n",
      "Block avg size: 10.00, Page avg: 9.59\n",
      "Block text: 5.1.3 Misdirection. The ‘Misdirection’ category of dark patterns uses visuals, language, and emo- tion to steer users toward or away from making a particular choice. Misdirection functions by exploiting different affective mechanisms and cognitive biases in users without actually restricting the set of choices available to users. Our version of the Misdirection dark pattern is inspired by Brignull’s original Misdirection dark pattern [ 32 ]. However, while Brignull considered Misdirection to occur exclusively using stylistic and visual manipulation, we take a broader view of the term, also including Misdirection caused by language and emotional manipulation. We observed four types of the Misdirection dark pattern: Confirmshaming [ 32 ], Trick Ques- tions [ 32 ], Visual Interference [ 48 ], and Pressured Selling on 244 shopping websites. Figure 5 highlights instances of these four types.\n",
      "Block avg size: 9.98, Page avg: 9.59\n",
      "Block text: Confirmshaming . Coined by Brignull [ 32 ], the ‘Confirmshaming’ dark pattern uses language and emotion to steer users away from making a certain choice. Confirmshaming appeared most often in popup dialogs that solicited users’ email addresses in exchange for a discount, where the option to decline the offer—which the website did not want users to select—was framed as a shameful choice. Examples of such framing included ‘No thanks, I like paying full price’, ‘No thanks, I hate saving money’, and ‘No thanks, I hate fun & games’. By framing the negative option as such, the Confirmshaming dark pattern exploits the framing effect cognitive bias in users and shame, a powerful behavior change agent [ 58 ]. Figure 5a shows one instance of the Confirmshaming dark pattern on radioshack.com . In our data set, we found a total of 169 such instances.\n",
      "Block avg size: 9.97, Page avg: 9.59\n",
      "Page 16: average font size = 9.71\n",
      "Block text: Dark Patterns at Scale 81:17\n",
      "Block avg size: 7.97, Page avg: 9.71\n",
      "Block text: Using our taxonomy of dark pattern characteristics, we classify Confirmshaming as asymmetric (the opt-out choice shames users into avoiding it) in nature. However, Confirmshaming is not covert , since users can visibly see and realize that the design is attempting to influence their choice.\n",
      "Block avg size: 9.89, Page avg: 9.71\n",
      "Block text: Visual Interference . The ‘Visual Interference’ dark pattern uses style and visual presentation to influence users into making certain choices over others (Brignull’s original description of Misdirection [ 32 ]). Although we excluded style information in our clustering analysis, we extracted these patterns as a consequence of examining the text the patterns displayed. In some instances, websites used the Visual Interference dark pattern to make certain courses of action more prominent over others. For example, the subscription offering on exposedskincare.com is stylistically more prominent and emphasized than the non-subscription offering. In other instances, websites used visual effects on textual descriptions to inflate the discounts available for products. For example, websites such as dyson.co.uk and justfab.com offered free gifts to users, and then used these gifts to inflate the savings on users’ purchases in the checkout page—even when the originally selected product was not on discount. In one instance on greenfingers.com , we discovered that the option to decline marketing communication is greyed out, creating an illusion that the option is unavailable or disabled even though it can be clicked, as shown in Figure 5b. In our data set, we found a total of 25 instances of the Visual Interference dark pattern. Using our taxonomy of dark pattern characteristics, we classify Visual Interference as sometimes asymmetric (in some instances it creates unequal choices, steering users into one choice over the other), covert (users may not realize the effect the visual presentation has had on their choice), and sometimes deceptive (e.g., when a website presents users with a ‘lucky draw’ from a list of potential deals, but the draw process is deterministic unbeknownst to users) in nature.\n",
      "Block avg size: 9.95, Page avg: 9.71\n",
      "Encountered 'References' in block: Trick Questions . Also originating from Brignull’s taxonomy [ 32 ], the ‘Trick Questions’ dark pattern uses confusing language to steer users into making certain choices. Like Confirmshaming, Trick Questions attempt to overcome users’ propensity to opt out of marketing and promotional messages by subtly inverting the entire opt-out process. Most often, websites achieved this effect by introducing confusing double negatives (e.g., ‘Uncheck the box if you prefer not to receive email updates’), or by using negatives to alter expected courses of action, such as checking a box to opt out (e.g., ‘We would like to send you emails. If you do not wish to be contacted via email, please ensure that the box is not checked’). We note here that we only considered an opt-out choice as a Trick Question dark pattern when it was misleading, such as when the user has to check a box and the text began with an affirmative statement about the undesirable practice (e.g., ‘We want to send you marketing email...’) since these would more likely be missed by users as opposed to ones that began with the opt-out choice (e.g., ‘Please tick here to opt-out of...’). 9 Trick Questions exploits the default and framing effect cognitive biases in users, who become more susceptible to a choice they erroneously believe is aligned with their preferences. Figure 5c shows one instance of Trick Questions on newbalance.co.uk . In our data set, we found a total of 9 such instances, occurring most often during the checkout process when collecting user information to complete purchases. Using our taxonomy of dark pattern characteristics, we classify Trick Questions as asymmetric (opting out is more burdensome than opting in) and covert (users fail to understand the effect of their choice as a consequence of the confusing language) in nature.. Stopping processing.\n",
      "Strict pass subheader count: 0\n",
      "Only 0 subheaders found with strict criteria. Retrying with relaxed criteria.\n",
      "Page 14: average font size = 9.66\n",
      "Block text: Dark Patterns at Scale 81:15\n",
      "Block avg size: 7.97, Page avg: 9.66\n",
      "Block text: (a) Countdown Timer on mattressfirm.com . The header displays a Flash Sale where the majority of discounted products remain the same on a day-to-day basis.\n",
      "Block avg size: 8.99, Page avg: 9.66\n",
      "Block text: (b) Countdown Timer on justfab.com . The offer is available even after the timer expires.\n",
      "Block avg size: 8.97, Page avg: 9.66\n",
      "Block text: (c) Limited-time Message on chicwish.com . The website claims the sale will end ‘soon’ without stating a deadline.\n",
      "Block avg size: 8.90, Page avg: 9.66\n",
      "Block text: Fig. 4. Two types of the Urgency category of dark patterns.\n",
      "Block avg size: 8.97, Page avg: 9.66\n",
      "Block text: Countdown Timers . The ‘Countdown Timer’ dark pattern is a dynamic indicator of a deadline, counting down until the deadline expires. Figures 4a and 4b show the Countdown Timer dark pattern on mattressfirm.com and justfab.com , respectively. One indicates the deadline for a recurring Flash Sale , the other a Member Exclusive . In our data set, we found a total of 393 instances of the Countdown Timer dark pattern.\n",
      "Block avg size: 9.94, Page avg: 9.66\n",
      "Block text: Deceptive Countdown Timers. Using the visit-and-record method described in Section 4.4, we examined the countdown timers in our data set for deceptive practices. We stitched the screenshots of each countdown timer from the repeated visits of our crawler to a website into a video, and viewed the resulting videos to observe the behavior of the timers. We considered a countdown timer deceptive if (1) the timer reset after timeout with the same offer still valid, or (2) the timer expired but the offer it claimed was expiring was still valid even following expiration. In our data set, we discovered a total of 157 instances of deceptive Countdown Timers on 140 shopping websites. One such example is shown in Figure 4b on justfab.com , where the advertised offer remains valid even after the countdown timer of 60 minutes expires. Using our taxonomy of dark pattern characteristics, we classify Countdown Timers as partially covert (it creates a heightened sense of immediacy, unbeknownst to at least some users), and sometimes deceptive (it can mislead users into believing an offer is expiring when in reality it is not) in nature.\n",
      "Block avg size: 10.00, Page avg: 9.66\n",
      "Block text: Limited-time Messages . Unlike Countdown Timers, the ‘Limited-time Message’ dark pattern is a static urgency message without an accompanying deadline. By not stating the deadline, websites withhold information from users, and thus misrepresent the nature of the offer [ 20 ]. Figure 4c shows an instance of the Limited-time Message dark pattern on chicwish.com , where the advertised sale is stated to end ‘soon’ with no mention of the end date. For every such instance we discovered, we verified that the shopping website made no disclosure about the accompanying deadline (e.g., in\n",
      "Block avg size: 9.90, Page avg: 9.66\n",
      "Page 15: average font size = 9.59\n",
      "Block text: 81:16 Arunesh Mathur et al.\n",
      "Block avg size: 7.97, Page avg: 9.59\n",
      "Block text: (a) Confirmshaming on radioshack.com . The option to dismiss the popup is framed to shame the user into avoiding it.\n",
      "Block avg size: 8.91, Page avg: 9.59\n",
      "Block text: (b) Visual Interference on greenfingers.com . The option to opt out of marketing communication is grayed, making it seem un- available even though it can be clicked.\n",
      "Block avg size: 8.94, Page avg: 9.59\n",
      "Block text: (c) Trick Questions on newbalance.co.uk . Opting out of marketing communication requires ticking the checkbox.\n",
      "Block avg size: 9.01, Page avg: 9.59\n",
      "Block text: (d) Pressured Selling on 1800flowers.com . The most expensive product is the default.\n",
      "Block avg size: 9.04, Page avg: 9.59\n",
      "Block text: Fig. 5. Four types of the Misdirection category of dark patterns.\n",
      "Block avg size: 8.97, Page avg: 9.59\n",
      "Block text: the fine print and in the terms of sale pages). In our data set, we discovered a total of 88 instances of the Limited-time Message dark pattern. Using our taxonomy of dark pattern characteristics, we classify Limited-time Messages as at least partially covert (similar to Countdown Timers), and information hiding (unlike Countdown Timers, they do not reveal the deadline in their offers) in nature.\n",
      "Block avg size: 10.00, Page avg: 9.59\n",
      "Block text: 5.1.3 Misdirection. The ‘Misdirection’ category of dark patterns uses visuals, language, and emo- tion to steer users toward or away from making a particular choice. Misdirection functions by exploiting different affective mechanisms and cognitive biases in users without actually restricting the set of choices available to users. Our version of the Misdirection dark pattern is inspired by Brignull’s original Misdirection dark pattern [ 32 ]. However, while Brignull considered Misdirection to occur exclusively using stylistic and visual manipulation, we take a broader view of the term, also including Misdirection caused by language and emotional manipulation. We observed four types of the Misdirection dark pattern: Confirmshaming [ 32 ], Trick Ques- tions [ 32 ], Visual Interference [ 48 ], and Pressured Selling on 244 shopping websites. Figure 5 highlights instances of these four types.\n",
      "Block avg size: 9.98, Page avg: 9.59\n",
      "Block text: Confirmshaming . Coined by Brignull [ 32 ], the ‘Confirmshaming’ dark pattern uses language and emotion to steer users away from making a certain choice. Confirmshaming appeared most often in popup dialogs that solicited users’ email addresses in exchange for a discount, where the option to decline the offer—which the website did not want users to select—was framed as a shameful choice. Examples of such framing included ‘No thanks, I like paying full price’, ‘No thanks, I hate saving money’, and ‘No thanks, I hate fun & games’. By framing the negative option as such, the Confirmshaming dark pattern exploits the framing effect cognitive bias in users and shame, a powerful behavior change agent [ 58 ]. Figure 5a shows one instance of the Confirmshaming dark pattern on radioshack.com . In our data set, we found a total of 169 such instances.\n",
      "Block avg size: 9.97, Page avg: 9.59\n",
      "Page 16: average font size = 9.71\n",
      "Block text: Dark Patterns at Scale 81:17\n",
      "Block avg size: 7.97, Page avg: 9.71\n",
      "Block text: Using our taxonomy of dark pattern characteristics, we classify Confirmshaming as asymmetric (the opt-out choice shames users into avoiding it) in nature. However, Confirmshaming is not covert , since users can visibly see and realize that the design is attempting to influence their choice.\n",
      "Block avg size: 9.89, Page avg: 9.71\n",
      "Block text: Visual Interference . The ‘Visual Interference’ dark pattern uses style and visual presentation to influence users into making certain choices over others (Brignull’s original description of Misdirection [ 32 ]). Although we excluded style information in our clustering analysis, we extracted these patterns as a consequence of examining the text the patterns displayed. In some instances, websites used the Visual Interference dark pattern to make certain courses of action more prominent over others. For example, the subscription offering on exposedskincare.com is stylistically more prominent and emphasized than the non-subscription offering. In other instances, websites used visual effects on textual descriptions to inflate the discounts available for products. For example, websites such as dyson.co.uk and justfab.com offered free gifts to users, and then used these gifts to inflate the savings on users’ purchases in the checkout page—even when the originally selected product was not on discount. In one instance on greenfingers.com , we discovered that the option to decline marketing communication is greyed out, creating an illusion that the option is unavailable or disabled even though it can be clicked, as shown in Figure 5b. In our data set, we found a total of 25 instances of the Visual Interference dark pattern. Using our taxonomy of dark pattern characteristics, we classify Visual Interference as sometimes asymmetric (in some instances it creates unequal choices, steering users into one choice over the other), covert (users may not realize the effect the visual presentation has had on their choice), and sometimes deceptive (e.g., when a website presents users with a ‘lucky draw’ from a list of potential deals, but the draw process is deterministic unbeknownst to users) in nature.\n",
      "Block avg size: 9.95, Page avg: 9.71\n",
      "Encountered 'References' in block: Trick Questions . Also originating from Brignull’s taxonomy [ 32 ], the ‘Trick Questions’ dark pattern uses confusing language to steer users into making certain choices. Like Confirmshaming, Trick Questions attempt to overcome users’ propensity to opt out of marketing and promotional messages by subtly inverting the entire opt-out process. Most often, websites achieved this effect by introducing confusing double negatives (e.g., ‘Uncheck the box if you prefer not to receive email updates’), or by using negatives to alter expected courses of action, such as checking a box to opt out (e.g., ‘We would like to send you emails. If you do not wish to be contacted via email, please ensure that the box is not checked’). We note here that we only considered an opt-out choice as a Trick Question dark pattern when it was misleading, such as when the user has to check a box and the text began with an affirmative statement about the undesirable practice (e.g., ‘We want to send you marketing email...’) since these would more likely be missed by users as opposed to ones that began with the opt-out choice (e.g., ‘Please tick here to opt-out of...’). 9 Trick Questions exploits the default and framing effect cognitive biases in users, who become more susceptible to a choice they erroneously believe is aligned with their preferences. Figure 5c shows one instance of Trick Questions on newbalance.co.uk . In our data set, we found a total of 9 such instances, occurring most often during the checkout process when collecting user information to complete purchases. Using our taxonomy of dark pattern characteristics, we classify Trick Questions as asymmetric (opting out is more burdensome than opting in) and covert (users fail to understand the effect of their choice as a consequence of the confusing language) in nature.. Stopping processing.\n",
      "Relaxed pass subheader count: 0\n",
      "\n",
      "Extracted Sections:\n",
      "Subheading: Introduction\n",
      "Text: Dark Patterns at Scale 81:15 (a) Countdown Timer on mattressfirm.com . The header displays a Flash Sale where the majority of discounted products remain the same on a day-to-day basis. (b) Countdown Timer on justfab.com . The offer is available even after the timer expires. (c) Limited-time Message on chicwish.com . The website claims the sale will end ‘soon’ without stating a deadline. Fig. 4. Two types of the Urgency category of dark patterns. Countdown Timers . The ‘Countdown Timer’ dark pattern is a dynamic indicator of a deadline, counting down until the deadline expires. Figures 4a and 4b show the Countdown Timer dark pattern on mattressfirm.com and justfab.com , respectively. One indicates the deadline for a recurring Flash Sale , the other a Member Exclusive . In our data set, we found a total of 393 instances of the Countdown Timer dark pattern. Deceptive Countdown Timers. Using the visit-and-record method described in Section 4.4, we examined the countdown timers in our data set for deceptive practices. We stitched the screenshots of each countdown timer from the repeated visits of our crawler to a website into a video, and viewed the resulting videos to observe the behavior of the timers. We considered a countdown timer deceptive if (1) the timer reset after timeout with the same offer still valid, or (2) the timer expired but the offer it claimed was expiring was still valid even following expiration. In our data set, we discovered a total of 157 instances of deceptive Countdown Timers on 140 shopping websites. One such example is shown in Figure 4b on justfab.com , where the advertised offer remains valid even after the countdown timer of 60 minutes expires. Using our taxonomy of dark pattern characteristics, we classify Countdown Timers as partially covert (it creates a heightened sense of immediacy, unbeknownst to at least some users), and sometimes deceptive (it can mislead users into believing an offer is expiring when in reality it is not) in nature. Limited-time Messages . Unlike Countdown Timers, the ‘Limited-time Message’ dark pattern is a static urgency message without an accompanying deadline. By not stating the deadline, websites withhold information from users, and thus misrepresent the nature of the offer [ 20 ]. Figure 4c shows an instance of the Limited-time Message dark pattern on chicwish.com , where the advertised sale is stated to end ‘soon’ with no mention of the end date. For every such instance we discovered, we verified that the shopping website made no disclosure about the accompanying deadline (e.g., in 81:16 Arunesh Mathur et al. (a) Confirmshaming on radioshack.com . The option to dismiss the popup is framed to shame the user into avoiding it. (b) Visual Interference on greenfingers.com . The option to opt out of marketing communication is grayed, making it seem un- available even though it can be clicked. (c) Trick Questions on newbalance.co.uk . Opting out of marketing communication requires ticking the checkbox. (d) Pressured Selling on 1800flowers.com . The most expensive product is the default. Fig. 5. Four types of the Misdirection category of dark patterns. the fine print and in the terms of sale pages). In our data set, we discovered a total of 88 instances of the Limited-time Message dark pattern. Using our taxonomy of dark pattern characteristics, we classify Limited-time Messages as at least partially covert (similar to Countdown Timers), and information hiding (unlike Countdown Timers, they do not reveal the deadline in their offers) in nature. 5.1.3 Misdirection. The ‘Misdirection’ category of dark patterns uses visuals, language, and emo- tion to steer users toward or away from making a particular choice. Misdirection functions by exploiting different affective mechanisms and cognitive biases in users without actually restricting the set of choices available to users. Our version of the Misdirection dark pattern is inspired by Brignull’s original Misdirection dark pattern [ 32 ]. However, while Brignull considered Misdirection to occur exclusively using stylistic and visual manipulation, we take a broader view of the term, also including Misdirection caused by language and emotional manipulation. We observed four types of the Misdirection dark pattern: Confirmshaming [ 32 ], Trick Ques- tions [ 32 ], Visual Interference [ 48 ], and Pressured Selling on 244 shopping websites. Figure 5 highlights instances of these four types. Confirmshaming . Coined by Brignull [ 32 ], the ‘Confirmshaming’ dark pattern uses language and emotion to steer users away from making a certain choice. Confirmshaming appeared most often in popup dialogs that solicited users’ email addresses in exchange for a discount, where the option to decline the offer—which the website did not want users to select—was framed as a shameful choice. Examples of such framing included ‘No thanks, I like paying full price’, ‘No thanks, I hate saving money’, and ‘No thanks, I hate fun & games’. By framing the negative option as such, the Confirmshaming dark pattern exploits the framing effect cognitive bias in users and shame, a powerful behavior change agent [ 58 ]. Figure 5a shows one instance of the Confirmshaming dark pattern on radioshack.com . In our data set, we found a total of 169 such instances. Dark Patterns at Scale 81:17 Using our taxonomy of dark pattern characteristics, we classify Confirmshaming as asymmetric (the opt-out choice shames users into avoiding it) in nature. However, Confirmshaming is not covert , since users can visibly see and realize that the design is attempting to influence their choice. Visual Interference . The ‘Visual Interference’ dark pattern uses style and visual presentation to influence users into making certain choices over others (Brignull’s original description of Misdirection [ 32 ]). Although we excluded style information in our clustering analysis, we extracted these patterns as a consequence of examining the text the patterns displayed. In some instances, websites used the Visual Interference dark pattern to make certain courses of action more prominent over others. For example, the subscription offering on exposedskincare.com is stylistically more prominent and emphasized than the non-subscription offering. In other instances, websites used visual effects on textual descriptions to inflate the discounts available for products. For example, websites such as dyson.co.uk and justfab.com offered free gifts to users, and then used these gifts to inflate the savings on users’ purchases in the checkout page—even when the originally selected product was not on discount. In one instance on greenfingers.com , we discovered that the option to decline marketing communication is greyed out, creating an illusion that the option is unavailable or disabled even though it can be clicked, as shown in Figure 5b. In our data set, we found a total of 25 instances of the Visual Interference dark pattern. Using our taxonomy of dark pattern characteristics, we classify Visual Interference as sometimes asymmetric (in some instances it creates unequal choices, steering users into one choice over the other), covert (users may not realize the effect the visual presentation has had on their choice), and sometimes deceptive (e.g., when a website presents users with a ‘lucky draw’ from a list of potential deals, but the draw process is deterministic unbeknownst to users) in nature.\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "\n",
    "def extract_pdf_sections(pdf_path, page_range=None, true_page_1=None,\n",
    "                           header_footer_margin=50, heading_factor=1.2, heading_length_max=80,\n",
    "                           min_subheaders=3, debug=False):\n",
    "    \"\"\"\n",
    "    Extracts sections from a PDF using a two-pass approach.\n",
    "    \n",
    "    First pass uses strict font size criteria: a block is a heading if its text is short (<= heading_length_max)\n",
    "    and its average font size is at least (page average * heading_factor).\n",
    "    \n",
    "    If fewer than min_subheaders are detected, a second pass is run that treats any block as a heading if its average\n",
    "    font size is greater than the page average and its text is short.\n",
    "    \n",
    "    Processing stops if a block containing \"References\" is encountered.\n",
    "    \n",
    "    Parameters:\n",
    "      pdf_path (str): Path to the PDF.\n",
    "      page_range (tuple): (start, end) as viewer page numbers.\n",
    "      true_page_1 (int): The viewer page number corresponding to the first \"real\" content page.\n",
    "      header_footer_margin (float): Margin in points to ignore blocks near the top/bottom.\n",
    "      heading_factor (float): In the first pass, required multiplier of page average font size.\n",
    "      heading_length_max (int): Maximum length of text to be considered a heading.\n",
    "      min_subheaders (int): Minimum number of subheaders expected.\n",
    "      debug (bool): If True, prints debug info.\n",
    "      \n",
    "    Returns:\n",
    "      List[Dict]: Each dict has \"subheading\" and \"text\" keys.\n",
    "    \"\"\"\n",
    "    \n",
    "    def adjust_page_range(page_range, true_page_1):\n",
    "        # Convert user page numbers (starting at 1) into zero-based PDF indices.\n",
    "        if not page_range or true_page_1 is None:\n",
    "            return None\n",
    "        start, end = page_range\n",
    "        adjusted_start = (start - 1) + (true_page_1 - 1)\n",
    "        adjusted_end   = (end - 1)   + (true_page_1 - 1)\n",
    "        return (adjusted_start, adjusted_end)\n",
    "    \n",
    "    def run_extraction(use_relaxed_heading=False):\n",
    "        sections = []\n",
    "        current_section = {\"subheading\": \"Introduction\", \"text\": \"\"}\n",
    "        subheader_count = 0\n",
    "        \n",
    "        doc = fitz.open(pdf_path)\n",
    "        adjusted = adjust_page_range(page_range, true_page_1) if (page_range and true_page_1) else None\n",
    "        if adjusted:\n",
    "            page_nums = range(adjusted[0], adjusted[1] + 1)\n",
    "        else:\n",
    "            page_nums = range(len(doc))\n",
    "        \n",
    "        stop_processing = False\n",
    "        for page_num in page_nums:\n",
    "            if stop_processing:\n",
    "                break\n",
    "            page = doc[page_num]\n",
    "            page_dict = page.get_text(\"dict\")\n",
    "            page_height = page.rect.height\n",
    "            \n",
    "            # Compute average font size for body text (ignoring blocks in header/footer regions)\n",
    "            body_font_sizes = []\n",
    "            for block in page_dict[\"blocks\"]:\n",
    "                if block[\"bbox\"][1] < header_footer_margin or block[\"bbox\"][3] > (page_height - header_footer_margin):\n",
    "                    continue\n",
    "                for line in block.get(\"lines\", []):\n",
    "                    for span in line.get(\"spans\", []):\n",
    "                        size = span.get(\"size\", 0)\n",
    "                        if size:\n",
    "                            body_font_sizes.append(size)\n",
    "            page_avg_font = sum(body_font_sizes)/len(body_font_sizes) if body_font_sizes else 10\n",
    "            \n",
    "            if debug:\n",
    "                print(f\"Page {page_num}: average font size = {page_avg_font:.2f}\")\n",
    "            \n",
    "            for block in page_dict[\"blocks\"]:\n",
    "                bbox = block[\"bbox\"]\n",
    "                if bbox[1] < header_footer_margin or bbox[3] > (page_height - header_footer_margin):\n",
    "                    continue  # Skip header/footer blocks\n",
    "                \n",
    "                # Combine text from all spans in the block.\n",
    "                block_text = \"\"\n",
    "                span_sizes = []\n",
    "                for line in block.get(\"lines\", []):\n",
    "                    for span in line.get(\"spans\", []):\n",
    "                        text = span.get(\"text\", \"\").strip()\n",
    "                        if text:\n",
    "                            block_text += text + \" \"\n",
    "                            span_sizes.append(span.get(\"size\", 0))\n",
    "                block_text = block_text.strip()\n",
    "                if not block_text:\n",
    "                    continue\n",
    "                \n",
    "                # Stop processing if \"References\" is encountered.\n",
    "                if \"references\" in block_text.lower():\n",
    "                    if debug:\n",
    "                        print(f\"Encountered 'References' in block: {block_text}. Stopping processing.\")\n",
    "                    stop_processing = True\n",
    "                    break\n",
    "                \n",
    "                block_avg_size = sum(span_sizes)/len(span_sizes) if span_sizes else page_avg_font\n",
    "                if debug:\n",
    "                    print(f\"Block text: {block_text}\")\n",
    "                    print(f\"Block avg size: {block_avg_size:.2f}, Page avg: {page_avg_font:.2f}\")\n",
    "                \n",
    "                is_heading = False\n",
    "                if not use_relaxed_heading:\n",
    "                    # Strict criteria: text length is within limit and average size >= page_avg * heading_factor.\n",
    "                    if len(block_text) <= heading_length_max and block_avg_size >= page_avg_font * heading_factor:\n",
    "                        is_heading = True\n",
    "                        if debug:\n",
    "                            print(f\"--> Strict criteria met for heading: '{block_text}'\")\n",
    "                else:\n",
    "                    # Relaxed criteria: text length is within limit and average size is just greater than page_avg.\n",
    "                    if len(block_text) <= heading_length_max and block_avg_size > page_avg_font:\n",
    "                        is_heading = True\n",
    "                        if debug:\n",
    "                            print(f\"--> Relaxed criteria met for heading: '{block_text}'\")\n",
    "                \n",
    "                if is_heading:\n",
    "                    if current_section[\"text\"]:\n",
    "                        sections.append(current_section)\n",
    "                    current_section = {\"subheading\": block_text, \"text\": \"\"}\n",
    "                    subheader_count += 1\n",
    "                else:\n",
    "                    if current_section[\"text\"]:\n",
    "                        current_section[\"text\"] += \" \"\n",
    "                    current_section[\"text\"] += block_text\n",
    "            # End of page loop.\n",
    "        if current_section[\"text\"]:\n",
    "            sections.append(current_section)\n",
    "        return sections, subheader_count\n",
    "    \n",
    "    # First pass: strict criteria.\n",
    "    sections, count = run_extraction(use_relaxed_heading=False)\n",
    "    if debug:\n",
    "        print(f\"Strict pass subheader count: {count}\")\n",
    "    # If too few subheaders, run second pass with relaxed criteria.\n",
    "    if count < min_subheaders:\n",
    "        print(f\"Only {count} subheaders found with strict criteria. Retrying with relaxed criteria.\")\n",
    "        sections, count = run_extraction(use_relaxed_heading=True)\n",
    "        if debug:\n",
    "            print(f\"Relaxed pass subheader count: {count}\")\n",
    "    \n",
    "    return sections\n",
    "\n",
    "# Example usage with debug prints:\n",
    "\n",
    "pdf_path = r\"raw_syllabi\\master_courses\\Human_computer_interaction\\pdf_material\\Mathur-2019-Dark-patterns-at-scale.pdf\"  # Change to your actual PDF path.\n",
    "# For example, if your viewer shows pages 1-12 and the \"true\" page 1 is 15:\n",
    "sections = extract_pdf_sections(pdf_path, page_range=(1, 12), true_page_1=15,\n",
    "                                header_footer_margin=50, heading_factor=1.2,\n",
    "                                heading_length_max=80, min_subheaders=3, debug=True)\n",
    "print(\"\\nExtracted Sections:\")\n",
    "for sec in sections:\n",
    "    print(\"Subheading:\", sec[\"subheading\"])\n",
    "    print(\"Text:\", sec[\"text\"])\n",
    "    print(\"-----\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'subheading': 'Introduction',\n",
       "  'text': 'Dark Patterns at Scale 81:15 (a) Countdown Timer on mattressfirm.com . The header displays a Flash Sale where the majority of discounted products remain the same on a day-to-day basis. (b) Countdown Timer on justfab.com . The offer is available even after the timer expires. (c) Limited-time Message on chicwish.com . The website claims the sale will end ‘soon’ without stating a deadline. Fig. 4. Two types of the Urgency category of dark patterns. Countdown Timers . The ‘Countdown Timer’ dark pattern is a dynamic indicator of a deadline, counting down until the deadline expires. Figures 4a and 4b show the Countdown Timer dark pattern on mattressfirm.com and justfab.com , respectively. One indicates the deadline for a recurring Flash Sale , the other a Member Exclusive . In our data set, we found a total of 393 instances of the Countdown Timer dark pattern. Deceptive Countdown Timers. Using the visit-and-record method described in Section 4.4, we examined the countdown timers in our data set for deceptive practices. We stitched the screenshots of each countdown timer from the repeated visits of our crawler to a website into a video, and viewed the resulting videos to observe the behavior of the timers. We considered a countdown timer deceptive if (1) the timer reset after timeout with the same offer still valid, or (2) the timer expired but the offer it claimed was expiring was still valid even following expiration. In our data set, we discovered a total of 157 instances of deceptive Countdown Timers on 140 shopping websites. One such example is shown in Figure 4b on justfab.com , where the advertised offer remains valid even after the countdown timer of 60 minutes expires. Using our taxonomy of dark pattern characteristics, we classify Countdown Timers as partially covert (it creates a heightened sense of immediacy, unbeknownst to at least some users), and sometimes deceptive (it can mislead users into believing an offer is expiring when in reality it is not) in nature. Limited-time Messages . Unlike Countdown Timers, the ‘Limited-time Message’ dark pattern is a static urgency message without an accompanying deadline. By not stating the deadline, websites withhold information from users, and thus misrepresent the nature of the offer [ 20 ]. Figure 4c shows an instance of the Limited-time Message dark pattern on chicwish.com , where the advertised sale is stated to end ‘soon’ with no mention of the end date. For every such instance we discovered, we verified that the shopping website made no disclosure about the accompanying deadline (e.g., in 81:16 Arunesh Mathur et al. (a) Confirmshaming on radioshack.com . The option to dismiss the popup is framed to shame the user into avoiding it. (b) Visual Interference on greenfingers.com . The option to opt out of marketing communication is grayed, making it seem un- available even though it can be clicked. (c) Trick Questions on newbalance.co.uk . Opting out of marketing communication requires ticking the checkbox. (d) Pressured Selling on 1800flowers.com . The most expensive product is the default. Fig. 5. Four types of the Misdirection category of dark patterns. the fine print and in the terms of sale pages). In our data set, we discovered a total of 88 instances of the Limited-time Message dark pattern. Using our taxonomy of dark pattern characteristics, we classify Limited-time Messages as at least partially covert (similar to Countdown Timers), and information hiding (unlike Countdown Timers, they do not reveal the deadline in their offers) in nature. 5.1.3 Misdirection. The ‘Misdirection’ category of dark patterns uses visuals, language, and emo- tion to steer users toward or away from making a particular choice. Misdirection functions by exploiting different affective mechanisms and cognitive biases in users without actually restricting the set of choices available to users. Our version of the Misdirection dark pattern is inspired by Brignull’s original Misdirection dark pattern [ 32 ]. However, while Brignull considered Misdirection to occur exclusively using stylistic and visual manipulation, we take a broader view of the term, also including Misdirection caused by language and emotional manipulation. We observed four types of the Misdirection dark pattern: Confirmshaming [ 32 ], Trick Ques- tions [ 32 ], Visual Interference [ 48 ], and Pressured Selling on 244 shopping websites. Figure 5 highlights instances of these four types. Confirmshaming . Coined by Brignull [ 32 ], the ‘Confirmshaming’ dark pattern uses language and emotion to steer users away from making a certain choice. Confirmshaming appeared most often in popup dialogs that solicited users’ email addresses in exchange for a discount, where the option to decline the offer—which the website did not want users to select—was framed as a shameful choice. Examples of such framing included ‘No thanks, I like paying full price’, ‘No thanks, I hate saving money’, and ‘No thanks, I hate fun & games’. By framing the negative option as such, the Confirmshaming dark pattern exploits the framing effect cognitive bias in users and shame, a powerful behavior change agent [ 58 ]. Figure 5a shows one instance of the Confirmshaming dark pattern on radioshack.com . In our data set, we found a total of 169 such instances. Dark Patterns at Scale 81:17 Using our taxonomy of dark pattern characteristics, we classify Confirmshaming as asymmetric (the opt-out choice shames users into avoiding it) in nature. However, Confirmshaming is not covert , since users can visibly see and realize that the design is attempting to influence their choice. Visual Interference . The ‘Visual Interference’ dark pattern uses style and visual presentation to influence users into making certain choices over others (Brignull’s original description of Misdirection [ 32 ]). Although we excluded style information in our clustering analysis, we extracted these patterns as a consequence of examining the text the patterns displayed. In some instances, websites used the Visual Interference dark pattern to make certain courses of action more prominent over others. For example, the subscription offering on exposedskincare.com is stylistically more prominent and emphasized than the non-subscription offering. In other instances, websites used visual effects on textual descriptions to inflate the discounts available for products. For example, websites such as dyson.co.uk and justfab.com offered free gifts to users, and then used these gifts to inflate the savings on users’ purchases in the checkout page—even when the originally selected product was not on discount. In one instance on greenfingers.com , we discovered that the option to decline marketing communication is greyed out, creating an illusion that the option is unavailable or disabled even though it can be clicked, as shown in Figure 5b. In our data set, we found a total of 25 instances of the Visual Interference dark pattern. Using our taxonomy of dark pattern characteristics, we classify Visual Interference as sometimes asymmetric (in some instances it creates unequal choices, steering users into one choice over the other), covert (users may not realize the effect the visual presentation has had on their choice), and sometimes deceptive (e.g., when a website presents users with a ‘lucky draw’ from a list of potential deals, but the draw process is deterministic unbeknownst to users) in nature.'}]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sec"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
