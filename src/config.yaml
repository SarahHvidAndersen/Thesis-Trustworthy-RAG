# config.yaml
model:
  type: "chatui"    # or "hf"
  hf_model: "https://api-inference.huggingface.co/models/meta-llama/Meta-Llama-3-8B-Instruct"
  chatui_model: "llama3.2:1b"

generation:
  n_samples: 5       # number of samples to draw; 0 triggers dummy/demo
  top_k: 5           # number of docs to retrieve
  temperature: 0.9   # sampling temperature
  top_p: 0.9         # nucleus sampling
  max_new_tokens: 150

uncertainty:
  method: "lexical_similarity"
  lexical_similarity:
    metric: "rougeL"
  deg_mat:
    batch_size: 10
    device: "cpu"
    affinity: "entail"
    verbose: True
  eccentricity:
    similarity_score: "NLI_score"
    affinity: "entail"
    verbose: True
    thres: 0.9