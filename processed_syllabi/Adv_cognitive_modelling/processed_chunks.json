[
  {
    "document_type": "research_paper",
    "title": "Taking others into account: combining directly experienced and indirect information in schizophrenia",
    "author": "Arndis Simonsen, Riccardo Fusaroli, Malte Lau Petersen, Arnault-Quentin Vermillet, Vibeke Bliksted, Ole Mors, Andreas Roepstorff and Daniel Campbell-Meiklejohn",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\taking_others_into_account.pdf",
    "date_published": "2021-06-18",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": "Taking others into account: combining directly experienced and indirect information in schizophrenia Arndis Simonsen, 1,2,3,4,5,† Riccardo Fusaroli, 3,6,† Malte Lau Petersen, 3 Arnault-Quentin Vermillet, 3,6 Vibeke Bliksted, 1,2,3 Ole Mors, 1,2 Andreas Roepstorff 3 and Daniel Campbell-Meiklejohn 7 † These authors contributed equally to this work. See Serie`s (doi.10.1093/brain/awab126) for a scientific commentary on this article. An abnormality in inference, resulting in distorted internal models of the world, has been argued to be a common mechanism underlying the heterogeneous psychopathology in schizophrenia. However, findings have been mixed as to wherein the abnormality lies and have typically failed to find convincing relations to symptoms. The limited and inconsistent findings may have been due to methodological limitations of the experimental design, such as conflating other factors (e.g. comprehension) with the inferential process of interest, and a failure to adequately assess and model the key aspects of the inferential process. Here, we investigated probabilistic inference based on multiple sources of information using a new digital version of the beads task, framed in a social context. Thirty-five patients with schizophrenia or schizoaffective disorder with a wide range of symptoms and 40 matched healthy control subjects performed the task, where they guessed the coour of the next marble drawn from a jar based on a sample from the jar as well as the choices and the expressed confidence of four people, each with their own independent sample (which was hidden from participant view). We relied on theoretically motivated computational models to assess which model best captured the inferential process and investigated whether it could serve as a mechanistic model for both psychotic and negative symptoms. We found that ‘circular inference’ best described the inference process, where patients over-weighed and ovecounted direct experience and under-weighed information from others",
    "chunk_id": "Adv_cognitive_modelling_op-brai210065_1603..1614.json_chunk_1"
  },
  {
    "document_type": "research_paper",
    "title": "Taking others into account: combining directly experienced and indirect information in schizophrenia",
    "author": "Arndis Simonsen, Riccardo Fusaroli, Malte Lau Petersen, Arnault-Quentin Vermillet, Vibeke Bliksted, Ole Mors, Andreas Roepstorff and Daniel Campbell-Meiklejohn",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\taking_others_into_account.pdf",
    "date_published": "2021-06-18",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". We found that ‘circular inference’ best described the inference process, where patients over-weighed and ovecounted direct experience and under-weighed information from others. Crucially, overcounting of direct experience was uniquely associated with most psychotic and negative symptoms. In addition, patients with worse social cogntive function had more difficulties using others’ confidence to inform their choices. This difficulty was related to worse real-world functioning. The findings could not be easily ascribed to differences in working memory, executive function, intelligence or antipsychotic medication. These results suggest hallucinations, delusions and negative symptoms could stem from a common underlying abnomality in inference, where directly experienced information is assigned an unreasonable weight and taken into account multiple times. By this, even unreliable first-hand experiences may gain disproportionate significance. The effect could lead to false perceptions (hallucinations), false beliefs (delusions) and deviant social behaviour (e.g. loss of interest in others, bizarre and inappropriate behaviour). This may be particularly problematic for patients with social cognitive defcits, as they may fail to make use of corrective information from others, ultimately leading to worse social functioning. 1 Psychosis Research Unit, Aarhus University Hospital, 8200 Aarhus, Denmark 2 The Lundbeck Foundation Initiative for Integrative Psychiatric Research, iPSYCH, 8200 Aarhus, Denmark Received June 22, 2020. Revised December 11, 2020. Accepted January 05, 2021. Advance access publication April 8, 2021 V C The Author(s) (2021). Published by Oxford University Press on behalf of the Guarantors of Brain. All rights reserved",
    "chunk_id": "Adv_cognitive_modelling_op-brai210065_1603..1614.json_chunk_2"
  },
  {
    "document_type": "research_paper",
    "title": "Taking others into account: combining directly experienced and indirect information in schizophrenia",
    "author": "Arndis Simonsen, Riccardo Fusaroli, Malte Lau Petersen, Arnault-Quentin Vermillet, Vibeke Bliksted, Ole Mors, Andreas Roepstorff and Daniel Campbell-Meiklejohn",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\taking_others_into_account.pdf",
    "date_published": "2021-06-18",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Accepted January 05, 2021. Advance access publication April 8, 2021 V C The Author(s) (2021). Published by Oxford University Press on behalf of the Guarantors of Brain. All rights reserved. For permissions, please email: journals.permissions@oup.com Downloaded from https://academic.oup.com/brain/article/144/5/1603/6214913 by guest on 24 March 2025 3 The Interacting Minds Centre, School of Culture and Society, Aarhus University, 8000 Aarhus, Denmark 4 Psykiatriski depilin, Landssju ́krahu ́sið, 100 To ́rshavn, Faroe Islands 5 I ́ legusavnið, 100 To ́rshavn, Faroe Islands 6 Cognitive Science, Aarhus University, 8000 Aarhus, Denmark 7 School of Psychology, University of Sussex, Falmer BN1 9RH, UK Correspondence to: Arndis Simonsen Psychosis Research Unit Aarhus University Hospital, Psychiatry Palle Juul-Jensens Blvd. 175, Entrance K DK-8200 Aarhus N Denmark E-mail: arndis.simonsen@clin.au.dk Keywords: cue integration; information integration; Bayesian inference; circular inference; probabilistic decisiomaking Abbreviations: PSP = Personal and Social Performance Scale; TASIT = The Awareness of Social Inference Test Introduction Abnormal inference mechanisms in the nervous system resulting in distorted internal models of the world have been argued to be key to schizophrenia. 1 Within this hierarchical Bayesian approach to brain function, beliefs and percepts emerge from an optimal itegration of prior expectations and new observations. 2 However, failures in this process may cause abnormal perceptions (hallucnations), abnormal beliefs (delusions) and possibly even negative symptoms such as asociality. 1 Despite the elegance of this theory of one common mechanism giving rise to such diverse symptoms, empirical evidence for this is yet scarce. 3 Findings have been mixed as to wherein the abnormality lies. 3 – 10 Furthermore, the identified inferential abnormalities are tyically only associated with one type of symptom (e.g. delusions), if any at all",
    "chunk_id": "Adv_cognitive_modelling_op-brai210065_1603..1614.json_chunk_3"
  },
  {
    "document_type": "research_paper",
    "title": "Taking others into account: combining directly experienced and indirect information in schizophrenia",
    "author": "Arndis Simonsen, Riccardo Fusaroli, Malte Lau Petersen, Arnault-Quentin Vermillet, Vibeke Bliksted, Ole Mors, Andreas Roepstorff and Daniel Campbell-Meiklejohn",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\taking_others_into_account.pdf",
    "date_published": "2021-06-18",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". 3 – 10 Furthermore, the identified inferential abnormalities are tyically only associated with one type of symptom (e.g. delusions), if any at all. 5 , 9 – 11 However, the limited and inconsistent findings could be due to methodological limitations of the experimental design, where other factors such as task comprehension and working meory abilities are conflated with the inferential process of interest, and a failure to adequately model the inferential process. 5 , 7 , 9 , 12 – 14 Typically, studies have used variations of the classical beads task to investigate explicit probabilistic inference in schizophrenia. This is a data-gathering paradigm, where participants sample beads from a hidden jar until they feel confident enough to guess which of two jars the beads are sampled from (e.g. the jar with most blue beads or most yellow beads) based on the colour of the sampled beads. The task was originally adapted to assess the reltion between inference and delusions, and although patients are consistently found to gather less information and tend to ‘jump to conclusions’ [i.e. show fewer draws-to-decision (DTD)], the relation between DTD and delusions has been found weak at best. 9 , 11 In fact, recent studies addressing limitations of the original task have found that both delusion proneness in healthy individuals and dlusion severity in patients are associated with increased informtion-seeking behaviour (i.e. increased DTD). 5 , 15 Further computational analyses by Baker et al . 5 showed that delusional patients displayed stronger reliance on beliefs formed early in the inferential process, or in other words, they had ‘sticky’ beliefs that were resistant to new evidence. 5 , 16 A reliable model of how patients perform sequential integrtion of one type of information could indeed prove essential in understanding a key abnormality in schizophrenia. However, this research neglects that we usually make inferences based on a multitude of information sources that vary both in type and reliability",
    "chunk_id": "Adv_cognitive_modelling_op-brai210065_1603..1614.json_chunk_4"
  },
  {
    "document_type": "research_paper",
    "title": "Taking others into account: combining directly experienced and indirect information in schizophrenia",
    "author": "Arndis Simonsen, Riccardo Fusaroli, Malte Lau Petersen, Arnault-Quentin Vermillet, Vibeke Bliksted, Ole Mors, Andreas Roepstorff and Daniel Campbell-Meiklejohn",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\taking_others_into_account.pdf",
    "date_published": "2021-06-18",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". However, this research neglects that we usually make inferences based on a multitude of information sources that vary both in type and reliability. This is the case for low-level perception, 17 but perhaps even more so for our social lives, where we constantly have to deal with different people that say or do different things with different degrees of certainty. This information has to be combined with our own experiences and beliefs, which may be more or less certain. In short, the classical beads task fails to address how we simultaeously balance and integrate heterogeneous information sources. This is of particular relevance in schizophrenia, where patients typically struggle with such everyday situations. Schizophrenia has even been described as a disorder of self-other processing, diplaying problems with self-other integration and distinction that range from self-disturbances (e.g. delusions of being controlled) to altered mimicry (e.g. echolalia) and difficulties inferring others’ mental states and distinguishing them from one’s own (i.e. metalizing deficits). 18 Indications of inferential problems with multiple sources were reported in a recent study by Jardri et al . 3 In this study, participants had to integrate two different sources of information, which varied in degree of certainty, in order to decide which lake a red fish was from. The two sources of information were: a prior (the basket size associated with each of two lakes, reflecting the probability of catching a red fish in them) and sensory evidence (the distribution of red and black fish in each lake). Interestingly, patients relied more on the most recent evidence (contrary to the findings of Baker et al . 5 ) and this tendency was related to psychotic symptoms. There may be several reasons for this. First, participants could only see the fish distributions in the lakes (sensory evidence) and not the basket sizes (prior information) when making the decision",
    "chunk_id": "Adv_cognitive_modelling_op-brai210065_1603..1614.json_chunk_5"
  },
  {
    "document_type": "research_paper",
    "title": "Taking others into account: combining directly experienced and indirect information in schizophrenia",
    "author": "Arndis Simonsen, Riccardo Fusaroli, Malte Lau Petersen, Arnault-Quentin Vermillet, Vibeke Bliksted, Ole Mors, Andreas Roepstorff and Daniel Campbell-Meiklejohn",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\taking_others_into_account.pdf",
    "date_published": "2021-06-18",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". There may be several reasons for this. First, participants could only see the fish distributions in the lakes (sensory evidence) and not the basket sizes (prior information) when making the decision. Patients may have disregarded the prior information due to woring memory deficits, which are prevalent in schizophrenia. 19 Indeed, weighing of prior information was associated with woring memory performance. 3 Second, the task is highly abstract. It may not be clear to patients how they should interpret and use the basket size compared to the number of red fish in the lakes. Such comprehension difficulties may contribute to larger reliance on sensory evidence. Finally, the task design conflates information type (basket or lake) and time (prior or new evidence). Thus, it is possible that if the lakes and baskets were presented in reversed order or simultaneously, we would still see a larger reliance on the lake distributions, i.e. it may be qualities of the information source rather than order that matters. To address these alternative interpretations and directly invetigate probabilistic inference based on multiple sources of infomation, we used a new version of the beads task. 21 On each trial, Downloaded from https://academic.oup.com/brain/article/144/5/1603/6214913 by guest on 24 March 2025 participants had to guess the colour (red or green) of the next mable drawn from a hidden jar based on a sample from the jar (eight marbles) and the choice and confidence of four other people. Each of the others’ choices were said to be based on their own sample of eight marbles from the same jar. By systematically varying the evdence for a specific colour in the sample and the others’ choices, we could assess how patients integrate different sources of infomation varying in degree of certainty. Importantly, all information was present when they had to make a choice to avoid confounding inference with working memory function",
    "chunk_id": "Adv_cognitive_modelling_op-brai210065_1603..1614.json_chunk_6"
  },
  {
    "document_type": "research_paper",
    "title": "Taking others into account: combining directly experienced and indirect information in schizophrenia",
    "author": "Arndis Simonsen, Riccardo Fusaroli, Malte Lau Petersen, Arnault-Quentin Vermillet, Vibeke Bliksted, Ole Mors, Andreas Roepstorff and Daniel Campbell-Meiklejohn",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\taking_others_into_account.pdf",
    "date_published": "2021-06-18",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Importantly, all information was present when they had to make a choice to avoid confounding inference with working memory function. To ease task comprhension and make the task less abstract, we gave careful task instructions (see ‘Materials and methods’ section) and framed the task in a social context, since reasoning is known to be easier in social contexts, 22 thus reducing such potential confound of misuderstanding. Altered inference may become particularly evident in social contexts, 23 given the pronounced social cognitive deficits in schizophrenia 24 , 25 and the very social nature of many symptoms (e.g. hearing voices, feeling persecuted, asociality). 26 To investigate the patients’ information integration processes, we relied on theoretically motivated computational models based on Bayes theorem. A common concern in the study of mental disoders is the lack of adequate modelling of behavioural data, with strong arguments in favour of theoretically motivated computatioal models replacing more traditional statistical techniques. 27 In this study, we compared four different Bayesian models as well as two control models: (i) simple Bayes; (ii) weighted Bayes; (iii) circular iference with; and (iv) without interference; (v) a heuristic model; and (vi) the generalized linear model (GLM) (for details, see ‘Materials and methods’ section and Supplementary material ). The Bayesian framework provides a formal solution to optimal integration of iformation under uncertainty where each source of information is weighed according to its precision or reliability. While simple and weighted Bayes are established models to integrate information, cicular inference is a biologically informed model that is shown to acount for psychotic symptoms. 3 , 20 The model builds on the theory that a failure to maintain the balance in excitatory/inhibitory neural processing may cause reverberation of sensory and prior informtion, so that sensory information is misinterpreted as prior beliefs (or vice versa)",
    "chunk_id": "Adv_cognitive_modelling_op-brai210065_1603..1614.json_chunk_7"
  },
  {
    "document_type": "research_paper",
    "title": "Taking others into account: combining directly experienced and indirect information in schizophrenia",
    "author": "Arndis Simonsen, Riccardo Fusaroli, Malte Lau Petersen, Arnault-Quentin Vermillet, Vibeke Bliksted, Ole Mors, Andreas Roepstorff and Daniel Campbell-Meiklejohn",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\taking_others_into_account.pdf",
    "date_published": "2021-06-18",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". The net result is an overcounting of potentially unrliable information, which might lead to abnormal perception (hallcinations) and abnormal beliefs (delusions). 3 , 20 We compared patients’ performance to a matched healthy cotrol group, and we investigated whether symptoms and social functioning were related to how patients integrated information. In addition, we assessed whether altered inference was related to social cognitive deficits, a relationship that is not yet well undestood. 6 , 28 – 30 Specifically, we assessed whether there was a relation between inferences made in the two contexts, i.e. inferences based on integration of direct experience and information from others, and mental state inferences based on integration of multiple social cues. Finally, we assessed the role of potential confounders (woring memory, executive function, intelligence, antipsychotic medcation). We hypothesized that patients would discount information from others in favour of directly experienced informtion (i.e. their own sample) relative to controls, and that this infomation integration style would be related to more severe psychotic symptoms, more severe negative symptoms, larger social cogntive deficits and lower social functioning. Materials and methods Participants Forty patients with an ICD-10 DCR diagnosis of schizophrenia or schizoaffective disorder and 40 matched healthy control subjects were included in the study (recruitment period: June 2013 to August 2014). Diagnosis was confirmed using the Schedules for Clinical Assessment in Neuropsychiatry (SCAN). 31 , 32 Controls were pairwise matched to the patients according to age, gender, childhood resdence as well as commenced educational level (or parents’ eductional attainment if higher than the patient’s) and parental socioeconomic status when possible ( Table 1 ). Patients were recruited through the Psychiatric Centre of the National Hospital of the Faroe Islands",
    "chunk_id": "Adv_cognitive_modelling_op-brai210065_1603..1614.json_chunk_8"
  },
  {
    "document_type": "research_paper",
    "title": "Taking others into account: combining directly experienced and indirect information in schizophrenia",
    "author": "Arndis Simonsen, Riccardo Fusaroli, Malte Lau Petersen, Arnault-Quentin Vermillet, Vibeke Bliksted, Ole Mors, Andreas Roepstorff and Daniel Campbell-Meiklejohn",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\taking_others_into_account.pdf",
    "date_published": "2021-06-18",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Patients were recruited through the Psychiatric Centre of the National Hospital of the Faroe Islands. Control subjects were cotacted based on age and gender and, if they fulfilled the inclusion criteria and matched a patient, were offered to participate in the study. Participants were between 18 and 55 years old. The inclsion criteria were: no current psychoactive substance use disoders (except nicotine), no head trauma, neurological or medical disorder that could affect brain functioning, and an estimated IQ 4 70 based on prior history or testing. In addition, the controls should not be taking psychotropic drugs or have a history of severe mental disorder either among themselves or a first-degree relative. The participants were screened for recent use of psychoactive sustances (THC/cannabis, opiates, amphetamine, MDMA, benzodizepines, cocaine) using a urine stick (NanoSticka V R 200-32). Patients without a prescription who had a positive test were excluded. None of the controls had a positive test. Based on pilot testing and a previous study using a similar paradigm, 21 we aimed to include 40 participants in each group to allow up to 20% drop-out. A total of 56 patients and 45 controls were invited to the initial interview. Of these nine declined to paticipate (six patients, three control subjects), seven participants (five patients, two control subjects) did not fulfil the inclusion crteria and were therefore excluded, and five patients dropped out during initial interviewing. Two additional patients were excluded after initial inclusion as it became clear that they did not fulfil the inclusion criteria. In addition, two patients did not perform the task because they did not understand the task instructions and one patient opted out due to lack of time. Thus, data from 35 patients (four with schizoaffective disorder) and 40 controls were included in the analyses. Thirty-two of these patients were taking antipsychotic medication at the time of testing",
    "chunk_id": "Adv_cognitive_modelling_op-brai210065_1603..1614.json_chunk_9"
  },
  {
    "document_type": "research_paper",
    "title": "Taking others into account: combining directly experienced and indirect information in schizophrenia",
    "author": "Arndis Simonsen, Riccardo Fusaroli, Malte Lau Petersen, Arnault-Quentin Vermillet, Vibeke Bliksted, Ole Mors, Andreas Roepstorff and Daniel Campbell-Meiklejohn",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\taking_others_into_account.pdf",
    "date_published": "2021-06-18",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Thirty-two of these patients were taking antipsychotic medication at the time of testing. Antipsychotic dose was converted to chlorpromazine equivalents. 33 , 34 General procedure The task was administered as part of a larger battery of cognitive tests. In addition, symptom severity and level of functioning were assessed with the Scale for the Assessment of Positive/Negative Symptoms (SAPS/SANS) 35 , 36 and the Personal and Social Performance Scale (PSP), 37 respectively. We used the Danish vesion of ‘The Awareness of Social Inference Test’ (TASIT, Part 2: Social Inference–Minimal) 38 to assess social cognition. It consists of short video vignettes depicting everyday interactions and paticipants answer yes/no questions about the protagonists’ thoughts, feelings, intentions and meaning. 39 , 40 The test requires social cue integration (e.g. intonation, facial expression, body laguage, verbal content) in order to infer when the protagonists are being sincere or sarcastic. We used the TASIT 2A total score. We used four subtests (Vocabulary, Similarities, Block Design, and Matrix Reasoning) of the Wechsler Adult Intelligence ScalIV 41 to estimate IQ. Working memory and executive function were assessed with Spatial Working Memory and the Intra-Extra Dimensional Set Shift (IED) from the Cambridge Neuropsychological Test Automated Battery (CANTAB), 42 respecively ( Table 1 ). The study was performed in accordance with the relevant national guidelines and regulations and with the Declaration of Helsinki. Written informed consent was obtained from all participants after the procedure had been explained. Downloaded from https://academic.oup.com/brain/article/144/5/1603/6214913 by guest on 24 March 2025 Participants received a fixed amount in compensation (gift card) for participating in the study. Experimental paradigm We used a shortened version of the urn task described in Campbell-Meiklejohn et al",
    "chunk_id": "Adv_cognitive_modelling_op-brai210065_1603..1614.json_chunk_10"
  },
  {
    "document_type": "research_paper",
    "title": "Taking others into account: combining directly experienced and indirect information in schizophrenia",
    "author": "Arndis Simonsen, Riccardo Fusaroli, Malte Lau Petersen, Arnault-Quentin Vermillet, Vibeke Bliksted, Ole Mors, Andreas Roepstorff and Daniel Campbell-Meiklejohn",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\taking_others_into_account.pdf",
    "date_published": "2021-06-18",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Experimental paradigm We used a shortened version of the urn task described in Campbell-Meiklejohn et al . 21 To ensure task comprehension, paticipants received detailed task instructions, practice trials and debriefing after the task. Although the jars were always hidden bhind cardboard during the task ( Fig. 1 ), during task instructions, participants were shown a picture of many jars containing diffeent distributions of red and green marbles, to make it clear that all jars were full of marbles and contained different distributions. In addition, they performed an individual pre-task before the actual task. It contained 16 trials plus five practice trials. On each trial, they were presented with a random sample of eight marbles (zero to eight red and green marbles) from a hidden jar and were instructed to infer the colour (red or green) of the next marble drawn from that specific jar as well as state their confidence in that choice (high or low). The marbles were said to be replaced bfore the decision had to be made. This pre-task was used to make sure that the participants understood the responses of the other people (agents) during the following task, including how they might be using confidence. During the experimental task, participants were again prsented with a new hidden jar on every trial and were instructed to infer the colour of the next marble drawn from that jar. Before deciding, however, participants were presented with a sample of eight marbles and the decisions of four other people (agents), which each stated their choice as well as the confidence in that choice ( Fig. 1 ). Others’ decisions were said to be based on their own sample of eight marbles randomly drawn from the same jar and all the marbles were said to be replaced before the participant had to make a decision. Due to the specific patient group, we delibeately avoided providing an elaborate cover story about these other people",
    "chunk_id": "Adv_cognitive_modelling_op-brai210065_1603..1614.json_chunk_11"
  },
  {
    "document_type": "research_paper",
    "title": "Taking others into account: combining directly experienced and indirect information in schizophrenia",
    "author": "Arndis Simonsen, Riccardo Fusaroli, Malte Lau Petersen, Arnault-Quentin Vermillet, Vibeke Bliksted, Ole Mors, Andreas Roepstorff and Daniel Campbell-Meiklejohn",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\taking_others_into_account.pdf",
    "date_published": "2021-06-18",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Due to the specific patient group, we delibeately avoided providing an elaborate cover story about these other people. Agents’ confidence was communicated as an explicit cue (identical to the response options during the pre-task): the smug (confident cue) or perplexed (unconfident) animated smiley that appeared within the indicated choice (red or green marble) ( Fig. 1 ). To avoid that participants made hasty guessing to reduce task duation, all information was available on the screen for 500 ms before a decision could be made. After a choice, confirmation of the choice was displayed. No feedback was provided",
    "chunk_id": "Adv_cognitive_modelling_op-brai210065_1603..1614.json_chunk_12"
  },
  {
    "document_type": "research_paper",
    "title": "Taking others into account: combining directly experienced and indirect information in schizophrenia",
    "author": "Arndis Simonsen, Riccardo Fusaroli, Malte Lau Petersen, Arnault-Quentin Vermillet, Vibeke Bliksted, Ole Mors, Andreas Roepstorff and Daniel Campbell-Meiklejohn",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\taking_others_into_account.pdf",
    "date_published": "2021-06-18",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". After a choice, confirmation of the choice was displayed. No feedback was provided. The task cosisted of 105 trials (plus 10 practice trials) that were generated by creating every possible combination, across trials, of: the number Table 1 Characteristics of the participants Schizophrenia Mean (SD) Controls Mean (SD) Demographics Sample size, n 35 40 Age 38.0 (10.7) 39.3 (10.5) Sex, males/females, n 22/13 27/13 Handedness, right/left, n 32/3 36/4 Educational level commenced a 2.1 (0.7) 2.3 (0.7) Years of education 12.6 (2.7) 14.3 (3.1) Parental socioeconomic status b , high/middle, n 12/23 13/27 Cognitive functions Estimated IQ 93.3 (14.4) 102.5 (13.8) The awareness of social inference test, total score 44.5 (7.3) 49.7 (5.4) Spatial Working Memory, total errors 16.1 (10.5) 7.6 (9.0) Intra Extra Dimensional Set Shift, total errors adjusted 42.1 (39.3) 18.6 (16.1) Level of functioning Personal and Social Performance Scale 59.8 (13.7) 86.1 (5.1) Living independently/with parents/in institution, n 13/15/7 37/3/0 Early retirement or other financial support c , n 30 0 Illness duration, psychopathology, medication status Illness duration in years 14.7 (9.8) – SAPS total score [range] 4.20 (4.13) [0–13] – Global rating of severity of hallucinations [range] 1.31 (1.94) [0–5] – Global rating of severity of delusions [range] 1.89 (2.03) [0–5] – Global rating of severity of bizarre behaviour [range] 0.49 (0.92) [0–3] – Global rating of positive formal thought disorder [range] 0.51 (0.98) [0–3] – SANS total score [range] 7.66 (4.63) [0–20] – Global rating of affective flattening [range] 1.34 (1.11) [0–4] – Global rating of alogia [range] 0.86 (1.31) [0–4] – Global rating of avolition—apathy [range] 2.34 (1.21) [0–5] – Global rating of anhedonia—asociality [range] 1.97 (1.48) [0–5] – Global rating of attention [range] 1.14 (1.40) [0–4] – Chlorpromazine equivalent dose 703 (577) – SANS = Scale for the Assessment of Negative Symptoms; SAPS = Scale for the Assessment of Positive Symptoms; SD = standard deviation",
    "chunk_id": "Adv_cognitive_modelling_op-brai210065_1603..1614.json_chunk_13"
  },
  {
    "document_type": "research_paper",
    "title": "Taking others into account: combining directly experienced and indirect information in schizophrenia",
    "author": "Arndis Simonsen, Riccardo Fusaroli, Malte Lau Petersen, Arnault-Quentin Vermillet, Vibeke Bliksted, Ole Mors, Andreas Roepstorff and Daniel Campbell-Meiklejohn",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\taking_others_into_account.pdf",
    "date_published": "2021-06-18",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". a Commenced educational level divided into four levels: 1: primary school (up to 10 years of education), 2: secondary school/professional training, 3: bachelor programme or shorter further education, 4: master programme. b Parental socioeconomic status (SES) was based on the parent with the highest education and an estimated salary according to their employment. It was divided into three levels: low, middle, high. None of the parents had a low SES. c For example, cash benefits, sickness benefits. Downloaded from https://academic.oup.com/brain/article/144/5/1603/6214913 by guest on 24 March 2025 of others choosing red or green, confidence of others choosing red or green, and participants’ samples—all varying independently of one another. For each number of others choosing red (0–4), there were 21 trials—three for every possible participant sample (1–7 reds). To reduce the number of necessary trials, agents that chose the same colour had the same confidence level. The trials were randomized. The task had no extrinsic gain or loss. There was no explicit or implicit cost to weighting one’s sample and the infomation from the agents, other than the intrinsic incentive to prvide a correct response. Statistical analyses and computational modelling We implemented four theory-driven models of information intgration, 3 as well as two control models. The models are briefly described here and the full implementation is detailed in the Supplementary material . The simple Bayes model assumes that the directly experienced information (i.e. the participant’s sample) and the information from the agents are fully trusted, thus weiging them equally, i.e. one’s own sample weighs as much as the iformation provided by the choice of one of the agents. In this situation, the optimal form of inference is to directly combine the sources of information using Bayes’ theorem",
    "chunk_id": "Adv_cognitive_modelling_op-brai210065_1603..1614.json_chunk_14"
  },
  {
    "document_type": "research_paper",
    "title": "Taking others into account: combining directly experienced and indirect information in schizophrenia",
    "author": "Arndis Simonsen, Riccardo Fusaroli, Malte Lau Petersen, Arnault-Quentin Vermillet, Vibeke Bliksted, Ole Mors, Andreas Roepstorff and Daniel Campbell-Meiklejohn",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\taking_others_into_account.pdf",
    "date_published": "2021-06-18",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". In this situation, the optimal form of inference is to directly combine the sources of information using Bayes’ theorem. Note that the simple Bayes model—although it is unlikely to capture the actual decsion-making process—is the best model when participants treat the different sources of information equally, and the model acts as a stepping stone to understand and build the more complex moels. The weighted Bayes model builds on the previous model, but allows the participant to attribute different degrees of trust to the directly experienced information and the agents’ information and therefore to weigh their impact on the decision differently. Note that when the two weights are equal and fully trusted (w Self = w Other = 1), the weighted Bayes model is equivalent to the simple Bayes model ( Supplementary Fig. 1 ). The circular inference model builds on the weighted Bayes model by adding two components: (i) a free parameter per information source, indicating the strength of the overcounting (alpha); and (ii) interference between the sources of information. In the weighted Bayes model, directly experienced information and information from the agents are considered only once, while in the circular inference model, the information can be counted multiple times. Note that even if a source of information might be considered multiple times, participants do not need to trust it fully, thus maintaining meaningful weight parameters. We also tested whether the model without the interference term could describe the data just as well, to avoid unnecessary complexity ( Supplementary Fig. 8 ). The circular inference model is equivalent to the weighted Bayes model when both alphas ( a Self and a Other ) are equal to one and no interference is present. If in addition, the weights are both equal to one, the model is equivalent to the siple Bayes model ( Supplementary Fig. 2 ). In order to make our finings more easily comparable with more traditional statistical approaches, 21 we also included a logistic regression model",
    "chunk_id": "Adv_cognitive_modelling_op-brai210065_1603..1614.json_chunk_15"
  },
  {
    "document_type": "research_paper",
    "title": "Taking others into account: combining directly experienced and indirect information in schizophrenia",
    "author": "Arndis Simonsen, Riccardo Fusaroli, Malte Lau Petersen, Arnault-Quentin Vermillet, Vibeke Bliksted, Ole Mors, Andreas Roepstorff and Daniel Campbell-Meiklejohn",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\taking_others_into_account.pdf",
    "date_published": "2021-06-18",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". 2 ). In order to make our finings more easily comparable with more traditional statistical approaches, 21 we also included a logistic regression model. Finally, previous studies suggest that participants may use simpler resoning strategies, 7 , 14 , 43 we therefore assessed whether participants were using simple heuristics to solve the task as opposed to the Bayesian models presented above. The heuristic model had the following probabilistic decision rules and always relied on one type of information only (i.e. no information integration): (i) Figure 1 The urn task . Modified from Campbell-Meiklejohn et al . 21 At the beginning of each trial a new jar was presented following the words ‘next jar’. This text was presented for 1000 ms and served as a reminder to the participants that each jar was different. During the ‘pre-task’, the jars were numbered, to make this explicit. When a new jar appeared, the contents were hidden. A display of five hands reaching for five different samples from the jar was then animated. Next, the decisions of the four agents were shown with their confidence in those decisions. Agent faces were reprsented with neutral expression. To avoid association between answers and specific agents, agents were randomly drawn from a set of 30 faces on each trial. Agent answers were expressed by the colour of the circle next to their faces. Confidence was indicated as the expression within the circle as well as the speed at which the answer was shown (rapid + smug = high confidence). Individual agent answers took between 300 and 2800 ms to appear. Next, the participant’s own sample of marbles appeared on the screen and was displayed with all other information for 500 ms before the participant could make his/her choice (red or green). The chosen colour was highlighted for 1000 ms, followed by the next trial",
    "chunk_id": "Adv_cognitive_modelling_op-brai210065_1603..1614.json_chunk_16"
  },
  {
    "document_type": "research_paper",
    "title": "Taking others into account: combining directly experienced and indirect information in schizophrenia",
    "author": "Arndis Simonsen, Riccardo Fusaroli, Malte Lau Petersen, Arnault-Quentin Vermillet, Vibeke Bliksted, Ole Mors, Andreas Roepstorff and Daniel Campbell-Meiklejohn",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\taking_others_into_account.pdf",
    "date_published": "2021-06-18",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". The chosen colour was highlighted for 1000 ms, followed by the next trial. Downloaded from https://academic.oup.com/brain/article/144/5/1603/6214913 by guest on 24 March 2025 choose the colour that is most of in the sample, if indecisive; then (ii) choose the colour that most others choose, if indecisive; then (iii) choose the preferred colour (bias). We used R, Stan and brms 44 , 45 to implement the models. All models were implemented in a Bayesian multilevel fashion: partially pooling information from all participants to improve our inferences and explicitly accounting for the uncertainty in the paameter estimates. For comparison we also report individually fited models (no pooling of information) in the Supplementary material . We chose to use regularizing priors, that is, priors weakly sceptical of the effects, to decrease chances of model overfitting. 46 We compared the models using estimated out-of-sample error (Pareto-smoothed Information Sampling Leave-One-Out Information Criteria, PSIS-LOO), 47 which estimates the likely geeralizability of the model to new data. We also performed tests of model and parameter recovery, reported in Supplementary Tables 1 and 2 and Supplementary Figs 3–5 . Cognitive and clinical features in parameter estimation After identifying the best fitting model, we further assessed in this model whether cognitive and clinical factors were related to the patient’s use of information. In particular, we assessed whether cognitive function (e.g. TASIT, IQ), specific symptom clusters (e.g. hallucinations, delusions), general symptom severity (SANS or SAPS total score), antipsychotic medication dose (chlorpromazine) and level of functioning (PSP) would modulate the integration of the directly experienced and the indirect information, by affecting the model parameters. All of these analyses were conducted on the patients only (and, when relevant, in controls only for baseline comparison) by conditioning the estimated parameters on each patient and the additional variable of interest (i.e",
    "chunk_id": "Adv_cognitive_modelling_op-brai210065_1603..1614.json_chunk_17"
  },
  {
    "document_type": "research_paper",
    "title": "Taking others into account: combining directly experienced and indirect information in schizophrenia",
    "author": "Arndis Simonsen, Riccardo Fusaroli, Malte Lau Petersen, Arnault-Quentin Vermillet, Vibeke Bliksted, Ole Mors, Andreas Roepstorff and Daniel Campbell-Meiklejohn",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\taking_others_into_account.pdf",
    "date_published": "2021-06-18",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". we expected the parameters to vary by individual—random effect—and by, for eample, global rating of hallucinations—fixed effect). For ease of comparison with previous studies not relying on multilevel modeling, and in order to assess the contribution of a symptom cluster when adjusting for the others, we also report the analysis of the relation between symptoms and individual-level fitted model parameters in the Supplementary material . Evidence ratio To quantify the support for our hypotheses, we calculated an evdence ratio in the form of the posterior probability of the directed hypothesis (e.g. parameter 4 0) against the posterior probability of the opposite hypothesis (e.g. parameter 4 0) 48 with the following interpretation of evidence: 1–3 = anecdotal; 3–10 = moderate; 10– 30 = strong. 49 Additionally, we report a credibility score for the hpothesis, that is, the proportion of the samples from the posterior conforming to the prediction. Data availability The dataset analysed is available from the corresponding author on reasonable request. The implementation code is available at https://github.com/fusaroli/TakingOthersIntoAccount . Results Model comparison We first compared the six models (simple Bayes, weighted Bayes, circular inference with and without interference, GLM and heuritic). The circular inference model with interference was the most likely given the data across groups, credibly minimizing estimated out-of-sample error. PSIS-LOO indicated credible differences from all other models. This was also the case within each group ( Table 2 ). Individual level fitted models confirmed that circular iference (with or without interference) was most likely for 70 of 75 participants ( Supplementary material ). We therefore focused on the circular inference model, but parameter estimates for all moels are available in Supplementary Tables 3–8",
    "chunk_id": "Adv_cognitive_modelling_op-brai210065_1603..1614.json_chunk_18"
  },
  {
    "document_type": "research_paper",
    "title": "Taking others into account: combining directly experienced and indirect information in schizophrenia",
    "author": "Arndis Simonsen, Riccardo Fusaroli, Malte Lau Petersen, Arnault-Quentin Vermillet, Vibeke Bliksted, Ole Mors, Andreas Roepstorff and Daniel Campbell-Meiklejohn",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\taking_others_into_account.pdf",
    "date_published": "2021-06-18",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". We therefore focused on the circular inference model, but parameter estimates for all moels are available in Supplementary Tables 3–8 . Note that model rcovery tests indicate that were the true model a circular inference without interference, our model comparison procedure would not perfectly differentiate between circular inference with and without interference (60% accuracy, see details in Supplementary mateial ). Therefore, further interpretation of which participants are identified as best described by the model with or without interfeence is not warranted. Schizophrenia and circular inference Participants generally took confidence into account, did not take any source of information at face value (weights 5 1, indicating ucertainty in the use of information), and overcounted information (loop parameters 4 1, indicating that participants paid more attetion to the direction of the evidence than to small differences in it). Participants were also more affected by directly experienced than by information from others (indirect information), but patients more so than control subjects. Specifically, patients over-weighed and overcounted directly experienced information [mean weight: 0.92, 95% credible interval (CI) 0.90 0.93, in patients versus 0.89, Table 2 Model comparison Model All participants Schizophrenia Controls D ELPD SE Weight D ELPD SE Weight D ELPD SE Weight Simple Bayes –3581.4 125.9 0 –2639.9 108.4 0 –968.5 60.6 0 Heuristic model –2052.5 46.1 0 –1482.2 65.1 0 –573.5 40.1 0 Weighted Bayes –466.2 23.0 0 –349.7 18.0 0 –146.2 13.8 0 GLM –56.0 18.6 0.33 –92.9 12.3 0 –45.6 13.1 0.13 Circular inference no interference –81.9 13.5 0 –7.1 8.7 0.43 –55.1 6.6 0 Circular inference 0 NA 0.67 0 NA 0.57 0 NA 0.87 ELPD = the expected log predictive density of the model, calculated using PSIS-LOO. In other words, it indicates the estimated out-of-sample error of the model: the relative likelihood of the model given the data, adjusting it for potential overfitting and influential data-points",
    "chunk_id": "Adv_cognitive_modelling_op-brai210065_1603..1614.json_chunk_19"
  },
  {
    "document_type": "research_paper",
    "title": "Taking others into account: combining directly experienced and indirect information in schizophrenia",
    "author": "Arndis Simonsen, Riccardo Fusaroli, Malte Lau Petersen, Arnault-Quentin Vermillet, Vibeke Bliksted, Ole Mors, Andreas Roepstorff and Daniel Campbell-Meiklejohn",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\taking_others_into_account.pdf",
    "date_published": "2021-06-18",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". In other words, it indicates the estimated out-of-sample error of the model: the relative likelihood of the model given the data, adjusting it for potential overfitting and influential data-points. D ELPD indicates the difference in ELPD compared to the best model: the lower the score, the bigger the distance from the best model. SE = standard error in the estimate of the difference. Weight indicates the stacking weights based on PSIS-LOO, that is, how strong the preference for a given model should be. 0 indicates a very unlikely model, 1 the most likely model having no likely competitors amongst the models analysed, intermediate values indicate relative uncertainty as to which model is best. 50 GLM = generalized linear model; NA = not applicable. Downloaded from https://academic.oup.com/brain/article/144/5/1603/6214913 by guest on 24 March 2025 95% CI 0.87 0.90, in controls; mean loops of 6.24, 95% CI 5.13 8.21, in patients versus 2.66, 95% CI 2.15 3.23, in controls]. In other words, small amounts of evidence in their samples (e.g. six red marbles instead of five) made a larger difference in the patients’ propensity to guess that the next marble would be red, than it did for control subjects. Patients also underweighted indirect information (both choice and confidence of others) more than controls, mean weight for others of 0.64 (95% CI 0.62 0.66) for high confidence and 0.57 (95% CI 0.54 0.59) for low confidence in patients versus 0.74 (95% CI 0.72 0.76) and 0.62 (95% CI 0.60 0.64) for high and low confidence in control subjects, but showed similar overcounting (2.05, 95% CI 1.41 3.18, versus 2.01, 95% CI 0.99 4.21) ( Table 3 and Fig. 2 ). Cognitive function and circular inference There was strong evidence for an association between TASIT peformance and the use of others’ confidence in informing choice bhaviour ( Supplementary Table 12 , evidence ratio 4 1000, credibility = 1), i.e",
    "chunk_id": "Adv_cognitive_modelling_op-brai210065_1603..1614.json_chunk_20"
  },
  {
    "document_type": "research_paper",
    "title": "Taking others into account: combining directly experienced and indirect information in schizophrenia",
    "author": "Arndis Simonsen, Riccardo Fusaroli, Malte Lau Petersen, Arnault-Quentin Vermillet, Vibeke Bliksted, Ole Mors, Andreas Roepstorff and Daniel Campbell-Meiklejohn",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\taking_others_into_account.pdf",
    "date_published": "2021-06-18",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". the better patients were at inferring others’ mental states, the more they relied on others’ confidence to weight information from them. In particular, patients with the minimum TASIT score would weight low and high confident others 0.55 and 0.58, respectively; while patients with the maximum TASIT score 0.58 and 0.68, respectively. We assessed whether this could be related to IQ, since IQ is known to be related to TASIT performance. 40 Indeed, there was a similar association, i.e. the higher the patients’ IQ, the more they relied on others’ confidence to weight information from them ( Supplementary Table 14 , evidence ratio 4 1000, credibility = 1). In particular, patients with the minimum IQ score would weight low and high confident others 0.54 and 0.57, respectively; while patients with the maximum IQ score 0.58 and 0.69. However, when adjusting for IQ, there was still strong evidence for a positive assciation between TASIT performance and use of others’ confidence ( Supplementary Table 16 , b = 1.02, 95% CIs = 0.52 1.52, evidence ratio 4 1000, credibility = 1). Interestingly, we saw the same patern in the control subjects, i.e. both TASIT and IQ were uniquely related to weighing of others’ confidence (Supplementary Tables 13, 15 and 17). In particular, control subjects with the minimum TASIT score would weight low and high confident others 0.59 and 0.64, respectively; while those with the maximum TASIT score 0.64 and 0.78 ( Supplementary Table 13 , evidence ratio 4 1000, credibiity = 1). Control subjects with the minimum IQ score would weight low and high confident others 0.61 and 0.69, respectively; while controls with the maximum IQ score 0.63 and 0.75 ( Supplementary Table 15 , evidence ratio 4 1000, credibility = 1). There was no evidence for a negative association between loops for self and IQ (evidence ratio = 0.08, credibility = 0.08). In fact, the evidence was in the opposite direction, i.e",
    "chunk_id": "Adv_cognitive_modelling_op-brai210065_1603..1614.json_chunk_21"
  },
  {
    "document_type": "research_paper",
    "title": "Taking others into account: combining directly experienced and indirect information in schizophrenia",
    "author": "Arndis Simonsen, Riccardo Fusaroli, Malte Lau Petersen, Arnault-Quentin Vermillet, Vibeke Bliksted, Ole Mors, Andreas Roepstorff and Daniel Campbell-Meiklejohn",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\taking_others_into_account.pdf",
    "date_published": "2021-06-18",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". There was no evidence for a negative association between loops for self and IQ (evidence ratio = 0.08, credibility = 0.08). In fact, the evidence was in the opposite direction, i.e. the higher the patient IQ, the higher the loops for self ( Supplementary Table 14 , mean loops for self changing from 3.78 to 5.05 from lowest to higest IQ, evidence ratio = 12.3, credibility = 0.92). In contrast, there was no evidence for an association between loops for self and IQ in the control subjects ( Supplementary Table 15 ). There was no creible evidence that working memory or executive function were associated with patients’ task performance ( Supplementary Tables 18 and 19 ). Model comparison also showed that models including measures of IQ, spatial working memory or executive function (IED) gained 0 weight, while the model including TASIT was the most likely given the data ( Supplementary Table 20 , stacking weight TASIT model: 0.89; baseline model: 0.11). Psychopathology and circular inference There was strong evidence for a positive association between loops for self and hallucinations (5.42 with a score of 0, 7.00 with a score of 5, evidence ratio = 18.1, credibility = 0.95, Supplementary Table 21 ), delusions (5.31 to 6.62, evidence ratio = 11.7, credibility = 0.92, Supplementary Table 22 ), bizarre behaviour (5.36 to 7.02, evdence ratio = 20.6, credibility = 0.95, Supplementary Table 23 ) and SAPS total score (5.21 to 7.1, evidence ratio = 29.9, credibility = 0.97, Supplementary Table 25 ), while it was moderate for formal thought disorder (5.58 to 6.69, evidence ratio = 5.5, credibility = 0.85, Supplementary Table 24 )",
    "chunk_id": "Adv_cognitive_modelling_op-brai210065_1603..1614.json_chunk_22"
  },
  {
    "document_type": "research_paper",
    "title": "Taking others into account: combining directly experienced and indirect information in schizophrenia",
    "author": "Arndis Simonsen, Riccardo Fusaroli, Malte Lau Petersen, Arnault-Quentin Vermillet, Vibeke Bliksted, Ole Mors, Andreas Roepstorff and Daniel Campbell-Meiklejohn",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\taking_others_into_account.pdf",
    "date_published": "2021-06-18",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Similarly, there was strong evdence for a positive association between loops for self and anhednia-asociality (5.21 to 7.1, evidence ratio = 28.7, credibility = 0.97, Supplementary Table 29 ), avolition-apathy (5.31 to 6.89, evidence ratio = 12.0, credibility = 0.92, Supplementary Table 28 ), attention (5.42 to 6.75, evidence ratio = 10.5, credibility = 0.91, Supplementary Table 30 ) and SANS total score (5.26 to 6.82, evdence ratio = 13.7, credibility = 0.93, Supplementary Table 31 ), while it was moderate for affective flattening (5.47 to 6.36, evdence ratio = 4.2, credibility = 0.81, Supplementary Table 26 ) and not credible for alogia (5.37 to 5.70, evidence ratio = 1.6, credibility = 0.62, Supplementary Table 27 ). For the other model parameters, there was either no or only moderate evidence for associations with different symptoms ( Supplementary material ). Table 3 Parameter estimates for the circular inference model including group Model Mean 2.5 % CI 97.5 % CI Evidence ratio Bias for red (controls) –0.07 –0.16 0.02 Group-level diff in bias for red 0.01 –0.10 0.13 Confidence (controls) 2.07 1.85 2.30 Group level diff in confidence –0.18 –0.48 0.13 7.1, 88 % credibility Weight for self (controls) 1.25 1.06 1.44 Group level diff in weight for self 0.39 0.11 0.67 362.6, 100 % credibility Weight for others (controls) –2.19 –2.41 –1.98 Group level diff in weight for others –0.61 –0.91 –0.32 4 1000, 100 % credibility Loops for self (controls) 0.98 0.77 1.17 Group level diff in loops for self 0.88 0.61 1.17 4 1000, 100 % credibility Loops for others (controls) 0.72 0.21 1.16 Group level diff in loops for others –0.02 –0.60 0.58 1.1, 53% credibility Note that the parameters can be on transformed scales, e.g. weights are on a log odds scale, and loops on an exponential scale. See the ‘Materials and methods’ section and the Supplementary material for more details",
    "chunk_id": "Adv_cognitive_modelling_op-brai210065_1603..1614.json_chunk_23"
  },
  {
    "document_type": "research_paper",
    "title": "Taking others into account: combining directly experienced and indirect information in schizophrenia",
    "author": "Arndis Simonsen, Riccardo Fusaroli, Malte Lau Petersen, Arnault-Quentin Vermillet, Vibeke Bliksted, Ole Mors, Andreas Roepstorff and Daniel Campbell-Meiklejohn",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\taking_others_into_account.pdf",
    "date_published": "2021-06-18",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". weights are on a log odds scale, and loops on an exponential scale. See the ‘Materials and methods’ section and the Supplementary material for more details. Downloaded from https://academic.oup.com/brain/article/144/5/1603/6214913 by guest on 24 March 2025 We assessed whether medication could be confounding the results. The evidence for a positive association between chlorprmazine and loops for self was only moderate (evidence ratio = 3.1, credibility = 0.75, mean loops changing from 5.5 for no medication to 6.3 for highest medication dose, Supplementary Table 32 ) and could just as well reflect disorder severity, where the evidence was much stronger. Finally, we also assessed parameters fitted at the individual level (no pooling), as done in previous studies. 3 Here, there was in most cases strong evidence for a positive association between loops or weight for self and all symptom clusters (except for formal thought disorder). There was a similar picture for loops and weight for others, where there was moderate to strong evidence for a negative association with all symptoms (except formal thought disorder). On the other hand, there was no credible evidence for an association between confidence and symptoms, expect for bizarre behaviour, where the evidence was moderate ( Supplementary Table 37 ). Importantly, since some of the symptoms covaried (see correlation matrix S39 and network structure in Supplementary Fig. 9 ), we also assessed associations between the model paramters and each psychotic or negative symptom cluster while cotrolling for the other psychotic or negative symptom clusters, respectively. Many of the associations survived this correction. For instance, hallucinations, delusions, bizarre behaviour, anhedoniasociality, alogia and attention were uniquely associated with loops for self. Similarly, hallucinations, delusions, affective flatteing, avolition-apathy and attention were uniquely associated with weight for others (for full details see Supplementary Table 38 )",
    "chunk_id": "Adv_cognitive_modelling_op-brai210065_1603..1614.json_chunk_24"
  },
  {
    "document_type": "research_paper",
    "title": "Taking others into account: combining directly experienced and indirect information in schizophrenia",
    "author": "Arndis Simonsen, Riccardo Fusaroli, Malte Lau Petersen, Arnault-Quentin Vermillet, Vibeke Bliksted, Ole Mors, Andreas Roepstorff and Daniel Campbell-Meiklejohn",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\taking_others_into_account.pdf",
    "date_published": "2021-06-18",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Similarly, hallucinations, delusions, affective flatteing, avolition-apathy and attention were uniquely associated with weight for others (for full details see Supplementary Table 38 ). Figure 2 Information integration in patients with schizophrenia and matched healthy controls. The top plots represent the influence of the agents on controls ( top left ) and patients ( top right ). The x -axis indicates the amount of combined evidence for red provided by the agents on a log-odds scale, the y -axis indicates the probability of choosing red. The colour indicates the level of evidence for red in the sample. The average patient showed less ifluence from others (shallower slopes) and more influence from directly experienced information (more spread curves). Note that for simplicity of representation we collapsed others’ confidence and choices, to construct a continuous one-dimensional scale of indirect evidence for red. The bottom plots represent the influence of directly experienced information on control subjects ( bottom left ) and patients ( bottom right ). The x -axis indicates the number of red marbles contained in one’s own sample, the y -axis indicates the probability of choosing red. The colour indicates the level of evidence for red provided by the other agents. Note how the coloured lines are steeper and more collected in the average patient compared to the average cotrol subject: this indicates a more decided role of directly experienced information (steeper slopes) and a lower influence of indirect information (as the lines are more similar to each other, no matter the level of indirect evidence). See Supplementary Figs 6, 7A and B for participant-level representtions of the model. Downloaded from https://academic.oup.com/brain/article/144/5/1603/6214913 by guest on 24 March 2025 Level of functioning and circular inference There was a similar pattern for PSP and IQ. Specifically, the higher the level of functioning, the more patients relied on confidence",
    "chunk_id": "Adv_cognitive_modelling_op-brai210065_1603..1614.json_chunk_25"
  },
  {
    "document_type": "research_paper",
    "title": "Taking others into account: combining directly experienced and indirect information in schizophrenia",
    "author": "Arndis Simonsen, Riccardo Fusaroli, Malte Lau Petersen, Arnault-Quentin Vermillet, Vibeke Bliksted, Ole Mors, Andreas Roepstorff and Daniel Campbell-Meiklejohn",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\taking_others_into_account.pdf",
    "date_published": "2021-06-18",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Specifically, the higher the level of functioning, the more patients relied on confidence. Patients with minimum PSP score used an average weight of 0.56 for low confident and 0.61 for high confident others; while patients with the highest score 0.57 and 0.64, respectively ( Supplementary Table 33 , evidence ratio = 36.6, credibility = 0.97). This was the case even when controlling for IQ (evidence ratio = 4.37, credibility = 0.81, Supplementary Table 35 ). In addition, there was moderate evidence for a positive association between PSP and loops for self (evidence ratio = 8.7, credibility = 0.90, Supplementary Table 33 ), which disappeared when controlling for IQ (evidence ratio = 1.15, credibility = 0.54, Supplementary Table 35 ). For control subjects, we saw a similar association between PSP score and confidence, also when adjusting for IQ, but not between PSP and loops for self ( Supplementary Tables 34 and 36 ). Controls with minimum PSP score used an average weight of 0.61 for low confident and 0.69 for high confident others; while controls with the highest score 0.63 and 0.74, respectively (evidence ratio 4 1000, credibility = 1, Supplementary Table 34 ). Control experiment We ran a control experiment in healthy individuals ( Supplementary material ) to assess whether framing the indirect source of information in a social or non-social context impacted task performance. Results showed that while there was no credible difference in how they used their own sample in the two contexts, they did rely more on a confident person than on a confident algrithm ( Supplementary Table 40 ). Discussion We investigated the hypothesis that the diverse symptoms charateristic of schizophrenia could stem from a common abnormality in inference mechanisms. 1 This was done using a new version of the beads task, designed to investigate inference based on concurent integration of multiple sources of information",
    "chunk_id": "Adv_cognitive_modelling_op-brai210065_1603..1614.json_chunk_26"
  },
  {
    "document_type": "research_paper",
    "title": "Taking others into account: combining directly experienced and indirect information in schizophrenia",
    "author": "Arndis Simonsen, Riccardo Fusaroli, Malte Lau Petersen, Arnault-Quentin Vermillet, Vibeke Bliksted, Ole Mors, Andreas Roepstorff and Daniel Campbell-Meiklejohn",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\taking_others_into_account.pdf",
    "date_published": "2021-06-18",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". 1 This was done using a new version of the beads task, designed to investigate inference based on concurent integration of multiple sources of information. By comparing different computational models of how inference could be altered in schizophrenia, we found that different degrees of circular infeence best described choice behaviour in both patients and cotrols. This is concordant with circular inference being the best model to describe the integration of sensory and prior information in a previous study and suggests that overcounting of information is not pathological per se and may even be a part of normal neural functioning. 3 , 51 Patients tended to put more weight on and overcount directly experienced information compared to control subjects and, coversely, they tended to put less weight on the information from others (indirect information). The findings are in line with the study by Jardri et al ., 3 which found that patients put more weight on and overcounted sensory evidence and less weight on prior iformation. Importantly, our results suggest that overcounting of direct experience may not only be a key mechanism underlying psychotic symptoms, as previously reported, 3 but also negative symptoms. The fact that overcounting of direct experience was associated with most symptom clusters cannot be simply ascribed to general disorder severity or high correlations between symtoms. Although some symptoms were correlated, many of the psychotic and negative symptoms were uniquely related to ovecounting of direct experience. Over-weighing of direct experience as well as under-weighing and under-counting of indirect information could also play a role in the psychopathology, athough the evidence for this was not as strong. We framed the task in a social context to make it less abstract, but also because social cognitive deficits are central in schizophrnia and patients typically display impairments in social functioing. 25 The social aspect could therefore play a key role",
    "chunk_id": "Adv_cognitive_modelling_op-brai210065_1603..1614.json_chunk_27"
  },
  {
    "document_type": "research_paper",
    "title": "Taking others into account: combining directly experienced and indirect information in schizophrenia",
    "author": "Arndis Simonsen, Riccardo Fusaroli, Malte Lau Petersen, Arnault-Quentin Vermillet, Vibeke Bliksted, Ole Mors, Andreas Roepstorff and Daniel Campbell-Meiklejohn",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\taking_others_into_account.pdf",
    "date_published": "2021-06-18",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". 25 The social aspect could therefore play a key role. Indeed, we found that the patients’ ability to make inferences about others’ mental states and their level of functioning were both specifically related to how they used information from others. This was also the case for the control subjects. Participants that were better at mentalizing and had a higher level of functioning relied more on cues about others’ confidence to weight information from others. This was also the case when controlling for IQ. The results suggest that these patients and controls were more attuned to the cues from others and/or better at making inferences based on them and therefore more able to make use of them, and ultimately to funtion in the real world. Our results also suggest that it is important to keep in mind that social cognitive function presumably modlates the inference process in social contexts and may therefore shape hallucinations and delusions as well as social behaviour. Note, that although the basic inference mechanism may be the same, and our main study does not discriminate between a speciic social or more general cognitive domain abnormality, our cotrol experiment shows that placing the task in a social versus nosocial context affects how the information is treated. In particular, we show that while directly experienced information is treated similarly in the two contexts, expressed confidence is treated diferently according to whether it comes from an algorithm (non-scial source) or a person (social source) and it is used more to inform decisions in the social context. In addition, the fact that neither context nor social cognitive function was related to the general tendency to overcount direct experience suggests that this specific abnormality, which may be central to schizophrenia symptomatology, is not closely related to how social information is processed",
    "chunk_id": "Adv_cognitive_modelling_op-brai210065_1603..1614.json_chunk_28"
  },
  {
    "document_type": "research_paper",
    "title": "Taking others into account: combining directly experienced and indirect information in schizophrenia",
    "author": "Arndis Simonsen, Riccardo Fusaroli, Malte Lau Petersen, Arnault-Quentin Vermillet, Vibeke Bliksted, Ole Mors, Andreas Roepstorff and Daniel Campbell-Meiklejohn",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\taking_others_into_account.pdf",
    "date_published": "2021-06-18",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". The fact that patients focused more on directly experienced iformation as opposed to information from others compared to controls, could not be easily explained by general cognitive defcits. First, both patients and controls differentiated between high and low confident others. This is arguably the most complex part of the task and suggests that they did not have problems with processing the information provided. Second, both patients and controls often stated during debriefing that they put more trust in their own sample (higher certainty) than the others’ decisions and not that they had problems with considering all the available iformation. Third, patients’ working memory and executive funtion were not related to task performance. While participants’ IQ was related to how they weighted others’ confidence, overcouning of directly experienced information was not associated with a lower but a higher IQ in patients. It is unclear why this was the case, and we did not see this pattern in the control subjects. Our findings are consistent with the idea previously put foward that patients are swayed by the evidence of their senses and tend to jump to conclusions based on this information, failing to take other—prior or in our case indirect—evidence into acount. 3 , 14 , 28 , 52 , 53 This has been interpreted as a precision imbaance, where a reduction in precision at higher levels of the inferential hierarchy biases inference towards sensory evidence and away from prior beliefs, 27 or in the circular inference framwork, that patients overweight and overcount sensory evidence and underweight prior beliefs. 3 This likely depends both on the context 6 and whether it concerns low-level sensory predictions or higher-order beliefs. 54 , 55 Importantly, it is an empirical question whether previous direct experiences are treated anything like Downloaded from https://academic.oup.com/brain/article/144/5/1603/6214913 by guest on 24 March 2025 indirect sources of information (e.g. social information)",
    "chunk_id": "Adv_cognitive_modelling_op-brai210065_1603..1614.json_chunk_29"
  },
  {
    "document_type": "research_paper",
    "title": "Taking others into account: combining directly experienced and indirect information in schizophrenia",
    "author": "Arndis Simonsen, Riccardo Fusaroli, Malte Lau Petersen, Arnault-Quentin Vermillet, Vibeke Bliksted, Ole Mors, Andreas Roepstorff and Daniel Campbell-Meiklejohn",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\taking_others_into_account.pdf",
    "date_published": "2021-06-18",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". social information). Another aspect is that patients do not always disregard social information. It presumably depends on whether they have access to directly experienced information or not, 56 as well as the level of procesing. 57 , 58 , 59 Relatedly, patients may form strong beliefs under cetain circumstances and are consequently reluctant to update them based on new information, 5 , 60 or as in our case, indirect informtion. Crucially, this new information typically comes from other people (disagreeing with the patient’s view) and therefore will be under-counted and not challenge the fixed beliefs (delusions) that are rooted in direct experience. More generally, our findings point to the limitation of conceptualizing abnormal inference in schizphrenia as solely a problem of sequential belief updating of one type of information. In fact, a key abnormality may lie in how mutiple sources of information are integrated simultaneously and in particular how directly experienced information is processed copared to other types of information, e.g. information from others. This only becomes evident when moving beyond one information source. Future studies could further investigate how different sources of information (direct experience versus indirect informtion) are treated during sequential belief updating. Some limitations of this study should be mentioned. We cannot, based on the current data, determine whether circular inference is causally related to the formation of psychotic and negative symtoms. While it seems unlikely that overcounting of direct experience should stem from all types of schizophrenia psychopathology, it is possible that for instance putting less weight on information from others could be a consequence of the distrust experienced by patients with severe delusions. Future studies could assess circular inference in prodromal stages of the disorder or in high-risk groups as well as across diagnoses with or without psychotic symptoms",
    "chunk_id": "Adv_cognitive_modelling_op-brai210065_1603..1614.json_chunk_30"
  },
  {
    "document_type": "research_paper",
    "title": "Taking others into account: combining directly experienced and indirect information in schizophrenia",
    "author": "Arndis Simonsen, Riccardo Fusaroli, Malte Lau Petersen, Arnault-Quentin Vermillet, Vibeke Bliksted, Ole Mors, Andreas Roepstorff and Daniel Campbell-Meiklejohn",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\taking_others_into_account.pdf",
    "date_published": "2021-06-18",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Future studies could assess circular inference in prodromal stages of the disorder or in high-risk groups as well as across diagnoses with or without psychotic symptoms. This could also circumvent the problem with antipsychotic mediction being a potential confounder, although the evidence for this was weak. Similarly, investigations could be extended to the general population to get a better understanding of whether even low levels of overcounting of directly experienced information are related to subthreshold symptoms. Future studies could also investigate the purported underlying neural mechanisms of the circular inference model to provide further medium for hypothesis testing and estalish a better understanding of the link between abnormal inference and the heterogeneous psychopathology of schizophrenia. In adition, although participants spoke of the agents as real people duing debriefing, future studies could more directly assess to what extent the participants thought the agents were real and how this would impact task performance. Similarly, as different people may differ in their motivation to make accurate decisions, 61 future stuies could directly compare how intrinsic versus extrinsic incetives 62 would affect task performance. In conclusion, our findings provide further evidence of the benefit of using biologically informed computational models to critically investigate the underlying mechanisms of disorders like schizophrenia, beyond the immediate behavioural data. Our results suggest that hallucinations, delusions and negative symtoms could stem from the same underlying abnormality in infeence, where directly experienced information is assigned an unreasonable weight and taken into account multiple times, so that even random and unreliable experiences may gain dispropotionate significance. This may eventually lead to false perceptions (hallucinations), false beliefs (delusions) and deviant social behaiour (e.g. loss of interest in others, bizarre and inappropriate bhaviour)",
    "chunk_id": "Adv_cognitive_modelling_op-brai210065_1603..1614.json_chunk_31"
  },
  {
    "document_type": "research_paper",
    "title": "Taking others into account: combining directly experienced and indirect information in schizophrenia",
    "author": "Arndis Simonsen, Riccardo Fusaroli, Malte Lau Petersen, Arnault-Quentin Vermillet, Vibeke Bliksted, Ole Mors, Andreas Roepstorff and Daniel Campbell-Meiklejohn",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\taking_others_into_account.pdf",
    "date_published": "2021-06-18",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". This may eventually lead to false perceptions (hallucinations), false beliefs (delusions) and deviant social behaiour (e.g. loss of interest in others, bizarre and inappropriate bhaviour). This may be particularly problematic for patients with social cognitive deficits, as they to a larger degree may miss or fail to make use of corrective information from others, ultimately leaing to worse social functioning. Acknowledgements We would like to thank Marjun Biskopstø and Oddbjørg Johansen for their assistance in the data collection, Chris Frith for helpful comments on the manuscript and Paul Buerkner for adding new features to the brms package to better accommodate the computtional models used in this manuscript. Funding This work was supported by the Lundbeck Foundation, Denmark (R102-A9118, R155-2014-1724); the Carlsberg Foundation; the Psychosis Research Unit, Aarhus University Hospital; and the Interacting Minds Centre, Aarhus University. Competing interests The authors report no competing interests. Supplementary material Supplementary material is available at Brain online.",
    "chunk_id": "Adv_cognitive_modelling_op-brai210065_1603..1614.json_chunk_32"
  },
  {
    "document_type": "research_paper",
    "title": "Rational approximations to rational models: Alternative algorithms for category learning",
    "author": "Sanborn, Adam N.; Griffiths, Thomas L.; Navarro, Danielle J.",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Sanborn-2010-Rational-approximations-to-rational.pdf",
    "date_published": "2015-08-05",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": "ACCEPTED VERSION Sanborn, Adam N.; Griffiths, Thomas L.; Navarro, Daniel le J. Rational approximations to rational models: Alternative algorithms for category learning Psychological Review, 2010; 117(4):1144-1167 Copyright 2010 APA, all rights reserved This article may not exactly replicate the final version published in the APA journal. It is not the copy of record. Published version available at: http://dx.doi.org/10.1037/a0020511 http://hdl.handle.net/2440/62109 PERMISSIONS http://www.apa.org/pubs/authors/posting.aspx Update effective November 1, 2008 If a paper is unpublished, the author may distribute it on the Internet or post it on a website but should label the paper with the date and with a statement that the paper has not (yet) been published. (Example: Draft version 1.3, 1/5/08. This paper has not been peer reviewed. Please do not copy or cite without author's permission.) Authors of articles published in APA journals may post a copy of the final manuscript, as accepted for publication, as a word processing file, on their personal website, their employer's server, or in their institution's repository after it is accepted for publication. The following conditions would prevail:  The posted article must carry an APA copyright notice and include a link to the APA journal home page or to the final published version using the article’s DOI, or digital object identifier, that may be found on the first page of the published article, in the upper right-hand corner.  Further, the posted article must include the following statement: \"This article may not exactly replicate the final version published in the APA journal. It is not the copy of record.\"  APA does not provide electronic copies of the APA published version for this purpose, and authors are not permitted to scan in the APA typeset version of the published article.  Authors are not permitted to download and subsequently post the APA typeset version of the published article",
    "chunk_id": "Adv_cognitive_modelling_sanborn-2010-rational-approximations-to-rational.json_chunk_1"
  },
  {
    "document_type": "research_paper",
    "title": "Rational approximations to rational models: Alternative algorithms for category learning",
    "author": "Sanborn, Adam N.; Griffiths, Thomas L.; Navarro, Danielle J.",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Sanborn-2010-Rational-approximations-to-rational.pdf",
    "date_published": "2015-08-05",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ".  Authors are not permitted to download and subsequently post the APA typeset version of the published article. 5 August 2015 This is an author manuscript version of the following paper: Sanborn, A. N., Griffiths, T. L. & Navarro, D. J. (2010). Rational approximations to rational models: Alternative algorithms for category learning. Psychological Review 117 , 1144-1167 The copyright is held by the American Psychological Association. To comply with their policies regarding authors posting manuscripts on personal webpages, we are required to note the following: this article may not exactly replicate the final version published in the APA journal. It is not the copy of record. Rational Approximations to Category Learning 1 Running head: RATIONAL APPROXIMATIONS TO CATEGORY LEARNING Rational approximations to rational models: Alternative algorithms for category learning Adam N. Sanborn Gatsby Computational Neuroscience Unit, University College London Thomas L. Griffiths University of California, Berkeley Danielle J. Navarro University of Adelaide Send Correspondence To: Adam Sanborn Gatsby Computational Neuroscience Unit 17 Queen Square London WC1N 3AR United Kingdom +44 07942 551970 asanborn@gatsby.ucl.ac.uk Rational Approximations to Category Learning 2 Abstract Rational models of cognition typically consider the abstract computational problems posed by the environment, assuming that people are capable of optimally solving those problems. This differs from more traditional formal models of cognition, which focus on the psychological processes responsible for behavior. A basic challenge for rational models is thus explaining how optimal solutions can be approximated by psychological processes. We outline a general strategy for answering this question, namely to explore the psychological plausibility of approximation algorithms developed in computer science and statistics",
    "chunk_id": "Adv_cognitive_modelling_sanborn-2010-rational-approximations-to-rational.json_chunk_2"
  },
  {
    "document_type": "research_paper",
    "title": "Rational approximations to rational models: Alternative algorithms for category learning",
    "author": "Sanborn, Adam N.; Griffiths, Thomas L.; Navarro, Danielle J.",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Sanborn-2010-Rational-approximations-to-rational.pdf",
    "date_published": "2015-08-05",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". We outline a general strategy for answering this question, namely to explore the psychological plausibility of approximation algorithms developed in computer science and statistics. In particular, we argue that Monte Carlo methods provide a source of “rational process models” that connect optimal solutions to psychological processes. We support this argument through a detailed example, applying this approach to Anderson’s (1990, 1991) Rational Model of Categorization (RMC), which involves a particularly challenging computational problem. Drawing on a connection between the RMC and ideas from nonparametric Bayesian statistics, we propose two alternative algorithms for approximate inference in this model. The algorithms we consider include Gibbs sampling, a procedure appropriate when all stimuli are presented simultaneously, and particle filters, which sequentially approximate the posterior distribution with a small number of samples that are updated as new data become available. Applying these algorithms to several existing datasets shows that a particle filter with a single particle provides a good description of human inferences. Rational Approximations to Category Learning 3 Rational approximations to rational models: Alternative algorithms for category learning Rational models of cognition aim to explain human thought and behavior as an optimal solution to the computational problems that are posed by our environment (Anderson, 1990; Chater & Oaksford, 1999; Marr, 1982; Oaksford & Chater, 1998). This approach has been used to model several aspects of cognition, including memory (Anderson, 1990; Shiffrin & Steyvers, 1997), reasoning (Oaksford & Chater, 1994), generalization (Shepard, 1987; Tenenbaum & Griffiths, 2001a), and causal induction (Anderson, 1990; Griffiths & Tenenbaum, 2005)",
    "chunk_id": "Adv_cognitive_modelling_sanborn-2010-rational-approximations-to-rational.json_chunk_3"
  },
  {
    "document_type": "research_paper",
    "title": "Rational approximations to rational models: Alternative algorithms for category learning",
    "author": "Sanborn, Adam N.; Griffiths, Thomas L.; Navarro, Danielle J.",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Sanborn-2010-Rational-approximations-to-rational.pdf",
    "date_published": "2015-08-05",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". However, executing optimal solutions to these problems can be extemely computationally expensive, a point that is commonly raised as an argument against the validity of rational models (e.g., Gigerenzer & Todd, 1999; Tversky & Kahneman, 1974). This establishes a basic challenge for advocates of rational models of cognition: identifying psychologically plausible mechanisms that would allow the human mind to approximate optimal performance. The question of how rational models of cognition can be approximated by psychologically plausible mechanisms addresses a fundamental issue in cognitive science: bridging levels of analysis. Rational models provide answers to questions posed at Marr’s (1982) computational level – questions about the abstract computational problems involved in cognition. This is a different kind of explanation to those provided by other modeling approaches, which tend to operate at the level of algorithms, considering the concrete processes that are assumed to operate in the human mind. Theories developed at these different levels of analysis provide different kinds of explanations for human behavior, with the computational level explaining why we do the things we do, and the algorithmic level explaining how these things are done. Both levels of analysis contribute to the development of a complete account of human cognition, just as our understanding Rational Approximations to Category Learning 4 of bird flight is informed by knowing both how the shape of wings results from aerodynamics and how those wings are articulated by muscle and bone. Despite the importance of both the computational and algorithmic level to understanding human cognition, there has been relatively little consideration of how the two levels might be connected. In differentiating these levels of analysis, Marr (1982) clearly stated that they were not independent, with the expectation that results yielded at one level would provide constraints on theories at another",
    "chunk_id": "Adv_cognitive_modelling_sanborn-2010-rational-approximations-to-rational.json_chunk_4"
  },
  {
    "document_type": "research_paper",
    "title": "Rational approximations to rational models: Alternative algorithms for category learning",
    "author": "Sanborn, Adam N.; Griffiths, Thomas L.; Navarro, Danielle J.",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Sanborn-2010-Rational-approximations-to-rational.pdf",
    "date_published": "2015-08-05",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". However, accounts of human cognition are typically offered at just one of these levels, offering theories of either the abstract computational problem or the psychological processes involved. Cases where rational and process models can be explicitly connected are rare and noteworthy, such as the equivalence of exemplar and prototype models of categorization to different forms of density estimation (Ashby & Alfonso-Reese, 1995), although recent work has begun to explore how rational models might be converted into process models (e.g., Kruschke, 2006b). Considering the processes by which human minds might approximate optimal solutions to computational problems thus provides us with an opportunity not just to address a challenge for rational models of cognition, but to consider how one might develop a general strategy for bridging levels of analysis. In this paper, we outline a strategy that is applicable to rational analyses of probabilistic inference tasks. In such tasks, the learner needs to repeatedly update a probability distribution over hypotheses as more information about those hypotheses becomes available. Due to the prevalence of such tasks, our strategy provides tools that can be used to derive rational approximations to a variety of rational models of cognition. The key idea behind our approach is that efficient implementation of probabilistic inference is not just a problem in cognitive science – it is an issue that arises in computer science and statistics, resulting in a number of general purpose algorithms (for an Rational Approximations to Category Learning 5 introduction and examples, see Bishop, 2006; Hastie, Tibshirani, & Friedman, 2001; Mackay, 2003). These algorithms often provide asymptotic guarantees on the quality of the approximation they provide, meaning that with sufficient resources they can approximate the optimal inference to any desired level of precision",
    "chunk_id": "Adv_cognitive_modelling_sanborn-2010-rational-approximations-to-rational.json_chunk_5"
  },
  {
    "document_type": "research_paper",
    "title": "Rational approximations to rational models: Alternative algorithms for category learning",
    "author": "Sanborn, Adam N.; Griffiths, Thomas L.; Navarro, Danielle J.",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Sanborn-2010-Rational-approximations-to-rational.pdf",
    "date_published": "2015-08-05",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". The existence of these algorithms suggests a strategy for bridging levels of analysis: starting with rational models, and then considering efficient approximations to those models as candidates for psychological process models. The models inspired by these algorithms will not be rational models, but instead will be process models that are closely tied to rational models, and typically come with guarantees of good performance as approximations – a kind of “rational process model”. Our emphasis in this paper will be on one class of approximation algorithms: Monte Carlo algorithms, which approximate a probability distribution with a set of samples from that distribution. Sophisticated Monte Carlo schemes provide methods for sampling from complex probability distributions (Gilks, Richardson, & Spiegelhalter, 1996), and for recursively updating a set of samples from a distribution as more data are obtained (Doucet, Freitas, & Gordon, 2001). These algorithms provide an answer to the question of how learners with finite memory resources might be able to maintain a distribution over a large hypothesis space. We introduce these algorithms in the general case, and then provide a detailed illustration of how these algorithms can be applied to one of the first rational models of cognition: Anderson’s (1990, 1991) rational model of categorization. Our analysis of Anderson’s rational model of categorization draws on a surprising connection between this model and work on density estimation in nonparametric Bayesian statistics. This connection allows us to identify two new algorithms that can be used in evaluating the predictions of the model. These two algorithms both asymptotically approximate ideal Bayesian inference, and help to separate the predictions that arise from the underlying statistical model from those that are due to the inference algorithm. We Rational Approximations to Category Learning 6 evaluate these algorithms by comparing the results to the full posterior distribution and to human data",
    "chunk_id": "Adv_cognitive_modelling_sanborn-2010-rational-approximations-to-rational.json_chunk_6"
  },
  {
    "document_type": "research_paper",
    "title": "Rational approximations to rational models: Alternative algorithms for category learning",
    "author": "Sanborn, Adam N.; Griffiths, Thomas L.; Navarro, Danielle J.",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Sanborn-2010-Rational-approximations-to-rational.pdf",
    "date_published": "2015-08-05",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". We Rational Approximations to Category Learning 6 evaluate these algorithms by comparing the results to the full posterior distribution and to human data. The new algorithms better approximate the posterior distribution and fit human data at least as well as the original algorithm proposed by Anderson. In addition, we show that these new algorithms have greater psychological plausibility and provide better fits to data that have proved challenging to Bayesian models. These results illustrate the use of rational process models to explain how people perform probabilistic inference, provide a tool for exploring the relationship between rational models and human performance, and begin to bridge the gap between computational and algorithmic levels of analysis. The plan of the paper is as follows. In the first part of the paper we describe the general approach. We begin with a discussion of the challenges associated with performing probabilistic inference, followed by a description of various Monte Carlo methods that can be used to address these challenges, leading finally to the development of the rational approximation framework. In the second part of the paper, we apply the rational approximation idea to categorization problems, using Anderson’s rational model. We first describe this model, and use its connection to nonparametric statistics to motivate new approximate inference algorithms. We then evaluate the psychological plausibility of these algorithms at both a descriptive level and with comparisons to human performance in several categorization experiments. The challenges of probabilistic inference The computational problems that people need to solve are often inductive problems , requiring an inference from limited data to underdetermined hypotheses. For example, when learning about a new category of objects, people need to infer the structure of the category from examples of its members",
    "chunk_id": "Adv_cognitive_modelling_sanborn-2010-rational-approximations-to-rational.json_chunk_7"
  },
  {
    "document_type": "research_paper",
    "title": "Rational approximations to rational models: Alternative algorithms for category learning",
    "author": "Sanborn, Adam N.; Griffiths, Thomas L.; Navarro, Danielle J.",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Sanborn-2010-Rational-approximations-to-rational.pdf",
    "date_published": "2015-08-05",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". For example, when learning about a new category of objects, people need to infer the structure of the category from examples of its members. This inference is inherently inductive, since the category structure is not completely specified by the limited set of examples given to the Rational Approximations to Category Learning 7 learner; and because of this, it is not possible to know exactly which structure is correct. That is, the optimal solution to problems of this kind requires the learner to make probabilistic inferences, evaluating the plausibility of different hypotheses in light of the information provided by the observed data. In the remainder of this section, we discuss two challenges that a learner attempting to implement the ideal solution faces: reasoning about hypotheses that are composed of large numbers of variables, and repeatedly updating beliefs about a set of hypotheses as more information becomes available over time. Reasoning about large numbers of variables One of the most fundamental challenges in performing probabilistic inference concerns the situation when the number of hypotheses is very large. This is typically encountered when each hypothesis corresponds to a statement about a number of different variables. The number of hypotheses then suffers from a combinatoric explosion. For example, many theories of category learning assume that people assign objects to clusters. If so, then each hypothesis is composed of many assignment variables, one per object. Likewise, in causal learning, hypotheses about causal structure can often be expressed in terms of all of the individual causal relationships that make up a given structure, thus requiring multiple variables. Reasoning about hypotheses comprised of large numbers of variables poses a particular challenge, because of the combinatorial nature of the hypothesis space: the number of hypotheses to be considered can increase exponentially in the number of relevant variables",
    "chunk_id": "Adv_cognitive_modelling_sanborn-2010-rational-approximations-to-rational.json_chunk_8"
  },
  {
    "document_type": "research_paper",
    "title": "Rational approximations to rational models: Alternative algorithms for category learning",
    "author": "Sanborn, Adam N.; Griffiths, Thomas L.; Navarro, Danielle J.",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Sanborn-2010-Rational-approximations-to-rational.pdf",
    "date_published": "2015-08-05",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". The number of possible clusterings of n objects, for example, is given by the n th Bell number, with the first ten values being 1, 2, 5, 15, 52, 203, 877, 4140, 21147, and 115975. In such cases, brute force enumeration of all hypotheses will be extremely computationally expensive, and scale badly with the number of variables under consideration. Rational Approximations to Category Learning 8 Updating beliefs over time When making probabilistic inferences, we rarely have all the information we need to definitively evaluate a hypothesis. As a result, when a learner observes a piece of data and uses this to form beliefs, he or she generally remains somewhat uncertain about which hypothesis is really the correct one. When a new piece of information arrives, this distribution needs to be updated to the new beliefs. The consequence is that an ideal learner needs to constantly update a probability distribution over hypotheses as more data are observed. Updating beliefs over time is computationally challenging because it requires the learner to draw inferences every time new information becomes available. Unless the learner uses methods that allow the efficient updating of his or her beliefs, he or she would be required to perform the entire inference from scratch every time new information arrives. The cost of probabilistic inference is thus multiplied by the number of observations that have to be processed. As one would expect, this becomes particularly expensive with large hypothesis spaces, such as the combinatorial spaces that result from having hypotheses expressed over large numbers of random variables. Making probabilistic inference computationally tractable thus requires developing strategies for efficiently updating a probability distribution over hypotheses as new data are observed. Algorithms to address the challenges Some of the challenges of probabilistic inference can be addressed by approximating optimal solutions using algorithms based on the Monte Carlo principle",
    "chunk_id": "Adv_cognitive_modelling_sanborn-2010-rational-approximations-to-rational.json_chunk_9"
  },
  {
    "document_type": "research_paper",
    "title": "Rational approximations to rational models: Alternative algorithms for category learning",
    "author": "Sanborn, Adam N.; Griffiths, Thomas L.; Navarro, Danielle J.",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Sanborn-2010-Rational-approximations-to-rational.pdf",
    "date_published": "2015-08-05",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Algorithms to address the challenges Some of the challenges of probabilistic inference can be addressed by approximating optimal solutions using algorithms based on the Monte Carlo principle. This principle is one of the most basic ideas in statistical computing: rather than performing computations using a probability distribution, we perform those computations using a set of samples from that distribution. The resulting approximation becomes increasingly accurate as the number of samples grows, and the relative costs of computing time and errors in Rational Approximations to Category Learning 9 approximation can be used to determine how many samples should be generated. This principle forms the foundation of an entire class of approximation algorithms (Motwani & Raghavan, 1996). Monte Carlo methods provide a way to efficiently approximate probabilistic inference. However, generating samples from posterior distributions is typically not straightforward: generating samples from a distribution requires knowing the form that distribution takes, which is a large part of the challenge of probabilistic inference in the first place. Consequently, sophisticated algorithms need to be used in order to generate samples. Here we introduce two such algorithms at an intuitive level: Gibbs sampling and particle filters. A parallel mathematical development of the general algorithms is given in the Appendix and toy examples of these algorithms applied to categorization and a discussion of their psychological plausibility are given later. Gibbs sampling Gibbs sampling (Geman & Geman, 1984) is a very commonly used Monte Carlo method for sampling from probability distributions. This algorithm is initialized with a particular set of values for each variable, often with random values. Gibbs sampling works on the principle of sampling a single random variable at each step. One random variable is selected, and the value of this variable is sampled, conditioned on the values of all of the other random variables and the data",
    "chunk_id": "Adv_cognitive_modelling_sanborn-2010-rational-approximations-to-rational.json_chunk_10"
  },
  {
    "document_type": "research_paper",
    "title": "Rational approximations to rational models: Alternative algorithms for category learning",
    "author": "Sanborn, Adam N.; Griffiths, Thomas L.; Navarro, Danielle J.",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Sanborn-2010-Rational-approximations-to-rational.pdf",
    "date_published": "2015-08-05",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". One random variable is selected, and the value of this variable is sampled, conditioned on the values of all of the other random variables and the data. The process is repeated for each variable; each is sampled conditioned on the values of all of the other variables and the data. Intuitively, Gibbs sampling corresponds to the process of inspecting one’s beliefs about each random variable conditioned on one’s beliefs about all of the other random variables, and the data. Reflecting on each variable in turn provides the opportunity for changes to propagate through the set of random variables. A complete run through sampling all of the random variables is an iteration and the algorithm is usually engaged for many iterations. Though the algorithm will eventually sample from the desired distribution, is starts Rational Approximations to Category Learning 10 at a particular, often random, set of values. The early iterations show the algorithm converging to the desired distribution, but are not yet samples from this distribution. These iterations are known as the burn-in and are thrown away. An additional difficulty is that iterations following the burn-in iterations often show strong dependency from one iteration to the next. These iterations are then thinned, which means keeping every n th iteration and discarding the rest. The remaining iterations after burn-in and thinning are used as samples from the desired distribution. This process provides a way to generate samples from probability distributions defined over large numbers of variables without ever having to enumerate the entire hypothesis space, providing a tractable way to perform probabilistic inference in these cases. Particle filters A second class of Monte Carlo algorithms, particle filters, are specifically designed to deal with sequential data",
    "chunk_id": "Adv_cognitive_modelling_sanborn-2010-rational-approximations-to-rational.json_chunk_11"
  },
  {
    "document_type": "research_paper",
    "title": "Rational approximations to rational models: Alternative algorithms for category learning",
    "author": "Sanborn, Adam N.; Griffiths, Thomas L.; Navarro, Danielle J.",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Sanborn-2010-Rational-approximations-to-rational.pdf",
    "date_published": "2015-08-05",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Particle filters A second class of Monte Carlo algorithms, particle filters, are specifically designed to deal with sequential data. Particle filters are underpinned by a simpler algorithm known as importance sampling, which is used in cases in which it is hard to sample from the target distribution, but easy to sample from a related distribution (known as the proposal distribution). The basic idea of importance sampling is that we generate samples from the proposal distribution, and then assign those samples weights that correct for the difference from the target distribution. Samples that are more likely under the proposal than the target distribution are assigned lower weights, since they should be over-represented in a set of draws from the proposal distribution, and samples that are more likely under the target than the proposal are assigned higher weights, increasing their influence. Particle filters extend importance sampling to a sequence of probability distributions, typically making use of the relationship between successive distributions to use samples from one distribution to generate samples from the next (for more details, see Doucet et al., 2001). The particle filter was originally developed for making inferences Rational Approximations to Category Learning 11 about variables in a dynamic environment – the problem of “filtering” is to infer the current state of the world given a sequence of observations. However, it also provides a natural solution to the general problem of updating a probability distribution over time. Each particle is a sample from the posterior distribution on the previous trial, and these samples are updated when new data become available. Rational approximations to rational models Monte Carlo algorithms provide efficient schemes for approximating probabilistic inference, and come with the asymptotic guarantee that they can produce an arbitrarily good approximation if sufficient computational resources are available",
    "chunk_id": "Adv_cognitive_modelling_sanborn-2010-rational-approximations-to-rational.json_chunk_12"
  },
  {
    "document_type": "research_paper",
    "title": "Rational approximations to rational models: Alternative algorithms for category learning",
    "author": "Sanborn, Adam N.; Griffiths, Thomas L.; Navarro, Danielle J.",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Sanborn-2010-Rational-approximations-to-rational.pdf",
    "date_published": "2015-08-05",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". These algorithms thus seem like good candidates for explaining how human minds could be capable of performing probabilistic inference, bridging the gap between the computational-level analyses typically associated with rational models of cognition and the algorithmic level at which psychological process models are defined. In particular, Gibbs sampling and particle filters provide solutions to the challenges posed by probabilistic inference with large numbers of variables and updating probability distributions over time. Part of the attraction of the Monte Carlo principle as the basis for developing rational process models is that it reduces probabilistic computations to one operation: generating samples from a probability distribution. The notion that people might be capable of generating samples from internalized probability distributions has previously appeared in psychological process models of decision making (Stewart, Chater, & Brown, 2006), estimation (Fiedler & Juslin, 2006), and prediction (Mozer, Pashler, & Homaei, 2008). Indeed, the foundational premise of the highly successful “sequential sampling” framework (Ratcliff, 1978; P. L. Smith & Ratcliff, 2004; Vickers, 1979) is that choice behavior is fundamentally reliant on people drawing and evaluating samples from probability distributions that in some cases derive from internally stored stimulus Rational Approximations to Category Learning 12 representations (Lee & Cummins, 2004; Ratcliff, 1978; Vandekerckhove, Verheyen, & Tuerlinckx, 2010). Taken together, these models provide support for the idea that the basic ingredients required for Monte Carlo simulation are already part of the psychological toolbox. Recent research has also identified correspondences between the kind of sophisticated Monte Carlo methods discussed above and psychological process models",
    "chunk_id": "Adv_cognitive_modelling_sanborn-2010-rational-approximations-to-rational.json_chunk_13"
  },
  {
    "document_type": "research_paper",
    "title": "Rational approximations to rational models: Alternative algorithms for category learning",
    "author": "Sanborn, Adam N.; Griffiths, Thomas L.; Navarro, Danielle J.",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Sanborn-2010-Rational-approximations-to-rational.pdf",
    "date_published": "2015-08-05",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Recent research has also identified correspondences between the kind of sophisticated Monte Carlo methods discussed above and psychological process models. Shi, Feldman, and Griffiths (2008) showed that the basic computations involved in importance sampling are identical to those used in exemplar models (also see Shi, Griffiths, Feldman, & Sanborn, in press). Exemplar models assume that people store stimuli in memory, activating them based on their similarity to new stimuli (e.g., Medin & Schaffer, 1978; Nosofsky, 1986). An importance sampler can be implemented by storing hypotheses in memory, and activating them in proportion to the probability of observed data under that hypothesis. Moreover, this interpretation of exemplars as stored hypotheses links exemplar-based learning nicely to previous rational analyses of exemplar-based decisions as a form of sequential analysis (see Navarro, 2007; Nosofsky & Palmeri, 1997). That is, the importance sampling method allows people to efficiently learn and store a posterior distribution, and the sequential analysis method allows efficient decisions to be made on the basis of this stored representation. This thus constitutes a natural, psychologically plausible scheme for approximating some probabilistic computations. Several recent papers have also examined the possibility that particle filters might be relevant to understanding how people can update probability distributions over time. This idea was first raised by Sanborn, Griffiths, and Navarro (2006), and particle filters have subsequently been used to explain behavioral patterns observed in several tasks. Daw and Courville (2008) argued that a particle filter with a small number of particles could explain rapid transitions seen in associative learning tasks with animals",
    "chunk_id": "Adv_cognitive_modelling_sanborn-2010-rational-approximations-to-rational.json_chunk_14"
  },
  {
    "document_type": "research_paper",
    "title": "Rational approximations to rational models: Alternative algorithms for category learning",
    "author": "Sanborn, Adam N.; Griffiths, Thomas L.; Navarro, Danielle J.",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Sanborn-2010-Rational-approximations-to-rational.pdf",
    "date_published": "2015-08-05",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Daw and Courville (2008) argued that a particle filter with a small number of particles could explain rapid transitions seen in associative learning tasks with animals. Brown and Steyvers (2009) used particle filters to explain individual differences in a change-point Rational Approximations to Category Learning 13 detection task, where variation of the number of particles being considered captured one dimension along which participants varied. Finally, Levy, Reali, and Griffiths (2009) showed that garden path effects in sentence processing could be accounted for by using a particle filter for parsing, where the frequency with which the parser produced no valid particles was predictive of the difficulty that people had interpreting the sentence. Evaluating Monte Carlo algorithms as candidates for rational process models requires exploring how the predictions of rational models of cognition vary under these different approximation schemes, and examining how well these predictions correspond to human behavior. In the remainder of the paper, we provide a detailed investigation of the performance of different approximation algorithms for Anderson’s (1990; 1991) rational model of categorization. This model is a good candidate for such an investigation, since it involves an extremely challenging computational problem: evaluating a posterior distribution over all possible partitions of a set of objects into clusters. This problem is so challenging that Anderson’s original presentation of the model resorted to a heuristic solution. We use a connection between this rational model and a model that is widely used in Bayesian statistics to specify a Gibbs sampler and particle filter for this model, which we evaluate against a range of empirical data. The Rational Model of Categorization The problem of category learning is to infer the structure of categories from a set of stimuli labeled as belonging to those categories",
    "chunk_id": "Adv_cognitive_modelling_sanborn-2010-rational-approximations-to-rational.json_chunk_15"
  },
  {
    "document_type": "research_paper",
    "title": "Rational approximations to rational models: Alternative algorithms for category learning",
    "author": "Sanborn, Adam N.; Griffiths, Thomas L.; Navarro, Danielle J.",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Sanborn-2010-Rational-approximations-to-rational.pdf",
    "date_published": "2015-08-05",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". The Rational Model of Categorization The problem of category learning is to infer the structure of categories from a set of stimuli labeled as belonging to those categories. The knowledge acquired through this process can ultimately be used to make decisions about how to categorize new stimuli. Several rational analyses of category learning have been proposed (Anderson, 1990; Ashby & Alfonso-Reese, 1995; Nosofsky, 1998). These analyses essentially agree on the nature of the computational problem involved, casting category learning as a problem of density estimation : determining the probability distributions associated with different category Rational Approximations to Category Learning 14 labels. Viewing category learning in this way helps to clarify the assumptions behind the two main classes of psychological models: exemplar models and prototype models. Exemplar models assume that a category is represented by a set of stored exemplars, and categorizing new stimuli involves comparing these stimuli to the set of exemplars in each category (e.g., Medin & Schaffer, 1978; Nosofsky, 1986). Prototype models assume that a category is associated with a single prototype and categorization involves comparing new stimuli to these prototypes (e.g., Reed, 1972). These approaches to category learning correspond to different strategies for density estimation used in statistics, being nonparametric and parametric density estimation respectively (Ashby & Alfonso-Reese, 1995). Anderson’s (1990, 1991) rational analysis of categorization takes a third approach, modeling category learning as Bayesian density estimation. This approach encompasses both prototype and exemplar representations, automatically selecting the number of clusters to be used in representing a set of objects. Unfortunately, the inference for this model is extremely complex, requiring an evaluation of every possible way of partitioning exemplars into clusters, with the number of possible partitions growing exponentially with the number of exemplars",
    "chunk_id": "Adv_cognitive_modelling_sanborn-2010-rational-approximations-to-rational.json_chunk_16"
  },
  {
    "document_type": "research_paper",
    "title": "Rational approximations to rational models: Alternative algorithms for category learning",
    "author": "Sanborn, Adam N.; Griffiths, Thomas L.; Navarro, Danielle J.",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Sanborn-2010-Rational-approximations-to-rational.pdf",
    "date_published": "2015-08-05",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Anderson proposed an approximation algorithm in which stimuli are sequentially assigned to clusters, and assignments of stimuli are fixed once they are made. However, this algorithm does not provide any asymptotic guarantees for the quality of the resulting assignments, and is extremely sensitive to the order in which stimuli are observed, a property which is not intrinsic to the underlying statistical model. As a result, evaluations of the model are tied to the particular approximation algorithm that was used. Before we consider alternative approximation algorithms for Anderson’s model, we need to provide a detailed specification of the model and the original algorithm. In this section, we first outline the Bayesian view of categorization, showing how exemplar and prototype models are special cases of the approach, and then describe the specific Rational Approximations to Category Learning 15 approach taken by Anderson. Bayesian categorization models Rational models of categorization must solve the density estimation problem outlined above and use this estimate to identify the category label or some other unobserved property of an object using its observed properties (Anderson, 1990; Ashby & Alfonso-Reese, 1995; Rosseel, 2002). This prediction problem has a natural interpretation as a form of Bayesian inference, which we now outline. Suppose that the learner has previously been shown a set of two stimuli and their labels, where the two stimuli are the first two stimuli in Figure 1. We let y i refer to the category label given to the i th object in this list (often a nonsense syllable such as “DAX”), and the mental representation of the object is assumed to be characterized by a collection of features, denoted x i . So for instance if the stimulus is the first stimulus, it could be simply described in terms of features such as “is circular”, “is black”, and “is large”. Thus, if the learner is told “the first stimulus is a DAX”, we would describe the trial by the pair ( x i , y i )",
    "chunk_id": "Adv_cognitive_modelling_sanborn-2010-rational-approximations-to-rational.json_chunk_17"
  },
  {
    "document_type": "research_paper",
    "title": "Rational approximations to rational models: Alternative algorithms for category learning",
    "author": "Sanborn, Adam N.; Griffiths, Thomas L.; Navarro, Danielle J.",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Sanborn-2010-Rational-approximations-to-rational.pdf",
    "date_published": "2015-08-05",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Thus, if the learner is told “the first stimulus is a DAX”, we would describe the trial by the pair ( x i , y i ). Across the set of two labelled objects, the information available to the learner can be thought of as a collection of statements (e.g., “the first stimulus is a DAX” and “the second stimulus is a ZUG”) that can be formally characterized by the collection of stimulus representations x 2 = ( x 1 , x 2 ), along with the labels given to each of these objects y 2 = ( y 1 , y 2 ). More generally we will refer to these already known stimuli as the first N − 1 stimuli with representations x N − 1 = ( x 1 , x 2 , x N − 1 ), and labels y N − 1 = ( y 1 , y 2 , y N − 1 ) With that in mind, the problem facing the learner can be written in the following way: on the N th trial in the experiment, he or she is shown a new stimulus x N (e.g., the third stimulus in Figure 1), and asked what label it should be given. If there are J possible labels involved in the task, the problem is to determine if the N th object should be given the j th label (i.e., infer that y N = j ), on the basis of the information available, Rational Approximations to Category Learning 16 ( x N , x N − 1 , y N − 1 ). If we apply Bayes’ rule to this problem, we are able to see that P ( y N = j | x N , x N − 1 , y N − 1 ) = P ( x N | y N = j, x N − 1 , y N − 1 ) P ( y N = j | y N − 1 ) ! J y =1 P ( x N | y N = y, x N − 1 , y N − 1 ) P ( y N = y | y N − 1 ) . (1) In this expression, P ( x N | y N = j, x N − 1 , y N − 1 ) denotes the estimated probability that an element of the j th category would possess the collection of features x N observed in the novel object, and P ( y N = j | y N − 1 ) is an estimate of the prior probability that a new object would belong to the j th category. Additionally, we have assumed that the prior probability of an object coming from a particular category is independent of the features of the previous objects",
    "chunk_id": "Adv_cognitive_modelling_sanborn-2010-rational-approximations-to-rational.json_chunk_18"
  },
  {
    "document_type": "research_paper",
    "title": "Rational approximations to rational models: Alternative algorithms for category learning",
    "author": "Sanborn, Adam N.; Griffiths, Thomas L.; Navarro, Danielle J.",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Sanborn-2010-Rational-approximations-to-rational.pdf",
    "date_published": "2015-08-05",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Additionally, we have assumed that the prior probability of an object coming from a particular category is independent of the features of the previous objects. Thus, this expression makes clear that the probability that an object with features x N should be given the label y N = j is related both the probability of sampling an object with features x N from that category, and the prior probability of choosing that category label. Category learning, then, becomes a matter of determining these probabilities – the problem known as density estimation. One advantage to describing categorization in terms of the density estimation problem is that both exemplar models and prototype models can be described as different methods for determining the probabilities described by Equation 1. Specifically, Ashby and Alfonso-Reese (1995) observed that if the learner uses a simple form of nonparametric density estimation known as kernel density estimation (e.g., Silverman, 1986) in order to compute the probability P ( x N | y N = j, x N − 1 , y N − 1 ), then an exemplar model of categorization is the result. On the other hand, they note that the learner could use a form of parametric density estimation (e.g., Rice, 1995), in which the category distribution is assumed to have some known form, and the learner’s goal is to estimate the unknown parameters of that distribution. If the learner uses this approach, then the result is a prototype model, with the centroid being an appropriate estimate for distributions whose parameters characterize their mean. To illustrate the point, Figure 2 shows a prototype model on the left, in which the category distribution is assumed to be normal Rational Approximations to Category Learning 17 distribution centered over the prototype, and an exemplar model on the right, in which a separate normal distribution (the “kernel”) is placed over each exemplar, and the resulting category distribution is a mixture model",
    "chunk_id": "Adv_cognitive_modelling_sanborn-2010-rational-approximations-to-rational.json_chunk_19"
  },
  {
    "document_type": "research_paper",
    "title": "Rational approximations to rational models: Alternative algorithms for category learning",
    "author": "Sanborn, Adam N.; Griffiths, Thomas L.; Navarro, Danielle J.",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Sanborn-2010-Rational-approximations-to-rational.pdf",
    "date_published": "2015-08-05",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Having cast the problem in these terms, it is clear that exemplar and prototype models are two extremes along a continuum of possible approaches to category representation. As illustrated in the middle panel of Figure 2, the learner might choose to break the category up into several clusters of stimuli, denoted z N − 1 , where z i = k if the i th stimulus is assigned to the k th cluster. Each such cluster is then associated with a simple parametric distribution, and the category distribution as a whole then becomes a mixture model (e.g. Rosseel, 2002; Vanpaemel & Storms, 2008). Expressed in these terms, prototype models map naturally onto the idea of a one-cluster representation, and exemplar models arise when there is a separate cluster for each object. In between lies a whole class of intermediate category representations, such as the one shown in the middle of Figure 2. In this case, the learner has divided the five objects into two clusters, and the resulting category distribution is a mixture of two normal distributions. The appeal of this more general class of category representations is that it allows people to use prototype-like models when called for, and to move to the more flexible exemplar-like models when needed. However, by proposing category representations of this form, we introduce a new problem: for a set of N objects how many clusters K are appropriate to represent the categories, and how should the cluster assignments z N be made in light of the available data ( x N , y N )? It is to this topic that we now turn. Statistical model A partial solution to this problem was given by Anderson (1990), in the form of the Rational Model of Categorization (RMC). The RMC is somewhat different to the various mixture models described in the previous section insofar as it treats the category labels as Rational Approximations to Category Learning 18 being equivalent to unobserved features",
    "chunk_id": "Adv_cognitive_modelling_sanborn-2010-rational-approximations-to-rational.json_chunk_20"
  },
  {
    "document_type": "research_paper",
    "title": "Rational approximations to rational models: Alternative algorithms for category learning",
    "author": "Sanborn, Adam N.; Griffiths, Thomas L.; Navarro, Danielle J.",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Sanborn-2010-Rational-approximations-to-rational.pdf",
    "date_published": "2015-08-05",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". As a consequence, the RMC specifies a joint distribution on features and category labels, rather than assuming that the distribution over category labels is estimated separately and then combined with a distribution on features for each category. This distribution is a mixture, with P ( x N , y N ) = \" z N P ( x N , y N | z N ) P ( z N ) (2) where P ( z N ) is a distribution over possible partitions of the N objects into clusters. Importantly, the number of clusters K in the partition z N is not assumed to be fixed in advance, but is rather something that the learner infers from the data. The RMC provides an explicit form for this prior distribution, namely P ( z N ) = (1 − c ) K c N − K # N − 1 i =0 [(1 − c ) + ci ] K $ k =1 ( M k − 1)! (3) where c is a parameter called the coupling probability , M k is the number of objects assigned to cluster k , and K is the total number of clusters in z N . Although this distribution appears unwieldy, it is in fact the distribution that results from sequentially assigning objects to clusters with probability P ( z i = k | z i − 1 ) =        cM k (1 − c )+ c ( i − 1) if M k > 0 (i.e., k is old) (1 − c ) (1 − c )+ c ( i − 1) if M k = 0 (i.e., k is new) (4) where the counts M k are accumulated over z i − 1 . Thus, each object can be assigned to an existing cluster with probability proportional to the number of objects already assigned to that cluster, or to a new cluster with probability determined by c . Since the prior distribution is set up in a way that allows K to grow as more objects are encountered, the RMC allows the learner to infer the number of clusters via the usual process of Bayesian updating. Intuitively, we can look at the prior as a rich-get-richer scheme: if a cluster already contains many objects, then it has a higher prior probability for new objects. The Rational Approximations to Category Learning 19 coupling probability is the parameter that determines the severity of this scheme",
    "chunk_id": "Adv_cognitive_modelling_sanborn-2010-rational-approximations-to-rational.json_chunk_21"
  },
  {
    "document_type": "research_paper",
    "title": "Rational approximations to rational models: Alternative algorithms for category learning",
    "author": "Sanborn, Adam N.; Griffiths, Thomas L.; Navarro, Danielle J.",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Sanborn-2010-Rational-approximations-to-rational.pdf",
    "date_published": "2015-08-05",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". The Rational Approximations to Category Learning 19 coupling probability is the parameter that determines the severity of this scheme. For high values of the coupling parameter, then larger clusters will be favored in the prior, while for low values of the coupling parameter, smaller clusters will be favored. The cluster sizes that actually result depend on the likelihoods as well as the prior. The local MAP algorithm When considering richer representations than prototypes and exemplars it is necessary to have a method for learning the appropriate representation from data. Using Equation 2 to make predictions about category labels and features requires summing over all possible partitions z N . This sum rapidly becomes intractable for large N , since the number of partitions grows rapidly with the number of stimuli according to the Bell number introduced earlier. Consequently, an approximate inference algorithm is needed and Anderson (1990, 1991) developed a simple inference algorithm to solve this problem. We will refer to this algorithm as the local MAP algorithm, as it involves assigning each stimulus to the cluster that has the highest posterior probability given the previous assignments (i.e., the maximum a posteriori or MAP cluster). The algorithm is a local implementation of the MAP because it makes an assignment for each new stimulus as it arrives, which does not necessarily result in the global MAP. The local MAP algorithm approximates the sum in Equation 2 with just a single clustering of the N objects, z N . This clustering is selected by assigning each object to a cluster as it is observed. At this point, the features and labels of all stimuli, along with the cluster assignments z i − 1 for the previous i − 1 stimuli are given",
    "chunk_id": "Adv_cognitive_modelling_sanborn-2010-rational-approximations-to-rational.json_chunk_22"
  },
  {
    "document_type": "research_paper",
    "title": "Rational approximations to rational models: Alternative algorithms for category learning",
    "author": "Sanborn, Adam N.; Griffiths, Thomas L.; Navarro, Danielle J.",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Sanborn-2010-Rational-approximations-to-rational.pdf",
    "date_published": "2015-08-05",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". At this point, the features and labels of all stimuli, along with the cluster assignments z i − 1 for the previous i − 1 stimuli are given. Thus, the posterior probability that stimulus i was generated from cluster k is P ( z i = k | z i − 1 , x i , x i − 1 , y i , y i − 1 ) ∝ (5) P ( x i | z i = k, z i − 1 , x i − 1 ) P ( y i | z i = k, z i − 1 , y i − 1 ) P ( z i = k | z i − 1 ) where P ( z i = k | z i − 1 ) is given by Equation 4. Under the local MAP algorithm, x i is Rational Approximations to Category Learning 20 assigned to the cluster k that maximizes Equation 5. Iterating this process results in a single partition of a set of N objects. To illustrate the local MAP algorithm, we show in Figure 3 how it would be applied it to the simple example of sequentially presented stimuli in Figure 1. Each stimulus is parameterized by three binary features and the likelihood P ( x i | z i = k, z i − 1 , x i − 1 ) P ( y i | z i = k, z i − 1 , y i − 1 ) is calculated using binomial distributions that are independent for each feature. These binomial likelihoods are parameterized by the probability of the outcome, and need a prior distribution over this probability. The standard prior for binomial likelihoods is the Beta distribution (see the Appendix for details). For the toy example, we used a symmetric Beta prior for the binomial likelihood, with β = 1. The symmetric Beta distribution with β = 1 is a simple choice, because it is equivalent to the uniform distribution. The local MAP algorithm initially assigns the first observed stimulus to its own cluster. When the second stimulus is observed, the algorithm generates each possible partition: either it is assigned to the same cluster as the first stimulus or to a new cluster. The posterior probability of each of these partitions is calculated and the partition with the highest posterior probability is always chosen as the representation",
    "chunk_id": "Adv_cognitive_modelling_sanborn-2010-rational-approximations-to-rational.json_chunk_23"
  },
  {
    "document_type": "research_paper",
    "title": "Rational approximations to rational models: Alternative algorithms for category learning",
    "author": "Sanborn, Adam N.; Griffiths, Thomas L.; Navarro, Danielle J.",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Sanborn-2010-Rational-approximations-to-rational.pdf",
    "date_published": "2015-08-05",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". The posterior probability of each of these partitions is calculated and the partition with the highest posterior probability is always chosen as the representation. After the third stimulus is observed, the algorithm produces all possible partitions involving the third stimulus, assuming that the clustering for the first two stimuli remains the same. Note that not all possible partitions of the three stimuli are considered, because the algorithm makes an irrevocable choice for the partition of the first two stimuli and the possible partitions on later trials have to be consistent with this choice. The local MAP algorithm will always produce the same final partition for a given sequential order of the stimuli, assuming there are no ties in the posterior probability. The local MAP algorithm approximates the complete joint distribution using only Rational Approximations to Category Learning 21 this partition. In effect, it assumes that P ( x N , y N ) ≈ P ( x N , y N | z N ) (6) where z N is produced via the procedure outlined above. The probability that a particular object receives a particular category label would likewise be computed using a single partition. Summary The RMC specifies a rational model of categorization, capturing many of the ideas embodied in other models and allowing the representation to be inferred from the data. However, the model is still significantly limited, because the approximate algorithm used for assigning objects to clusters in the RMC can be a poor approximation to the posterior. In particular, this makes it hard to discriminate the predictions that result from the underlying statistical model from those that are a consequence of the algorithm being used. In order to explore alternative approximation algorithms, we now discuss the connections between the RMC and nonparametric Bayesian statistics. Dirichlet process mixture models One of the most interesting properties of the RMC is that it has a direct connection to a model used in nonparametric Bayesian statistics (Neal, 1998)",
    "chunk_id": "Adv_cognitive_modelling_sanborn-2010-rational-approximations-to-rational.json_chunk_24"
  },
  {
    "document_type": "research_paper",
    "title": "Rational approximations to rational models: Alternative algorithms for category learning",
    "author": "Sanborn, Adam N.; Griffiths, Thomas L.; Navarro, Danielle J.",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Sanborn-2010-Rational-approximations-to-rational.pdf",
    "date_published": "2015-08-05",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Dirichlet process mixture models One of the most interesting properties of the RMC is that it has a direct connection to a model used in nonparametric Bayesian statistics (Neal, 1998). The rationale for using nonparametric methods is that real data are not generally sampled from some neat, finite-dimensional family of distributions, so it is best to avoid this assumption at the outset. From a Bayesian perspective, the nonparametric approach requires us to use priors that include as broad a range of densities of possible, thereby allowing us to infer very complex densities if they are warranted by data. The most commonly used method for placing broad priors over probability distributions is the Dirichlet process (DP; Ferguson, 1973). The distributions indexed by the Dirichlet process can be expressed as countably Rational Approximations to Category Learning 22 infinite mixtures of point masses (Sethuraman, 1994), making them ideally suited to act as priors in infinite mixture models (Escobar & West, 1995; Rasmussen, 2000). When used in this fashion, the resulting model is referred to as a Dirichlet process mixture model (DPMM; Antoniak, 1974; Ferguson, 1983; Neal, 1998). Although a complete description of the Dirichlet process is beyond the scope of this paper (for more details, see Navarro, Griffiths, Steyvers, & Lee, 2006), what matters for our purposes is that the Dirichlet process implies a distribution over partitions: any two observations in the sample that were generated from the same mixture component may be treated as members of the same cluster, allowing us to specify priors over an unbounded number of clusters. In the case where N observations have been made, the prior probability that a Dirichlet process will partition those observations into the clusters z N is P ( z N ) = α K # N − 1 i =0 [ α + i ] K $ k =1 ( M k − 1)! (7) where α is the dispersion parameter of the Dirichlet process",
    "chunk_id": "Adv_cognitive_modelling_sanborn-2010-rational-approximations-to-rational.json_chunk_25"
  },
  {
    "document_type": "research_paper",
    "title": "Rational approximations to rational models: Alternative algorithms for category learning",
    "author": "Sanborn, Adam N.; Griffiths, Thomas L.; Navarro, Danielle J.",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Sanborn-2010-Rational-approximations-to-rational.pdf",
    "date_published": "2015-08-05",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". This distribution over partitions can be produced by a simple sequential stochastic process (Blackwell & MacQueen, 1973). If observations are assigned to clusters one after another and the probability that observation i + 1 is assigned to cluster k is P ( z i = k | z i − 1 ) =        M k i − 1+ α if M k > 0 (i.e., k is old) α i − 1+ α if M k = 0 (i.e., k is new) (8) we obtain Equation 7 for the probability of the resulting partition. This distribution has a number of nice properties, with one of the most important being exchangeability : the prior probability of a partition is unaffected by the order in which the observations are received (Aldous, 1985). Intuitively, exchangeability is similar to independence, but slightly weaker. To make some of these ideas more concrete, Figure 4 presents a visual depiction of the relationship between the partitioning implied by the DP, the distribution over parameters that is sampled from the DP, and the resulting mixture distribution over Rational Approximations to Category Learning 23 stimuli that results in the DPMM. The partitioning implied by the DPMM shows that items are divided into discrete clusters. Each of these clusters is given a parameter drawn from the prior distribution over parameters. A large number of parameter draws are shown in Figure 4b. Each spike is a new parameter value and the height of the bars depends on the number of clusters that use that parameter. Finally, combining the parameter values with a continuous likelihood function, such as a Gaussian distribution, gives the mixture distribution shown in Figure 4c. It should be apparent from our description of the prior distribution used in the DPMM that it is similar in spirit to the prior distribution underlying the RMC. In fact, the two are directly equivalent, a point that was first made in the statistics literature by Neal (1998). If we let α = (1 − c ) /c , Equations 3 and 7 are equivalent, as are Equations 4 and 8",
    "chunk_id": "Adv_cognitive_modelling_sanborn-2010-rational-approximations-to-rational.json_chunk_26"
  },
  {
    "document_type": "research_paper",
    "title": "Rational approximations to rational models: Alternative algorithms for category learning",
    "author": "Sanborn, Adam N.; Griffiths, Thomas L.; Navarro, Danielle J.",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Sanborn-2010-Rational-approximations-to-rational.pdf",
    "date_published": "2015-08-05",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". If we let α = (1 − c ) /c , Equations 3 and 7 are equivalent, as are Equations 4 and 8. Thus the prior over cluster assignments used in the RMC is exactly the same as that used in the DPMM. Anderson (1990, 1991) thus independently discovered one of the most celebrated models in nonparametric Bayesian statistics, deriving this distribution from first principles. Alternative approximate inference algorithms The connection between the RMC and the DPMM suggests a solution to the shortcomings of the local MAP algorithm. In this section, we draw on the extensive literature on approximate inference for DPMMs to offer two alternative algorithms for the RMC: Gibbs sampling and particle filtering. These algorithms are less sensitive to order and are asymptotically guaranteed to produce accurate predictions. As discussed above, both Gibbs sampling and particle filters are Monte Carlo methods. This means that they provide ways of approximating the intractable sum over partitions numerically using a collection of samples. Specifically, to compute the probability that a particular object receives a particular category label, a Monte Carlo Rational Approximations to Category Learning 24 approximation gives P ( y N = j | x N , y N − 1 ) = \" z N P ( y N = j | x N , y N − 1 , z N ) P ( z N | x N , y N − 1 ) (9) ≈ 1 M M \" l =1 P ( y N = j | x N , y N − 1 , z ( l ) N ) where z (1) N , , z ( M ) N are M samples from P ( z N | x N , y N − 1 ), and the approximation becomes exact as M →∞ . The two algorithms differ only in how these samples are generated. Gibbs sampling Gibbs sampling is the approximate inference algorithm most commonly used with the DPMM (e.g., Escobar & West, 1995; Neal, 1998). It provides a way to construct a Markov chain that converges to the posterior distribution over partitions",
    "chunk_id": "Adv_cognitive_modelling_sanborn-2010-rational-approximations-to-rational.json_chunk_27"
  },
  {
    "document_type": "research_paper",
    "title": "Rational approximations to rational models: Alternative algorithms for category learning",
    "author": "Sanborn, Adam N.; Griffiths, Thomas L.; Navarro, Danielle J.",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Sanborn-2010-Rational-approximations-to-rational.pdf",
    "date_published": "2015-08-05",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". It provides a way to construct a Markov chain that converges to the posterior distribution over partitions. The state space of the Markov chain is the set of partitions, and transitions between states are produced by sampling the cluster assignment of each stimulus from its conditional distribution, given the current assignments of all other stimuli. The clustering evolves by sequentially sampling each z i from the distribution P ( z i = k | z − i , x i , x − i , y i , y − i ) ∝ (10) P ( x i | z i = k, z − i , x − i ) P ( y i | z i = k, z − i , y − i ) P ( z i = k | z − i ) where z − i refers to all cluster assignments except for the i th. Equation 10 is extremely similar to Equation 5, although it gives the probability of a cluster based on the all of the trials in the entire experiment except for the current trial, instead of just the previous trials. The statistical property of exchangeability, briefly noted above, means that these probabilities are actually computed in exactly the same way: the order of the observations can be rearranged so that any particular observation is considered the last observation. Hence, we can use Equation 8 to compute P ( z i | z − i ), with old clusters receiving probability in proportion to their popularity, and a new cluster Rational Approximations to Category Learning 25 being chosen with probability determined by α (or, equivalently, c ). The other terms reflect the probability of the features and category label of stimulus i under the partition that results from this choice of z i , and depends on the nature of the features. The Gibbs sampling algorithm for the DPMM is straightforward (Neal, 1998), and is illustrated for the simple example in Figure 5. First, an initial assignment of stimuli to clusters is chosen, with a convenient choice being all stimuli assigned to a single cluster. Unlike the local MAP algorithm, Gibbs sampling is not a sequential algorithm; all stimuli must be observed before it can be run",
    "chunk_id": "Adv_cognitive_modelling_sanborn-2010-rational-approximations-to-rational.json_chunk_28"
  },
  {
    "document_type": "research_paper",
    "title": "Rational approximations to rational models: Alternative algorithms for category learning",
    "author": "Sanborn, Adam N.; Griffiths, Thomas L.; Navarro, Danielle J.",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Sanborn-2010-Rational-approximations-to-rational.pdf",
    "date_published": "2015-08-05",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Unlike the local MAP algorithm, Gibbs sampling is not a sequential algorithm; all stimuli must be observed before it can be run. Next, we choose a single stimulus and consider all possible reassignments of that stimulus to clusters, including not making a change in assignments or assigning the stimulus to a new cluster. Equation 10 gives the probability of each partition and one of the partitions is sampled based on its posterior probability, making this algorithm stochastic, unlike the local MAP. The stochastic nature of the algorithm is evident in the example in Figure 5, because the first circled assignment has lower probability than the alternatives. The example shows two iterations of Gibbs sampling, in which each stimulus is cycled through and reassigned. In an actual application the algorithm would go through many iterations, with the output of one iteration providing the input to the next. Since the probability of obtaining a particular partition after each iteration depends only on the partition produced on the previous iteration, this is a Markov chain. After enough iterations for the Markov chain to converge, we begin to save the partitions it produces. The partition produced on one iteration is not independent of the next, so the results of some iterations are discarded to approximate independence. The partitions generated by the Gibbs sampler can be used in the same way as samples z ( l ) N in Equation 9. As with standard Monte Carlo approximations, the quality of the approximation increases as the number of partitions in that collection increases. The Gibbs sampler provides an effective means of constructing the approximation in Rational Approximations to Category Learning 26 Equation 9, and thus of making accurate predictions about the unobserved features of stimuli. Particle filtering There are several ways to construct a particle filter for the DPMM. The method we will use is most closely related to the one discussed by Fearnhead (2004)",
    "chunk_id": "Adv_cognitive_modelling_sanborn-2010-rational-approximations-to-rational.json_chunk_29"
  },
  {
    "document_type": "research_paper",
    "title": "Rational approximations to rational models: Alternative algorithms for category learning",
    "author": "Sanborn, Adam N.; Griffiths, Thomas L.; Navarro, Danielle J.",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Sanborn-2010-Rational-approximations-to-rational.pdf",
    "date_published": "2015-08-05",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Particle filtering There are several ways to construct a particle filter for the DPMM. The method we will use is most closely related to the one discussed by Fearnhead (2004). The key idea is to treat each new observation as a new “time step”, with each particle being a partition z ( l ) i of the stimuli from the first i trials. Unlike the local MAP algorithm, in which the posterior distribution is approximated with a single partition, the particle filter uses M partitions. Summing over these particles gives us an approximation to the posterior distribution over partitions P ( z i | x i , y i ) ≈ M \" l =1 1 M δ ( z i , z ( l ) i ) (11) where δ ( z , z ′ ) is 1 when z = z ′ , and 0 otherwise. If Equation 11 is used as an approximation to the posterior distribution over partitions z i after the first i trials, then we can approximate the distribution of z i +1 given the observations x i , y i in the following manner: P ( z i +1 | x i , y i ) = \" z i P ( z i +1 | z i ) P ( z i | x i , y i ) ≈ \" z i P ( z i +1 | z i ) m \" l =1 1 m δ ( z i , z ( l ) i ) = 1 m m \" l =1 P ( z i +1 | z ( l ) i ) (12) where P ( z i +1 | z i ) is given by Equation 8. We can then incorporate the information conveyed by the features and label of stimulus i + 1, arriving at the approximate posterior probability P ( z i +1 | x i +1 , y i +1 ) ∝ P ( x i +1 | z i +1 , x i ) P ( y i +1 | z i +1 , y i ) P ( z i +1 | x i , y i ) ≈ 1 m m \" l =1 P ( x i +1 | z i +1 , x i ) P ( y i +1 | z i +1 , y i ) P ( z i +1 | z ( l ) i ) (13) Rational Approximations to Category Learning 27 The result is a discrete distribution over all the previous particle assignments and all possible assignments for the current stimulus. Drawing M samples from this distribution provides us with our new set of particles. The particle filter for the simple example is illustrated in Figure 6. The particle filter for the DPMM is initialized with the first stimulus assigned to the first cluster for all M particles, in this case M = 2",
    "chunk_id": "Adv_cognitive_modelling_sanborn-2010-rational-approximations-to-rational.json_chunk_30"
  },
  {
    "document_type": "research_paper",
    "title": "Rational approximations to rational models: Alternative algorithms for category learning",
    "author": "Sanborn, Adam N.; Griffiths, Thomas L.; Navarro, Danielle J.",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Sanborn-2010-Rational-approximations-to-rational.pdf",
    "date_published": "2015-08-05",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". The particle filter for the DPMM is initialized with the first stimulus assigned to the first cluster for all M particles, in this case M = 2. On observing each new stimulus, the distribution in Equation 13 is calculated, based on the particles sampled in the last trial. Like the local MAP, the particle filter updates the partition as each new stimulus is observed, and like the local MAP, only new partitions that are consistent with the previous choices made by the algorithm are considered. This consistency can be seen in the potential partitions when the third stimulus is observed in Figure 6: each descendant is consistent with the partition choices made by its ancestor. Intuitively, the psychological processes involved in this approximation are very similar to those involved in the local MAP algorithm. People update their beliefs incrementally, keeping the assignments of old items fixed, and making the assignments of new items conditional on these fixed beliefs. There are two key differences between the local MAP and particle filter algorithms. The first is that the choice of new partitions is stochastic instead of deterministic. The particle filter algorithm samples new partitions based on their posterior probabilities instead of always selecting the partition with the maximum probability. A particle filter with M = 1 particles is equivalent to the local MAP algorithm, except that the new partition is sampled instead of deterministically selected. The second difference is that multiple particles means that multiple partitions can be used instead of the single partition passed forward by the local MAP. The M partitions are selected without regard for ancestry, allowing a partition that was selected for the early observations to die out as the descendants of other partitions replace it. Rational Approximations to Category Learning 28 Approximation quality The differences in quality of the various approximations can be explored by a toy example using sequential observations of the stimuli in Figure 1",
    "chunk_id": "Adv_cognitive_modelling_sanborn-2010-rational-approximations-to-rational.json_chunk_31"
  },
  {
    "document_type": "research_paper",
    "title": "Rational approximations to rational models: Alternative algorithms for category learning",
    "author": "Sanborn, Adam N.; Griffiths, Thomas L.; Navarro, Danielle J.",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Sanborn-2010-Rational-approximations-to-rational.pdf",
    "date_published": "2015-08-05",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". We compared the local MAP, a particle filter with M = 100 particles, a particle filter with M = 1 particle, and Gibbs sampling to the exact posterior. For each algorithm a symmetric Beta prior in which β = 1 was used for the likelihood (see Appendix for details). The local MAP was run a single time, because its outcome is deterministic on a fixed stimulus order. The particle filters were each replicated 10,000 times, and the Gibbs sampler was run for 101,000 iterations. For the Gibbs sampler, the first 1,000 iterations were discarded and every 10th iteration was taken as a sample, yielding 10,000 samples. The results of this comparison are shown in Figure 7. The local MAP algorithm has selected a single partition as an approximation to the exact posterior. In this example, the partition selected by the local MAP is also the MAP of the exact posterior distribution, but the two will not always be equivalent. By taking the MAP partition as each stimulus arrives, the local MAP can be misled to choose a partition that is not the global MAP, if the initial trials are not representative of the whole run of trials. An example of this can be seen in the experiment by Anderson and Matessa in a later section. The particle filter with M = 100 particles and the Gibbs sampler both produce a posterior distribution that is nearly indistinguishable from the exact posterior. The single-particle particle filter is an interesting intermediate case. Each run of the single-particle particle filter produces a single partition, not the distribution produced by a particle filter with M > 1 particles. However, averaging over runs of the single-particle particle filter gives an approximation that is much closer to the exact posterior than the local MAP. Unlike the asymptotic performance of the Gibbs sampler and particle filter with infinite particles, the approximation of the single-particle particle filter is slightly biased, as can be seen in the figure",
    "chunk_id": "Adv_cognitive_modelling_sanborn-2010-rational-approximations-to-rational.json_chunk_32"
  },
  {
    "document_type": "research_paper",
    "title": "Rational approximations to rational models: Alternative algorithms for category learning",
    "author": "Sanborn, Adam N.; Griffiths, Thomas L.; Navarro, Danielle J.",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Sanborn-2010-Rational-approximations-to-rational.pdf",
    "date_published": "2015-08-05",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". The bias is much less than the local MAP because the Rational Approximations to Category Learning 29 algorithm is stochastic, but is still present because each run of the M = 1 particle filter cannot correct its previous assignments by resampling. Psychological plausibility of the algorithms Before turning to a quantitative comparison of the algorithms with human data it is worth considering their psychological plausibility at a descriptive level, to see whether they are appropriate for human cognition. We take as a starting point Anderson’s (1990, 1991) two desiderata for an approximate inference algorithm: that it be incremental, and that people see objects as arising from a single cause. These desiderata were based on beliefs about the nature of human category learning. In tasks in which people see objects presented sequentially and must judge which category they arise from “people need to be able to make predictions all the time not just at particular junctures after seeing many objects and much deliberation” (Anderson, 1991, p. 412), and “people tend to perceive objects as coming from specific categories” (Anderson, 1991, p. 411). In addition to these two desiderata, we are concerned with how these algorithms might introduce new order effects into a model. Often statistical models, such as the DPMM, are invariant to the order in which observations arrive. However, the approximations used in practical applications of these models tend to introduce order effects as a side effect of limited computation. People show effects of the order of presentation of stimuli (Anderson, 1990; Medin & Bettger, 1994; Murdock, 1962), and to have a psychologically plausible algorithm, the cumulative order effects of the model and those introduced by the approximation should match the order effects displayed by people. In the remainder of this section we summarize the psychological plausibility of the local MAP, Gibbs sampling, and particle filters",
    "chunk_id": "Adv_cognitive_modelling_sanborn-2010-rational-approximations-to-rational.json_chunk_33"
  },
  {
    "document_type": "research_paper",
    "title": "Rational approximations to rational models: Alternative algorithms for category learning",
    "author": "Sanborn, Adam N.; Griffiths, Thomas L.; Navarro, Danielle J.",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Sanborn-2010-Rational-approximations-to-rational.pdf",
    "date_published": "2015-08-05",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". In the remainder of this section we summarize the psychological plausibility of the local MAP, Gibbs sampling, and particle filters. We relate these algorithms to the properties of incrementalism, a single interpretation of how the data arise, and the order effects introduced by the algorithms, which are summarized in Table 1. Rational Approximations to Category Learning 30 Local MAP Anderson (1990, 1991) introduced the local MAP algorithm to satisfy his two desiderata for psychological plausibility. The first desideratum is satisfied because the local MAP is updated incrementally. In addition, the second desideratum is satisfied because only a single partition of the stimuli into clusters is available to the algorithm in order to make judgments about new stimuli. However, as a result of the single interpretation and its maximization operation, the local MAP algorithm is extremely sensitive to the order in which stimuli are observed. For example, Anderson and Matessa (reported in Anderson, 1990) showed that the predictions of the local MAP algorithm depended strongly on the order the stimuli were introduced in their clustering experiment. For one type of order, the local MAP always predicted one partition of the stimuli, but for the other order it always predicted a second partition. We will explore how the local MAP can be led down garden paths when we compare the algorithms quantitatively. Gibbs sampling Gibbs sampling draws samples from one random variable conditioned on all of the rest and all of the data, thus requiring all of the data be present before inference begins. New data cannot be incrementally added to the sampling scheme, so in order to sample from a posterior distribution when a new piece of data arrives, Gibbs sampling must start from scratch. This property makes the algorithm computationally wasteful if sequential judgments are required. For other tasks, however, Gibbs sampling is more psychologically plausbile",
    "chunk_id": "Adv_cognitive_modelling_sanborn-2010-rational-approximations-to-rational.json_chunk_34"
  },
  {
    "document_type": "research_paper",
    "title": "Rational approximations to rational models: Alternative algorithms for category learning",
    "author": "Sanborn, Adam N.; Griffiths, Thomas L.; Navarro, Danielle J.",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Sanborn-2010-Rational-approximations-to-rational.pdf",
    "date_published": "2015-08-05",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". This property makes the algorithm computationally wasteful if sequential judgments are required. For other tasks, however, Gibbs sampling is more psychologically plausbile. In tasks in which all of the data arrive simultaneously, such as when a researcher gives participants a set of objects to sort into groups, participants do not need to make judgments until all of the stimuli are present. Here Gibbs sampling seems psychologically plausible. Standard implementations of Gibbs sampling do not provide a single interpretation Rational Approximations to Category Learning 31 of the data. The algorithm gathers a set of samples from a probability distribution and all of these samples are used to infer other properties about the data, such as category labels. However, we should note that it would be possible to implement a modified version of the Gibbs sampling algorithm that would provide a fixed interpretation of the data. Instead of keeping all of the iterations, we could create a very forgetful Gibbs sampler that would only recall the current values of the variables when making inferences. Likewise, referring to our third property, Gibbs sampling is asymptotically unbiased, meaning that generating a huge number samples would not introduce any order effects not already present in the statistical model. Again though, the iterations of Gibbs sampling are dependent on one another, so in the forgetful Gibbs sampler we would have iteration to iteration dependence. This iteration to iteration dependence would not be an effect of the order in which the stimuli were presented, but instead an autocorrelation of judgments made by this model. Particle filters Particle filters are designed as sequential algorithms that explicitly use incremental updating, which clearly satisfies the first property and makes this algorithm appropriate for modeling sequential judgments. For the second property, the answer depends on the number of particles",
    "chunk_id": "Adv_cognitive_modelling_sanborn-2010-rational-approximations-to-rational.json_chunk_35"
  },
  {
    "document_type": "research_paper",
    "title": "Rational approximations to rational models: Alternative algorithms for category learning",
    "author": "Sanborn, Adam N.; Griffiths, Thomas L.; Navarro, Danielle J.",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Sanborn-2010-Rational-approximations-to-rational.pdf",
    "date_published": "2015-08-05",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". For the second property, the answer depends on the number of particles. Each particle is a sample from the posterior distribution, so a single-particle particle filter will provide a single interpretation of the data. With a multi-particle particle filter, the interpretation becomes probabilistic. The order effects introduced depend on the number of particles, analogous to how the Gibbs sampler’s order effects depend on the number of samples. With an infinite number of particles, the particle filter is a very faithful representation of the posterior distribution and thus does not introduce any order effects not present in the statistical model. However, small numbers of particles will introduce order effects and we explore this property in detail later. Rational Approximations to Category Learning 32 Comparing the algorithms Using the local MAP algorithm, the Rational Model of Categorization (RMC; Anderson, 1991) has successfully predicted human choices in a wide range of experimental paradigms. We introduced two new algorithms for the RMC in the above sections: the Gibbs sampler and the particle filter. We have demonstrated that both of these algorithms provide a closer approximation to the underlying model than the local MAP algorithm and both share some aspects of its psychological plausibility. In this section, we compare the local MAP algorithm, a sequential updating algorithm, against the sequential algorithm we have introduced: the particle filter. Most empirical investigations of human categorization use a sequential trial structure, so we have focused on this comparison. We compare the fits of the multi-particle particle filter, the single-particle particle filter, and the local MAP algorithm to show that the particle filter provides comparable fits to the human data and for some paradigms, the particle filter algorithm actually allows the RMC to better predict human choices",
    "chunk_id": "Adv_cognitive_modelling_sanborn-2010-rational-approximations-to-rational.json_chunk_36"
  },
  {
    "document_type": "research_paper",
    "title": "Rational approximations to rational models: Alternative algorithms for category learning",
    "author": "Sanborn, Adam N.; Griffiths, Thomas L.; Navarro, Danielle J.",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Sanborn-2010-Rational-approximations-to-rational.pdf",
    "date_published": "2015-08-05",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". There are a large number of categorization paradigms on which we could compare the algorithms – we chose to compare the algorithms on several data sets for which the local MAP algorithm performs well, including several cases from Anderson’s (1990; 1991) original evaluation of the model. Testing our algorithm against data on which the local MAP is known to perform well provides a strong test of the particle filter algorithm. We examine the effect of specific instances with binary (Medin & Schaffer, 1978) and continuous parameters (Nosofsky, 1988), and show the algorithms predict a similar correspondence with human data. Next we explore paradigms that have been chosen to highlight differences between the local MAP algorithm and the particle filter. The effects of trial order (Anderson, 1990), how linearly separable and non-separable categories are learned (J. D. Smith & Minda, 1998), and the wider class of learning problems in the Shepard, Hovland, and Jenkins (1961) task (Nosofsky, Gluck, Palmeri, McKinley, & Rational Approximations to Category Learning 33 Glauthier, 1994) are employed to illustrate the advantages of using the particle filter to approximate the RMC. Effect of specific instances In a classic paper, Medin and Schaffer (1978) tested whether categorization judgments were influenced by the central tendency of a category alone. In their Experiment 1, the stimuli were designed so as to test whether the nearness of stimuli had an effect above contributing to the category center. The stimuli consisted of six training items, each with five binary features (including the category label, listed last): 11111, 10101, 01011, 00000, 01000, and 10110. In the transfer session, the training items and additional items were rated. The transfer stimuli are presented in Table 2, ordered by human category ratings. These transfer stimuli were structured so that some were closer to specific instances than others, while the distance to the category centers was constant",
    "chunk_id": "Adv_cognitive_modelling_sanborn-2010-rational-approximations-to-rational.json_chunk_37"
  },
  {
    "document_type": "research_paper",
    "title": "Rational approximations to rational models: Alternative algorithms for category learning",
    "author": "Sanborn, Adam N.; Griffiths, Thomas L.; Navarro, Danielle J.",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Sanborn-2010-Rational-approximations-to-rational.pdf",
    "date_published": "2015-08-05",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". These transfer stimuli were structured so that some were closer to specific instances than others, while the distance to the category centers was constant. In this experiment, an effect of specific instances was found in the ratings. Anderson (1991) ran the local MAP algorithm for several different values of the coupling parameter, but with a fixed prior of β = 1. The order of the training items was randomized on each block. Low values of the coupling parameter, such as c = 0 . 3, produced high correlations to human ratings ( r = 0 . 87). At such values of the coupling parameter, the representation tends to be more exemplar-like than prototype-like, which is consistent with an effect of specific instances. We ran the particle filter algorithm on this experimental design with M = 100 and M = 1 particles. The particle filter with M = 1 particle was replicated 1,000 times and the M = 100 particle particle filter was replicated 10 times. The results are shown in Figure 8. Using the same coupling parameter, c = 0 . 3, we found good correlations for the multi-particle particle filter ( r = 0 . 78) and for the single-particle particle filter ( r = 0 . 77). We also examined lower values of the coupling parameter. For c = 0 . 1 the local MAP algorithm produced nearly the same correlation, Rational Approximations to Category Learning 34 r = 0 . 88, but the single-particle improved somewhat, to r = 0 . 84, as did the particle filter with M = 100 particles ( r = 0 . 84). Prediction performance and the range of predicted probabilities both increase if the model is trained with the same number of blocks human subjects were trained (ten) instead of just a single block. Across coupling parameters, the best correlation with human ratings were high for the local MAP ( r = 0 . 95), the particle filter with M = 1 particles ( r = 0 . 90), and the particle filter with M = 100 particles ( r = 0 . 93)",
    "chunk_id": "Adv_cognitive_modelling_sanborn-2010-rational-approximations-to-rational.json_chunk_38"
  },
  {
    "document_type": "research_paper",
    "title": "Rational approximations to rational models: Alternative algorithms for category learning",
    "author": "Sanborn, Adam N.; Griffiths, Thomas L.; Navarro, Danielle J.",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Sanborn-2010-Rational-approximations-to-rational.pdf",
    "date_published": "2015-08-05",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". 95), the particle filter with M = 1 particles ( r = 0 . 90), and the particle filter with M = 100 particles ( r = 0 . 93). Overall, the results in Figure 8 look accurate for all of the models, except for a serious disagreement between the human data and model predictions for 1110, the seventh stimulus from the left. Human ratings for 1110 diverged from the ratings of 0111 and 1101, the fourth and fifth stimuli from the left. However these three stimuli are the same distances from the training stimuli, so the models tended to give these three stimuli the same probability of Category 1 as a result. Specific instances with continuous features The effect of specific instances has been studied with continuous features in Nosofsky (1988). In this study, subjects were trained on 12 stimuli that varied in brightness and saturation. As in Medin and Schaffer (1978), the category structure could not be learned using only one feature. However, in this experiment, the frequency of specific examples was manipulated. Over the course of two experiments, subjects showed a sensitivity to the presentation frequency of specific colors. Anderson (1991) fit the RMC to these data using a likelihood function (following Gelman, Carlin, Stern, & Rubin, 2004) appropriate for continuous data. The continuous likelihood used was a Gaussian distribution for each cluster and the chosen parameters are described in the Appendix. In this simulation, the values of the continuous dimension prior parameters were λ 0 = 1 and a 0 = 1. The label prior parameter was set to β = 1. Using these parameters, the local MAP algorithm had Rational Approximations to Category Learning 35 an overall correlation between the two experiments of r = 0 . 98 with the human data. Both the single-particle particle filter and the particle filter with M = 100 particles were run with these same parameters. There were 1,000 replications of the single-particle particle filter and 10 repetitions of the M = 100 particle particle filter",
    "chunk_id": "Adv_cognitive_modelling_sanborn-2010-rational-approximations-to-rational.json_chunk_39"
  },
  {
    "document_type": "research_paper",
    "title": "Rational approximations to rational models: Alternative algorithms for category learning",
    "author": "Sanborn, Adam N.; Griffiths, Thomas L.; Navarro, Danielle J.",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Sanborn-2010-Rational-approximations-to-rational.pdf",
    "date_published": "2015-08-05",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". There were 1,000 replications of the single-particle particle filter and 10 repetitions of the M = 100 particle particle filter. On each replication, the stimuli were presented in a new random order. The overall correlation between the human data in the two experiments and the average output of the model was r = 0 . 97 for the single-particle particle filter and r = 0 . 98 for M = 100 particles. Here again, both types of particle filters perform as well as the local MAP algorithm. Order effects Order effects provide a strong challenge to stationary Bayesian models, such as the statistical model underlying the RMC (Kruschke, 2006a, 2006b). A DPMM by nature does not produce order effects, because the observations are exchangeable under the model. However, order effects are easily found in investigations of human cognition, most saliently in the primacy and recency effects found in free recall of a list of words (Murdock, 1962). In categorization research, order effects are well established (Medin & Bettger, 1994). We examine the order effects found including order sensitivity data collected by Anderson and Matessa (reported in Anderson, 1990) to support the approximation used in the RMC. The rational model is not able to predict these order effects, but approximations to the rational model can. Approximations only assign mass to a small portion of the posterior space over partitions, in effect embodying only a small number of hypotheses about how the stimuli should be clustered. When a new trial is added to the representation, the possible new representations are extensions of the previous representations. So, if a particular partition of the existing stimuli is not present among the particles, then it will never appear when the representation has been updated. In this way, the approximation to the DPMM can be led down a garden path by presenting many Rational Approximations to Category Learning 36 early trials that point toward a particular type of representation 1",
    "chunk_id": "Adv_cognitive_modelling_sanborn-2010-rational-approximations-to-rational.json_chunk_40"
  },
  {
    "document_type": "research_paper",
    "title": "Rational approximations to rational models: Alternative algorithms for category learning",
    "author": "Sanborn, Adam N.; Griffiths, Thomas L.; Navarro, Danielle J.",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Sanborn-2010-Rational-approximations-to-rational.pdf",
    "date_published": "2015-08-05",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". If the likelihood of this type of representation is large enough, then the particles will all tend to show that particular representation. Later trials that point toward a different partition of the early trials will not be able to change the partition of the early trials. As a result, early examples can have a greater influence than later trials. In Anderson and Matessa’s experiment, subjects were presented with a set of 16 stimuli in one of two orders, shown in Table 3. These stimuli were designed to either emphasize the first two features (“front-anchored stimuli”) or the last two features (“end-anchored stimuli”) in the first eight trials. Subjects were trained in one of the two orders. Following the training phase, subjects were shown the full set of stimuli on a sheet of paper and asked to divide the stimuli into two categories of eight stimuli each. Eleven of twenty subjects presented with the front-anchored order split the stimuli into groups along one of the two features emphasized by the front-anchored ordering. Fourteen of twenty subjects presented with the end-anchored order split the stimuli along the features that were emphasized by that ordering. Overall, there was a significant result as twenty-five of forty subjects (62 . 5%) produced the anticipated order effect. We compared order effects produced by the range of approximation algorithms to the human data. For all algorithms, c = 0 . 5 and β = 1, the values used for the local MAP by Anderson and Matessa (Anderson, 1990). The Adjusted Rand Index (Hubert & Arabie, 1985), a standard measure of distance between partitions, was used to find the similarity of the output of the local MAP and particle filter to each of the four partitions that split the stimuli along a single feature. The single-feature-based partition that had the highest Adjusted Rand Index was selected as the partition for that sample. If there was a tie, one of the best was selected with equal probability",
    "chunk_id": "Adv_cognitive_modelling_sanborn-2010-rational-approximations-to-rational.json_chunk_41"
  },
  {
    "document_type": "research_paper",
    "title": "Rational approximations to rational models: Alternative algorithms for category learning",
    "author": "Sanborn, Adam N.; Griffiths, Thomas L.; Navarro, Danielle J.",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Sanborn-2010-Rational-approximations-to-rational.pdf",
    "date_published": "2015-08-05",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". The single-feature-based partition that had the highest Adjusted Rand Index was selected as the partition for that sample. If there was a tie, one of the best was selected with equal probability. In this experiment the local MAP algorithm predicts that participants will always produce the anticipated ordering effect. We ran the single-particle particle filter for 1,000 Rational Approximations to Category Learning 37 repetitions and the M = 100 particle particle filter for 10 repetitions in this experimental design to compare it with the local MAP. The single-particle particle filter produces the anticipated order effect on 63% of trials, while the particle filter with M = 100 particles produces the order effect only 52% of the time. In this experiment, the particle filter with a single particle is closer to the human results than either the local MAP algorithm or the particle filter with a large number of particles. Linear separability The property of linear separability, in which two categories can be perfectly discriminated using a line as a decision bound, has been used in experimental designs to test different types of category representations (Medin & Schwanenflugel, 1981; Nosofsky & Zaki, 2002; J. D. Smith & Minda, 1998). Many models, such as prototype models, inherently predict that linearly separable categories are easier to learn than non-linearly separable categories. In contrast, models such as the RMC do not necessarily predict that linearly separable categories are easier to learn (Anderson, 1991). An interesting aspect to the study of non-linearly separable categories is exploring how category outliers are learned. The standard design is to select two category centers, with most training stimuli clustered near to the center. A small number of outliers, however, are actually very close to the center of the other category. Examples of these types of structures can be seen in Table 4",
    "chunk_id": "Adv_cognitive_modelling_sanborn-2010-rational-approximations-to-rational.json_chunk_42"
  },
  {
    "document_type": "research_paper",
    "title": "Rational approximations to rational models: Alternative algorithms for category learning",
    "author": "Sanborn, Adam N.; Griffiths, Thomas L.; Navarro, Danielle J.",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Sanborn-2010-Rational-approximations-to-rational.pdf",
    "date_published": "2015-08-05",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". A small number of outliers, however, are actually very close to the center of the other category. Examples of these types of structures can be seen in Table 4. In both these designs, Category A consists of binary features mainly set to zero, and Category B consists of binary features mainly set to one. One stimulus in each category is an outlier and is a better match to the stimuli in the other category than to the stimuli in its own category. Prototype models predicts that these outlier stimuli will always be classified in the incorrect category, while exemplar models can predict that they will be classified fairly accurately. J. D. Smith and Minda (1998) ran a series of experiments that examined the Rational Approximations to Category Learning 38 time course of learning central and outlier members of categories. Initially outlier items were classified as belonging to the incorrect category, but performance improved over blocks of training trials. Figure 9 displays these average results as well as the results of individual subjects. The data of the individual subjects were noisy, so the training blocks are grouped into three bins which are summarized in bar graphs. The outlier stimuli could either both be classified incorrectly (labelled “opposite categories”), both classified in one category or another, or both classified correctly. The decrease in the number of individuals who classify both outliers incorrectly and increase in the number who classify both outliers correctly over blocks mirrors the average results. J. D. Smith and Minda (1998) proposed that the crossover of the outliers from misclassified to classified correctly seen in the human data was the result of a shift from prototype-like to exemplar-like processing. These results were fit with a mixture of prototypes and exemplars. Later work with a variant of the DPMM showed the crossover could be due to an initial prior for simple representations that is eventually overwhelmed by the data (Griffiths, Canini, Sanborn, & Navarro, 2007)",
    "chunk_id": "Adv_cognitive_modelling_sanborn-2010-rational-approximations-to-rational.json_chunk_43"
  },
  {
    "document_type": "research_paper",
    "title": "Rational approximations to rational models: Alternative algorithms for category learning",
    "author": "Sanborn, Adam N.; Griffiths, Thomas L.; Navarro, Danielle J.",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Sanborn-2010-Rational-approximations-to-rational.pdf",
    "date_published": "2015-08-05",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". An alternative explanation was proposed by Nosofsky and Zaki (2002), who explained the crossover as a transition from focused attention to a single dimension to more equal weights across all dimensions. In Experiment 2, Nosofsky and Zaki (2002) demonstrated that the exemplar model constrained to attend to a few dimensions did not fit the transfer data after a few blocks significantly worse than the full exemplar model. These additional data provide an interesting counterpoint to the representational change explanation, but we are unable to address them because of the computational complexity in fitting the RMC with any approximation algorithm if all the weights can vary independently. Here we focus on what algorithms allow the RMC to predict a human-like crossover effect. The RMC using the local MAP and single-particle particle filter algorithms were fit to both the non-linearly separable and linearly separable conditions in the first three Rational Approximations to Category Learning 39 experiments of J. D. Smith and Minda (1998). To fit the models, a grid search was performed over model parameters, using values of 0 . 01, 0 . 1, 0 . 5, and 1 for the β prior parameters. Independent β prior parameters were used for the physical dimensions, β p , and for the label, β l . The coupling parameter was varied using the values 0 . 1, 0 . 3, 0 . 5, 0 . 7, and 0 . 9. Each simulation was repeated 1,000 times with the stimuli re-randomized within block on each simulation, which was the same randomization scheme used for the human participants. For all eighty settings of the parameters, the combined likelihoods over all conditions and experiments was compared. The single-particle particle filter produced a higher likelihood than the local MAP algorithm did for each of the eighty settings. To better understand how well the two approximation algorithms fit the outlier stimuli, we re-calculated the likelihoods for each parameter setting using only the outlier stimuli",
    "chunk_id": "Adv_cognitive_modelling_sanborn-2010-rational-approximations-to-rational.json_chunk_44"
  },
  {
    "document_type": "research_paper",
    "title": "Rational approximations to rational models: Alternative algorithms for category learning",
    "author": "Sanborn, Adam N.; Griffiths, Thomas L.; Navarro, Danielle J.",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Sanborn-2010-Rational-approximations-to-rational.pdf",
    "date_published": "2015-08-05",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". To better understand how well the two approximation algorithms fit the outlier stimuli, we re-calculated the likelihoods for each parameter setting using only the outlier stimuli. For the these stimuli, the single-particle particle filter produced a better fit to the data on seventy-six of the eighty parameter settings. The best-fitting parameters for the local MAP were β p = 0 . 1 for the physical dimensions, β l = 1 for the label dimension, and c = 0 . 7 for the coupling parameter. For the M = 1 particle filter, the best fitting parameters were β p = 1, β l = 0 . 5, and c = 0 . 5. The maximum likelihood fits for the local MAP and single-particle particle filter are shown in Figure 9. The local MAP algorithm produces a cross-over of the average of the outliers: going from both mis-classified to both classified correctly over blocks, at least for Experiments 1 and 2. However, the results of the individual runs show that the local MAP does not produce crossovers on individual runs of the algorithm. Instead, examination of the bar plots of individual runs show that the local MAP crossover is an artifact of averaging. Unlike the local MAP, the single-particle particle filter produces both average crossovers and individual crossovers, as seen in the changing bar plots of individual runs. The intuitive reason the local MAP algorithm does not produce human-like Rational Approximations to Category Learning 40 crossovers for individual runs is because it becomes stuck in a pattern based on the initial ordering of the stimuli. To illustrate this idea, we will make the simplifying assumption that each of the central items of Category A are assigned to one cluster and all of the central items of Category B are assigned to a second cluster. The logical possibilities for an outlier is that it is assigned to the correct cluster, assigned to the incorrect cluster, or assigned to its own cluster",
    "chunk_id": "Adv_cognitive_modelling_sanborn-2010-rational-approximations-to-rational.json_chunk_45"
  },
  {
    "document_type": "research_paper",
    "title": "Rational approximations to rational models: Alternative algorithms for category learning",
    "author": "Sanborn, Adam N.; Griffiths, Thomas L.; Navarro, Danielle J.",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Sanborn-2010-Rational-approximations-to-rational.pdf",
    "date_published": "2015-08-05",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". The logical possibilities for an outlier is that it is assigned to the correct cluster, assigned to the incorrect cluster, or assigned to its own cluster. Whatever cluster it is initially assigned to, which depends on the parameter settings and the order of the stimuli, it will likely be assigned to the same cluster in later blocks. The repetition occurs because the cluster the outlier was assigned to initially had the highest probability of generating that stimulus, and on subsequent blocks this cluster will contain a copy of the outlier, which increases the likelihood of assignment to this cluster. The local MAP algorithm always assigned stimuli to the maximum likelihood cluster, so that the initial assignment of the outlier is almost perfectly predictive of its later assignment. In fact, examining samples of 100 runs of the local MAP using the best parameters on each experiment’s non-linearly separable condition, the initial assignment was perfectly predictive of all later assignments. In contrast, the stochastic assignment of the single-particle particle filter allows for individual runs of the RMC to display crossovers. Unlike the local MAP, the particle filter allows an outlier to be assigned to a less-probable cluster, depending on the relative probability of the new cluster. One way in which sampling can cause crossing-over is if an outlier is initially assigned to a cluster containing the central stimuli from the other category. This outlier will initially be categorized incorrectly. But in later blocks, the outlier has the possibility of being assigned to a new cluster that contains only that outlier. Once the outlier is assigned to a new cluster, the outlier in later blocks tends to be assigned to the same cluster, because the new cluster contains only the outlier and thus is a very good likelihood match",
    "chunk_id": "Adv_cognitive_modelling_sanborn-2010-rational-approximations-to-rational.json_chunk_46"
  },
  {
    "document_type": "research_paper",
    "title": "Rational approximations to rational models: Alternative algorithms for category learning",
    "author": "Sanborn, Adam N.; Griffiths, Thomas L.; Navarro, Danielle J.",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Sanborn-2010-Rational-approximations-to-rational.pdf",
    "date_published": "2015-08-05",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Prediction of the outlier’s category label will become more accurate, because the cluster containing only the outlier will have a stronger influence over Rational Approximations to Category Learning 41 blocks and it predicts the correct category label. As the assignments are stochastic, the block on which the crossover occurs will vary over runs of the algorithm. The prediction of individual crossovers at variable blocks in training matches the human data. The prediction of the single-particle particle filter stands in contrast with the prediction of a particle filter with a very large number of particles. Each block contains a random ordering of all of the training stimuli, so as the number of particles becomes very large, the distribution over partitions on each run of the model after each block will be the same. Unlike the single-particle particle filter, a particle filter with many particles will not be able to predict between-subject variability with the same parameters, which is an interesting consequence of the single-particle particle filter. The number of particles needed to produce the same outcome on each block is actually quite large, as simulations with M = 1 , 000 particles still showed between-run variability, so this may only be a problem for the ideal statistical model. Learning types of category structures A wide range of learning problems were examined in the classic experimental design of Shepard et al. (1961). Binary stimuli with three dimensions were divided into all categories of equal size, and six interesting categorization problems emerged. These problems, shown in Figure 10, were numbered by their difficulty, with Type I the easiest and Type VI the hardest. In a later replication and extension of this design, Nosofsky et al. (1994) collected data on the time course of learning for these six problems, shown in Figure 11. In addition to running the experiment, Nosofsky et al. (1994) fit the RMC using the local MAP algorithm to the data. The best fitting parameters were β p = 0",
    "chunk_id": "Adv_cognitive_modelling_sanborn-2010-rational-approximations-to-rational.json_chunk_47"
  },
  {
    "document_type": "research_paper",
    "title": "Rational approximations to rational models: Alternative algorithms for category learning",
    "author": "Sanborn, Adam N.; Griffiths, Thomas L.; Navarro, Danielle J.",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Sanborn-2010-Rational-approximations-to-rational.pdf",
    "date_published": "2015-08-05",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". In addition to running the experiment, Nosofsky et al. (1994) fit the RMC using the local MAP algorithm to the data. The best fitting parameters were β p = 0 . 488, β l = 0 . 046, c = 0 . 318, and a response mapping parameter (used as an exponent to scale the responses) of 0 . 93. This algorithm predicted a sum squared deviation across learning Rational Approximations to Category Learning 42 problems (SSD) of 0.182. Attempting to replicate this result with the local MAP revealed some surprising subtleties of the local MAP algorithm. First, sometimes there are ties between clusters for the cluster with the maximum probability, for which the local MAP algorithm must be adjusted. A straightforward solution is to assign the new stimulus with equal probability to any cluster that shares the maximum probability. A more troubling discovery is that there are clusters of the stimuli that have only slightly less probability than the cluster with the maximum posterior probability. Using the best parameters of Nosofsky et al. (1994), we found that the maximum ratio of the second-best posterior probability to the maximum posterior probability could be as high as 0.9997. The behavior of the local MAP algorithm should be very different in the case of tied probabilities and not-quite-tied probabilities, but the difference between the two cases can be very subtle and depend on the precision of the numbers used in the simulation. We found this to be the case when using these best-fitting parameters: using the double precision numbers of Matlab (64 bits) and assigning ties equally to the best clusters, the SSD of the local MAP at these parameters rises to 0.32, and the ordering of problem difficulty on the final block is changed. A grid search of parameters for both the local MAP and particle filter algorithms was done using the same grid as in the linear separability section with 1000 repetitions per algorithm",
    "chunk_id": "Adv_cognitive_modelling_sanborn-2010-rational-approximations-to-rational.json_chunk_48"
  },
  {
    "document_type": "research_paper",
    "title": "Rational approximations to rational models: Alternative algorithms for category learning",
    "author": "Sanborn, Adam N.; Griffiths, Thomas L.; Navarro, Danielle J.",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Sanborn-2010-Rational-approximations-to-rational.pdf",
    "date_published": "2015-08-05",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". A grid search of parameters for both the local MAP and particle filter algorithms was done using the same grid as in the linear separability section with 1000 repetitions per algorithm. A new random order for the stimuli was set for each replication, and the randomization scheme was the same within-block randomization scheme as used in Nosofsky et al. (1994). Over the set of all parameters, the single-particle particle filter algorithm fit better than the local MAP algorithm on 58% of parameter settings. In addition, the best fit of the local MAP was a total SSD of 0.31, while the best SSD for the single-particle particle filter was 0.24. The best fitting parameters were β p = 0 . 5, β l = 0 . 01, and c = 0 . 3 for the local MAP and β p = 0 . 1, β l = 0 . 1, and c = 0 . 3 for the particle filter with M = 1 particles. These results, shown in Figure 11, demonstrate that Rational Approximations to Category Learning 43 the single-particle particle filter exceeds the performance of the local MAP for the parameters we tested. However, the brittleness of local MAP algorithm in this paradigm means that there are probably very specific parameter sets that may provide a much better match to the human data. Summary of simulations We began with experimental paradigms on which the local MAP algorithm performs well (Anderson, 1991), and the simulations we have performed demonstrate that the particle filter algorithm, especially the single-particle particle filter performs as well or better in these categorization paradigms. For the effects of specific instances with binary (Medin & Schaffer, 1978) and continuous data (Nosofsky, 1988), the single-particle particle filter and the multi-particle particle filter performed about as well as the local MAP algorithm. However, in the later simulations the local MAP algorithm was outperformed by the particle filter, especially by the single-particle particle filter",
    "chunk_id": "Adv_cognitive_modelling_sanborn-2010-rational-approximations-to-rational.json_chunk_49"
  },
  {
    "document_type": "research_paper",
    "title": "Rational approximations to rational models: Alternative algorithms for category learning",
    "author": "Sanborn, Adam N.; Griffiths, Thomas L.; Navarro, Danielle J.",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Sanborn-2010-Rational-approximations-to-rational.pdf",
    "date_published": "2015-08-05",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". However, in the later simulations the local MAP algorithm was outperformed by the particle filter, especially by the single-particle particle filter. For the order effects of stimuli presentation, the local MAP algorithm predicts order effects that are stronger than those displayed by human subjects. A particle filter with M = 100 particles predicted almost no order effects, but for the single-particle particle filter the size of the order effect was similar to the empirical average. Further advantages of the particle filter were found for newer experiments with categories that differed in linear separability (J. D. Smith & Minda, 1998). The statistical model underlying the RMC predicts that outlier stimuli will initially be categorized incorrectly, but over blocks will eventually be categorized correctly. The local MAP algorithm did not predict the crossover in individual runs with its best-fitting parameters, and imitates it in the average data by averaging over different trial orders. In contrast, the single-particle particle filter predicts both the crossover in average data, as well as individual variability in how quickly the outlier is learned to be classified correctly. Rational Approximations to Category Learning 44 Finally, the local MAP is extremely sensitive to small changes in probability, as demonstrated with the data and model fits of Nosofsky et al. (1994). The absolute fit and even the order of errors of the six problems depended on the precision of the representation and how ties were dealt with. In the particle filter, the clustering of a new example is sampled, providing a much more plausible implementation that is not sensitive to small changes in relative probability. Discussion Bridging the gap between why human cognition might operate the way it does (as described by rational analysis) and how the mind performs the operations required to do so (as per process models) is a fundamental question in cognitive science",
    "chunk_id": "Adv_cognitive_modelling_sanborn-2010-rational-approximations-to-rational.json_chunk_50"
  },
  {
    "document_type": "research_paper",
    "title": "Rational approximations to rational models: Alternative algorithms for category learning",
    "author": "Sanborn, Adam N.; Griffiths, Thomas L.; Navarro, Danielle J.",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Sanborn-2010-Rational-approximations-to-rational.pdf",
    "date_published": "2015-08-05",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". This bridge can be built in a number of different ways: by establishing isomorphisms between models framed at these two levels (e.g., Ashby & Alfonso-Reese, 1995; Griffiths et al., 2007; Shi et al., 2008, in press), by describing the rational foundations of process theories (e.g., Gigerenzer & Brighton, 2009; Perfors & Navarro, 2009; Tenenbaum & Griffiths, 2001b) or by building models that are able to interpolate between heuristic processes and rational accounts (e.g., Brown & Steyvers, 2009; Daw & Courville, 2008; Lee & Cummins, 2004; Sanborn et al., 2006). In this paper we have pursued the third option, arguing that the Monte Carlo principle can provide a foundation for an entire class of “rational process models” that are equivalent to rational models when given unlimited processing resources, but give rise to fast, simple heuristics when computational resources are scarce. Our analysis of the Rational Model of Categorization provides a good example of how this idea can be put to good use. The RMC is an example of a successful Bayesian model of cognition. It provides a reasonable explanation of how objects should be grouped into clusters and the result of this clustering can be used to explain many categorization experiments. As a purely rational analysis, however, the RMC runs into difficulties Rational Approximations to Category Learning 45 because the complexity of the computational problems involved makes inference difficult, and the fact that the underlying statistical model cannot produce order effects. Approximation algorithms address both issues, by simplifying inferences and inducing order effects. However, the original “local MAP” approximation produces some order effects that could be considered too strong, and unlike people it learns by deterministic assignments rather than probabilistic ones. Using the Monte Carlo principle, however, we are able to derive a particle filtering algorithm that retains the strengths of the local MAP algorithm but fixes its weaknesses",
    "chunk_id": "Adv_cognitive_modelling_sanborn-2010-rational-approximations-to-rational.json_chunk_51"
  },
  {
    "document_type": "research_paper",
    "title": "Rational approximations to rational models: Alternative algorithms for category learning",
    "author": "Sanborn, Adam N.; Griffiths, Thomas L.; Navarro, Danielle J.",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Sanborn-2010-Rational-approximations-to-rational.pdf",
    "date_published": "2015-08-05",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Using the Monte Carlo principle, however, we are able to derive a particle filtering algorithm that retains the strengths of the local MAP algorithm but fixes its weaknesses. A single-particle particle filter retains the desiderata of Anderson (1991): online updating of the representation plus a single partition of all of the stimuli into clusters. The only difference of the algorithm is that it uses sampling instead of a maximization operation in order to select new partitions. The change to using sampling produces some important differences. Averaging many runs of the same order with the local MAP approximation produces the same result every time. However, averaging many runs with the same order using sampling produces a much better approximation to the true posterior. Though each run of a single-particle particle filter produces a potentially extreme result, the aggregate of these results resembles the optimal solution. This effect echoes the wisdom of the crowds: the accuracy of the average over individuals can exceed the accuracy of the individuals (Surowiecki, 2004). This effect has also been found for averaging the judgments of a single individual (Vul & Pashler, 2008). In addition, for a task that requires learning categories that are not linearly separable, sampling allows for the model to occasionally assign a repeated item to a new cluster, allowing it reproduce the finding that people initially categorize an outlier stimulus incorrectly, but slowly learn the correct response. The single-particle particle filter shows a real advantage on this task: not only can it produce the same results as many particles at a lower computational cost, it produces realistic-looking individual differences over runs of the model. Rational Approximations to Category Learning 46 Sampling also avoids the necessity of precise representations. It is implausible that people would make deterministic choices based on values that are almost exactly equal, but this is what the local MAP algorithm assumes",
    "chunk_id": "Adv_cognitive_modelling_sanborn-2010-rational-approximations-to-rational.json_chunk_52"
  },
  {
    "document_type": "research_paper",
    "title": "Rational approximations to rational models: Alternative algorithms for category learning",
    "author": "Sanborn, Adam N.; Griffiths, Thomas L.; Navarro, Danielle J.",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Sanborn-2010-Rational-approximations-to-rational.pdf",
    "date_published": "2015-08-05",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". It is implausible that people would make deterministic choices based on values that are almost exactly equal, but this is what the local MAP algorithm assumes. Nearly indiscriminable choice probabilities arise in fitting the local MAP algorithm to learning data under a plausible set of parameters. In contrast, the particle filter algorithm samples, so that choices between representations that have nearly equal probability are chosen nearly equally often. This algorithm, or one that interpolates between pure sampling and pure maximization makes for a more psychologically plausible alternative to the local MAP. These results, combined with recent work that has successfully applied particle filters to a range of problems (Brown & Steyvers, 2009; Daw & Courville, 2008; Levy et al., 2009; Yi, Steyvers, & Lee, in press), lead us to believe that particle filters have the potential to be a powerful tool for producing rational process models. The introduction of these new algorithms also inspires the development of intermediate cases. It seems necessary to limit the precision of the local MAP algorithm in some way to create a psychologically plausible algorithm. One possible way to do this is by casting the local MAP as a sampling algorithm. As each new stimulus is presented, the local MAP algorithm computes the posterior probability, f ( x ), that the new stimulus belongs to each of the existing clusters and to a new cluster. The local MAP algorithm selects the maximum of f ( x ), which we can represent by sampling. If we construct a new distribution, g ( x ) ∝ f ( x ) γ , and set γ = ∞ , then sampling from g ( x ) will be equivalent to taking the maximum value of f ( x ). We refer to the γ parameter as the distributional scaling parameter 2 . The usefulness of this representation is that we can use values of γ that are less than ∞",
    "chunk_id": "Adv_cognitive_modelling_sanborn-2010-rational-approximations-to-rational.json_chunk_53"
  },
  {
    "document_type": "research_paper",
    "title": "Rational approximations to rational models: Alternative algorithms for category learning",
    "author": "Sanborn, Adam N.; Griffiths, Thomas L.; Navarro, Danielle J.",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Sanborn-2010-Rational-approximations-to-rational.pdf",
    "date_published": "2015-08-05",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". We refer to the γ parameter as the distributional scaling parameter 2 . The usefulness of this representation is that we can use values of γ that are less than ∞ . Using smaller values of γ produces a soft-max rule, which greatly changes the behavior of the algorithm when the best two clusters for a new stimulus have nearly the same, but not exactly the same probability. Now, instead of always selecting the highest probability cluster, the adjusted algorithm will select the top two clusters with Rational Approximations to Category Learning 47 nearly equal probability, which is more psychologically plausible. At the other end of the range of the γ parameter, when γ = 1, this representation is equivalent to a particle filter with M = 1 particles, which selects clusters according to their posterior probability. We should note that our simulations are not particularly constraining on the number of particles that might best be used to fit human participants. The second desideratum for psychological plausibility stated that there should be a single interpretation of which cluster generated an object. This desideratum is debatable, because it may be that people can hold multiple hypotheses of how objects are generated. In simulations we did not present, we looked at a range of approximations that varied both the number of particles and distributional scaling parameter. Our simulations were not particularly constraining for these parameters. For example, a 100 particles with γ = 2 produces order effects in the Anderson and Matessa experiment that were approximately equal to that produced by the single-particle particle filter. We elected to test the local MAP to the single-particle particle filter in most of the simulations because it provided a clean comparison between maximization and sampling. However, we do not draw the conclusion that a single-particle particle filter is necessarily the way forward. Other work has successfully fit individual subject data by varying the number of particles (Brown & Steyvers, 2009)",
    "chunk_id": "Adv_cognitive_modelling_sanborn-2010-rational-approximations-to-rational.json_chunk_54"
  },
  {
    "document_type": "research_paper",
    "title": "Rational approximations to rational models: Alternative algorithms for category learning",
    "author": "Sanborn, Adam N.; Griffiths, Thomas L.; Navarro, Danielle J.",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Sanborn-2010-Rational-approximations-to-rational.pdf",
    "date_published": "2015-08-05",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Other work has successfully fit individual subject data by varying the number of particles (Brown & Steyvers, 2009). More generally, the Monte Carlo principle can be used to motivate other interesting psychological processes. As noted earlier, exemplar-based category learning can be interpreted as a kind of importance sampling (Shi et al., 2008, in press), and the field of decision-making already has many sampling-based theories (Lee & Cummins, 2004; Ratcliff, 1978; Stewart et al., 2006; Vickers, 1979), but other possibilities exist. In the area of problem solving – which, to a large extent is defined in terms of a focus on difficult learning problems – several avenues of work seem promising. For instance, to the extent that incubation effects in problem solving (S. M. Smith & Blankenship, 1989; Wallas, 1926) relate to a loss of fixation of mental set, they could be interpreted as a form of Rational Approximations to Category Learning 48 particle rejuvenation. Similarly, while trial-and-error learning can be quite complex (Anzai & Simon, 1979), it is nevertheless a natural candidate for Markov Chain Monte Carlo explanations. More speculatively, the fact that human problem solving is not invariant to changes in surface form (Kotovsky, Hayes, & Simon, 1985) makes sense given the Monte Carlo principle, insofar as reparameterization of the hypothesis space can make an inference problem harder or easier. Rational models of cognition provide a way to understand how human behavior can be explained in terms of optimal solutions to problems posed by the environment. The promise of rational process models is that they can link the Platonic world of ideal forms and ideal learners to the less lofty reality of inexact representations and limited resources. By linking these two levels of analysis more closely, we can build models that more completely characterize both the why and the how of human cognition. Rational Approximations to Category Learning 49",
    "chunk_id": "Adv_cognitive_modelling_sanborn-2010-rational-approximations-to-rational.json_chunk_55"
  },
  {
    "document_type": "online_article",
    "title": "Chapter 11 Bayesian Models of Cognition",
    "author": "Riccardo Fusaroli",
    "source": "https://fusaroli.github.io/AdvancedCognitiveModeling2023/bayesian-models-of-cognition.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": "The impressive power of Bayes theorem and Bayesian approaches to modeling has tempted cognitive scientists into exploring how far they could get in thinking the mind and brain as Bayesian machines. The idea is that the mind is a probabilistic machine that updates its beliefs based on the evidence it receives. The human mind constantly receives input from various sources – direct personal experience, social information from others, prior knowledge, and sensory input. A fundamental question in cognitive science is how these disparate pieces of information are combined to produce coherent beliefs about the world. The Bayesian framework offers a powerful approach to modeling this process. Under this framework, the mind is conceptualized as a probabilistic machine that continuously updates its beliefs based on new evidence. This contrasts with rule-based or purely associative models by emphasizing: Representations of uncertainty: Beliefs are represented as probability distributions, not single values Optimal integration: Information is combined according to its reliability Prior knowledge: New evidence is interpreted in light of existing beliefs In this chapter, we will explore how Bayesian integration can be formalized and used to model cognitive processes. We’ll start with simple models that give equal weight to different information sources, then develop more sophisticated models that allow for differential weighting based on source reliability, and finally consider how beliefs might update over time. This chapter is not a comprehensive review of Bayesian cognitive modeling, but rather a practical introduction to the topic. We’ll focus on simple models that illustrate key concepts and provide a foundation for more advanced applications. To go further in your learning check on Bayesian models of cognition check: Ma, W. J., Kording, K. P., & Goldreich, D. (2023). Bayesian models of perception and action: An introduction. MIT press. Griffiths, T. L., Chater, N., & Tenenbaum, J. B. (Eds.). (2024)",
    "chunk_id": "Adv_cognitive_modelling_chapter_11_bayesian_models_of_cognition.json_chunk_1"
  },
  {
    "document_type": "online_article",
    "title": "Chapter 11 Bayesian Models of Cognition",
    "author": "Riccardo Fusaroli",
    "source": "https://fusaroli.github.io/AdvancedCognitiveModeling2023/bayesian-models-of-cognition.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". J., Kording, K. P., & Goldreich, D. (2023). Bayesian models of perception and action: An introduction. MIT press. Griffiths, T. L., Chater, N., & Tenenbaum, J. B. (Eds.). (2024). Bayesian models of cognition: reverse engineering the mind. MIT Press. N. D. Goodman, J. B. Tenenbaum, and The ProbMods Contributors (2016). Probabilistic Models of Cognition (2nd ed.). Retrieved 2025-3-10 fromhttps://probmods.org/ After completing this chapter, you will be able to: Understand the basic principles of Bayesian information integration Implement models that combine multiple sources of information in a principled Bayesian way Fit and evaluate these models using Stan Differentiate between alternative Bayesian updating schemes Apply Bayesian cognitive models to decision-making data In this chapter, we will: Introduce the Bayesian framework for cognitive modeling Implement a simple Bayesian integration model Develop and test a weighted Bayesian model that allows for different source reliability Explore temporal Bayesian updating Extend our models to multilevel structures that capture individual differences Compare alternative Bayesian models and evaluate their cognitive implications Bayesian models of cognition explore the idea that the mind operates according to principles similar to Bayes’ theorem, combining different sources of evidence to form updated beliefs. Most commonly this is framed in terms of prior beliefs being updated with new evidence to form updated posterior beliefs. Formally: P(belief | evidence) ∝ P(evidence | belief) × P(belief) Where: P(belief | evidence) is the posterior belief after observing evidence P(evidence | belief) is the likelihood of observing the evidence given a belief P(belief) is the prior belief before observing evidence In cognitive terms, this means people integrate new information with existing knowledge, giving more weight to reliable information sources and less weight to unreliable ones. Yet, there is nothing mathematically special about the prior and the likelihood",
    "chunk_id": "Adv_cognitive_modelling_chapter_11_bayesian_models_of_cognition.json_chunk_2"
  },
  {
    "document_type": "online_article",
    "title": "Chapter 11 Bayesian Models of Cognition",
    "author": "Riccardo Fusaroli",
    "source": "https://fusaroli.github.io/AdvancedCognitiveModeling2023/bayesian-models-of-cognition.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". Yet, there is nothing mathematically special about the prior and the likelihood. They are just two sources of information that are combined in a way that is consistent with the rules of probability. Any other combination of information sources can be modeled with the same theorem. Note that a more traditional formula for Bayes Theorem would be P(belief | evidence) = [P(evidence | belief) × P(belief)] / P(evidence) where the product of prior and likelihood is normalized by P(evidence) (bringing it back to a probability scale). That’s why we used a ∝ symbol in the formula above, to indicate that we are not considering the normalization constant, and that the posterior is only proportional (and not exactly equal) to the multiplication of the two sources of information. Nevertheless, this is a first useful approximation of the theorem, which we can build on in the rest of the chapter. *** To better understand Bayesian updating, let’s create a conceptual diagram: This diagram illustrates the key elements of Bayesian updating: Prior belief (blue dashed line): Our initial uncertainty about a phenomenon, before seeing evidence Likelihood (red dotted line): The pattern of evidence we observe Posterior belief (purple solid line): Our updated belief after combining prior and evidence Notice how the posterior distribution: Is narrower than either the prior or likelihood alone (indicating increased certainty) Sits between the prior and likelihood, but closer to the likelihood (as the evidence was fairly strong) Has its peak shifted from the prior toward the likelihood (reflecting belief updating) The bottom diagram shows the algebraic process: we multiply the prior by the likelihood, then normalize to get the posterior belief",
    "chunk_id": "Adv_cognitive_modelling_chapter_11_bayesian_models_of_cognition.json_chunk_3"
  },
  {
    "document_type": "online_article",
    "title": "Chapter 11 Bayesian Models of Cognition",
    "author": "Riccardo Fusaroli",
    "source": "https://fusaroli.github.io/AdvancedCognitiveModeling2023/bayesian-models-of-cognition.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". Bayesian cognitive models have been successfully applied to a wide range of phenomena: Perception: How we combine multiple sensory cues (visual, auditory, tactile) to form a unified percept Learning: How we update our knowledge from observation and instruction Decision-making: How we weigh different sources of evidence when making choices Social cognition: How we integrate others’ opinions with our own knowledge Language: How we disambiguate words and sentences based on context Psychopathology: How crucial aspects of conditions like schizophrenia and autism can be understood in terms of atypical Bayesian inference (e.g. atypical weights given to different sources of information, or hyper-precise priors or hyper-precise likelihood). To ground our discussion in a cognitive science context, let’s consider a simplified version of a recent study examining how people with and without schizophrenia integrate information from different sources (Simonsen et al., 2021). In this task, participants needed to guess the color of the next marble drawn from a jar. They received information from two sources: Direct evidence: A small sample of 8 marbles drawn from the jar (e.g., 6 blue and 2 red marbles) Social evidence: The choices and confidence ratings of four other people who had seen their own independent samples from the jar This paradigm allows researchers to examine how individuals integrate their own direct perceptual evidence with socially transmitted information — a fundamental process in human cognition that may be altered in certain clinical conditions and be involved in generating some aspects of their psychopathology. For simplicity, we’ll focus on a binary version where participants must guess whether the next marble will be blue or red, and we’ll examine how they integrate their direct sample with social information from just what one other person has chosen",
    "chunk_id": "Adv_cognitive_modelling_chapter_11_bayesian_models_of_cognition.json_chunk_4"
  },
  {
    "document_type": "online_article",
    "title": "Chapter 11 Bayesian Models of Cognition",
    "author": "Riccardo Fusaroli",
    "source": "https://fusaroli.github.io/AdvancedCognitiveModeling2023/bayesian-models-of-cognition.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". Further, at every trial the participants are given a new jar with a potentially different proportion of blue and red marbles, so there is no learning involved. In a fully Bayesian approach, participants would: Use direct evidence to form a belief about the proportion of blue marbles in the jar Use social evidence to form another belief about the same proportion Combine these beliefs in a principled way to make their final judgment The beta distribution provides an elegant way to represent beliefs about proportions (like the proportion of blue marbles in a jar): The beta distribution is defined by two parameters, traditionally called α (alpha) and β (beta). These parameters have an intuitive interpretation: you can think of α as the number of “successes” you’ve observed (e.g., blue marbles) plus 1, and β as the number of “failures” (e.g., red marbles) plus 1. So a Beta(1,1) distribution represents a uniform belief - no prior knowledge about the proportion. After observing evidence, you simply add the counts to these parameters: To combine multiple sources of evidence, you simply add all the counts together: If direct evidence gives Beta(7, 3) and social evidence suggests Beta(2, 4) Your combined belief is Beta(7+2, 3+4) = Beta(9, 7) This has its peak at 9/(9+7) = 0.56, reflecting a compromise between the two sources The beauty of this approach is that it automatically weights evidence by its strength (amount of data) and properly represents uncertainty through the width of the distribution. For our marble task, the Bayesian inference process involves: Direct evidence: Observing blue1 blue marbles and red1 red marbles out of total1 trials Social evidence: Inferring blue2 blue marbles and red2 red marbles from social information. If we consider only their choice: red corresponds to the sampling of one red marble; blue corresponds to the sampling of one blue marble",
    "chunk_id": "Adv_cognitive_modelling_chapter_11_bayesian_models_of_cognition.json_chunk_5"
  },
  {
    "document_type": "online_article",
    "title": "Chapter 11 Bayesian Models of Cognition",
    "author": "Riccardo Fusaroli",
    "source": "https://fusaroli.github.io/AdvancedCognitiveModeling2023/bayesian-models-of-cognition.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". If we consider only their choice: red corresponds to the sampling of one red marble; blue corresponds to the sampling of one blue marble. If we consider their confidence, we might try to make this correspond to the marbles the sampled: “Clear blue” might imply 8 blue marbles; maybe blue might imply 6 blue and 2 red marbles; “maybe red” might imply 6 red and 2 blue marbles; “clear red” might imply 8 red marbles. Alternatively we can keep it more uncertain and reduce the assumed sample to 0 blue out of 3, 1 blue out of 3, 2 blue marbles out of 3, or 3 blue marbles out of 3. This intrinsically models the added uncertainty in observing the other’s choice and not their samples. The integrated belief is represented by a posterior beta distribution: Beta(α + blue1 + blue2, β + red1 + red2) Where α and β are prior parameters (typically 1 each for a uniform prior) Final choice (blue or red) depends on whether the expected value of this distribution is above 0.5 Confidence depends on the concentration of the distribution We’ll create a comprehensive set of scenarios by varying both direct evidence (number of blue marbles observed directly) and social evidence (number of blue marbles inferred from social information). Let’s examine how expected proportion and uncertainty vary across different evidence combinations: A few notes about the plot: Evidence integration: The expected proportion of blue marbles (top plot) varies with both direct and social evidence. I would normally expect a non-linear interaction: when direct evidence is ambiguous (e.g., 4 blue out of 8), social evidence should have a stronger effect on the final belief. However, the effect is subtle if any. Evidence Interaction: It may be hard to see, but the influence of social evidence is strongest when direct evidence is ambiguous (around 4 blue marbles) and weakest at the extremes (0 or 8 blue marbles). This reflects the Bayesian property that stronger evidence dominates weaker evidence",
    "chunk_id": "Adv_cognitive_modelling_chapter_11_bayesian_models_of_cognition.json_chunk_6"
  },
  {
    "document_type": "online_article",
    "title": "Chapter 11 Bayesian Models of Cognition",
    "author": "Riccardo Fusaroli",
    "source": "https://fusaroli.github.io/AdvancedCognitiveModeling2023/bayesian-models-of-cognition.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". This reflects the Bayesian property that stronger evidence dominates weaker evidence. Credible intervals: The 95% credible intervals (shaded regions) show our uncertainty about the true proportion. These intervals narrow with more evidence, indicating increased confidence in our estimates. This is better seen in the lower plot than in the upper one. Notice how the variance is highest when direct evidence is ambiguous (around 4 blue marbles) and lowest at the extremes (as they combine congruent evidence from both sources). While the summary statistics give us a high-level view, examining the full posterior distributions provides deeper insight into how evidence is combined. Let’s visualize the complete probability distributions for a selected subset of scenarios: This comprehensive visualization shows how the different probability distributions interact: Prior distribution (gray line): Our initial uniform belief about the proportion of blue marbles. Direct evidence distribution (blue dashed line): Belief based solely on our direct observation of marbles. Notice how it becomes more concentrated with more extreme evidence (e.g., 1 or 7 blue marbles). Social evidence distribution (red dashed line): Belief based solely on social information. This is generally less concentrated than the direct evidence distribution since it’s based on lower evidence (0-3 vs. 0-8). Posterior distribution (purple area): The final belief that results from combining all information sources. Notice how it tends to lie between the direct and social evidence distributions, but is typically narrower than either, reflecting increased certainty from combining information, unless the evidence is in conflict. In real cognitive systems, people often weight information sources differently based on their reliability or relevance. Let’s implement a weighted Bayesian model that allows for differential weighting of evidence sources",
    "chunk_id": "Adv_cognitive_modelling_chapter_11_bayesian_models_of_cognition.json_chunk_7"
  },
  {
    "document_type": "online_article",
    "title": "Chapter 11 Bayesian Models of Cognition",
    "author": "Riccardo Fusaroli",
    "source": "https://fusaroli.github.io/AdvancedCognitiveModeling2023/bayesian-models-of-cognition.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". Let’s implement a weighted Bayesian model that allows for differential weighting of evidence sources. Our weighted Bayesian integration model extends the simple model by introducing weight parameters for each information source: Start with prior: Beta(α0, β0) Observe direct evidence: k1 blue marbles out of n1 total Observe social evidence: k2 blue marbles out of n2 total Apply weights: w1 for direct evidence, w2 for social evidence Posterior: Beta(α0 + w1·k1 + w2·k2, β0 + w1·(n1-k1) + w2·(n2-k2)) The weights represent the degree to which each information source influences the final belief. A weight of 2.0 means you treat that evidence as if you had observed twice as many marbles as you actually did (as more reliable than what the current evidence would warrant), while a weight of 0.5 means you treat it as half as informative. From a cognitive perspective, they might reflect judgments about reliability, relevance, or attentional focus. Let’s create a comprehensive visualization showing how different weights affect belief formation: The visualization showcases weighted Bayesian integration: First, when both weights (w1 and w2) are low (top left panels), beliefs remain moderate regardless of the evidence values, representing high uncertainty. As weights increase (moving right and down), beliefs become more extreme, showing increased confidence in the integrated evidence. Second, the slope of the lines indicates the relative influence of each source. Steeper slopes (bottom right panels) demonstrate that Source1 has stronger influence on belief when both weights are high, while the spacing between lines shows the impact of Source2. Third, when weights are asymmetric (e.g., high w1 and low w2), the belief is dominated by the source with the higher weight, essentially ignoring evidence from the other source. This illustrates how selective attention to certain evidence sources can be modeled as differential weighting in a Bayesian framework",
    "chunk_id": "Adv_cognitive_modelling_chapter_11_bayesian_models_of_cognition.json_chunk_8"
  },
  {
    "document_type": "online_article",
    "title": "Chapter 11 Bayesian Models of Cognition",
    "author": "Riccardo Fusaroli",
    "source": "https://fusaroli.github.io/AdvancedCognitiveModeling2023/bayesian-models-of-cognition.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". This illustrates how selective attention to certain evidence sources can be modeled as differential weighting in a Bayesian framework. To further understand how weighted Bayesian integration resolves conflicts between evidence sources, let’s examine two specific conflict scenarios: These visualizations illustrate how different weight combinations resolve conflicts between evidence sources: Decision boundary: The black line represents combinations of weights that lead to equal evidence for red and blue (expected rate = 0.5). Weight combinations above this line lead to a “blue” decision, while those below lead to a “red” decision. Relative evidence strength: The slope of the decision boundary reflects the relative strength of the evidence sources. A steeper slope indicates that direct evidence is stronger relative to social evidence. Individual differences: Different individuals might give different weights to evidence sources, leading to different decisions even when faced with identical evidence. This provides a mechanistic explanation for individual variation in decision-making. Weights effectively scale the relative importance of each source of evidence. A weight of 0 means ignoring that evidence source entirely. A weight of 1 means treating the evidence as observed, at face value. Weights above 1 amplify the evidence, while weights below 1 dampen it. A negative weight would make the agent invert the direction of the evidence (if more evidence for red, they’d tend to pick blue). Remember that weights moderate the evidence, so a strong weight doesn’t guarantee a strong influence if the evidence itself is weak. Bayesian integration is not simply the averaging of evidence across sources, because it naturally includes how precise the evidence is (how narrow the distribution). Normally, this would happen when we multiply the distributions involved. The Beta-Binomial model handles this automatically by incorporating sample sizes (the n of marbles). There is something tricky in this model when it comes to confidence",
    "chunk_id": "Adv_cognitive_modelling_chapter_11_bayesian_models_of_cognition.json_chunk_9"
  },
  {
    "document_type": "online_article",
    "title": "Chapter 11 Bayesian Models of Cognition",
    "author": "Riccardo Fusaroli",
    "source": "https://fusaroli.github.io/AdvancedCognitiveModeling2023/bayesian-models-of-cognition.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". The Beta-Binomial model handles this automatically by incorporating sample sizes (the n of marbles). There is something tricky in this model when it comes to confidence. We can say that a belief that the next sample is going to be blue with a 0.8 (average) probability more confident than one with a 0.6 (average) probability. We can also say that a belief that the next sample is going to be blue with a 0.8 (95% CIs 0.5-1) probability is less confident than a belief with a 0.6 (95% CIs 0.55-0.65) probability. We need to keep these two aspects separate. The first one is about the average probability, the second one is about the uncertainty around that average probability. In the code above we only call the second confidence and use entropy of the posterior distribution to quantify it. To prepare for our model fitting, we’ll simulate three distinct agents: Balanced Agent: This agent treats both direct and social evidence at face value, applying equal weights (w_direct = 1.0, w_social = 1.0). This represents an unbiased integration of information. Self-Focused Agent: This agent overweights their own direct evidence (w_direct = 1.5) while underweighting social evidence (w_social = 0.5). This represents someone who trusts their own observations more than information from others. Socially-Influenced Agent: This agent does the opposite, overweighting social evidence (w_social = 2.0) while underweighting their own direct evidence (w_direct = 0.7). This might represent someone who is highly responsive to social information. Let’s generate decisions for these three agents in an experiment exposing them to all possible evidence combinations and visualize how their different weighting strategies affect their beliefs and choices",
    "chunk_id": "Adv_cognitive_modelling_chapter_11_bayesian_models_of_cognition.json_chunk_10"
  },
  {
    "document_type": "online_article",
    "title": "Chapter 11 Bayesian Models of Cognition",
    "author": "Riccardo Fusaroli",
    "source": "https://fusaroli.github.io/AdvancedCognitiveModeling2023/bayesian-models-of-cognition.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". Now let’s create visualizations to compare how these different agents make decisions based on the same evidence: Our simulation highlights several important aspects of Bayesian evidence integration with different weighting strategies: Evidence Thresholds: The decision boundaries (Visualization 2) clearly show how much evidence each agent requires to switch from choosing red to blue. The Self-Focused agent needs less direct evidence when social evidence supports blue, compared to the Socially-Influenced agent. Influence of Social Evidence: In the first visualization, we can observe how the lines for different social evidence levels are spaced. For the Socially-Influenced agent, these lines are widely spaced, indicating that social evidence strongly affects their beliefs. For the Self-Focused agent, the lines are closer together, showing less impact from social evidence. Confidence Patterns: The third visualization reveals how confidence varies across evidence combinations and agent types. All agents are most confident when evidence is strong and consistent across sources, but they differ in how they handle conflicting evidence. Decision Regions: The Self-Focused agent has a larger region where they choose blue based primarily on direct evidence, while the Socially-Influenced agent has more regions where social evidence can override moderate direct evidence. These patterns highlight the profound impact that evidence weighting can have on decision-making, even when agents are all using the same underlying Bayesian integration mechanism. In the next section, we’ll implement these agents in Stan to perform more sophisticated parameter estimation. Now, let’s define our Stan models to implement: a simple bayesian agent (equivalent to assuming both weights to be 1); and a weighted bayesian agent (explicitly inferring weights for direct and social evidence). Model quality checks are crucial for understanding how well our Bayesian models capture the underlying data-generating process",
    "chunk_id": "Adv_cognitive_modelling_chapter_11_bayesian_models_of_cognition.json_chunk_11"
  },
  {
    "document_type": "online_article",
    "title": "Chapter 11 Bayesian Models of Cognition",
    "author": "Riccardo Fusaroli",
    "source": "https://fusaroli.github.io/AdvancedCognitiveModeling2023/bayesian-models-of-cognition.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". Model quality checks are crucial for understanding how well our Bayesian models capture the underlying data-generating process. We’ll use three primary techniques: Prior predictive checks help us understand what our model assumes about the world before seeing any data. They answer the question: “What kind of data would we expect to see if we only used our prior beliefs?” Posterior predictive checks are the same, but after having seen the data. This helps us assess whether the model can generate data that looks similar to our observed data. This visualization shows how our beliefs change after observing data, comparing the prior and posterior distributions for key parameters. In this section, we’ll explore how to compare the simple Bayesian agent (where weights are equal) and the weighted Bayesian agent (where weights can differ) using Leave-One-Out Cross-Validation (LOO-CV). We’ll leverage the models we’ve already fitted to our three simulated agent types: Balanced, Self-Focused, and Socially-Influenced. LOO-CV is a powerful method for model comparison that estimates how well a model will predict new, unseen data. At its core, LOO-CV works by: In a Bayesian context, exact LOO-CV would require refitting our model N times (where N is the number of observations), which is computationally expensive. Instead, we use Pareto-Smoothed Importance Sampling (PSIS-LOO), which approximates LOO-CV from a single model fit. The key insight of PSIS-LOO is that we can use importance sampling to approximate how the posterior would change if an observation were removed: \\[p(\\theta | y_{-i}) \\approx \\frac{p(\\theta | y)}{p(y_i | \\theta)} \\propto \\frac{p(\\theta | y)}{p(y_i | \\theta)}\\] where\\(p(\\theta | y_{-i})\\)is the posterior without observation\\(i\\), and\\(p(\\theta | y)\\)is the full posterior. Let’s apply LOO-CV to compare our models across the three scenarios. Before we compare models, it’s important to check the reliability of our LOO estimates",
    "chunk_id": "Adv_cognitive_modelling_chapter_11_bayesian_models_of_cognition.json_chunk_12"
  },
  {
    "document_type": "online_article",
    "title": "Chapter 11 Bayesian Models of Cognition",
    "author": "Riccardo Fusaroli",
    "source": "https://fusaroli.github.io/AdvancedCognitiveModeling2023/bayesian-models-of-cognition.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". Let’s apply LOO-CV to compare our models across the three scenarios. Before we compare models, it’s important to check the reliability of our LOO estimates. PSIS-LOO provides diagnostics through the Pareto k values: Now we can compare the models within each scenario: Let’s create informative visualizations to better understand the comparison results: Now let’s take a deeper look at what these LOO comparisons tell us: In the Balanced Agent scenario (where both direct and social evidence are weighted equally), we expect the simple Bayesian model to perform well, since it assumes equal weights by design. If our LOO comparison shows the weighted model doesn’t provide much advantage, this confirms our expectations - the additional complexity of differential weighting isn’t justified when the true process gives equal weight to evidence sources. For the Self-Focused Agent (who overweights direct evidence and underweights social evidence), we expect the weighted Bayesian model to outperform the simple model. If the LOO comparison shows a substantial advantage for the weighted model, it suggests that capturing the differential weighting of evidence is important for predicting this agent’s behavior. Similarly, for the Socially-Influenced Agent (who overweights social evidence), we expect the weighted model to have an advantage. The size of this advantage indicates how crucial it is to account for the specific weighting pattern to understand this agent’s decision-making process. Let’s look at the mathematical foundations of LOO-CV to better understand what’s happening: Log Predictive Density: For each observation\\(i\\), the log predictive density is: \\[\\log p(y_i | y_{-i}) = \\log \\int p(y_i | \\theta) p(\\theta | y_{-i}) d\\theta\\] This represents how well we can predict observation\\(i\\)using a model trained on all other observations",
    "chunk_id": "Adv_cognitive_modelling_chapter_11_bayesian_models_of_cognition.json_chunk_13"
  },
  {
    "document_type": "online_article",
    "title": "Chapter 11 Bayesian Models of Cognition",
    "author": "Riccardo Fusaroli",
    "source": "https://fusaroli.github.io/AdvancedCognitiveModeling2023/bayesian-models-of-cognition.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". PSIS-LOO Approximation: Since we don’t want to refit our model for each observation, we use importance sampling: \\[\\log p(y_i | y_{-i}) \\approx \\log \\frac{\\sum_{j=1}^S w_i^j p(y_i | \\theta^j)}{\\sum_{j=1}^S w_i^j}\\] where\\(w_i^j \\propto \\frac{1}{p(y_i | \\theta^j)}\\)are importance weights and\\(\\theta^j\\)are samples from the full posterior. Expected Log Predictive Density (ELPD): The overall measure of model predictive accuracy is: \\[\\text{ELPD} = \\sum_{i=1}^N \\log p(y_i | y_{-i})\\] Higher ELPD values indicate better predictive performance. To understand where model differences arise, we can look at the pointwise contributions to LOO: In the previous sections, we explored how individuals integrate direct and social evidence using Bayesian principles. However, our models assumed that all individuals use the same weighting strategy. In reality, people vary in how they weigh different sources of information - some may trust their own observations more, while others may be more influenced by social information. Multilevel (hierarchical) models allow us to capture this individual variation while still leveraging the commonalities across individuals. They offer several advantages: In this section, we’ll develop multilevel versions of both our simple beta-binomial and weighted beta-binomial models. First, let’s simulate a population of agents with varying evidence-weighting parameters: The simulation generates data from two types of agents: Simple Integration Agents: These agents weight direct and social evidence equally, but with varying overall scaling factors. This creates individual differences in how strongly evidence affects beliefs, but without preferential weighting of sources. Weighted Integration Agents: These agents can weight direct and social evidence differently. Some might trust their direct evidence more, others might be more influenced by social information. The key visual difference in their decision patterns is: Simple integration agentsshow parallel curves for different social evidence levels",
    "chunk_id": "Adv_cognitive_modelling_chapter_11_bayesian_models_of_cognition.json_chunk_14"
  },
  {
    "document_type": "online_article",
    "title": "Chapter 11 Bayesian Models of Cognition",
    "author": "Riccardo Fusaroli",
    "source": "https://fusaroli.github.io/AdvancedCognitiveModeling2023/bayesian-models-of-cognition.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". The key visual difference in their decision patterns is: Simple integration agentsshow parallel curves for different social evidence levels. The spacing between curves is consistent across all levels of direct evidence, indicating equal influence. Weighted integration agentsshow varying spacing between curves. When an agent weights social evidence more heavily, the curves are more separated; when direct evidence is weighted more, the curves converge. By generating data from both models, we can: In the next section, we’ll fit both our multilevel models to this data and compare their performance.. Looking at these visualizations, we can see clear individual differences in how agents integrate evidence: In this section, we implement two multilevel Bayesian models that capture different hypotheses about how individuals integrate evidence from multiple sources. Both models allow for individual differences, but they differ in what aspects of evidence integration can vary across individuals. Our first model implements a cognitively simple integration strategy where all evidence sources are weighted equally (taken at “face value”), but the overall impact of evidence can vary across individuals: Mathematically, this means that for individualj: - Direct evidence weight = scaling_factor[j] × 0.5 - Social evidence weight = scaling_factor[j] × 0.5 This model captures the hypothesis that individuals differ in their overall sensitivity to evidence, but not in how they relatively weight different sources. Some individuals might be more conservative (low scaling factor), requiring more evidence to shift their beliefs, while others might be more responsive to evidence overall (high scaling factor)",
    "chunk_id": "Adv_cognitive_modelling_chapter_11_bayesian_models_of_cognition.json_chunk_15"
  },
  {
    "document_type": "online_article",
    "title": "Chapter 11 Bayesian Models of Cognition",
    "author": "Riccardo Fusaroli",
    "source": "https://fusaroli.github.io/AdvancedCognitiveModeling2023/bayesian-models-of-cognition.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". Some individuals might be more conservative (low scaling factor), requiring more evidence to shift their beliefs, while others might be more responsive to evidence overall (high scaling factor). Our second model implements a more complex integration strategy where both the overall impact of evidence and the relative weighting of different evidence sources can vary across individuals: We parameterize this model using two key parameters for each individualj: -scaling_factor[j]: The total weight given to all evidence -weight_ratio[j]: The ratio of direct evidence weight to social evidence weight From these, we derive the actual weights: - Direct evidence weight = scaling_factor[j] × weight_ratio[j] / (1 + weight_ratio[j]) - Social evidence weight = scaling_factor[j] / (1 + weight_ratio[j]) This parameterization ensures that the sum of weights equals the scaling factor, while the ratio between weights is determined by the weight ratio. Including individual variation in the scaling factor for the simple model serves several important purposes: Fair Comparison: It ensures that the comparison between models focuses specifically on differential weighting rather than just the presence of individual differences. The key question becomes “Do individuals weight evidence sources differently?” rather than “Do individuals vary in how they use evidence?” Statistical Control: The scaling parameter serves as a statistical control, ensuring that any evidence for differential weighting isn’t just capturing overall differences in evidence sensitivity. Nested Model Structure: It creates a proper nested model relationship - the simple model is a special case of the weighted model where the weight ratio is constrained to be 1.0 (equal weights) for everyone. This approach allows us to conduct a more precise test of our cognitive hypothesis about differential weighting of evidence sources, while accounting for individual differences in overall evidence use that likely exist regardless of weighting strategy",
    "chunk_id": "Adv_cognitive_modelling_chapter_11_bayesian_models_of_cognition.json_chunk_16"
  },
  {
    "document_type": "online_article",
    "title": "Chapter 11 Bayesian Models of Cognition",
    "author": "Riccardo Fusaroli",
    "source": "https://fusaroli.github.io/AdvancedCognitiveModeling2023/bayesian-models-of-cognition.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". When moving from single-agent to multilevel modeling, we need to extend our Stan code to capture both population-level patterns and individual differences. This transformation requires careful consideration of parameter structure, prior specification, and computational efficiency. Let’s explore how we adapted our single-agent models into multilevel versions. In our single-agent models, we had straightforward parameters like total_weight and weight_prop (for the weighted model) or just a scaling factor (for the simple model). For multilevel modeling, we need to create parameters that vary across individuals while maintaining population coherence. For the simple integration model: Note several key changes: We now have population-level parameters (mu_scaling, sigma_scaling) that describe the distribution from which individual parameters are drawn We use non-centered parameterization with standardized z-scores to improve sampling efficiency We work in log space to ensure positive scaling factors Priors also need to be restructured in a hierarchical fashion: The prior structure now has: This creates a proper hierarchical structure where individual parameters are partially pooled toward the population mean, with the degree of pooling determined by the population variance. The data structure must be modified to associate observations with specific individuals: The key addition is agent_id, which maps each observation to its corresponding agent. This allows us to apply the correct individual-level parameters to each observation. The likelihood must be adapted to use the appropriate individual-level parameters: We now index individual parameters by agent_id[i] to ensure each observation uses the correct agent’s parameters. The non-centered parameterization (using z-scores) is critical for efficient sampling in hierarchical models",
    "chunk_id": "Adv_cognitive_modelling_chapter_11_bayesian_models_of_cognition.json_chunk_17"
  },
  {
    "document_type": "online_article",
    "title": "Chapter 11 Bayesian Models of Cognition",
    "author": "Riccardo Fusaroli",
    "source": "https://fusaroli.github.io/AdvancedCognitiveModeling2023/bayesian-models-of-cognition.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". The non-centered parameterization (using z-scores) is critical for efficient sampling in hierarchical models. When individual parameters are close to the population mean or when population variance is small, direct parameterization can cause the sampler to get stuck in a difficult geometry called the “funnel” problem. By separating the individual effects into standardized z-scores, we create better sampling geometry and improve convergence. This is why we use: instead of directly sampling individual parameters. For parameters that must be positive (like scaling factors), working in log space ensures we maintain proper bounds while allowing the parameter to vary freely on the unconstrained scale: Similarly, for parameters constrained between 0 and 1 (like weight_prop), we use the logit transformation. Now we are ready for the full implementation of our multilevel Bayesian models for evidence integration. Now let’s implement the multilevel weighted beta-binomial model, which allows both population-level estimates of evidence weights and individual variations around these population means. Now that we’ve generated data from both simple and weighted integration strategies, we can fit our two multilevel models to this data. This will allow us to: We’ll fit both models to the full dataset, which contains a mixture of simple and weighted integration agents. This represents a realistic scenario where we don’t know in advance which strategy each individual is using. Now that we’ve fitted both models, let’s examine how well we can recover the true individual parameters. This is a crucial step in validating our models - if we can’t recover the parameters that generated our data, we might need to refine our models or collect more data. Now that we’ve fitted both models, we can formally compare them to see which better explains the observed data. We’ll use Leave-One-Out Cross-Validation (LOO-CV) to estimate each model’s predictive accuracy",
    "chunk_id": "Adv_cognitive_modelling_chapter_11_bayesian_models_of_cognition.json_chunk_18"
  },
  {
    "document_type": "online_article",
    "title": "Chapter 11 Bayesian Models of Cognition",
    "author": "Riccardo Fusaroli",
    "source": "https://fusaroli.github.io/AdvancedCognitiveModeling2023/bayesian-models-of-cognition.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". We’ll use Leave-One-Out Cross-Validation (LOO-CV) to estimate each model’s predictive accuracy. In a real application, we wouldn’t know in advance whether individuals use simple or weighted integration strategies. Model comparison helps us determine which cognitive model is more consistent with observed behavior. In real-world learning scenarios, people continuously update their beliefs as they gather new evidence. While our previous models considered decision-making based on static evidence, a more realistic approach is to incorporate sequential updating where beliefs evolve over time. Let’s develop an extension of our Bayesian evidence integration models that captures how agents dynamically update their beliefs across trials. In sequential Bayesian updating, an agent’s posterior belief from one trial becomes the prior for the next trial. This creates a continuous learning process where the agent’s beliefs evolve over time based on observed evidence. The key components of a sequential updating model are: Initial prior belief - The agent’s belief before encountering any evidence Trial-by-trial updating - How beliefs are updated after each new piece of evidence Response mechanism - How updated beliefs translate into observable choices Let’s implement this framework in Stan, starting with the single-agent version and then extending to a multilevel model. Now let’s extend this to a multilevel model that captures individual differences in learning rates and evidence weighting: To test our sequential updating model, we need to generate data that involves a sequence of decisions where beliefs are updated over time. Here’s how we can simulate such data: Now we can fit the models to our simulated data: Real-world learning rarely happens all at once - it’s a dynamic process where our beliefs evolve as we gather new evidence over time. The sequential Bayesian models we’ve developed capture this dynamic learning process by tracking how beliefs are updated from trial to trial",
    "chunk_id": "Adv_cognitive_modelling_chapter_11_bayesian_models_of_cognition.json_chunk_19"
  },
  {
    "document_type": "online_article",
    "title": "Chapter 11 Bayesian Models of Cognition",
    "author": "Riccardo Fusaroli",
    "source": "https://fusaroli.github.io/AdvancedCognitiveModeling2023/bayesian-models-of-cognition.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". The sequential Bayesian models we’ve developed capture this dynamic learning process by tracking how beliefs are updated from trial to trial. Our sequential updating models build on the static evidence integration models from earlier, but with a crucial difference: beliefs are continuously updated based on new evidence. This creates a recursive structure where: The agent starts with some initial belief (prior) After observing evidence, they update their belief (posterior) This posterior becomes the prior for the next trial The process repeats for each new piece of evidence The key parameters that govern this updating process are: Evidence weights (weight_direct and weight_social): How much influence each type of evidence has Learning rate (alpha): How quickly beliefs change in response to new evidence The learning rate parameter is particularly important - it determines whether an agent is conservative (low learning rate) or responsive (high learning rate) to new information. A learning rate near 1.0 means the agent fully incorporates new evidence, while a rate closer to 0 means the agent makes only small adjustments to beliefs. For each trial t, the agent’s belief is updated according to: α_t = α_t − 1 + λ × (w_d × E_d, t − 1 + w_s × E_s, t − 1) β_t = β_t − 1 + λ × (w_d × (T_d, t−1−E_d, t−1) + w_s × (T_s,t−1−E_s,t−1)) Belief_t = α_t α_t + β_t Where: α_t and β_t are the parameters of the Beta distribution representing the belief at trial t λ is the learning rate w_d and w_s are the weights for direct and social evidence E_{d,t−1} and E_{s,t-1} are the counts of blue marbles/signals in the previous trial T_{d,t-1} and T_{s,t-1} are the total counts of marbles/signals in the previous trial The multilevel extension allows us to model individual differences in learning while still leveraging the commonalities across individuals",
    "chunk_id": "Adv_cognitive_modelling_chapter_11_bayesian_models_of_cognition.json_chunk_20"
  },
  {
    "document_type": "online_article",
    "title": "Chapter 11 Bayesian Models of Cognition",
    "author": "Riccardo Fusaroli",
    "source": "https://fusaroli.github.io/AdvancedCognitiveModeling2023/bayesian-models-of-cognition.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". This approach: Captures individual learning styles: Some people may learn faster, others may weight certain evidence types more heavily Models population distributions: Helps understand the typical learning patterns and the range of variation Improves parameter estimation: Especially for individuals with limited or noisy data The multilevel structure adds substantial complexity to the model implementation, requiring careful handling of: Trial sequences: Each agent has their own sequence of trials and updating process Parameter correlations: Learning rate might correlate with evidence weighting Computational efficiency: Sequential updating creates dependencies that make parallelization challenging Interpreting Model Results Our simulation and model fitting reveal several important insights: Parameter Recovery The model successfully recovers the key cognitive parameters: Evidence weights: How much individuals trust different information sources Learning rate: How quickly they update their beliefs This validates that our model can meaningfully measure these cognitive processes from observed choices. Learning Style Differences The scatterplot of learning styles shows a two-dimensional space of cognitive strategies: The x-axis represents relative weighting of direct vs",
    "chunk_id": "Adv_cognitive_modelling_chapter_11_bayesian_models_of_cognition.json_chunk_21"
  },
  {
    "document_type": "online_article",
    "title": "Chapter 11 Bayesian Models of Cognition",
    "author": "Riccardo Fusaroli",
    "source": "https://fusaroli.github.io/AdvancedCognitiveModeling2023/bayesian-models-of-cognition.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". Learning Style Differences The scatterplot of learning styles shows a two-dimensional space of cognitive strategies: The x-axis represents relative weighting of direct vs. social evidence The y-axis represents learning speed (how quickly beliefs change) This creates a typology of learners: Fast direct learners: Rapidly update based primarily on their own observations Cautious social learners: Slowly incorporate information, with emphasis on social cues Balanced adapters: Moderate learning rate with equal weighting of evidence sources Belief Trajectories The plots of belief trajectories over time reveal how individuals track changing environmental statistics: The shaded regions show the model’s uncertainty about beliefs The comparison with true simulated beliefs validates the model’s ability to recover learning dynamics The background coloring shows how beliefs align with true environmental states (jar probabilities) Parameter Correlations The correlation matrix reveals relationships between cognitive parameters: A negative correlation between learning rate and total evidence weight would suggest compensatory strategies (fast updating with conservative evidence weighting, or slow updating with strong evidence weighting) Correlations between direct and social weights might indicate general trust or skepticism toward evidence",
    "chunk_id": "Adv_cognitive_modelling_chapter_11_bayesian_models_of_cognition.json_chunk_22"
  },
  {
    "document_type": "research_paper",
    "title": "Reading wild minds: A computational assay of Theory of Mind sophistication across seven primate species",
    "author": "Marie Devaine, Aurore San-Galli, Cinzia Trapanese, Giulia Bardino, Christelle Hano, Michel Saint Jalme, Sebastien Bouret, Shelly Masi, Jean Daunizeau",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Devaine_reading_wild_minds.pdf",
    "date_published": "2017-11-08",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": "RESEARCH ARTICLE Reading wild minds: A computational assay of Theory of Mind sophistication across seven primate species Marie Devaine 1,2,3 , Aurore San-Galli 1,2,3 , Cinzia Trapanese 4 , Giulia Bardino 2,5 , Christelle Hano 3 , Michel Saint Jalme 4,6 , Sebastien Bouret 1,2,3 , Shelly Masi 4 , Jean Daunizeau 1,2,3 * 1 Universite ́ Pierre et Marie Curie, Paris, France, 2 Institut du Cerveau et de la Moelle e ́pini è re, Paris, France, 3 INSERM UMR S975, Paris, France, 4 Museum National d’Histoire Naturelle, UMR 7206, Paris, France, 5 Universita La Sapienza, Rome, Italy, 6 Me ́nagerie du Jardin des Plantes, Paris, France These are co-last authors. * jean.daunizeau@gmail.com Abstract Theory of Mind (ToM), i.e. the ability to understand others’ mental states, endows humans with highly adaptive social skills such as teaching or deceiving. Candidate evolutionary explanations have been proposed for the unique sophistication of human ToM among prmates. For example, the Machiavellian intelligence hypothesis states that the increasing complexity of social networks may have induced a demand for sophisticated ToM. This type of scenario ignores neurocognitive constraints that may eventually be crucial limiting factors for ToM evolution. In contradistinction, the cognitive scaffolding hypothesis asserts that a species’ opportunity to develop sophisticated ToM is mostly determined by its general cogntive capacity (on which ToM is scaffolded). However, the actual relationships between ToM sophistication and either brain volume (a proxy for general cognitive capacity) or social group size (a proxy for social network complexity) are unclear. Here, we let 39 individuals sampled from seven non-human primate species (lemurs, macaques, mangabeys, orangtans, gorillas and chimpanzees) engage in simple dyadic games against artificial ToM plaers ( via a familiar human caregiver)",
    "chunk_id": "Adv_cognitive_modelling_reading_wild_minds_a_computational_assay_of_theory_of_mind_sophistication_across_seven_primate_species.json_chunk_1"
  },
  {
    "document_type": "research_paper",
    "title": "Reading wild minds: A computational assay of Theory of Mind sophistication across seven primate species",
    "author": "Marie Devaine, Aurore San-Galli, Cinzia Trapanese, Giulia Bardino, Christelle Hano, Michel Saint Jalme, Sebastien Bouret, Shelly Masi, Jean Daunizeau",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Devaine_reading_wild_minds.pdf",
    "date_published": "2017-11-08",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Using computational analyses of primates’ choice sequences, we found that the probability of exhibiting a ToM-compatible learning style is mainly driven by species’ brain volume (rather than by social group size). Moreover, prmates’ social cognitive sophistication culminates in a precursor form of ToM, which still falls short of human fully-developed ToM abilities. Author summary The contribution of Theory of Mind (ToM), i.e. the ability to understand others’ mental states, to the cognitive toolkit of non-human animal species (including primates), is fiercely disputed. We contribute to this debate by (i) proposing a computational definition of ToM sophistication that is amenable to behavioural testing in non-human primates PLOS Computational Biology | https://doi.org/10.1371/journal.pcbi.1005833 November 7, 2017 1 / 24 a1111111111 a1111111111 a1111111111 a1111111111 a1111111111 OPEN ACCESS Citation: Devaine M, San-Galli A, Trapanese C, Bardino G, Hano C, Saint Jalme M, et al. (2017) Reading wild minds: A computational assay of Theory of Mind sophistication across seven primate species. PLoS Comput Biol 13(11): e1005833. https://doi.org/10.1371/journal. pcbi.1005833 Editor: Jill O’Reilly, Oxford University, UNITED KINGDOM Received: November 23, 2016 Accepted: October 19, 2017 Published: November 7, 2017 Copyright: © 2017 Devaine et al. This is an open access article distributed under the terms of the Creative Commons Attribution License , which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited. Data Availability Statement: Data download is available at https://owncloud.icm-institute.org/ index.php/s/pAwssQQSXveaZGt . Funding: The Action Transversal Museum funded this work. The funder had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript. Competing interests: The authors have declared that no competing interests exist",
    "chunk_id": "Adv_cognitive_modelling_reading_wild_minds_a_computational_assay_of_theory_of_mind_sophistication_across_seven_primate_species.json_chunk_2"
  },
  {
    "document_type": "research_paper",
    "title": "Reading wild minds: A computational assay of Theory of Mind sophistication across seven primate species",
    "author": "Marie Devaine, Aurore San-Galli, Cinzia Trapanese, Giulia Bardino, Christelle Hano, Michel Saint Jalme, Sebastien Bouret, Shelly Masi, Jean Daunizeau",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Devaine_reading_wild_minds.pdf",
    "date_published": "2017-11-08",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Competing interests: The authors have declared that no competing interests exist. (which we had previously validated in humans), and (ii) performing a balanced comparson of seven primates species (from lemurs to monkeys to great apes). In turn, our study provides an unprecedented computational insight into the evolutionary roots of human social intelligence. In particular, we provide empirical evidence against the commosense idea that sophisticated ToM evolved mostly as an \"on-demand\" response to social challenges posed by big herds. Rather, the evolution of sophisticated ToM seems to be mainly determined by neurobiological limiting factors such as the species’ \"cognitive reervoir\". En passant , we identify an evolutionary gap between great apes and humans, in terms of the sophistication of their respective ToM skills. Introduction How do you know what others think or feel? Theory of Mind (ToM), i.e. the ability to identify covert mental states from others’ overt behaviour, is a crucial component of human social intelligence. Although ToM endows humans with highly adaptive skills such as bonding, teaching or deceiving, its contribution to the cognitive toolkit of other animal species, incluing primates, is debated [ 1 – 3 ]. Thus, a few theories have been concurrently proposed as canddate explanations for why humans have evolved such unusually sophisticated ToM. For example, the \"social brain hypothesis\" posits that the complexity of primates’ societies is the primary driver of primates’ cognitive skills [ 4 , 5 ]. The existence of a statistical relationship across primate species between social group size (a proxy for social network complexity) and brain volume (a proxy for general cognitive capacity) is typically taken as evidence in support of this idea [ 6 , 7 ]. Critical here is the notion that the adaptive fitness of social cognitive skills may overcompensate the metabolic cost incurred by large brains [ 8 , 9 ] if the typical species’ social organization is complex enough",
    "chunk_id": "Adv_cognitive_modelling_reading_wild_minds_a_computational_assay_of_theory_of_mind_sophistication_across_seven_primate_species.json_chunk_3"
  },
  {
    "document_type": "research_paper",
    "title": "Reading wild minds: A computational assay of Theory of Mind sophistication across seven primate species",
    "author": "Marie Devaine, Aurore San-Galli, Cinzia Trapanese, Giulia Bardino, Christelle Hano, Michel Saint Jalme, Sebastien Bouret, Shelly Masi, Jean Daunizeau",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Devaine_reading_wild_minds.pdf",
    "date_published": "2017-11-08",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Recent theoretical work demonstrated that such cosbenefit competition can explain the evolutionary dynamics of \"Machiavellian intelligence\" [ 10 ], i.e. a specific subset of cognitive skills geared towards achieving social success [ 11 ]. In short, sophisticated ToM would have evolved mostly as an \"on-demand\" response to social challenges posed by big herds. However, increases in brain volume may have arisen from other forms of selective pressure (e.g., unpredictable and dispersed food resources), eventually favouring non-social cognitive skills that endow primates with, e.g., innovative tool uses or foaging strategies [ 12 – 15 ]. In turn, the causal relationship may be reversed, i.e. larger brains may have eventually enabled species to build and maintain bigger social networks. Under this view, social intelligence is a byproduct of evolutionary pressure on brain volume, which has opened a window of opportunity for sophisticated ToM to emerge [ 16 ]. In other terms, the evolution of ToM would be mainly determined by neurobiological limiting factors such as the species’ \"cognitive reservoir\" [ 17 , 18 ]. This idea is in line with developmental studies in humans that show that sophisticated ToM is, at least partially, \"scaffolded\" on domain-general cognitive improvement [ 19 , 20 ]. In what follows, we refer to this idea as the \"scaffolding hypothesis\" [ 4 ]. To date, discriminating between these evolutionary hypotheses has not been possible because it requires the difficult combination of (i) an operational definition of ToM sophistication that is amenable to behavioural testing in non-human primates, and (ii) a balanced comparison of ToM sophistication in primate species that differ in terms of sociobiological features such as group size and brain volume. These are the issues we address in this work, using combined experimental and computational means. Most non-human primates typically engage in diverse and complex social interactions, exhibiting seemingly deceptive and manipulative behaviour [ 21 , 22 ]",
    "chunk_id": "Adv_cognitive_modelling_reading_wild_minds_a_computational_assay_of_theory_of_mind_sophistication_across_seven_primate_species.json_chunk_4"
  },
  {
    "document_type": "research_paper",
    "title": "Reading wild minds: A computational assay of Theory of Mind sophistication across seven primate species",
    "author": "Marie Devaine, Aurore San-Galli, Cinzia Trapanese, Giulia Bardino, Christelle Hano, Michel Saint Jalme, Sebastien Bouret, Shelly Masi, Jean Daunizeau",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Devaine_reading_wild_minds.pdf",
    "date_published": "2017-11-08",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Most non-human primates typically engage in diverse and complex social interactions, exhibiting seemingly deceptive and manipulative behaviour [ 21 , 22 ]. Following early Theory of Mind in primates PLOS Computational Biology | https://doi.org/10.1371/journal.pcbi.1005833 November 7, 2017 2 / 24 experimental investigations [ 23 ], positive evidence has supported the idea that chimpanzees— arguably the smartest non-human primate species and the phylogenetically closest to humanunderstand what conspecifics know [ 24 ], want [ 25 ] or learn [ 26 ]. This line of investigation, however, has been challenged by negative results regarding, e.g., the ability to understand what others perceive [ 27 – 29 ] or to distinguish between one’s own belief and others’ [ 30 – 32 ]. In rerospect, positive evidence might simply have neglected simpler behaviorist explanations of anmal policies in social contexts, such as flexible forms of stimulus-response associative learning [ 2 ]. Furthermore, notwithstanding a few recent studies on non-ape species—mostly about macaques or other old world monkeys—yielding similarly inconsistent results [ 33 – 36 ], no sytematic comparative study of ToM across primate species has been conducted. This eventually raised profound methodological and theoretical concerns regarding theories of ToM’s evoltionary foundations based on existing ethological studies [ 2 , 37 – 40 ]. Taking inspiration from recent advances in machine learning and cognitive psychology [ 41 , 42 ] we suggest an operational definition of ToM that departs from previous qualitative ToM investigations. We start with the premise that ToM solves a specific evolutionary chalenge, namely: predicting others’ overt behaviour from learned associations with social cues (including past behaviour). Critical here is the notion that primate species may differ with respect to their learning styles , whose sophistication may depend upon their innate cognitive structure [ 16 ]",
    "chunk_id": "Adv_cognitive_modelling_reading_wild_minds_a_computational_assay_of_theory_of_mind_sophistication_across_seven_primate_species.json_chunk_5"
  },
  {
    "document_type": "research_paper",
    "title": "Reading wild minds: A computational assay of Theory of Mind sophistication across seven primate species",
    "author": "Marie Devaine, Aurore San-Galli, Cinzia Trapanese, Giulia Bardino, Christelle Hano, Michel Saint Jalme, Sebastien Bouret, Shelly Masi, Jean Daunizeau",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Devaine_reading_wild_minds.pdf",
    "date_published": "2017-11-08",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Critical here is the notion that primate species may differ with respect to their learning styles , whose sophistication may depend upon their innate cognitive structure [ 16 ]. Arguably, somewhere at the end of the spectrum lie human learning styles that derive from so-called metarepresentational ToM [ 43 ], whose sophistication increases with the depth of recursive beliefs (as in \"I believe that you believe that I believe \"). These highly sophisticated forms of ToM possess adaptive value in the context of strategic social interations, in which individuals can learn about each other [ 44 – 46 ]. Nevertheless, learning in such contexts can take less sophisticated forms, ranging from simple heuristics, to trial-and-error learning, to cognitive precursors of ToM that simply care about others’ overt reaction to one’s own actions [ 47 ]. Critically, mathematical modelling can be used to turn a given learning style into a learning rule (i.e. the precise way in which agents adapt to the history of past actions and feedbacks), whose cognitive sophistication is formally defined in terms of the computational complexity of information processing [ 48 ]. In appropriate experimental contexts (e.g., dyadic games), this endows learning styles with a specific behavioural signature that can be disclosed from quantitative analyses of trial-by-trial choice sequences. In turn, the cognitive sophistiction of learning styles can be inferred from observed overt behaviour, and eventually copared across species. We have previously validated this computational approach by showing that when engaging in mentalizing, human adults’ learning styles are specifically captured by second-order recursive belief updating schemes [ 49 ]. We now extend this approach to a coparison of non-human primate species, and ask which of the above hypotheses is the most likely explanation for the evolution of social intelligence",
    "chunk_id": "Adv_cognitive_modelling_reading_wild_minds_a_computational_assay_of_theory_of_mind_sophistication_across_seven_primate_species.json_chunk_6"
  },
  {
    "document_type": "research_paper",
    "title": "Reading wild minds: A computational assay of Theory of Mind sophistication across seven primate species",
    "author": "Marie Devaine, Aurore San-Galli, Cinzia Trapanese, Giulia Bardino, Christelle Hano, Michel Saint Jalme, Sebastien Bouret, Shelly Masi, Jean Daunizeau",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Devaine_reading_wild_minds.pdf",
    "date_published": "2017-11-08",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". We now extend this approach to a coparison of non-human primate species, and ask which of the above hypotheses is the most likely explanation for the evolution of social intelligence. We let 39 individuals from seven non-human primate species with different phylogenetic distances from humans (including lemurs, macaques, mangabeys, orangutans, gorillas and chimpanzees) play simple repeated games with familiar zookeepers who followed the instrutions of (on-line) learning algorithms endowed with calibrated ToM sophistication. Fig 1 below depicts the statistical relationship between endocranial volume (ECV) and social group size (in the wild) across primate species. Critically, although ECV and social group size are corelated across the full range of primate species (r = 0.62, p < 10 −4 ; see graphical inset in Fig 1 ), the sample correlation is very weak across the seven tested species (r = -0.37, p = 0.41; see Fig 1 ). This enables us to evaluate the evidence for candidate evolutionary scenarios by identifying the ensuing statistical relationships existing between social group size, brain volume and ToM sophistication, across tested species. Note that there is an ongoing debate regarding which Theory of Mind in primates PLOS Computational Biology | https://doi.org/10.1371/journal.pcbi.1005833 November 7, 2017 3 / 24 sociobiological feature of primate species is appropriate for such type of analysis (see first setion of S1 Text ). We will comment on this and related issues in the Discussion section. Results Our main task consisted of multiple sessions of a so-called \"hide and seek\" game (60 trials each) against three distinct opponents (below). To succeed, primates had to anticipate and prdict the behaviour of their opponent, who hid a fruit in one out of two possible locations (left/ right hand) at each trial (see Fig 2 below)",
    "chunk_id": "Adv_cognitive_modelling_reading_wild_minds_a_computational_assay_of_theory_of_mind_sophistication_across_seven_primate_species.json_chunk_7"
  },
  {
    "document_type": "research_paper",
    "title": "Reading wild minds: A computational assay of Theory of Mind sophistication across seven primate species",
    "author": "Marie Devaine, Aurore San-Galli, Cinzia Trapanese, Giulia Bardino, Christelle Hano, Michel Saint Jalme, Sebastien Bouret, Shelly Masi, Jean Daunizeau",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Devaine_reading_wild_minds.pdf",
    "date_published": "2017-11-08",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". To succeed, primates had to anticipate and prdict the behaviour of their opponent, who hid a fruit in one out of two possible locations (left/ right hand) at each trial (see Fig 2 below). Opponents either followed a predetermined pseudrandom sequence with a 65% bias for one hand (condition RB ), or attempted to deceive the primates from learned anticipations of their behaviour (conditions 0-ToM and 1-ToM ). The difference between 0-ToM and 1-ToM lies in how they learn from the past history of primates’ actions. In brief, 0-ToM does not try to interpret the primates’ action sequence in terms of a strategic attempt to win. Rather, it simply assumes that abrupt changes in the primates’ behaiour are a priori unlikely. It thus tracks the evolving frequency of primates’ actions, and chooses to hide the reward where it predicts the primate will not seek. It is an extension of “fititious play” learning [ 50 ], which can exploit primates’ tendency to repeat their recent actions. Fig 1. Sociobiological features of tested non-human primates species. On this graph, the social group size (x-axis) and ECV (y-axis) are shown for each species on a log-log scale. Note that reported species’ group sizes exhibit substantial variability across ethological field studies. In this work, we have chosen to rely on the average group size from a series of more than a hundred published studies (ensuing standard deviations are depicted as horizontal bars on the graph). We refer the interested reader to S2 Text for more details. Overall, there is no significant statistical correlation between group size and ECV (r = -0.37, p = 0.41) across these species. The position of the human species is shown for comparison purposes. The graphical inset also shows the relationship between group size and ECV, this time across the 130 primate species reported in [ 91 ]. Species investigated in this work are depicted in red. https://doi.org/10.1371/journal.pcbi.1005833.g001 Fig 2. Experimental protocol showing the three basic phases of the game",
    "chunk_id": "Adv_cognitive_modelling_reading_wild_minds_a_computational_assay_of_theory_of_mind_sophistication_across_seven_primate_species.json_chunk_8"
  },
  {
    "document_type": "research_paper",
    "title": "Reading wild minds: A computational assay of Theory of Mind sophistication across seven primate species",
    "author": "Marie Devaine, Aurore San-Galli, Cinzia Trapanese, Giulia Bardino, Christelle Hano, Michel Saint Jalme, Sebastien Bouret, Shelly Masi, Jean Daunizeau",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Devaine_reading_wild_minds.pdf",
    "date_published": "2017-11-08",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Species investigated in this work are depicted in red. https://doi.org/10.1371/journal.pcbi.1005833.g001 Fig 2. Experimental protocol showing the three basic phases of the game. A : the experimenter hiding the food in one hand out of individual’s view (inside the brown paper box visible in two following pictures), B : the individual choosing one hand by pointing or touching it, C : the individual getting the food reward if choosing the correct hand. Photo credits C. Trapanese. https://doi.org/10.1371/journal.pcbi.1005833.g002 Theory of Mind in primates PLOS Computational Biology | https://doi.org/10.1371/journal.pcbi.1005833 November 7, 2017 4 / 24 In contrast, 1-ToM is equipped with (limited) artificial mentalizing, i.e. it attributes simple beliefs and desires to primates. More precisely, it assumes that primates’ actions originate from the strategic response of a 0-ToM agent that attempts to predict his own actions. Note that the computational sophistication of artificial mentalizing is not trivial, since 1-ToM has to explicitly represent and update its (recursive) belief about its opponents’ beliefs. In turn, 1-ToM learning essentially consists in an on-line estimation of 0-ToM ’s parameters (i.e.: learing rate and behavioural temperature; see Methods ) given the past history of both players’ actions. This makes 1-ToM a so-called “meta-Bayesian” agent [ 49 , 51 ] that can outwit strategic opponents that do not mentalize when competing in the game (such as 0-ToM ). Critically, prmates were not cued about opponent conditions. This implies that they had to adapt their behaviour according to their understanding of the history of past actions and outcomes. In addition, except in the control ( RB ) condition, there is no possibility to learn the correct answer from simple reinforcement. This is because 0-ToM and 1-ToM artificial learners exhibit no systematic bias in their response",
    "chunk_id": "Adv_cognitive_modelling_reading_wild_minds_a_computational_assay_of_theory_of_mind_sophistication_across_seven_primate_species.json_chunk_9"
  },
  {
    "document_type": "research_paper",
    "title": "Reading wild minds: A computational assay of Theory of Mind sophistication across seven primate species",
    "author": "Marie Devaine, Aurore San-Galli, Cinzia Trapanese, Giulia Bardino, Christelle Hano, Michel Saint Jalme, Sebastien Bouret, Shelly Masi, Jean Daunizeau",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Devaine_reading_wild_minds.pdf",
    "date_published": "2017-11-08",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". This is because 0-ToM and 1-ToM artificial learners exhibit no systematic bias in their response. Further details regarding the experimental protocol (including animal training) as well as k-ToM artificial agents can be found in the methods setion below. As we will see below, one cannot unambiguously recognize primates’ ToM sophistication from their pattern of performance across task conditions. Rather, one has to decompose action sequences and identify learning styles. Nevertheless, let us start with a simple summary of peformance results. Fig 3A below shows the net rate of correct answers (averaged across indiviuals within species), after adjustment for non-specific session effects (see Methods section). One can see that, on average, primates seem to perform reasonably well in the control codition ( RB ), which means that they have understood the basic tasks’ rules. We performed a Fig 3. Behavioural performance results. A: net rate of correct answer (y-axis) is shown as a function of species (x-axis) and opponent condition ( RB : blue, 0-ToM : green and 1-ToM : red). Errorbars depict standard error of the mean. B: condition-specific performance pattern averaged across species. C: simulated performance pattern of 0-ToM. D: simulated performance pattern of cooperative 1-ToM. E: performance pattern of human adults [ 49 ]. Graphs B to E use the same colour coding as in A. https://doi.org/10.1371/journal.pcbi.1005833.g003 Theory of Mind in primates PLOS Computational Biology | https://doi.org/10.1371/journal.pcbi.1005833 November 7, 2017 5 / 24 random-effect analysis to test for the effects of opponent’ sophistication and species onto peformance (see Methods ). At the group-level, we found a significant main effect of opponent (F [2,58] = 14.0, R 2 = 32.6%, p < 10 −4 ) and a trend for a main effect of species (F[6,58] = 2.17, R 2 = 18.3%, p = 0.06). No interaction between species and opponent was found (F[12,58] = 1.0, R 2 = 17.1%, p = 0.46)",
    "chunk_id": "Adv_cognitive_modelling_reading_wild_minds_a_computational_assay_of_theory_of_mind_sophistication_across_seven_primate_species.json_chunk_10"
  },
  {
    "document_type": "research_paper",
    "title": "Reading wild minds: A computational assay of Theory of Mind sophistication across seven primate species",
    "author": "Marie Devaine, Aurore San-Galli, Cinzia Trapanese, Giulia Bardino, Christelle Hano, Michel Saint Jalme, Sebastien Bouret, Shelly Masi, Jean Daunizeau",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Devaine_reading_wild_minds.pdf",
    "date_published": "2017-11-08",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". No interaction between species and opponent was found (F[12,58] = 1.0, R 2 = 17.1%, p = 0.46). Moreover, when further testing inter-species differences, we found that the ECV predicted overall performance (F[1,58] = 5.2, R 2 = 32.6%, p = 0.026) whereas group size did not (F[1,58] = 0.3, R 2 = 0.5%, p = 0.14). Intriguingly, the effect of ECV went in the opposite direction of what could be intuitively expected, in that having a larger brain actually yields worse performance on average. As will be clearer below, this is due to the non-trivial effect of ToM sophistication on performance in this task. This issue will be addressed later, using model-based analyses of action sequences. Now eyeballing the opponent’s effect on perfomance (see Fig 3B ) reveals the following pattern: overall, primates win in the control ( RB ) codition, whereas they tend to lose similarly against 0-ToM and 1-ToM . This strongly contrasts with the results of our previous experiment on healthy human participants [ 49 ], who win against 0-ToM and 1-ToM , most likely by relying on sophisticated mentalizing akin to compeitive 2-ToM learning (see Fig 3E ). In fact, two classes of learning styles would be qualitatively compatible with the pattern of primates’ performances across conditions. On the one hand, numerical simulations show that simple non-mentalizing learning schemes such as 0-ToM show a gradual performance decrement with opponent’s sophistication (see Fig 3C ). On the other hand, cooperative strategies based upon sophisticated mentalizing (e.g., 1-ToM or 2-ToM ) eventually win against RB and lose against 0-ToM and 1-ToM (see Fig 3D ). Thus, dicriminative evidence for or against mentalizing can only be derived from quantitative analyses of trial-by-trial choice sequences. As we will see, these are in fact much more sensitive and informative than model-free performance analyses. Our second step of analysis thus consisted of Volterra decompositions [ 52 ] of primates’ choice sequences, i.e",
    "chunk_id": "Adv_cognitive_modelling_reading_wild_minds_a_computational_assay_of_theory_of_mind_sophistication_across_seven_primate_species.json_chunk_11"
  },
  {
    "document_type": "research_paper",
    "title": "Reading wild minds: A computational assay of Theory of Mind sophistication across seven primate species",
    "author": "Marie Devaine, Aurore San-Galli, Cinzia Trapanese, Giulia Bardino, Christelle Hano, Michel Saint Jalme, Sebastien Bouret, Shelly Masi, Jean Daunizeau",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Devaine_reading_wild_minds.pdf",
    "date_published": "2017-11-08",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Our second step of analysis thus consisted of Volterra decompositions [ 52 ] of primates’ choice sequences, i.e. we looked at how much trial-by-trial variance in choice sequences can be concurrently explained by the past history of both players actions (see Methods ). This decoposition enables us to capture learning styles in terms of model-free mixtures of imitative and perseverative tendencies [ 49 ]. Fig 4 below summarizes the mean magnitudes of each species’ Volterra kernels, for all conditions. One can see that, on average, primates tend to imitate their opponents’ choices (positive impact of past opponent’s choice, A op ), which is a good strategy when playing against RB because this, on average, yields reward more often than chance. Although this is reminiscent of a \"win-stay/lose-switch\" heuristic strategy, we will see below that other learning styles may eventually exhibit this tendency. In addition, they also seem to perseverate, i.e. they tend to repeat their own past choices (positive A self on average). However, the relative magnitudes of imitative and perseverative tendencies seem to differ across species and conditions. Thus, we performed a random-effect analysis to test for the effects of opponent’ sophistication and spcies onto perseverative ( A self ) and imitative ( A op ) tendencies. We found a main effect of oppnent for A self (F[2,58] = 9.8, R 2 = 25.3%, p = 2×10 −4 ) but not for A op (F[2,58] = 2.3, R 2 = 7.3%, p = 0.1). This is important, since this is a sign of a (moderate) strategic adaptation to oppnents, such that primates persevere less against 0-ToM than in the other conditions. In addtion, we found a strong effect of species on both A self (F[6,58] = 22.0, R 2 = 69.5%, p < 10 −4 ) and A op (F[6,58] = 19.0, R 2 = 66.3%, p < 10 −4 ), and no interaction (p = 0.7 for A self and p = 0.5 for A op ). Note that, when further investigating inter-species differences, we found that both imitative and perseverative tendencies increased with EVC and network size (all p < 10 −4 )",
    "chunk_id": "Adv_cognitive_modelling_reading_wild_minds_a_computational_assay_of_theory_of_mind_sophistication_across_seven_primate_species.json_chunk_12"
  },
  {
    "document_type": "research_paper",
    "title": "Reading wild minds: A computational assay of Theory of Mind sophistication across seven primate species",
    "author": "Marie Devaine, Aurore San-Galli, Cinzia Trapanese, Giulia Bardino, Christelle Hano, Michel Saint Jalme, Sebastien Bouret, Shelly Masi, Jean Daunizeau",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Devaine_reading_wild_minds.pdf",
    "date_published": "2017-11-08",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Note that, when further investigating inter-species differences, we found that both imitative and perseverative tendencies increased with EVC and network size (all p < 10 −4 ). At this point, we asked whether the effect of species and opponent onto performance were mediated by changes in learning styles. We thus computed the correlation between the estmated Volterra kernel of each individual’s choice sequence in each condition and that of the Theory of Mind in primates PLOS Computational Biology | https://doi.org/10.1371/journal.pcbi.1005833 November 7, 2017 6 / 24 corresponding optimal learning style (namely: 0-ToM against RB , 1-ToM against 0-ToM and 2-ToM against 1-ToM ). Classical Sobel mediation tests [ 53 ] then confirmed that primates’ siilarity to optimal learning styles mediated the effect of opponent (p = 0.025), ECV (p = 4×10 −4 ) and group size (p = 5×10 −4 ) onto performance. We refer the interested reader to the Methods section for methodological details regarding Volterra analyses. These results are important, because they indicate that performance variations are likely to be driven by differences in species-specific learning styles. For example, a tendency to perseerate may signal a strategic behavioural response relying on sophisticated ToM inference, based on a cooperative interpretation of the game. Intuitively, if primates believe that the goal of the zoo keeper (the opponent) is aligned with their own (e.g., that he wants to feed them), then repeating their own choices is instrumental (it serves the purpose of achieving coordintion). Fig 5 below illustrates how different the Volterra kernels of cooperative learning styles and non-mentalizing learning styles can be. We also included a summary of the Volterra results from our previous experiment in humans, which will serve as a reference point. To begin with, note how Volterra kernels of human subjects differ from those of nohuman primate species",
    "chunk_id": "Adv_cognitive_modelling_reading_wild_minds_a_computational_assay_of_theory_of_mind_sophistication_across_seven_primate_species.json_chunk_13"
  },
  {
    "document_type": "research_paper",
    "title": "Reading wild minds: A computational assay of Theory of Mind sophistication across seven primate species",
    "author": "Marie Devaine, Aurore San-Galli, Cinzia Trapanese, Giulia Bardino, Christelle Hano, Michel Saint Jalme, Sebastien Bouret, Shelly Masi, Jean Daunizeau",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Devaine_reading_wild_minds.pdf",
    "date_published": "2017-11-08",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". To begin with, note how Volterra kernels of human subjects differ from those of nohuman primate species. Critical here is the fact that they adapt their imitative and perseverative tendencies in a quasi-optimal manner. In particular, humans correctly repress their imitative tendency when playing (unknowingly) against 1-ToM (as competitive 2-ToM learners do). No non-human primate species exhibits such adaptive flexibility. As one can see on Fig 5 , prmates’ Volterra kernels are in fact more compatible with either non-mentalizing agents (0-ToM) or cooperative agents with mild sophistication (1-ToM). More precisely, the strong and rigid imitative tendency of most primate species is similar to 0-ToM’s, while the moderate flexibility of their perseverative tendencies is rather reminiscent of cooperative 1-ToM learning (cf. U-shaped perseverative kernels across opponent conditions). Taken together, we have found strong inter-species differences in Volterra kernels, and some of these variations may be compatible with mentalizing learning styles. One cannot, however, directly interpret quantitative changes in Volterra kernels across species in terms of Fig 4. Volterra decomposition of primates’ trial-by-trial choices sequences. The magnitude of Volterra kernels (y-axis) is plotted as a function of species (x-axis) and opponent condition (same colour coding as in Fig 3 ). A: weight of the opponent’s actions (imitative tendency). B: weight of one’s own actions (perseverative tendency). https://doi.org/10.1371/journal.pcbi.1005833.g004 Theory of Mind in primates PLOS Computational Biology | https://doi.org/10.1371/journal.pcbi.1005833 November 7, 2017 7 / 24 differences in, e.g., cooperativeness or learning style. Evidence for the latter can only be derived from direct quantitative comparisons of primates’ trial-by-trial choices sequences and predictions derived from learning models",
    "chunk_id": "Adv_cognitive_modelling_reading_wild_minds_a_computational_assay_of_theory_of_mind_sophistication_across_seven_primate_species.json_chunk_14"
  },
  {
    "document_type": "research_paper",
    "title": "Reading wild minds: A computational assay of Theory of Mind sophistication across seven primate species",
    "author": "Marie Devaine, Aurore San-Galli, Cinzia Trapanese, Giulia Bardino, Christelle Hano, Michel Saint Jalme, Sebastien Bouret, Shelly Masi, Jean Daunizeau",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Devaine_reading_wild_minds.pdf",
    "date_published": "2017-11-08",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Evidence for the latter can only be derived from direct quantitative comparisons of primates’ trial-by-trial choices sequences and predictions derived from learning models. In what follows, we report the results of a statistical (Bayesian) model comparison that quantifies, for each species, the evidence in favour or against ToM-compatible learning styles, given primates’ trial-by-trial choice sequences. We considered a set of candidate learning models that differ in terms of their sophistiction, ranging from simple behavioural heuristics, to mildly sophisticated learning schemes, to ToM-based (meta-Bayesian) recursive belief update schemes. This model set first consists of a family of four different non-ToM models, namely: BN (biased Nash), WS (\"win-stay/losswitch\" heuristic), RL (reinforcement learning) and 0-ToM . In addition, we included a family of six ToM models, namely: Inf (cooperative and competitive \"influence learning\"), 1-ToM (cooperative and competitive) and 2-ToM (cooperative and competitive). Each of these computational models provides a probabilistic prediction of observed primates’ trial-by-trial choice sequences, given the past history of players’ actions and specific unknown parameters controlling e.g., biases and learning rates [ 49 ]. Note that the essential difference between ToM and non-ToM models is that only the former assume that observed responses are intentional actions. We fitted these models on primates’ trial-by-trial choice sequences and evaluated their marginal likelihood. We then derived a species-specific estimate of the probability pToM of exhibiting a ToM-compatible learning style. We refer the interested reader to the Methods setion for details regarding computational models and the ensuing statistical model comparison procedure, the result of which is summarized on Fig 6 below. We are now in a position to directly compare our two main hypotheses",
    "chunk_id": "Adv_cognitive_modelling_reading_wild_minds_a_computational_assay_of_theory_of_mind_sophistication_across_seven_primate_species.json_chunk_15"
  },
  {
    "document_type": "research_paper",
    "title": "Reading wild minds: A computational assay of Theory of Mind sophistication across seven primate species",
    "author": "Marie Devaine, Aurore San-Galli, Cinzia Trapanese, Giulia Bardino, Christelle Hano, Michel Saint Jalme, Sebastien Bouret, Shelly Masi, Jean Daunizeau",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Devaine_reading_wild_minds.pdf",
    "date_published": "2017-11-08",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". We are now in a position to directly compare our two main hypotheses. Recall that under the Machiavelian intelligence hypothesis , ToM sophistication should mostly align with social group size, whereas, under the cognitive scaffolding hypothesis , it should rather align with brain volume (ECV). We can directly test these predictions by asking whether inter-species diffeences in pToM are best predicted by either group size or brain volume. The result of this procdure is summarized on Fig 6 below. Fig 6A reports the estimated probability of exhibiting a ToM-compatible learning style (pToM). One can see that this probability varies greatly across species, ranging from Fig 5. Volterra decompositions of non-mentalizing and cooperative mentalizing artificial agents, as well as human adults [ 49 ] performing the same task. A: competitive 0-ToM, B: cooperative 1-ToM, C: human adults. Same format as Fig 4 . https://doi.org/10.1371/journal.pcbi.1005833.g005 Theory of Mind in primates PLOS Computational Biology | https://doi.org/10.1371/journal.pcbi.1005833 November 7, 2017 8 / 24 pToM = 0.25 ± 0.12 (mangabeys) to pToM = 0.81 ± 0.09 (chimpanzees). Fig 6B summarizes the statistical relationship between group size and pToM (across species). One can see that the pairwise correlation between the two variables is very weak and does not reach statistical signifcance (r = -0.22, p = 0.69). Now Fig 6C summarizes the statistical relationship between ECV and pToM. Here, there is a strong and significant pairwise correlation between the two variables (r = 0.75, p = 0.03). Note that this result remains statistically significant when accounting for the structured phylogenic relationships between these species (p = 0.04 for a one-sided test on the correlation; cf. S1 Text ). In addition, ECV is marginally better than group size at predicting inter-species variability in pToM (p = 0.07)",
    "chunk_id": "Adv_cognitive_modelling_reading_wild_minds_a_computational_assay_of_theory_of_mind_sophistication_across_seven_primate_species.json_chunk_16"
  },
  {
    "document_type": "research_paper",
    "title": "Reading wild minds: A computational assay of Theory of Mind sophistication across seven primate species",
    "author": "Marie Devaine, Aurore San-Galli, Cinzia Trapanese, Giulia Bardino, Christelle Hano, Michel Saint Jalme, Sebastien Bouret, Shelly Masi, Jean Daunizeau",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Devaine_reading_wild_minds.pdf",
    "date_published": "2017-11-08",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". S1 Text ). In addition, ECV is marginally better than group size at predicting inter-species variability in pToM (p = 0.07). These qualitative results are left unchanged if one assumes that inter-species variability in pToM results from a linear mixture of inter-species vaiability in group size and ECV. Indeed, when regressing pToM concurrently against both ECV and group size, we find that the effect of ECV is significant (t[4] = 2.18, adjusted R 2 = 54.3%, p = 0.047) whereas group size is not (t[4] = 0.28, adjusted R 2 = 2.0%, p = 0.39). This holds true even if we account for the interaction between ECV and group size (ECV: p = 0.02, group size: p = 0.45, [ECV x group size]: p = 0.13), or if we include the human species in the analysis (ECV: p = 0.02, group size: p = 0.95; assuming pToM[humans] = 1). Let us now ask which learning style (among the ten candidate models considered here) best captures choice sequences within species with either small or large brains (according to a median-split on ECV). Note that, using a between-groups Bayesian model comparison [ 54 ], we find that the posterior probability that species with large brains have evolved a more Tosophisticated learning style than species with small brains is P = 0.99. Additional details regarding this procedure can be found in S1 Text . Fig 7 below shows the estimated frequency of all learning models for each subgroup of species. Fig 6. Bayesian model comparison results. A : the average probability pToM of exhibiting a Tocompatible learning style ( ± standard error) is plotted for each species, in ascending order. The red dotted line corresponds to chance discrimination ( pToM = 0.5). Note that orangutans’ ToM sophistication reaches pToM = 0.51 ± 0.14 if we exclude one individual that shows characteristic signs of Down syndrome (see Discussion section). B: the probability of exhibiting a ToM-compatible learning style ( pToM , y-axis) is plotted as a function of group size (x-axis)",
    "chunk_id": "Adv_cognitive_modelling_reading_wild_minds_a_computational_assay_of_theory_of_mind_sophistication_across_seven_primate_species.json_chunk_17"
  },
  {
    "document_type": "research_paper",
    "title": "Reading wild minds: A computational assay of Theory of Mind sophistication across seven primate species",
    "author": "Marie Devaine, Aurore San-Galli, Cinzia Trapanese, Giulia Bardino, Christelle Hano, Michel Saint Jalme, Sebastien Bouret, Shelly Masi, Jean Daunizeau",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Devaine_reading_wild_minds.pdf",
    "date_published": "2017-11-08",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". B: the probability of exhibiting a ToM-compatible learning style ( pToM , y-axis) is plotted as a function of group size (x-axis). The red plain line indicates the best-fitting linear regression, and the red dotted lines depict the corresponding 95% confidence interval. C: the probability of exhibiting a Tocompatible learning style ( pToM , y-axis) is plotted as a function of ECV (x-axis). https://doi.org/10.1371/journal.pcbi.1005833.g006 Theory of Mind in primates PLOS Computational Biology | https://doi.org/10.1371/journal.pcbi.1005833 November 7, 2017 9 / 24 One can see that the two subgroups of species strongly differ in terms of learning styles prevlence. More precisely, the learning style that best captures choice sequences of primate species with large brains is the cooperative \"influence learning\" model (estimated frequency = 50%), whereas species with small brains seem to mostly rely on either reinforcement learning (estimated frequency = 33%) or \"win-stay/lose-switch\" strategies (estimated frequency = 28%). These results are qualitatively consistent with the previous model-free analyses, essentially because \"influence learning\" exhibit performance and Volterra patterns that are similar to those of 1-ToM . Impotantly, none of these subsets of species matches our previous estimate of human ToM sophistiction, which was dominated by 2-ToM learning styles [ 49 ]. This signals an evolutionary gap between apes and humans, given that \"influence learning\" is much less sophisticated than 2-ToM learning. We will comment on the computational distinction between \"influence learning\" and ToM learning in the discussion section below. Discussion In this work, we have performed a comparison of non-human primate species playing simple competitive games against human opponents. Using computational analyses of primates’ choices sequences, we found that inter-species differences in ToM sophistication are predicted by differences in brain volume but not by differences in social group size",
    "chunk_id": "Adv_cognitive_modelling_reading_wild_minds_a_computational_assay_of_theory_of_mind_sophistication_across_seven_primate_species.json_chunk_18"
  },
  {
    "document_type": "research_paper",
    "title": "Reading wild minds: A computational assay of Theory of Mind sophistication across seven primate species",
    "author": "Marie Devaine, Aurore San-Galli, Cinzia Trapanese, Giulia Bardino, Christelle Hano, Michel Saint Jalme, Sebastien Bouret, Shelly Masi, Jean Daunizeau",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Devaine_reading_wild_minds.pdf",
    "date_published": "2017-11-08",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Moreover, we identfied an evolutionary gap between great apes and humans, in terms of the sophistication of their respective ToM skills. Our results provide evidence against the common-sense notion that selective pressure favoured sophisticated ToM in species that lived in bigger herds. They are in line with studies showing that, e.g., the prevalence of social learning (e.g., imitative behaviours) is correlated Fig 7. Estimated frequencies of learning styles. The posterior mean of model frequency (y-axis) is shown for each learning style (x-axis), among species with large brains ( A ) and small brains ( B ). Note that the median-split on ECV actually separates apes from prosimians and monkeys, which is consistent with primates’ phylogenic relationships (see S1 Text ). The colour code indicates the type of learning style (blue: no-ToM, red: competitive ToM, violet: cooperative ToM). Errorbars indicate posterior standard deviations. For comparison purposes, chance level (10%) is indicated using black dotted lines. https://doi.org/10.1371/journal.pcbi.1005833.g007 Theory of Mind in primates PLOS Computational Biology | https://doi.org/10.1371/journal.pcbi.1005833 November 7, 2017 10 / 24 with neocortex ratio but not with social group size [ 14 ]. This immediately raises the following question: given the biological cost of brain tissue, what then endows social intelligence and, in particular, ToM sophistication, with adaptive fitness? One possibility is that, when it comes to comparing social cognitive skills, social group size is a poorly reliable proxy for the complexity of primates’ societies. This has led some authors to rather focus on field reports of, e.g., \"animal culture\", which would be operationally defined as the within-species heterogeneity of sociallacquired behaviour [ 55 ]. Alternatively, the adaptive fitness of ToM sophistication may depend in a non-trivial manner on the nature of within-species interactions",
    "chunk_id": "Adv_cognitive_modelling_reading_wild_minds_a_computational_assay_of_theory_of_mind_sophistication_across_seven_primate_species.json_chunk_19"
  },
  {
    "document_type": "research_paper",
    "title": "Reading wild minds: A computational assay of Theory of Mind sophistication across seven primate species",
    "author": "Marie Devaine, Aurore San-Galli, Cinzia Trapanese, Giulia Bardino, Christelle Hano, Michel Saint Jalme, Sebastien Bouret, Shelly Masi, Jean Daunizeau",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Devaine_reading_wild_minds.pdf",
    "date_published": "2017-11-08",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Alternatively, the adaptive fitness of ToM sophistication may depend in a non-trivial manner on the nature of within-species interactions. For example, it has been shown, using evolutionary game theory, that cooperative interactions promote ToM sophistcation to a much lesser extent than competitive interactions, essentially because less sophistcated phenotypes can benefit from the sophistication of cooperative partners [ 44 ]. Yet another perspective is that complex primate societies may endow ToM with adaptive fitness only when in conjunction with other socially-relevant skills such as, e.g., intentional communication [ 56 , 57 ], empathy [ 58 ] or reputation management [ 59 ]. None of the above suggestions actually challenge the idea that ToM has been selected because it addressed some of the specific chalenges posed by complex (primate) societies. But this neglects the fact that, in most primate species, combinations of rigid social norms and/or hierarchies with mundane though expedent heuristics have proven sufficient to solve most social challenges [ 60 – 63 ]. An intriguing alternative however, is that sophisticated ToM derived its adaptive fitness from its contribution to solving non-social challenges. For example, social skills such as ToM may enable group members to \"distribute their cognition by storing information into other minds\" [ 4 , 64 ]. Humans, in particular, have reached an unprecedented level of \"distributed cognition\", anedotally culminating in unique forms of collective memory [ 65 ]. Under this view, if equipped with the \"cognitive reservoir\" necessary to scaffold sophisticated ToM, a species can bypass the cognitive limitations of its constituent individuals. Although highly speculative, this perspetive is interesting because it explains how a moderate though critical ToM gap between apes and humans can eventually trigger the remarkable evolutionary success of the human species [ 39 ]. We will further discuss this notion on computational grounds below",
    "chunk_id": "Adv_cognitive_modelling_reading_wild_minds_a_computational_assay_of_theory_of_mind_sophistication_across_seven_primate_species.json_chunk_20"
  },
  {
    "document_type": "research_paper",
    "title": "Reading wild minds: A computational assay of Theory of Mind sophistication across seven primate species",
    "author": "Marie Devaine, Aurore San-Galli, Cinzia Trapanese, Giulia Bardino, Christelle Hano, Michel Saint Jalme, Sebastien Bouret, Shelly Masi, Jean Daunizeau",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Devaine_reading_wild_minds.pdf",
    "date_published": "2017-11-08",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". We will further discuss this notion on computational grounds below. Let us now discuss a few striking aspects of our inter-species comparison. This work coroborates the existing body of studies that provide evidence for a rudimentary form of ToM in apes, as opposed to prosimians and monkeys [ 16 , 35 , 66 ]. This is perhaps best exemplified on Fig 7 , which shows the relative frequencies of learning styles for apes and monkeys, respetively: the former learn the influence they may have on others, whereas the latter engage in some form of trial-and-error learning heuristics. Our results are in line with field studies reporting that, e.g., monkeys show some evidence of imitative behaviours, but to a much lesser extent than apes [ 67 , 68 ]. This resonates with the quote that \"apes are good psychologists—in that they are good at reading minds—whereas monkeys are good ethologists—in that they are good at reading behaviour—\" [ 69 ]. Note that one may be surprised by the relatively disapointing results of orangutans, whose estimated ToM sophistication does not quite live up to one’s expectations. This deserves a few clarifying comments. First, our estimate of orangutans’ ToM sophistication (worse than other apes but better than most monkey and prosimian spcies) may in fact be deemed quite consistent with what would be expected from their position in the primates’ phylogenic tree (see S1 Text ). Second, there is in fact very few published stuies on orangutans’ ToM, and these yield quite inconsistent results [ 30 , 70 , 71 ]. Third, we tested orangutans in different zoos. This implies that tested individuals are not coming from a single population, which increases the chance that our results are generalizable. Finally, one of the orangutans is somehow special in that she is showing characteristic signs of primates’ Down syndrome [ 72 ]. Interestingly, her pToM score is zero, which may have decreased our empirical estimate of orangutans ToM sophistication ( pToM = 0.51±0.14 if this individual is excluded)",
    "chunk_id": "Adv_cognitive_modelling_reading_wild_minds_a_computational_assay_of_theory_of_mind_sophistication_across_seven_primate_species.json_chunk_21"
  },
  {
    "document_type": "research_paper",
    "title": "Reading wild minds: A computational assay of Theory of Mind sophistication across seven primate species",
    "author": "Marie Devaine, Aurore San-Galli, Cinzia Trapanese, Giulia Bardino, Christelle Hano, Michel Saint Jalme, Sebastien Bouret, Shelly Masi, Jean Daunizeau",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Devaine_reading_wild_minds.pdf",
    "date_published": "2017-11-08",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Interestingly, her pToM score is zero, which may have decreased our empirical estimate of orangutans ToM sophistication ( pToM = 0.51±0.14 if this individual is excluded). Theory of Mind in primates PLOS Computational Biology | https://doi.org/10.1371/journal.pcbi.1005833 November 7, 2017 11 / 24 Note that the results of our analyses are left qualitatively unchanged if we exclude this indiviual from the data sample. Recall that our experiment aimed at revealing the sophistication of learning styles by observing the patterns of primates’ response to the history of choices from artificial agents endowed with calibrated ToM sophistication. We had originally designed the experiment using competitive agents mostly because it yielded the best expected discriminability between learning styles [ 44 , 49 ]. However, despite careful training sessions (see methods ), primates seem to have partly misinterpreted the human opponent’s intentions. In particular, those prmate species that display a ToM-compatible learning style behave as if they were engaging in a cooperative game. This may be seen as an unavoidable consequence of the fact that primates were playing with their usual (human) caregivers, who are feeding them on a daily basis. One may thus wonder whether this non-ecological aspect of our experimental paradigm may have influenced our analyses. For example, one may think that this may have somehow impeded on their pragmatic understanding of the task. However, primates perform well above chance level against RB , which indicates that they have at least understood the game’s contingency between their choice and the reward they get. In fact, primates also perform below chance level against 0-ToM and 1-ToM , which should count as evidence that their learning style was consistent enough to be exploited by artificial competitive agents",
    "chunk_id": "Adv_cognitive_modelling_reading_wild_minds_a_computational_assay_of_theory_of_mind_sophistication_across_seven_primate_species.json_chunk_22"
  },
  {
    "document_type": "research_paper",
    "title": "Reading wild minds: A computational assay of Theory of Mind sophistication across seven primate species",
    "author": "Marie Devaine, Aurore San-Galli, Cinzia Trapanese, Giulia Bardino, Christelle Hano, Michel Saint Jalme, Sebastien Bouret, Shelly Masi, Jean Daunizeau",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Devaine_reading_wild_minds.pdf",
    "date_published": "2017-11-08",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". On a similar line, one could argue that observed inter-species differences may be cofounded by variations in domain-general cognitive competence, which would eventually determine learning efficiency. The intuition here is that, with sufficient training, animals could eventually learn the best response to their opponent, without having to mentalize. We agree that this is in principle possible, since k-ToM artificial agents are reducible (up to about 80% accuracy) to a linear convolution of past competing players’ actions [ 49 ]. Thus, known specficities of species cognitive skills (such as, e.g., working memory or attention) could in princple make a difference. To begin with, note that our stopping criterion for the training/ habituation phase was based upon performance, i.e. all species engaged the main protocol with an identical understanding of the task (see methods section below). Now, irrespective of any potential performance improvement across session repetitions, the evidence in favour of ToM-compatible learning styles correlates negatively with performance (cf. main effect of ECV). Finally, in contrast to Volterra kernel magnitudes, we found no difference in Volterra decay rates across species. This means that the effective number of past trials that was impacing on subjects’ behavioural responses was the same for all species. In other terms, all species learned from the same amount of past remembered/attended actions and outcomes, but they differed in how they learned. Taken together, this makes domain-general cognitive comptence an unlikely confounding factor for our computational results. One may also question the robustness and/or efficiency of our computational approach. First, recall that Bayesian inference is immune to the statistical criticisms that have been raised against the use of p-values in classical inference [ 73 – 75 ]. Nevertheless, one may wonder whether our model-based Bayesian data analysis may not be somehow biased towards Tocompatible models, eventually yielding artefactual results",
    "chunk_id": "Adv_cognitive_modelling_reading_wild_minds_a_computational_assay_of_theory_of_mind_sophistication_across_seven_primate_species.json_chunk_23"
  },
  {
    "document_type": "research_paper",
    "title": "Reading wild minds: A computational assay of Theory of Mind sophistication across seven primate species",
    "author": "Marie Devaine, Aurore San-Galli, Cinzia Trapanese, Giulia Bardino, Christelle Hano, Michel Saint Jalme, Sebastien Bouret, Shelly Masi, Jean Daunizeau",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Devaine_reading_wild_minds.pdf",
    "date_published": "2017-11-08",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Nevertheless, one may wonder whether our model-based Bayesian data analysis may not be somehow biased towards Tocompatible models, eventually yielding artefactual results. This is highly unlikely however, given the differences in model comparison results for species with small and large brains (cf. S1 Text ). In brief, it is difficult to think of a statistical bias (favouring either more or less sophisticated models) that would be inconsistently expressed in two different groups of subjects. Second, one may ask how reliable our model-based results are, given the apparent complexity of the Bayesian statistical procedure. Beyond authoritative arguments, we are comitted to provide pragmatic demonstrations of our methodological rigor. First, we performed a statistical confusion analysis, which confirmed that candidate models were well identifiable under our experimental design (see S1 Text for details). This means that the potential Theory of Mind in primates PLOS Computational Biology | https://doi.org/10.1371/journal.pcbi.1005833 November 7, 2017 12 / 24 algorithmic imperfections of our statistical procedure do not compromise the interpretation of our results. Second, although less sensitive, the results of performance and Volterra analyses are consistent with our model-based conclusions (cf. Figs 4 and 5 ). This provides construct validity to our computational approach. Finally, one may argue that our sample of selected spcies is too small for drawing any definitive conclusion. We acknowledge that, in statistical terms, our sample size is arguably limited (n = 7 primate species and about 5 individuals per species). However, it is largely exceeding the standards in the field, in which data availability is a known issue [ 76 , 77 ]. Besides, it is in fact remarkable that we detect our effect of interest in the context of such small-powered study. Equipped with computational means for discriminating learning styles, we have separated learning styles that do rely on mentalizing from learning styles that do not",
    "chunk_id": "Adv_cognitive_modelling_reading_wild_minds_a_computational_assay_of_theory_of_mind_sophistication_across_seven_primate_species.json_chunk_24"
  },
  {
    "document_type": "research_paper",
    "title": "Reading wild minds: A computational assay of Theory of Mind sophistication across seven primate species",
    "author": "Marie Devaine, Aurore San-Galli, Cinzia Trapanese, Giulia Bardino, Christelle Hano, Michel Saint Jalme, Sebastien Bouret, Shelly Masi, Jean Daunizeau",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Devaine_reading_wild_minds.pdf",
    "date_published": "2017-11-08",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Equipped with computational means for discriminating learning styles, we have separated learning styles that do rely on mentalizing from learning styles that do not. This effectively induced some sophistication cut-off between those behavioural patterns that are likely to be based upon ToM and those that are not. We used this to assess the evidence in favour of a sttistical relationship between ToM sophistication and either brain volume or group size. This raises a number of related comments. First, one may ask how robust to changes in species’ sociobiological features our results really are. The relevance of such concern is at least twofold. First, we used ECV as a proxy for some measure of \"cognitive reservoir\", which ToM could eventually be scaffolded upon. Hoever, ECV also grows with \"non-cognitive\" brain mass (e.g., cerebellum, basal forebrain, etc ), which is why other measures such as relative neocortex volume have been sometimes preferred. Although the two measures are known to correlate with each other [ 14 , 78 , 79 ], cosidering relative neocortex volume instead of ECV may make a difference for, e.g., gorillas, which have a relatively small neocortex given their total brain volume. Second, field estimates of group size in the wild are notoriously debated for orangutans species, which may evolve in so-called \"fission-fusion societies\" [ 80 ]. In our context, this calls for a critical reappraisal of their semi-solitary status (see S2 Text ), eventually revising their estimated community size by one order of magnitude. Having said this, it turns out that the conclusion of our analyses does not change if we regress ToM sophistication against relative neocortex volume instead of ECV (neocortex ratio: p = 0.03, group size: p = 0.97), even if we modify orangutans’ group size estmate (neocortex ratio: p = 0.04, group size: p = 0.95). In addition, we acknowledge that other important factors may eventually determine prmates’ social cognitive skills",
    "chunk_id": "Adv_cognitive_modelling_reading_wild_minds_a_computational_assay_of_theory_of_mind_sophistication_across_seven_primate_species.json_chunk_25"
  },
  {
    "document_type": "research_paper",
    "title": "Reading wild minds: A computational assay of Theory of Mind sophistication across seven primate species",
    "author": "Marie Devaine, Aurore San-Galli, Cinzia Trapanese, Giulia Bardino, Christelle Hano, Michel Saint Jalme, Sebastien Bouret, Shelly Masi, Jean Daunizeau",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Devaine_reading_wild_minds.pdf",
    "date_published": "2017-11-08",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". In addition, we acknowledge that other important factors may eventually determine prmates’ social cognitive skills. Examples include, but are not limited to: flexibility of social hiearchies [ 81 ] or dietary constraints on foraging strategies [ 82 ]. The issue with considering such sociobiological constraints is twofold. Whether and how they complement or moderate sipler features such as ECV or group size cannot be predicted from first (evolutionary) princples [ 16 ]. In fact, this may critically depend on how they are operationally defined. More pragmatically speaking, exploring these dimensions would require testing a huge amount of species in order to compensate for likely statistical correlations between explanatory variables. Taken together, we think it is beyond the scope of the present study to commit to such an exhaustive assessment of the candidate social and biological determinants of animal cognitive skills. Second, one may challenge our computational definition of ToM, whose least sophisticated form simply cares about others’ instrumental reaction to one’s actions [ 47 ]. Recall that the algorithmic complexity of such \"influence learning\" scheme lies somewhere between that of 0-ToM and 1-ToM . Interestingly, although it is in principle possible to augment the \"influence learning\" rule with higher-order adjustment terms (cf. Eq 5 in the Methods section), this does not bring any significant behavioural change [ 49 ]. This contrasts with k-ToM learners, whose depth of recursive beliefs critically determines the expected outcome of social interactions [ 44 ]. Note that, in our previous investigation of ToM sophistication in healthy human adults, Theory of Mind in primates PLOS Computational Biology | https://doi.org/10.1371/journal.pcbi.1005833 November 7, 2017 13 / 24 we found that people mostly behave as either 1-ToM (estimated frequency = 26%) or 2-ToM (estimated frequency = 59%) meta-Bayesian agents [ 49 ]",
    "chunk_id": "Adv_cognitive_modelling_reading_wild_minds_a_computational_assay_of_theory_of_mind_sophistication_across_seven_primate_species.json_chunk_26"
  },
  {
    "document_type": "research_paper",
    "title": "Reading wild minds: A computational assay of Theory of Mind sophistication across seven primate species",
    "author": "Marie Devaine, Aurore San-Galli, Cinzia Trapanese, Giulia Bardino, Christelle Hano, Michel Saint Jalme, Sebastien Bouret, Shelly Masi, Jean Daunizeau",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Devaine_reading_wild_minds.pdf",
    "date_published": "2017-11-08",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". We found no strong evidence for such recursive ToM belief update schemes in non-human primates. This implies that metBayesian recursive belief updating schemes may be the hallmark of human social cognition. As we have discussed earlier, the lack of evidence for meta-Bayesian learning in monkeys and apes is in line with the notion of an evolutionary gap between human and non-human minds [ 39 ]. But this is not to say that apes lack anything remotely resembling ToM. This is because they behave as if they were adjusting their estimate of others’ likely responses to their own actions. Recall that this adjustment depends upon others’ covert (cooperative or competitive) intentions. Although it is beyond the grasp of such \"influence learning\" to realize that others may be using ToM themselves (in contrast to, e.g., 2-ToM ), we argue that it should be seen as a precursor form of ToM in its own right. In conclusion, although this work does not resolve the debate regarding whether ToM is a uniquely human cognitive skill, it provides an unprecedented computational insight onto the evolutionary roots of social intelligence. In particular, we provide empirical evidence against an orthodox variant of the Machiavellian intelligence hypothesis, which would state that sophisticated ToM evolved mostly as an \"on-demand\" response to complex societies. Rather, the evolution of sophisticated ToM seems to be mainly determined by neurobiological limiting factors such as the species’ \"cognitive reservoir\". Importantly also, the sophistication of nohuman primates’ ToM culminates in some form of cognitive precursor of human ToM, or proto-ToM . These results are compatible with the idea that ToM may be a byproduct of evoltionary pressure on non-social cognitive skills, which, in conjunction with rigid social norms and/or hierarchies, may otherwise be sufficient to solve most social challenges in most primate species",
    "chunk_id": "Adv_cognitive_modelling_reading_wild_minds_a_computational_assay_of_theory_of_mind_sophistication_across_seven_primate_species.json_chunk_27"
  },
  {
    "document_type": "research_paper",
    "title": "Reading wild minds: A computational assay of Theory of Mind sophistication across seven primate species",
    "author": "Marie Devaine, Aurore San-Galli, Cinzia Trapanese, Giulia Bardino, Christelle Hano, Michel Saint Jalme, Sebastien Bouret, Shelly Masi, Jean Daunizeau",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Devaine_reading_wild_minds.pdf",
    "date_published": "2017-11-08",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Methods Ethics statement Animals’ care and behavioural assessment was performed in accordance with institutional etical guidelines. Experimental methods The experiments were carried out in four different institutions: the Institut du Cerveau et de la Moelle épinière (Paris, France), the Ménagerie du Jardin des Plantes (Paris, France), the St Matin-la-Plaine zoo (France) and the Bioparco (Roma, Italy). Seven primate species were sampled as follows: N = 7 orangutans ( Pongo pygmeus ), N = 6 chimpanzees ( Pan troglodytes) , N = 5 western gorillas ( Gorilla gorilla ), N = 4 lion-tailed macaques ( Macaca silenus ), N = 5 rhesus macaques ( Macaca mulatta ), N = 9 sooty mangabeys ( Cercocebus atys lunulatus ) and N = 4 ring-tailed lemurs ( Lemurs catta ). This gives an average of about 5.7 ± 1.8 individuals per spcies. We refer the interested reader to S1 Text for additional information regarding individual characteristics (e.g., sex, age, rearing) these and species’ sociobiological features (social group size and ECV). The protocol consisted in two phases: a habituation/training and an experimental phase, which occurred right before the daily food delivery to keep animals motivated. The food reward was matched to the animal body size (e.g., one or two pieces of dried grapes or papaya) and was kept constant across the entire protocol. The experimenter (a familiar caregiver) always faced the animal in front of the cage (through which the animal could pass their hands or fingers) and positioned his two hands symmetrically (to avoid postural biases). To prevent Theory of Mind in primates PLOS Computational Biology | https://doi.org/10.1371/journal.pcbi.1005833 November 7, 2017 14 / 24 any olfactory detection of the hiding hand, the caregiver carefully rubbed both hands with the food reward before each test",
    "chunk_id": "Adv_cognitive_modelling_reading_wild_minds_a_computational_assay_of_theory_of_mind_sophistication_across_seven_primate_species.json_chunk_28"
  },
  {
    "document_type": "research_paper",
    "title": "Reading wild minds: A computational assay of Theory of Mind sophistication across seven primate species",
    "author": "Marie Devaine, Aurore San-Galli, Cinzia Trapanese, Giulia Bardino, Christelle Hano, Michel Saint Jalme, Sebastien Bouret, Shelly Masi, Jean Daunizeau",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Devaine_reading_wild_minds.pdf",
    "date_published": "2017-11-08",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". The habituation phase was introduced to teach the animal that the reward was hidden in one hand only (before their choice), that a trial begins by the presentation of the caregiver’s closed hands, and that it would obtain the content of the hand it would touch or point at. It consisted of two distinct steps. In the first step, the caregiver placed the food reward in one hand and a small stone in the other. Then, he presented both open hands to the animal, such that both contents were clearly visible. The animal received the food only when it touched or clearly pointed uniquely the hand containing the reward. Rewarded side was counterbalanced across trials according to a pseudorandom sequence. This first step was considered successful once the animal reached 10 consecutive correct answers. The second step consisted of a series of three sequences of five trials each: (i) the caregiver first showed both open hands (while attended by the animal) but then closed the non-rewarded hand, (ii) he first showed both open hands and then closed the rewarded hand, and (iii) he first showed both open hands and then closed both hands. In all cases, the individual had to choose the correct hand to obtain the reward. The second step was considered successful once the individual made no error through the entire set of trials (if unsuccessful, the three steps were repeated). The proper experimental phase began after successful habituation/training, and was grouped into 4x3 = 12 daily sessions of 60 trials each. The order of the three game conditions ( RB , 0-ToM or 1-ToM ) were counterbalanced across the 12 sessions, but each game condition was performed by a specific caregiver (counterbalanced across subjects). All sessions were video-recorded. If a daily session was interrupted for more than 10 minutes (because of, e.g., frustration or attentional distraction), the session was terminated and possibly restarted on another day. Only sessions longer than 20 trials were included in the final analysis",
    "chunk_id": "Adv_cognitive_modelling_reading_wild_minds_a_computational_assay_of_theory_of_mind_sophistication_across_seven_primate_species.json_chunk_29"
  },
  {
    "document_type": "research_paper",
    "title": "Reading wild minds: A computational assay of Theory of Mind sophistication across seven primate species",
    "author": "Marie Devaine, Aurore San-Galli, Cinzia Trapanese, Giulia Bardino, Christelle Hano, Michel Saint Jalme, Sebastien Bouret, Shelly Masi, Jean Daunizeau",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Devaine_reading_wild_minds.pdf",
    "date_published": "2017-11-08",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Only sessions longer than 20 trials were included in the final analysis. At each trial, the caregiver presented his two hands closed after having hidden the food reward and the stone out of the animal’s sight. If the animal chose the correct hand, he was allowed to take and eat the food reward. Otherwise, the caregiver acted as if he was eating the food while exagerating chewing, vocalizing pleasure and staring at the animal. The reward location was instructed by the algorithm corresponding to the game condition ( RB , 0-ToM or 1-ToM ). This required the presence of a co-experimenter who entered the individual’s response into a laptop computer at each trial, enabling the model to compute on-line the reward location at the next trial. Computational modelling of learning styles In this section, we give a brief overview of the set of candidate learning models, with a particlar emphasis on k-ToM models (because these are also used as on-line algorithms during the experimental phase). We will consider repeated dyadic (two-players) games, in which only two actions are available for each player (the animal and the caregiver). Hereafter, the action of a given agent (resp., his opponent) is denoted by a self (resp., a op ). A game is defined in terms of its payoff table, whose entries are the player-specific utility U ( a self , a op ) of any combination of players’ actions at each trial. In particular, competitive (resp., cooperative) social interactions simply reduce to anti-symmetric (resp. symmetric) players’ payoff tables (see tables S3 and S4 in S1 Text ). By convention, actions a op and a self take binary values encoding the first ( a = 1) and the seond ( a = 0) available options. According to Bayesian decision theory, agents aim at maximising expected payoff V = E [ U ( a self , a op )], where the expectation is defined in relation to the agent’s uncertain predictions about his opponent’s next move",
    "chunk_id": "Adv_cognitive_modelling_reading_wild_minds_a_computational_assay_of_theory_of_mind_sophistication_across_seven_primate_species.json_chunk_30"
  },
  {
    "document_type": "research_paper",
    "title": "Reading wild minds: A computational assay of Theory of Mind sophistication across seven primate species",
    "author": "Marie Devaine, Aurore San-Galli, Cinzia Trapanese, Giulia Bardino, Christelle Hano, Michel Saint Jalme, Sebastien Bouret, Shelly Masi, Jean Daunizeau",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Devaine_reading_wild_minds.pdf",
    "date_published": "2017-11-08",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". This implies that the form of the decsion policy is the same for all agents, irrespective of their ToM sophistication. Here, we Theory of Mind in primates PLOS Computational Biology | https://doi.org/10.1371/journal.pcbi.1005833 November 7, 2017 15 / 24 consider that choices may exhibit small deviations from the rational decision rule, i.e. we assume agents employ the so-called \"softmax\" probabilistic policy: P ð a self 1⁄4 1 Þ 1⁄4 1 1 þ exp D V b ð 1 Þ where P ( a self = 1) is the probability that the agent chooses the action a self = 1, Δ V is the expected payoff difference (between actions a self = 1 and a self = 0), and β is the so-called behavioural \"temperature\" (which controls the magnitude of deviations from rationality). The sigmoidal form of Eq 1 simply says that the probability of choosing the action a self = 1 increases with the expected payoff difference Δ V , which is given by: D V 1⁄4 p op ð U ð 1 ; 1 Þ U ð 0 ; 1 ÞÞ þ ð 1 p op Þð U ð 1 ; 0 Þ U ð 0 ; 0 ÞÞ ð 2 Þ where p op is the probability that the opponent will choose the action a op = 1. This prediction is critical, in that it provides the agent with prospective action values. For example, if one believes that the opponent is likely to pick action a op = 1 (i.e. if p op 1), then the expected payoff reduces to Δ V = U (1,1)− U (0,1), which directly determine the incentive towards choosing either a self = 1 or a self = 0. In our context, animals are rewarded for choosing the hand in which the caregiver has hidden the food reward, which is simply written as: U (1,1)− U (0,1) = U (0,0) − U (1,0) = 1 ) Δ V = 2 p op −1. Let us first disclose the intuition behind k-ToM models, which essentially differ in how they estimate p op . We refer the interested reader to S1 Text for a more detailed mathematical description. In brief, the repeated observation of his opponent’s behaviour ( a op ) gives the agent the opportunity to learn his opponent’s behavioural tendency p op",
    "chunk_id": "Adv_cognitive_modelling_reading_wild_minds_a_computational_assay_of_theory_of_mind_sophistication_across_seven_primate_species.json_chunk_31"
  },
  {
    "document_type": "research_paper",
    "title": "Reading wild minds: A computational assay of Theory of Mind sophistication across seven primate species",
    "author": "Marie Devaine, Aurore San-Galli, Cinzia Trapanese, Giulia Bardino, Christelle Hano, Michel Saint Jalme, Sebastien Bouret, Shelly Masi, Jean Daunizeau",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Devaine_reading_wild_minds.pdf",
    "date_published": "2017-11-08",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". In brief, the repeated observation of his opponent’s behaviour ( a op ) gives the agent the opportunity to learn his opponent’s behavioural tendency p op . Theory of Mind comes into play when agents consider that p op is driven by the opponent’s hidden beliefs and desires. More precisely, k-ToM agents consider that the opponent is himself a Bayesian agent, whose decision policy p op = P ( a op = 1) is formally similar to Eq 1 . In this situation, k-ToM agents have to track their opponent’s prediction p self about their own actions. In line with [ 42 ], this metBayesian inference is based upon recursive belief updating (\"I believe that you believe that I believe \"). The recursion depth k induces distinct ToM sophistication levels, which differ in how they update their subjective prediction p op , hence k-ToM . More formally, k-ToM learning agents are defined recursively, starting with 0-ToM . By convention, a 0-ToM agent does not attribute mental states to his opponent, but rather tracks his overt behavioural tendency without mentalizing. More precisely, 0-ToM agents siply assume that their opponents choose the action a op = 1 with probability p op = s ( x t ), where the log-odds x t varies across trials t with a certain volatility σ 0 (and s is the sigmoid function). Observing his opponent’s choices gives 0-ToM information about the hidden state x , which can be updated trial after trial using Bayes rule, as follows: m 0 t m 0 t 1 þ S 0 t ð a op t s ð m 0 t 1 ÞÞ S 0 t 1 1 S 0 t 1 þ s 0 þ s ð m 0 t 1 Þð 1 s ð m 0 t 1 ÞÞ ð 3 Þ where m 0 t (resp. S 0 t ) is the approximate mean (resp. variance) of 0-ToM ’s posterior distribution p ð x 0 t j a op 1: t Þ . Inserting ^ p op t þ 1 1⁄4 E 1⁄2 s ð x t þ 1 Þj a op 1: t into Eq 1 now yields 0-ToM ’s decision rule. Here, the effective learning rate is the subjective uncertainty ∑ 0 , which is controlled by the volatility σ 0",
    "chunk_id": "Adv_cognitive_modelling_reading_wild_minds_a_computational_assay_of_theory_of_mind_sophistication_across_seven_primate_species.json_chunk_32"
  },
  {
    "document_type": "research_paper",
    "title": "Reading wild minds: A computational assay of Theory of Mind sophistication across seven primate species",
    "author": "Marie Devaine, Aurore San-Galli, Cinzia Trapanese, Giulia Bardino, Christelle Hano, Michel Saint Jalme, Sebastien Bouret, Shelly Masi, Jean Daunizeau",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Devaine_reading_wild_minds.pdf",
    "date_published": "2017-11-08",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Here, the effective learning rate is the subjective uncertainty ∑ 0 , which is controlled by the volatility σ 0 . At the limit σ 0 ! 0, Eq 3 converges towards the (stationary) opponent’s choice frequency and 0-ToM essentially reproduce \"fictitious play\" strategies [ 50 , 83 ]. Theory of Mind in primates PLOS Computational Biology | https://doi.org/10.1371/journal.pcbi.1005833 November 7, 2017 16 / 24 0-ToM ’s learning rule is the starting point for a 1-ToM agent, who considers that she is faing a 0-ToM agent. This means that 1-ToM has to predict 0-ToM ’s next move, given his beliefs and the choices’ payoffs. The issue here is that 0-ToM ’s parameters (volatility σ 0 and explortion temperature β ) are unknown to 1-ToM and have to be learned, through their non-trivial effect on 0-ToM' s choices. At trial t + 1, a 1-ToM agent predicts that 0-ToM will chose the action a op = 1 with probability p op ; 0 t þ 1 1⁄4 s v 0 ð x 0 t ; a ! t Þ , where the hidden states x 0 t lumps σ 0 and β together and the mapping v 0 is derived from inserting 0- ToM’s learning rule ( Eq 3 ) into Eqs 1 and 2 . Similarly to 0-ToM agents, 1-ToM assumes that the hidden states x 0 t vary across trials with a certain volatility σ 1 , which yields a meta-Bayesian learning rule similar in form to 0-ToM ’s, but relying on first-order meta-beliefs (i.e. beliefs about beliefs). In brief, 1-ToM eventually learns how her ( 0-ToM ) opponent learns about herself, and acts accordingly (cf. Eqs 1 and 2 ). 1-ToM agents are well equipped to deal with situations of observational learning. However, when it comes to reciprocal social interactions, one may benefit from considering that others are also using ToM. This calls for learning styles that rely upon higher-order meta-beliefs. By construction, k-ToM agents ( k 2) consider that their opponent is a κ -ToM agent with a lower ToM sophistication level (i.e.: κ < k )",
    "chunk_id": "Adv_cognitive_modelling_reading_wild_minds_a_computational_assay_of_theory_of_mind_sophistication_across_seven_primate_species.json_chunk_33"
  },
  {
    "document_type": "research_paper",
    "title": "Reading wild minds: A computational assay of Theory of Mind sophistication across seven primate species",
    "author": "Marie Devaine, Aurore San-Galli, Cinzia Trapanese, Giulia Bardino, Christelle Hano, Michel Saint Jalme, Sebastien Bouret, Shelly Masi, Jean Daunizeau",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Devaine_reading_wild_minds.pdf",
    "date_published": "2017-11-08",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". By construction, k-ToM agents ( k 2) consider that their opponent is a κ -ToM agent with a lower ToM sophistication level (i.e.: κ < k ). Importantly, the sophistication level κ of k-ToM ’s opponent has to be learned, in addition to the hidden states x κ that control the opponent’s learning and decision making. The difficulty for a k-ToM agent is that she needs to consider different scenarios: each of her opponent’s possible sophistication level κ yields a specific proability p op ; k t þ 1 1⁄4 s v k ð x k t ; a ! t Þ that she will choose action a op = 1. The ensuing meta-Bayesian learning rule entails updating k-ToM ’s uncertain belief about her opponent’s sophistication level κ and hidden states x κ : l k ; k t l k ; k t 1 p op ; k t X k 0 < k l k ; k 0 t 1 p op ; k 0 t 2 664 3 775 a op t l k ; k t 1 ð 1 p op ; k t Þ X k 0 < k l k ; k 0 t 1 ð 1 p op ; k 0 t Þ 2 664 3 775 1 a op t m k ; k t m k ; k t 1 þ l k t S k ; k t W k t 1 ð a op t s v k ð m k ; k t 1 ÞÞ P k ; k t 1⁄2ð P k ; k t 1 þ s k Þ 1 þ s 0 v k ð m k ; k t 1 Þ l k t W k t 1 T W k t 1 1 ð 4 Þ where l k ; k t is k-ToM ’s posterior probability that her opponent is κ - ToM , and W κ is the gradient of v κ with respect to the hidden states x κ . Note that although the dimensionality of k-ToM ’s beliefs increases with k , k-ToM models do not differ in terms of the number of their free parameters. More precisely, k-ToM ’s learning and decision rules are entirely specified by their prior volatility σ k and behavioural temperature β . Finally, the only difference between \"compeitive\" and \"cooperative\" k-ToM learners lies in the specification of the utility table U ( a self , a op ). Although it is held constant across trials, it can induce profound changes in the effective learing style of k-ToM agents [ 44 , 49 ]. We refer the interested reader to the S1 Text for mathematcal details regarding k-ToM learning models. Critically, only k-ToM agents with k 1 are learning about others’ covert mental states (by updating meta-beliefs)",
    "chunk_id": "Adv_cognitive_modelling_reading_wild_minds_a_computational_assay_of_theory_of_mind_sophistication_across_seven_primate_species.json_chunk_34"
  },
  {
    "document_type": "research_paper",
    "title": "Reading wild minds: A computational assay of Theory of Mind sophistication across seven primate species",
    "author": "Marie Devaine, Aurore San-Galli, Cinzia Trapanese, Giulia Bardino, Christelle Hano, Michel Saint Jalme, Sebastien Bouret, Shelly Masi, Jean Daunizeau",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Devaine_reading_wild_minds.pdf",
    "date_published": "2017-11-08",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Critically, only k-ToM agents with k 1 are learning about others’ covert mental states (by updating meta-beliefs). This would suggest a clear sophistication cut-off for discriminating ToM and no-ToM learning styles. But in fact, we will also consider a hybrid (non Bayesian) model that somehow lies in between 0-ToM and 1-ToM , and still qualifies for ToM. We refer the interested reader to [ 47 ] for a mathematical derivation of the \"influence learning\" model. In brief, it is essentially a 0-ToM learner that heuristically adjusts his learning rule to account Theory of Mind in primates PLOS Computational Biology | https://doi.org/10.1371/journal.pcbi.1005833 November 7, 2017 17 / 24 for how her own actions influence her opponent’s strategy: p op t þ 1 1⁄4 p op t þ Z ð a op t p op t Þ |fflfflfflfflfflffl{zfflfflfflfflfflffl} prediction error l p op t ð 1 p op t Þð 2 a self t þ ð 2 I comp 1 Þ b s 1 ð p op t Þ þ I comp Þ |fflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflffl{zfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflffl} influence adjustment term ð 5 Þ where η (resp. λ ) controls the relative weight of its prediction error (resp. the “influence” adjustment term), and I comp is a binary indicator variable for the type of social interaction (competition: I comp = 1, cooperation: I comp = 0). In contrast to 1-ToM , this learning rule bypasses any form of recursive belief update. However, Inf explicitly depends upon the other player’s covert (competitive or cooperative) intention, which is beyond the grasp of 0-ToM . In analogy with k-ToM models, it is in principle possible to augment Eq 5 with higher-order adjustment terms. This, however, has little effect on the way the algorithm learns [ 49 ]. In addtion, numerical simulations show that, in a competitive game setting, Inf wins over 0-ToM but loses against 1-ToM",
    "chunk_id": "Adv_cognitive_modelling_reading_wild_minds_a_computational_assay_of_theory_of_mind_sophistication_across_seven_primate_species.json_chunk_35"
  },
  {
    "document_type": "research_paper",
    "title": "Reading wild minds: A computational assay of Theory of Mind sophistication across seven primate species",
    "author": "Marie Devaine, Aurore San-Galli, Cinzia Trapanese, Giulia Bardino, Christelle Hano, Michel Saint Jalme, Sebastien Bouret, Shelly Masi, Jean Daunizeau",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Devaine_reading_wild_minds.pdf",
    "date_published": "2017-11-08",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". This, however, has little effect on the way the algorithm learns [ 49 ]. In addtion, numerical simulations show that, in a competitive game setting, Inf wins over 0-ToM but loses against 1-ToM . This is why, altogether, we think of \"influence learning\" as some form of proto-ToM. With the exception of 0-ToM , we so far only described sophisticated learning models that are capable of (artificial) ToM. But even 0-ToM can be considered too sophisticated for some primate species. In the aim of assessing the evidence for ToM sophistication (from primates’ choice sequences), we thus have to benchmark the above models against simpler learning styles that involve even fewer cognitive resources. We will describe three of these \"unsophistcated\" learning models below. First, animals may learn by trial and error, eventually reinforcing the actions that led to a reward. Such learning style is the essence of classical conditioning, which is typically moelled using reinforcement learning or RL [ 84 ]. In this perspective, animals would directly learn the value of alternative actions, which bypasses Eq 2 . More precisely, an RL agent would update the value of the chosen option in proportion to the reward prediction error, as follows: V i t þ 1 1⁄4 V i t þ a ð R t V i t Þ if action a self t 1⁄4 i was chosen V i t þ 1 1⁄4 V i t otherwise ð 6 Þ ( where R t 1⁄4 U ð a self t ; a op t Þ is the last reward outcome and α is the (unknown) learning rate. At the time of choice, animals simply tend to pick the most valuable option (cf. Eq 1 ). Second, an even simpler way of adapting one’s behaviour in operant contexts such as this one is to repeat one’s last choice if it was successful and alternate otherwise. This can be moeled by the following update in action values: V i t þ 1 1⁄4 R t action a self t 1⁄4 i was chosen V i t þ 1 1⁄4 R t otherwise ð 7 Þ ( This strategy is called win-stay/lose-switch ( WS ), and is almost identical to the above RL model when the learning rate is α = 1",
    "chunk_id": "Adv_cognitive_modelling_reading_wild_minds_a_computational_assay_of_theory_of_mind_sophistication_across_seven_primate_species.json_chunk_36"
  },
  {
    "document_type": "research_paper",
    "title": "Reading wild minds: A computational assay of Theory of Mind sophistication across seven primate species",
    "author": "Marie Devaine, Aurore San-Galli, Cinzia Trapanese, Giulia Bardino, Christelle Hano, Michel Saint Jalme, Sebastien Bouret, Shelly Masi, Jean Daunizeau",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Devaine_reading_wild_minds.pdf",
    "date_published": "2017-11-08",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Despite its simplicity, WS can be shown to have remarable adaptive properties [ 85 ]. Last, the agent may simply act randomly, which can be modeled by fixing the value diffeence to zero ( Δ V = 0). Although embarrassingly simple, this probabilistic policy eventually prvents one’s opponent from controlling one’s expected earnings. It thus minimizes the risk of being exploited at the cost of providing chance-level expected earnings. It is the so-called \"Nash equilibrium\" of our \"hide and seek\" game [ 86 ]. Since we augment this chance model Theory of Mind in primates PLOS Computational Biology | https://doi.org/10.1371/journal.pcbi.1005833 November 7, 2017 18 / 24 with a potential bias for one of the two alternative options (as all the above learning models), we refer to it as biased Nash or BN . Statistical data analyses Our statistical data analysis proceeds in three steps of increasing specificity, namely: multiple regression of behavioural performances, Volterra decompositions of trial-by-trial choice sequences and Bayesian model comparison. All statistical analyses were performed using the VBA toolbox [ 87 ]. First, let us summarize our random-effect analysis of performance. As a preliminary stage, we regressed out the effect of session repetition and time elapsed since the last experimental session from measured individual performances. We then reported the adjusted individual performance scores per opponent at the group level. We regressed performance against the effect of species, opponent (conditions RB , 0-ToM and 1-ToM ), and their interaction. In addtion to subject-specific intercepts, we also included the interactions of the opponent effect with age (normalized by species-specific life time expectancy in the wild), sex and rearing (wild vs captivity). In turn, statistical tests for effects of species and opponent assess significance above and beyond these potential inter-individual differences. The specific effects of ECV and group size were tested using weighted linear contrasts",
    "chunk_id": "Adv_cognitive_modelling_reading_wild_minds_a_computational_assay_of_theory_of_mind_sophistication_across_seven_primate_species.json_chunk_37"
  },
  {
    "document_type": "research_paper",
    "title": "Reading wild minds: A computational assay of Theory of Mind sophistication across seven primate species",
    "author": "Marie Devaine, Aurore San-Galli, Cinzia Trapanese, Giulia Bardino, Christelle Hano, Michel Saint Jalme, Sebastien Bouret, Shelly Masi, Jean Daunizeau",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Devaine_reading_wild_minds.pdf",
    "date_published": "2017-11-08",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". The specific effects of ECV and group size were tested using weighted linear contrasts. Second, we performed Volterra decompositions of trial-by-trial choice sequences using sesion-specific Bayesian logistic regressions, as follows: p ð a self j o Þ 1⁄4 Y t q t ð o Þ a self t ð 1 q t ð o ÞÞ 1 a self t q t ð o Þ 1⁄4 s o 0 þ X t o op t 2 a op t t 1 þ X t o self t 2 a self t t 1 ð 8 Þ where q t ð o Þ 1⁄4 p ð a self t 1⁄4 1 j o Þ is the probability that the agent chooses the first option at trial t , τ is some arbitrary time lag and ω is the so-called Volterra kernel ( ω 0 is a potential bias for one of the alternative options). Volterra kernels ω op (resp. ω s elf ) capture the impact of lagged oppnent’s (resp. own) actions a op (resp. a self ) onto primates’ choice probability. For the sake of effciency, we further reduce the Volterra kernels to parameterized exponential mappings, i.e.: ω τ = A exp(− λ τ ), where A (resp. λ ) is the kernel’s magnitude (resp. temporal decay). For each individual and each session, we fit the resulting model and report the kernels’ magnitudes A op and A self at the group level. The ensuing random-effect analyses are identical to the above peformance scores. Third, we performed statistical (Bayesian) model comparisons. For each subject, we fitted the above ten learning models on trial-by-trial action sequences using a variational-Laplace approach [ 88 , 89 ]. Different sessions of the same opponent condition were pooled together, allowing us to constrain the model parameters to be identical across sessions (but not across opponents). Eventually, we obtained 10x35 = 350 model evidences (10 models and 35 indiviuals; the 3 opponent conditions were lumped together for model inversions). These model evdences were partitioned into ToM ( 1-ToM , 2-ToM and Inf ) and no-ToM (all other models) families, to obtain within-subject posterior probabilities pToM of exhibiting a ToM-compatble learning style",
    "chunk_id": "Adv_cognitive_modelling_reading_wild_minds_a_computational_assay_of_theory_of_mind_sophistication_across_seven_primate_species.json_chunk_38"
  },
  {
    "document_type": "research_paper",
    "title": "Reading wild minds: A computational assay of Theory of Mind sophistication across seven primate species",
    "author": "Marie Devaine, Aurore San-Galli, Cinzia Trapanese, Giulia Bardino, Christelle Hano, Michel Saint Jalme, Sebastien Bouret, Shelly Masi, Jean Daunizeau",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Devaine_reading_wild_minds.pdf",
    "date_published": "2017-11-08",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". These scores were then averaged across individuals within species to yield the variable pToM , for further analyses (see Fig 5 ). In addition, we performed a group-level random-effect Bayesian model comparison [ 54 , 90 ]. In particular, this analysis enabled us to estimate the frequency profiles of learning models within species with high versus low ECV. We refer the interested reader to S1 Text for additional statistical details regarding the Bayeian model comparison. Theory of Mind in primates PLOS Computational Biology | https://doi.org/10.1371/journal.pcbi.1005833 November 7, 2017 19 / 24 Supporting information S1 Text. This document contains additional details regarding methods (species’ feature variables, k-ToM learning model, control task, Bayesian model comparison, phylogenic analyses) and additional results (performance, Volterra analyses, fit accuracy of learning models, confusion analyses for model comparison). (DOCX) S2 Text. This document contains a table summarizing all reported species’ group size data as well as the list of all corresponding source references. (DOCX) Acknowledgments We thank the Bioparco di Roma, the zoo of Saint Martin La Plaine, the ICM and the Me ́naerie du Jardin des Plantes for allowing us to pursue our research on their animals. Particularly, we thank the scientific directors, Fulvio Fraticelli, Michel Saint-Jalme, Pierre and Eliane Thivilon, and Yitzhak Yadid as well as Pilar Di Cerbo for their logistic support. We also thank all zoo keepers who tested the different individuals, at Bioparco: Fabio Ferretti, Sara Scire, Maria Ravagli, Benedetta Pellegrini, Monica Cianfrini, Ilaria Alvino; at Saint Martin La Plaine Espace Zoologique: Romain, Corentin Surmont, Lois Roger-Bocabarteille, Vincent Gauffreau, Nicolas Picouet, Blaise Morel, Jean Michelle Caillaud; at the Menagerie ́ du Jardin de Plantes: Christelle Hano, Annabelle Jamard, Christophe, Valerie ́. Author Contributions Conceptualization: Marie Devaine, Sebastien Bouret, Shelly Masi, Jean Daunizeau",
    "chunk_id": "Adv_cognitive_modelling_reading_wild_minds_a_computational_assay_of_theory_of_mind_sophistication_across_seven_primate_species.json_chunk_39"
  },
  {
    "document_type": "research_paper",
    "title": "Reading wild minds: A computational assay of Theory of Mind sophistication across seven primate species",
    "author": "Marie Devaine, Aurore San-Galli, Cinzia Trapanese, Giulia Bardino, Christelle Hano, Michel Saint Jalme, Sebastien Bouret, Shelly Masi, Jean Daunizeau",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Devaine_reading_wild_minds.pdf",
    "date_published": "2017-11-08",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Author Contributions Conceptualization: Marie Devaine, Sebastien Bouret, Shelly Masi, Jean Daunizeau. Data curation: Marie Devaine, Aurore San-Galli, Cinzia Trapanese, Giulia Bardino, Christelle Hano, Sebastien Bouret. Formal analysis: Shelly Masi, Jean Daunizeau. Funding acquisition: Shelly Masi, Jean Daunizeau. Investigation: Marie Devaine, Aurore San-Galli, Cinzia Trapanese, Giulia Bardino, Christelle Hano, Michel Saint Jalme, Sebastien Bouret. Methodology: Marie Devaine, Jean Daunizeau. Project administration: Jean Daunizeau. Resources: Shelly Masi, Jean Daunizeau. Software: Marie Devaine. Supervision: Shelly Masi, Jean Daunizeau. Validation: Jean Daunizeau. Visualization: Marie Devaine. Writing – original draft: Marie Devaine, Shelly Masi, Jean Daunizeau. Writing – review & editing: Shelly Masi, Jean Daunizeau.",
    "chunk_id": "Adv_cognitive_modelling_reading_wild_minds_a_computational_assay_of_theory_of_mind_sophistication_across_seven_primate_species.json_chunk_40"
  },
  {
    "document_type": "online_article",
    "title": "Introduction to Bayesian Data Analysis for Cognitive Science",
    "author": "Bruno Nicenboim",
    "source": "https://bruno.nicenboim.me/bayescogsci/ch-mixture.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": "Mixture models integrate multiple data generating processes into a single model. This is especially useful in cases where the data alone don’t allow us to fully identify which observations belong to which process. Mixture models are important in cognitive science because many theories of cognition assume that the behavior of subjects in certain tasks is determined by an interplay of different cognitive processes(e.g., response times in schizophrenia in Levy et al.1993; retrieval from memory in sentence processing in McElree2000; Nicenboim and Vasishth2018; fast choices in Ollman1966; Dutilh et al.2011; generalized processing tree models in Heck, Erdfelder, and Kieslich2018). It is important to stress that a mixture distribution of observations is anassumptionof the latent process developing trial by trial based on a given theory—it doesn’t necessarily represent the true generative process. The role of Bayesian modeling is to help us understand the extent to which this assumption is well-founded, by using posterior predictive checks and by comparing different models. We focus here on the case where we have only two components; each component represents a distinct cognitive process based on the domain knowledge of the researcher. The vector\\(\\mathbf{z}\\)serves as a latentindicator variablethat indicates which of the mixture components an observation\\(y_n\\)belongs to (\\(n=1,\\dots,N\\)is the number of data points). We assume two components, and thus each\\(z_n\\)can be either\\(0\\)or\\(1\\)(this will allows us to generate\\(z_n\\)with a Bernoulli distribution). We also assume two different generative processes,\\(p_1\\)and\\(p_2\\), which generate different distributions of the observations based on a vector of parameters indicated by\\(\\Theta_{1}\\)and\\(\\Theta_{2}\\), respectively",
    "chunk_id": "Adv_cognitive_modelling_introduction_to_bayesian_data_analysis_for_cognitive_science_d478409d.json_chunk_1"
  },
  {
    "document_type": "online_article",
    "title": "Introduction to Bayesian Data Analysis for Cognitive Science",
    "author": "Bruno Nicenboim",
    "source": "https://bruno.nicenboim.me/bayescogsci/ch-mixture.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". These two processes occur with probability\\(\\theta\\)and\\(1-\\theta\\), and each observation is generated as follows: \\[\\begin{equation} \\begin{aligned} z_n \\sim \\mathit{Bernoulli}(\\theta)\\\\ y_n \\sim \\begin{cases} p_1(\\Theta_1), & \\text{ if } z_n =1 \\\\ p_2(\\Theta_2), & \\text{ if } z_n=0 \\end{cases} \\end{aligned} \\tag{17.1} \\end{equation}\\] We focus on only two components because this type of model is already hard to fit and, as we show in this chapter, it requires plenty of prior information to be able to sample from the posterior in most applied situations. However, the approach presented here can in principle be extended to a larger number of mixtures by replacing the Bernoulli distribution with a categorical one. This can be done if the number of components in the mixture is finite; the number of components is determined by the researcher. In order to fit this model, we need to estimate the posterior of each of the parameters contained in the vectors\\(\\Theta_{1}\\)and\\(\\Theta_{2}\\)(intercepts, slopes, group-level effects, etc.), the probability\\(\\theta\\), and the indicator variable that corresponds to each observation\\(z_n\\). One issue that presents itself here is that\\(z_n\\)must be a discrete parameter, and Stan only allows continuous parameters. This is because Stan’s algorithm requires the derivatives of the (log) posterior distribution with respect to all parameters, and discrete parameters are not differentiable (since they have “breaks”). In probabilistic programming languages like WinBUGS(Lunn et al.2012), JAGS(Plummer2016), PyMC3(Salvatier, Wiecki, and Fonnesbeck2016)and Turing(Ge, Xu, and Ghahramani2018), discrete parameters are possible to use; but not in Stan",
    "chunk_id": "Adv_cognitive_modelling_introduction_to_bayesian_data_analysis_for_cognitive_science_d478409d.json_chunk_2"
  },
  {
    "document_type": "online_article",
    "title": "Introduction to Bayesian Data Analysis for Cognitive Science",
    "author": "Bruno Nicenboim",
    "source": "https://bruno.nicenboim.me/bayescogsci/ch-mixture.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". In Stan, we can circumvent this issue by marginalizing out the indicator variable\\(z\\).58If\\(p_1\\)appears in the mixture with probability\\(\\theta\\), and\\(p_2\\)with probability\\(1-\\theta\\), then the joint likelihood is defined as a function of\\(\\Theta\\)(which concatenates the mixing probability,\\(\\theta\\), and the parameters of the\\(p_{1}\\)and\\(p_{2}\\),\\(\\Theta_1\\)and\\(\\Theta_2\\)), and importantly\\(z_n\\)“disappears”: \\[\\begin{equation} p(y_n | \\Theta) = \\theta \\cdot p_1(y_n| \\Theta_1) + (1-\\theta) \\cdot p_2(y_n | \\Theta_2) \\end{equation}\\] The intuition behind this formula is that each likelihood function,\\(p_1\\),\\(p_2\\)is weighted by its probability of being the relevant generative process. For our purposes, it suffices to say that marginalization works; the reader interested in the mathematics behind marginalization is directed to the further reading section at the end of the chapter.59 Even though Stan cannot fit a model with the discrete indicator of the latent class\\(\\mathbf{z}\\)that we used in Equation(17.1), this equation will prove very useful when we want to generate synthetic data. In the following sections, we model a well-known phenomenon (i.e., the speed-accuracy trade-off) assuming an underlying finite mixture process. We start from the verbal description of the model, and then implement the model step by step in Stan. When we are faced with multiple choices that require an immediate decision, we can speed up the decision at the expense of accuracy and become more accurate at the expense of speed; this is called the speed-accuracy trade-off(Wickelgren1977). The most popular class of models that can incorporate both response times and accuracy, and give an account for the speed-accuracy trade-off is the class of sequential sampling models, which include the drift diffusion model(Ratcliff1978), the linear ballistic accumulator(Brown and Heathcote2008), and the log-normal race model(Heathcote and Love2012; Rouder et al.2015), which we discuss in chapter18; for a review seeRatcliff et al. (2016)",
    "chunk_id": "Adv_cognitive_modelling_introduction_to_bayesian_data_analysis_for_cognitive_science_d478409d.json_chunk_3"
  },
  {
    "document_type": "online_article",
    "title": "Introduction to Bayesian Data Analysis for Cognitive Science",
    "author": "Bruno Nicenboim",
    "source": "https://bruno.nicenboim.me/bayescogsci/ch-mixture.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". (2016). However, an alternative model that has been proposed in the past is Ollman’s simple fast-guess model(Ollman1966; Yellott1967,1971).60Although it has mostly fallen out of favor(but see Dutilh et al.2011; and Heck and Erdfelder2020for more modern variants of this model), it presents a very simple framework using finite mixture modeling that can also account for the speed-accuracy trade-off. In the next sections, we’ll use this model to exemplify the use of finite mixtures to represent different cognitive processes. One way to examine the behavior of human and primate subjects when faced with two-alternative forced choices is the detection of the global motion of a random dot kinematogram(Britten et al.1993). In this task, a subject sees a number of random dots on the screen. A proportion of dots move in a single direction (e.g., right) and the rest move in random directions. The subject’s goal is to estimate the overall direction of the movement. One of the reasons for the popularity of this task is that it permits the fine-tuning of the difficulty of trials(Dutilh et al.2019): The task is harder when the proportion of dots that move coherently (the level ofcoherence) is lower; see Figure17.1. FIGURE 17.1: Three levels of difficulty of the global motion detection task. The figures show a consistent movement to the right with three levels of coherence (10%, 50%, and 100%). The subjects see the dots moving in the direction indicated by the arrows. The subjects do not see the arrows and all the dots look identical in the actual task. Adapted fromHan et al. (2018); licensed under CC BY 4.0 (https://creativecommons.org/licenses/by/4.0/). Ollman’s(1966)fast-guess model assumes that the behavior in this task (and in any other choice task) is governed by two distinct cognitive processes: (i) a guessing mode, and (ii) a task-engaged mode. In the guessing mode, responses are fast and accuracy is at chance level. In the task-engaged mode, responses are slower and accuracy approaches 100%",
    "chunk_id": "Adv_cognitive_modelling_introduction_to_bayesian_data_analysis_for_cognitive_science_d478409d.json_chunk_4"
  },
  {
    "document_type": "online_article",
    "title": "Introduction to Bayesian Data Analysis for Cognitive Science",
    "author": "Bruno Nicenboim",
    "source": "https://bruno.nicenboim.me/bayescogsci/ch-mixture.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". In the guessing mode, responses are fast and accuracy is at chance level. In the task-engaged mode, responses are slower and accuracy approaches 100%. This means that intermediate values of response times and accuracy can only be achieved by mixing responses from the two modes. Further assumptions of this model are that response times depend on the difficulty of the choice, and that the probability of being on one of the two states depend on the speed incentives during the instructions. To simplify matters, we ignore the possibility that the accuracy of the choice is also affected by the difficulty of the choice. Also, we ignore the possibility that subjects might be biased to one specific response in the guessing mode, but see exerciseG.17.3in the online materials. We implement the assumptions behind Ollman’s fast-guess model and examine its fit to data of a global motion detection task fromDutilh et al. (2019). The data set fromDutilh et al. (2019)contains approximately 2800 trials of each of the 20 subjects participating in a global motion detection task and can be found indf_dotsin thebcogscipackage. There were two level of coherence, yielding hard and easy trials (diff), and the trials where done under instructions that emphasized either accuracy or speed (emphasis). More information about the data set can be found by accessing the documentation for the data set (by typing?df_dotson the R command line, assuming that thebcogscipackage is installed). We might think that if the fast-guess model were true, we would see a bimodal distribution, when we plot a histogram of the data. Unfortunately, when two similar distributions are mixed, we won’t necessarily see any apparent bimodality; see Figure17.2. FIGURE 17.2: Distribution of response times in the data of the global motion detection task inDutilh et al. (2019). However, Figure17.3reveals that incorrect responses were generally faster, and this was especially true when the instructions emphasized accuracy",
    "chunk_id": "Adv_cognitive_modelling_introduction_to_bayesian_data_analysis_for_cognitive_science_d478409d.json_chunk_5"
  },
  {
    "document_type": "online_article",
    "title": "Introduction to Bayesian Data Analysis for Cognitive Science",
    "author": "Bruno Nicenboim",
    "source": "https://bruno.nicenboim.me/bayescogsci/ch-mixture.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". (2019). However, Figure17.3reveals that incorrect responses were generally faster, and this was especially true when the instructions emphasized accuracy. FIGURE 17.3: The distribution of response times by accuracy in the data of the global motion detection task inDutilh et al. (2019). The description of the model makes it clear that an ideal subject who never guesses has a response time that depends only on the difficulty of the trial. As we did in previous chapters, we assume that response times are log-normally distributed, and for simplicity we start by modeling the behavior of a single subject: \\[\\begin{equation} rt_n \\sim \\mathit{LogNormal}(\\alpha + \\beta \\cdot x_n, \\sigma) \\end{equation}\\] In the previous equation,\\(x\\)is larger for difficult trials. If we center\\(x\\),\\(\\alpha\\)represents the average logarithmic transformed response time for a subject engaged in the task, and\\(\\beta\\)is the effect of trial difficulty on log-response time. We assume a non-deterministic process, with a noise parameter\\(\\sigma\\). Also see the online sectionA.4for more information about log-normally distributed response times. Alternatively, a subject that guesses in every trial would show a response time distribution that is independent of the difficulty of the trial: \\[\\begin{equation} rt_n \\sim \\mathit{LogNormal}(\\gamma, \\sigma_2) \\end{equation}\\] Here\\(\\gamma\\)represents the the average logarithmic transformed response time when a subject only guesses. We assume that responses from the guessing mode might have a different noise component than from the task-engaged mode. The fast-guess model makes the assumption that during a task, a single subject would behave in these two ways: They would be engaged in the task a proportion of the trials and would guess on the rest of the trials",
    "chunk_id": "Adv_cognitive_modelling_introduction_to_bayesian_data_analysis_for_cognitive_science_d478409d.json_chunk_6"
  },
  {
    "document_type": "online_article",
    "title": "Introduction to Bayesian Data Analysis for Cognitive Science",
    "author": "Bruno Nicenboim",
    "source": "https://bruno.nicenboim.me/bayescogsci/ch-mixture.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". This means that for a single subject, there is an underlying probability of being engaged in the task,\\(p_{task}\\), that determines whether they are actually choosing (\\(z=1\\)) or guessing (\\(z=0\\)): \\[\\begin{equation} z_n \\sim \\mathit{Bernoulli}(p_{task}) \\end{equation}\\] The value of the parameter\\(z\\)in every trial determines the behavior of the subject. This means that the distribution that we observe is a mixture of the two distributions presented before: \\[\\begin{equation} rt_n \\sim \\begin{cases} \\mathit{LogNormal}(\\alpha + \\beta \\cdot x_n, \\sigma), & \\text{ if } z_n =1 \\\\ \\mathit{LogNormal}(\\gamma, \\sigma_2), & \\text{ if } z_n=0 \\end{cases} \\tag{17.2} \\end{equation}\\] In order to have a Bayesian implementation, we also need to define some priors. We use priors that encode what we know about response time experiments. These priors are slightly more informative than the ones that we used in section4.2, but they still can be considered regularizing priors. One can verify this by performing prior predictive checks. As we increase the complexity of our models, it’s worth spending some time designing more realistic priors. These will speed up computation and in some cases they will be crucial for solving convergence problems. \\[\\begin{equation} \\begin{aligned} \\alpha &\\sim \\mathit{Normal}(6, 1)\\\\ \\beta &\\sim \\mathit{Normal}(0, 0.1)\\\\ \\sigma &\\sim \\mathit{Normal}_+(0.5, 0.2) \\end{aligned} \\end{equation}\\] \\[\\begin{equation} \\begin{aligned} \\gamma &\\sim \\mathit{Normal}(6, 1)\\\\ \\sigma_2 &\\sim \\mathit{Normal}_+(0.5, 0.2) \\end{aligned} \\end{equation}\\] For now, we allow all values for the probability of having an engaged response equal likelihood; we achieve this by setting the following prior to\\(p_{task}\\): \\[\\begin{equation} p_{task} \\sim \\mathit{Beta}(1, 1) \\end{equation}\\] This represents a flat, uninformative prior over the probability parameter\\(p_{task}\\). Before we fit our model to the real data, we generate synthetic data to make sure that our model is working as expected",
    "chunk_id": "Adv_cognitive_modelling_introduction_to_bayesian_data_analysis_for_cognitive_science_d478409d.json_chunk_7"
  },
  {
    "document_type": "online_article",
    "title": "Introduction to Bayesian Data Analysis for Cognitive Science",
    "author": "Bruno Nicenboim",
    "source": "https://bruno.nicenboim.me/bayescogsci/ch-mixture.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". Before we fit our model to the real data, we generate synthetic data to make sure that our model is working as expected. We first define the number of observations, predictors, and fixed point values for each of the parameters. We assume\\(1000\\)observations and two levels of difficulty,\\(x\\), coded\\(-0.5\\)(easy) and\\(0.5\\)(hard). The point values chosen for the parameters are relatively realistic (based on our previous experience on response time experiments). Although in the priors we try to encode the range of possible values for the parameters, in this simulation we assume only one instance of this possible range: For generating a mixture of response times, we use the indicator of a latent class,z. We verify that our simulated data is realistic, that is, it’s in the same range as the original data; see Figure17.4. FIGURE 17.4: Response times in the simulated data (df_dots_simdata1) that follows the fast-guess model. To implement the mixture model defined in Equation(3.10)in Stan, the discrete parameter\\(z\\)needs to be marginalized out: \\[\\begin{equation} \\begin{aligned} p(rt_n | \\Theta) &= p_{task} \\cdot LogNormal(rt_n | \\alpha + \\beta \\cdot x_n, \\sigma) +\\\\ & (1 - p_{task}) \\cdot LogNormal(rt_n | \\gamma, \\sigma_2) \\end{aligned} \\end{equation}\\] In addition, Stan requires the likelihood to be defined in log-space: \\[\\begin{equation} \\begin{aligned} \\log(p(rt | \\Theta)) &= \\log(p_{task} \\cdot LogNormal(rt_n | \\alpha + \\beta \\cdot x_n, \\sigma) +\\\\ & (1 - p_{task}) \\cdot LogNormal(rt_n | \\gamma, \\sigma_2)) \\end{aligned} \\end{equation}\\] A “naive” implementation in Stan would look like the following (recall that_lpdffunctions provide log-transformed densities): However, we need to take into account that\\(log(A \\pm B)\\)can be numerically unstable(i.e., prone to underflow/ overflow, see Blanchard, Higham, and Higham2020). Stan provides several functions to deal with different special cases of logarithms of sums and differences",
    "chunk_id": "Adv_cognitive_modelling_introduction_to_bayesian_data_analysis_for_cognitive_science_d478409d.json_chunk_8"
  },
  {
    "document_type": "online_article",
    "title": "Introduction to Bayesian Data Analysis for Cognitive Science",
    "author": "Bruno Nicenboim",
    "source": "https://bruno.nicenboim.me/bayescogsci/ch-mixture.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". Stan provides several functions to deal with different special cases of logarithms of sums and differences. Here we needlog_sum_exp(x, y)that corresponds tolog(exp(x) + exp(y))andlog1m(x)that corresponds tolog(1-x). First, we need to take into account that the first summand of the logarithm,p_task * exp(lognormal_lpdf(rt[n] | alpha + x[n] * beta, sigma))corresponds toexp(x), and the second one,(1-p_task) * exp(lognormal_lpdf(rt[n] | gamma, sigma2))toexp(y)inlog_sum_exp(x, y). This means that we need to first apply the logarithm to each of them to use them as arguments oflog_sum_exp(x, y): Now we can just replacelog(1-p_task)by the more stablelog1m(p_task): The complete model (mixture_rt.stan) is shown below: Call the Stan modelmixture_rt.stan, and fit it to the simulated data. First, we set up the simulated data as a list structure: Then fit the model: There are a lot of warnings, the Rhats are too large, and number of effective samples is too low: The traceplots show clearly that the chains aren’t mixing; see Figure17.5. FIGURE 17.5: Traceplots from the modelmixture_rt.stanfit to simulated data. The problem with this model is that the mixture components (i.e., the fast-guesses and the engaged mode) are underlyingly exchangeable and thus the posterior is multimodal and the model does not converge. Each chain (and each iteration) doesn’t know how each component was identified by the rest of the chains (e.g., in some chains and iterations,\\(z=0\\)corresponds to fast guesses, whereas in other cases, it corresponds to deliberate responses). However, we do have information that can identify the components: According to the theoretical model, we know that the average response in the engaged mode, represented by\\(\\alpha\\), should be slower than the average response in the guessing mode,\\(\\gamma\\). Even though the theoretical model assumes that guesses are faster than engaged responses, this is not explicit in our computational model",
    "chunk_id": "Adv_cognitive_modelling_introduction_to_bayesian_data_analysis_for_cognitive_science_d478409d.json_chunk_9"
  },
  {
    "document_type": "online_article",
    "title": "Introduction to Bayesian Data Analysis for Cognitive Science",
    "author": "Bruno Nicenboim",
    "source": "https://bruno.nicenboim.me/bayescogsci/ch-mixture.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". Even though the theoretical model assumes that guesses are faster than engaged responses, this is not explicit in our computational model. That is, our model lacks some of the theoretical information that we have, namely that the distribution of engaged response times should be slower than the distribution of guessing times. This can be encoded withorder constraintsorinequality constraints: a strong prior for\\(\\gamma\\), where we assume that the upper bound of its prior distribution is truncated at the value\\(\\alpha\\): \\[\\begin{equation} \\gamma \\sim \\mathit{Normal}(6, 1), \\text{for } \\gamma < \\alpha \\end{equation}\\] This would be enough to make the model converge. Another softer constraint that we could add to our implementation is the assumption that subjects are generally more likely to be trying to do the task than just guessing. If this assumption is correct, we also improve the accuracy of our estimation of the posterior of the model. (The opposite is also true: If subjects are not trying to do the task, this assumption will be unwarranted and our prior information will lead us further from the “true” values of the parameters). The following prior has the probability density concentrated near\\(1\\). \\[\\begin{equation} p_{task} \\sim \\mathit{Beta}(8, 2) \\end{equation}\\] Plotting this prior confirms where most of the probability mass lies; see Figure17.6. FIGURE 17.6: A density plot for the\\(\\mathit{Beta}(8,2)\\)prior on\\(p_{task}\\). The Stan code for this model is shown below asmixture_rt2.stan. Once we change the upper bound ofgammain theparametersblock, we also need to truncate the distribution in themodelblock by correcting the PDF with its CDF. This correction is carried out using the CDF because we are truncating the distribution at the right-hand side; recall that earlier we used the complement of the CDF when we truncate a distribution at the left-hand side); see the online sectionA.2",
    "chunk_id": "Adv_cognitive_modelling_introduction_to_bayesian_data_analysis_for_cognitive_science_d478409d.json_chunk_10"
  },
  {
    "document_type": "online_article",
    "title": "Introduction to Bayesian Data Analysis for Cognitive Science",
    "author": "Bruno Nicenboim",
    "source": "https://bruno.nicenboim.me/bayescogsci/ch-mixture.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". Fit this model (call itmixture_rt2.stan) to the same simulated data set that we used before: Now the summaries and traceplots look fine; see Figure17.7. FIGURE 17.7: Traceplots from the modelmixture_rt2.stanfit to simulated data. A problem with the previous implementation of the fast-guess model is that we ignore the accuracy information in the data. We can implement a version that is closer to the verbal description of the model: In particular, we also want to model the fact that accuracy is at chance level in the fast-guessing mode and that accuracy approaches 100% during the task-engaged mode. This means that the mixture affects two pairs of distributions: \\[\\begin{equation} z_n \\sim \\mathit{Bernoulli}(p_{task}) \\end{equation}\\] The response time distribution \\[\\begin{equation} rt_n \\sim \\begin{cases} \\mathit{LogNormal}(\\alpha + \\beta \\cdot x_n, \\sigma), & \\text{ if } z_n =1 \\\\ \\mathit{LogNormal}(\\gamma, \\sigma_2), & \\text{ if } z_n=0 \\end{cases} \\tag{17.3} \\end{equation}\\] and an accuracy distribution \\[\\begin{equation} acc_n \\sim \\begin{cases} \\mathit{Bernoulli}(p_{correct}), & \\text{ if } z_n =1 \\\\ \\mathit{Bernoulli}(0.5), & \\text{ if } z_n=0 \\end{cases} \\tag{17.4} \\end{equation}\\] We have a new parameter\\(p_{correct}\\), which represent the probability of making a correct answer in the engaged mode. The verbal description says that it is closer to 100%, and here we have the freedom to choose whatever prior we believe represents for us values that are close to 100% accuracy. We translate this belief into a prior as follows; our prior choice is relatively informative but does not impose a hard constraint; if a subject consistently shows relatively low (or high) accuracy,\\(p_{correct}\\)will change accordingly: \\[\\begin{equation} p_{correct} \\sim \\mathit{Beta}(995, 5) \\end{equation}\\] In our simulated data, we assume that the global motion detection task is done by a very accurate subject, with an accuracy of 99.9%",
    "chunk_id": "Adv_cognitive_modelling_introduction_to_bayesian_data_analysis_for_cognitive_science_d478409d.json_chunk_11"
  },
  {
    "document_type": "online_article",
    "title": "Introduction to Bayesian Data Analysis for Cognitive Science",
    "author": "Bruno Nicenboim",
    "source": "https://bruno.nicenboim.me/bayescogsci/ch-mixture.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". First, simulate response times, as done earlier: Simulate accuracy and include both response times and accuracy in the simulated data set: Plot the simulated data in Figure17.8. This time we can see the effect of task difficulty on the simulated response times and accuracy: FIGURE 17.8: Response times by accuracy, accounting for task difficulty in the simulated data (df_dots_simdata3) that follows the fast-guess model. Next, we need to marginalize out the discrete parameters from the joint distribution of accuracy and response times. However, we assume that conditional on the latent indicator parameter\\(z\\), response times and accuracy are independent. For this reason, we can multiply the likelihoods forrtandaccwithin each component. \\[\\begin{equation} \\begin{aligned} p(rt, acc | \\Theta) = & p_{task} \\cdot \\\\ & LogNormal(rt_n | \\alpha + \\beta \\cdot x_n, \\sigma) \\cdot \\\\ & Bernoulli(acc_n | p_{correct}) \\\\ & +\\\\ & (1 - p_{task}) \\cdot \\\\ & LogNormal(rt_n | \\gamma, \\sigma_2) \\cdot\\\\ & Bernoulli(acc_n | 0.5) \\end{aligned} \\end{equation}\\] In log-space: \\[\\begin{equation} \\begin{aligned} \\log(p(rt, acc | \\Theta)) = \\log(\\exp(&\\\\ & \\log(p_{task}) +\\\\ &\\log(LogNormal(rt_n | \\alpha + \\beta \\cdot x_n, \\sigma)) + \\\\ &\\log(Bernoulli(acc_n | p_{correct})))\\\\ +&\\\\ \\exp(&\\\\ & \\log(1 - p_{task}) + \\\\ & \\log(LogNormal(rt_n |\\gamma, \\sigma_2)) + \\\\ & \\log(Bernoulli(acc_n | 0.5)))\\\\ )& \\\\ \\end{aligned} \\end{equation}\\] Our model translates to the following Stan code (mixture_rtacc.stan): Next, set up the data in list format: Then fit the model: We see that our model can be fit to both response times and accuracy, and its parameters estimates have sensible values (given the fixed parameters we used to generate our simulated data). We will evaluate the recovery of the parameters more carefully when we deal with the hierarchical version of the fast-guess model in section17.1.5. Before we extend this model hierarchically, let us also take into account the instructions given to the subjects",
    "chunk_id": "Adv_cognitive_modelling_introduction_to_bayesian_data_analysis_for_cognitive_science_d478409d.json_chunk_12"
  },
  {
    "document_type": "online_article",
    "title": "Introduction to Bayesian Data Analysis for Cognitive Science",
    "author": "Bruno Nicenboim",
    "source": "https://bruno.nicenboim.me/bayescogsci/ch-mixture.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". Before we extend this model hierarchically, let us also take into account the instructions given to the subjects. The actual global motion detection experiment that we started with has another manipulation that can help us to evaluate better the fast-guess model. In some trials, the instructions emphasized accuracy (e.g., “Be as accurate as possible.”) and in others speed (e.g., “Be as fast as possible.”). The fast-guess model also assumes that the probability of being in one of the two states depends on the speed incentives given during the instructions. This entails that now\\(p_{task}\\)depends on the instructions\\(x_2\\), where we encode a speed incentive with\\(-0.5\\)and an accuracy incentive with\\(0.5\\). Essentially, we need to fit the following regression: \\[\\begin{equation} \\alpha_{task} + x_2 \\cdot \\beta_{task} \\end{equation}\\] As we did with MPT models in the previous chapter (in section16.2.3), we need to bound the previous regression between 0 and 1; we achieve this using the logistic or inverse logit function: \\[\\begin{equation} p_{task} = logit^{-1}(\\alpha_{task} + x_2 \\cdot \\beta_{task}) \\end{equation}\\] This means that we need to interpret\\(\\alpha_{task} + x_2 \\cdot \\beta_{task}\\)in log-odds space, which has the range\\((-\\infty, \\infty)\\)rather than the probability space\\([0,1]\\); also see section16.2.3",
    "chunk_id": "Adv_cognitive_modelling_introduction_to_bayesian_data_analysis_for_cognitive_science_d478409d.json_chunk_13"
  },
  {
    "document_type": "online_article",
    "title": "Introduction to Bayesian Data Analysis for Cognitive Science",
    "author": "Bruno Nicenboim",
    "source": "https://bruno.nicenboim.me/bayescogsci/ch-mixture.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". The likelihood (defined before in section17.1.3) now depends on the value of\\(x_{2}\\)for the specific row: \\[\\begin{equation} z_n \\sim \\mathit{Bernoulli}(p_{{task}_n}) \\end{equation}\\] A response time distribution is defined: \\[\\begin{equation} rt_n \\sim \\begin{cases} \\mathit{LogNormal}(\\alpha + \\beta \\cdot x_n, \\sigma), & \\text{ if } z_n =1 \\\\ \\mathit{LogNormal}(\\gamma, \\sigma_2), & \\text{ if } z_n=0 \\end{cases} \\end{equation}\\] and an accuracy distribution is defined as well: \\[\\begin{equation} acc_n \\sim \\begin{cases} \\mathit{Bernoulli}(p_{correct}), & \\text{ if } z_n =1 \\\\ \\mathit{Bernoulli}(0.5), & \\text{ if } z_n=0 \\end{cases} \\end{equation}\\] The only further change in our model is that rather than a prior on\\(p_{task}\\), we now need priors for\\(\\alpha_{task}\\)and\\(\\beta_{task}\\), which are on the log-odds scale. For\\(\\beta_{task}\\), we assume an effect that can be rather large and we won’t assume a direction a priori (for now): \\[\\begin{equation} \\beta_{task} \\sim \\mathit{Normal}(0, 1) \\end{equation}\\] This means that the subject could be affected by the instructions in the expected way, with an increased probability to be task-engaged, leading to better accuracy when the instructions emphasize accuracy (\\(\\beta_{task} >0\\)). Alternatively, the subject might behave in an unexpected way, with a decreased probability to be task-engaged, leading to worse accuracy when the instructions emphasize accuracy (\\(\\beta_{task} <0\\)). The latter situation,\\(\\beta_{task} <0\\), could represent the instructions being misunderstood. It’s certainly possible to include priors that encode the expected direction of the effect instead:\\(\\mathit{Normal}_{+}(0,1)\\). Unless there is a compelling reason to constrain the prior in this way, following Cromwell’s rule (BoxE.2in the online chapterE), we leave open the possibility of the\\(\\beta\\)parameter having negative values",
    "chunk_id": "Adv_cognitive_modelling_introduction_to_bayesian_data_analysis_for_cognitive_science_d478409d.json_chunk_14"
  },
  {
    "document_type": "online_article",
    "title": "Introduction to Bayesian Data Analysis for Cognitive Science",
    "author": "Bruno Nicenboim",
    "source": "https://bruno.nicenboim.me/bayescogsci/ch-mixture.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". How can we choose a prior for\\(\\alpha_{task}\\)that encodes the same information that we had in the previous model in\\(p_{task}\\)? One possibility is to create an auxiliary parameter\\(p_{btask}\\), that represents the baseline probability of being engaged in the task, with the same prior that we use in the previous section, and then transform it to an unconstrained space for our regression with the logit function: \\[\\begin{equation} \\begin{aligned} &p_{btask} \\sim \\mathit{\\mathit{Beta}}(8, 2)\\\\ &\\alpha_{task} = logit(p_{btask}) \\end{aligned} \\end{equation}\\] To verify that our priors make sense, in Figure17.9we plot the difference in prior predicted probability of being engaged in the task under the two emphasis conditions: FIGURE 17.9: The difference in prior predicted probability of being engaged in the task under the two emphasis conditions for the simulated data (diff_p_pred) that follows the fast-guess model. Figure17.9shows that we are predicting a priori that the difference in\\(p_{task}\\)will tend to be smaller than\\(\\pm 0.3\\), which seems to make sense intuitively. If we had more information about the likely range of variation, we could of course have adapted the prior to reflect that belief. We are ready to generate a new data set, by deciding on some fixed values for\\(\\beta_{task}\\)and\\(p_{btask}\\): We can generate a plot now where both the difficulty of the task and the instructions are manipulated; see Figure17.10. FIGURE 17.10: Response times and accuracy by the difficulty of the task and the instructions type for the simulated data (df_dots_simdata4) that follows the fast-guess model. In the Stan implementation,log_inv_logit(x)is applying the logistic (or inverse logit) function toxto transform it into a probability and then applying the logarithm;log1m_inv_logit(x)is applying the logistic function tox, and then applying the logarithm to its complement\\((1 - p)\\)",
    "chunk_id": "Adv_cognitive_modelling_introduction_to_bayesian_data_analysis_for_cognitive_science_d478409d.json_chunk_15"
  },
  {
    "document_type": "online_article",
    "title": "Introduction to Bayesian Data Analysis for Cognitive Science",
    "author": "Bruno Nicenboim",
    "source": "https://bruno.nicenboim.me/bayescogsci/ch-mixture.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". We do this because rather than havingp_taskin probability space, we havelodds_taskin log-odds space: The parameterlodds_taskestimates the mixing probabilities in log-odds: We also add agenerated quantitiesblock that can be used for further (prior or posterior) predictive checks. In this block, we do usezas an indicator of the latent class (task-engaged mode or fast-guessing mode), since we do not estimatez, but rather generate it based on the parameter’s posteriors. We use the dummy variableonlypriorto indicate whether we use the data or we only sample from the priors. One can always do the predictive checks in R, transforming the code that we wrote for the simulation into a function, and writing the priors in R. However, it can be simpler to take advantage of Stan output format and rewrite the code in Stan. One downside of this is that thestanfitobject that stores the model output can become too large for the memory of the computer. Another downside is reduced robustness, as it is more likely that we overlook an error if we only work in Stan rather than re-implementing the code in different programming languages (e.g., R and Stan)(Cooper and Guest2014). The code shown below is available in thebcogscipackage and is calledmixture_rtacc2.stan. Before fitting the model to the simulated data, we perform prior predictive checks. Generate prior predictive distributions, by settingonlypriorto1. We plot prior predictive distributions of response times as follows in Figure17.11(a), by settingy = rtusingppd_dens_overlay(). Some of the predictive data sets contain responses that are too large, and some of them have too much probability mass close to zero, but there is nothing clearly wrong in the prior predictive distributions (considering that the model hasn’t “seen” the data yet). If we want to plot the prior predicted distribution of differences in response time conditioning on task difficulty, we need to define a new function",
    "chunk_id": "Adv_cognitive_modelling_introduction_to_bayesian_data_analysis_for_cognitive_science_d478409d.json_chunk_16"
  },
  {
    "document_type": "online_article",
    "title": "Introduction to Bayesian Data Analysis for Cognitive Science",
    "author": "Bruno Nicenboim",
    "source": "https://bruno.nicenboim.me/bayescogsci/ch-mixture.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". If we want to plot the prior predicted distribution of differences in response time conditioning on task difficulty, we need to define a new function. Then we use thebayesplotfunctionppc_stat()that takes as an argument ofstatany summary function; see Figure17.11(a). FIGURE 17.11: (a) Prior predictive distributions of response times from the fast-guess model (mixture_rtacc2.stan). (b) Prior predictive distribution of response time differences, using the same model and prior settings, conditioned on task difficulty. We find that the range of response times look reasonable. There are, however, always more checks that can be done; examples are plotting other summary statistics, or predictions conditioned on other aspects of the data. Fit the model to data, by settingonlyprior = 0: We see that we fit the model without problems. Before we evaluate the recovery of the parameters more carefully, we implement a hierarchical version of the fast-guess model. So far we have evaluated the behavior of one simulated subject. We discussed before (in the context of distributional regression models, in section5.2.6, and in the MPT modeling chapter16) that, in principle, every parameter in a model can be made hierarchical. However, this doesn’t guarantee that we’ll learn anything from the data for those parameters, or that our model will converge. A safe approach here is to start simple, using simulated data. If a model converges on simulated data, it does not guarantee convergence on real data. However, if a model fails to converge on simulated data, it is very likely to fail with real data as well. For our hierarchical version, we assume that both response times and the effect of task difficulty vary by subject, and that different subjects have different guessing times",
    "chunk_id": "Adv_cognitive_modelling_introduction_to_bayesian_data_analysis_for_cognitive_science_d478409d.json_chunk_17"
  },
  {
    "document_type": "online_article",
    "title": "Introduction to Bayesian Data Analysis for Cognitive Science",
    "author": "Bruno Nicenboim",
    "source": "https://bruno.nicenboim.me/bayescogsci/ch-mixture.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". For our hierarchical version, we assume that both response times and the effect of task difficulty vary by subject, and that different subjects have different guessing times. This entails the following change to the response time distribution: \\[\\begin{equation} rt_n \\sim \\begin{cases} \\mathit{LogNormal}(\\alpha + u_{subj[n],1} + x_n \\cdot (\\beta + u_{subj[n], 2}), \\sigma), & \\text{ if } z_n =1 \\\\ \\mathit{LogNormal}(\\gamma + u_{subj[n], 3}, \\sigma_2), & \\text{ if } z_n=0 \\end{cases} \\end{equation}\\] We assume that the three vectors of\\(u\\)(adjustment to the intercept and slope of the task-engaged distribution, and the adjustment to the guessing time distribution) follow a multivariate normal distribution centered on zero. For simplicity and lack of any prior knowledge about this experiment design and method, we assume the same (weakly informative) prior distribution for the three variance components and the same regularizing LKJ prior for the correlation matrix\\(\\mathbf{R_u}\\)that contains the three correlations between the adjustments (\\(\\rho_{u_{1,2}}, \\rho_{u_{1,3}}, \\rho_{u_{2,3}}\\)): \\[\\begin{equation} \\begin{aligned} \\boldsymbol{u} &\\sim\\mathcal{N}(0, \\Sigma_u)\\\\ \\tau_{u_{1}}, \\tau_{u_{2}}, \\tau_{u_{3}} & \\sim \\mathit{ \\mathit{Normal}}_+(0, 0.5)\\\\ \\mathbf{R_u} &\\sim \\mathit{LKJcorr}(2) \\end{aligned} \\end{equation}\\] Before we fit the model to the real data set, we simulate data again; this time we simulate\\(20\\)subjects, each of whom delivers a total of\\(100\\)trials (each subject sees\\(25\\)trials for each of the four conditions). Verify that the distribution of the simulated response times conditional on the simulated accuracy and the experimental manipulations make sense; see Figure17.12. FIGURE 17.12: The distribution of response times conditional on the simulated accuracy and the experimental manipulations for the simulated hierarchical data (df_dots_simdata) that follows the fast-guess model. We implement the model in Stan as follows inmixture_h.stan",
    "chunk_id": "Adv_cognitive_modelling_introduction_to_bayesian_data_analysis_for_cognitive_science_d478409d.json_chunk_18"
  },
  {
    "document_type": "online_article",
    "title": "Introduction to Bayesian Data Analysis for Cognitive Science",
    "author": "Bruno Nicenboim",
    "source": "https://bruno.nicenboim.me/bayescogsci/ch-mixture.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". We implement the model in Stan as follows inmixture_h.stan. The hierarchical extension uses the Cholesky factorization for the group-level effects (as in section9.1.3). Save the model code and fit it to the simulated data: Print the posterior summary: We see that we can fit the hierarchical extension of our model to simulated data. Next, we’ll evaluate whether we can recover the true point values of the parameters. By “recovering” the true values of the parameters, we mean that the true point values are somewhere inside the bulk of the posterior distribution of the model. In in Figure17.13, we usemcmc_recover_hist()to compare the posterior distributions of the relevant parameters of the model with their true point values. FIGURE 17.13: Posterior distributions of the main parameters of the mixture modelfit_mix_htogether with their true point values. The model seems to be underestimating the probability of subjects being correct (p_correct) and the amount of noise (sigma). However, the numerical differences are relatively small. We can be relatively certain that the model is not seriously misspecified. As mentioned in previous chapters, a more principled (and computationally demanding) approach uses simulation based calibration introduced in section10.2of chapter10(also see Talts et al.2018; Schad, Betancourt, and Vasishth2020). An intermediate approach would be to re-run the simulation above a few times with a larger number of observations and/or with different true, data-generating parameters to see whether the estimates behave as expected. After verifying that our model works as expected, we are ready to fit it to real data. We code the predictors\\(x\\)and\\(x_2\\)as we did for the simulated data: The main obstacle now is that fitting the entire data set takes around 12 hours! We’ll sample 600 observations of each subject as follows: The model has not converged at all! The traceplots in Figure17.14show that the chains are not mixing at all",
    "chunk_id": "Adv_cognitive_modelling_introduction_to_bayesian_data_analysis_for_cognitive_science_d478409d.json_chunk_19"
  },
  {
    "document_type": "online_article",
    "title": "Introduction to Bayesian Data Analysis for Cognitive Science",
    "author": "Bruno Nicenboim",
    "source": "https://bruno.nicenboim.me/bayescogsci/ch-mixture.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". It seems that the posterior is multimodal, and there are at least two combinations of parameters that would fit the data equally well. (Rerunning the model might sometimes reveal three combinations.) FIGURE 17.14: Traceplots from the hierarchical model (mixture_h.stan) fit to (a subset) of the real data. The traceplot shows clearly that the posterior has at least two modes, though rerunning the model might sometimes reveal three modes. What should we do now? It can be a good idea to back off and simplify the model. Once the simplified model converges, we can think about adding further complexity. The verbal description of our model says that the accuracy in the task-engaged mode should be close to 100%. To simplify the model, we’ll assume that it’s exactly 100%. This entails the following: \\[\\begin{equation} p_{correct} = 1 \\end{equation}\\] We adapt our Stan code inmixture_h2.stan, reflecting the assumption thatp_correcthas a fixed value; this parameter is now in a block calledtransformed data. There, we assign top_correctthe value of1. Fit the model again to the same data: The model has now converged: The traceplots in Figure17.15show that this times the chains are mixing well. FIGURE 17.15: Traceplots from the simplified hierarchical model (mixture_h2.stan, assuming thatp_correct = 1) fit to (a subset) of the real data. The traceplot shows that chains are mixing well. What can we say about the fit of the model now? Under the assumptions that we have made(e.g., that there are two processing modes, response times are affected by the difficulty of the task in the task-engaged mode, accuracy is not affected by the difficulty of the task and is perfect at the task-engaged mode, etc.), we can look at the parameters and conclude the following: If we want to know whether our model achieves descriptive adequacy, we need to look at the posterior predictive distributions of the model. However, by using posterior predictive checks, we won’t be able to conclude that our model is not overfitting",
    "chunk_id": "Adv_cognitive_modelling_introduction_to_bayesian_data_analysis_for_cognitive_science_d478409d.json_chunk_20"
  },
  {
    "document_type": "online_article",
    "title": "Introduction to Bayesian Data Analysis for Cognitive Science",
    "author": "Bruno Nicenboim",
    "source": "https://bruno.nicenboim.me/bayescogsci/ch-mixture.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". However, by using posterior predictive checks, we won’t be able to conclude that our model is not overfitting. Our success in fitting the fast-guess model to real data does not entail that the model is a good account of the data. It just means that it’s flexible enough to fit the data. One further step would be to test whether each parameter can be selectively influenced by specific experimental manipulations as theoretically predicted. Another step could be to develop a competing model and then compare the performance of the models using Bayes factors or cross-validation. For the posterior predictive checks, we can write the generated quantities block in a new file; in thebcogscipackage, this code is in the filemixture_h2_gen.stan. The advantage of creating a new file is that we can generate as many observations as neededafter estimating the parameters. There is no model block in the following Stan program and the parameters together with all the transformed parameters appear in theparametersblock. We use thegqs()function in therstanlibrary, which allows us to use the posterior draws from a previously fitted model to generate posterior predicted data. Generate responses from 500 simulated experiments as follows: First, take a look at the general distribution of response times generated by the posterior predictive model and by our real data in Figure17.16(a). We see that the distribution of the observed response times is narrower than the predictive distribution. We are generating response times that are more spread out than the real data. Next, examine the effect of the experimental manipulation in Figure17.16(b): The posterior predictive check reveals that the model underestimates the observed effect of the experimental manipulation: the observed difference between response times is well outside the bulk of the predictive distribution. FIGURE 17.16: (a) Posterior predictive distribution of the hierarchical fast-guess model (mixture_h2_gen.stan) compared to observed response times",
    "chunk_id": "Adv_cognitive_modelling_introduction_to_bayesian_data_analysis_for_cognitive_science_d478409d.json_chunk_21"
  },
  {
    "document_type": "online_article",
    "title": "Introduction to Bayesian Data Analysis for Cognitive Science",
    "author": "Bruno Nicenboim",
    "source": "https://bruno.nicenboim.me/bayescogsci/ch-mixture.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". FIGURE 17.16: (a) Posterior predictive distribution of the hierarchical fast-guess model (mixture_h2_gen.stan) compared to observed response times. (b) Posterior predictive distribution of the response time difference due to experimental manipulation, using the same model; the vertical bar indicates the observed difference in the data. Another important posterior predictive check includes comparing the fit of the model using a quantile probability plot, which is presented in the next chapter. We also look at some instances of the predictive distribution. Figure17.17shows a simulated data set in black overlaid onto the real observations in gray. As we noticed in Figure17.16(a), the model is predicting less variability than what we find in the data, especially when the emphasis is on accuracy. FIGURE 17.17: A simulated (posterior predictive) data set in black overlaid onto the observations in gray (based onmixture_h2_gen.stan). If we would like to compare this model with a competing one using cross-validation, we would need to calculate the point-wise log-likelihood in the generated block: It is important to bear in mind that we can only compare models on the same dependent variable(s). That is, we would need to compare this model with another one fit to the same dependent variables and also in the same scale: accuracy (0or1) and response time in milliseconds. This means that, for example, we cannot compare our fast-guess model with an accuracy-only model. It also means that to compare our fast-guess model with a model based on left/right choices (known as stimulus coding, see section18.1.1) and response times, we would need to reparameterize one of the two models; see the online exerciseG.18.3for chapter18. To conclude, the fast-guess model shows a relatively decent fit to the data and is able to account for the speed-accuracy trade-off. The model shows some inaccuracies that could lead to its revision and improvement",
    "chunk_id": "Adv_cognitive_modelling_introduction_to_bayesian_data_analysis_for_cognitive_science_d478409d.json_chunk_22"
  },
  {
    "document_type": "online_article",
    "title": "Introduction to Bayesian Data Analysis for Cognitive Science",
    "author": "Bruno Nicenboim",
    "source": "https://bruno.nicenboim.me/bayescogsci/ch-mixture.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". The model shows some inaccuracies that could lead to its revision and improvement. To what extent the inaccuracies are acceptable or not depends on (i) the empirical finding that we want to account for (for example, we can already assume that the model will struggle to fit data sets that show slow errors); and (ii) its comparison with a competing account. In this chapter, we learned how to fit increasingly complex two-component mixture models using Stan, starting with a simple model and ending with a fully hierarchical model. We saw how to ensure model convergence via prior constraints, and how to evaluate model fit using the usual prior and posterior predictive checks, and to investigate parameter recovery. Such mixture models are notoriously difficult to fit, but they have a lot of potential in cognitive science applications, especially in developing computational models of different kinds of cognitive processes. The reader interested in a deeper understanding of marginalization is referred toPullin, Gurrin, and Vukcevic (2021). Betancourt discusses problems of identification in Bayesian mixture models in a case study (https://mc-stan.org/users/documentation/case-studies/identifying_mixture_models.html). An in-depth treatment of finite mixture modeling can be found inFrühwirth-Schnatter (2006). An in-depth treatment of the fast-guess model and other mixture models of response times is provided in Chapter 7 ofLuce (1991). Blanchard, Pierre, Desmond J. Higham, and Nicholas J. Higham. 2020. “Accurately computing the log-sum-exp and softmax functions.”IMA Journal of Numerical Analysis41 (4): 2311–30.https://doi.org/10.1093/imanum/draa038. Britten, Kenneth H., Michael N. Shadlen, William T. Newsome, and J. Anthony Movshon. 1993. “Responses of Neurons in Macaque MT to Stochastic Motion Signals.”Visual Neuroscience10 (6): 1157–69.https://doi.org/10.1017/S0952523800010269. Brown, Scott D., and Andrew Heathcote. 2005. “A Ballistic Model of Choice Response Time.”Psychological Review112 (1): 117",
    "chunk_id": "Adv_cognitive_modelling_introduction_to_bayesian_data_analysis_for_cognitive_science_d478409d.json_chunk_23"
  },
  {
    "document_type": "online_article",
    "title": "Introduction to Bayesian Data Analysis for Cognitive Science",
    "author": "Bruno Nicenboim",
    "source": "https://bruno.nicenboim.me/bayescogsci/ch-mixture.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". Brown, Scott D., and Andrew Heathcote. 2005. “A Ballistic Model of Choice Response Time.”Psychological Review112 (1): 117. Cooper, Richard P., and Olivia Guest. 2014. “Implementations Are Not Specifications: Specification, Replication and Experimentation in Computational Cognitive Modeling.”Cognitive Systems Research27: 42–49. Dutilh, Gilles, Jeffrey Annis, Scott D. Brown, Peter Cassey, Nathan J. Evans, Raoul P. P. P. Grasman, Guy E. Hawkins, et al. 2019. “The Quality of Response Time Data Inference: A Blinded, Collaborative Assessment of the Validity of Cognitive Models.”Psychonomic Bulletin & Review26 (4): 1051–69.https://doi.org/https://doi.org/10.3758/s13423-017-1417-2. Dutilh, Gilles, Eric-Jan Wagenmakers, Ingmar Visser, and Han L. J. van der Maas. 2011. “A Phase Transition Model for the Speed-Accuracy Trade-Off in Response Time Experiments.”Cognitive Science35 (2): 211–50.https://doi.org/10.1111/j.1551-6709.2010.01147.x. Frühwirth-Schnatter, Sylvia. 2006.Finite Mixture and Markov Switching Models. Springer Series in Statistics. Springer.https://doi.org/10.1007/978-0-387-35768-3. Ge, Hong, Kai Xu, and Zoubin Ghahramani. 2018. “Turing: A Language for Flexible Probabilistic Inference.” InProceedings of Machine Learning Research, edited by Amos Storkey and Fernando Perez-Cruz, 84:1682–90. Playa Blanca, Lanzarote, Canary Islands: PMLR.http://proceedings.mlr.press/v84/ge18b.html. Han, Ding, Jana Wegrzyn, Hua Bi, Ruihua Wei, Bin Zhang, and Xiaorong Li. 2018. “Practice Makes the Deficiency of Global Motion Detection in People with Pattern-Related Visual Stress More Apparent.”PLOS ONE13 (2): 1–13.https://doi.org/10.1371/journal.pone.0193215. Heathcote, Andrew, and Jonathon Love. 2012. “Linear Deterministic Accumulator Models of Simple Choice.”Frontiers in Psychology3: 292.https://doi.org/10.3389/fpsyg.2012.00292. Heck, Daniel W, and Edgar Erdfelder. 2020",
    "chunk_id": "Adv_cognitive_modelling_introduction_to_bayesian_data_analysis_for_cognitive_science_d478409d.json_chunk_24"
  },
  {
    "document_type": "online_article",
    "title": "Introduction to Bayesian Data Analysis for Cognitive Science",
    "author": "Bruno Nicenboim",
    "source": "https://bruno.nicenboim.me/bayescogsci/ch-mixture.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". 2012. “Linear Deterministic Accumulator Models of Simple Choice.”Frontiers in Psychology3: 292.https://doi.org/10.3389/fpsyg.2012.00292. Heck, Daniel W, and Edgar Erdfelder. 2020. “Benefits of Response Time-Extended Multinomial Processing Tree Models: A Reply to Starns (2018).”Psychonomic Bulletin &Amp; Review27 (3): 571–80.https://doi.org/10.3758/s13423-019-01663-0. Heck, Daniel W, Edgar Erdfelder, and Pascal J. Kieslich. 2018. “Generalized Processing Tree Models: Jointly Modeling Discrete and Continuous Variables.”Psychometrika83 (4): 893–918.https://doi.org/10.1007/s11336-018-9622-0. Levy, Deborah L., Philip S. Holzman, Steven Matthysse, and Nancy R. Mendell. 1993. “Eye Tracking Dysfunction and Schizophrenia: A Critical Perspective.”Schizophrenia Bulletin19 (3): 461–536.https://doi.org/https://doi.org/10.1093/schbul/19.3.461. Luce, R. Duncan. 1991.Response Times: Their Role in Inferring Elementary Mental Organization. Oxford University Press. Lunn, David J., Chris Jackson, David J. Spiegelhalter, Nichola G. Best, and Andrew Thomas. 2012.The BUGS Book: A Practical Introduction to Bayesian Analysis. Vol. 98. CRC Press. McElree, Brian. 2000. “Sentence Comprehension Is Mediated by Content-Addressable Memory Structures.”Journal of Psycholinguistic Research29 (2): 111–23.https://doi.org/https://doi.org/10.1023/A:1005184709695. Nicenboim, Bruno, and Shravan Vasishth. 2018. “Models of Retrieval in Sentence Comprehension: A Computational Evaluation Using Bayesian Hierarchical Modeling.”Journal of Memory and Language99: 1–34.https://doi.org/10.1016/j.jml.2017.08.004. Ollman, Robert. 1966. “Fast Guesses in Choice Reaction Time.”Psychonomic Science6 (4): 155–56.https://doi.org/https://doi.org/10.3758/BF03328004. Plummer, Martin. 2016. “JAGS Version 4.2.0 User Manual.” Pullin, Jeffrey, Lyle Gurrin, and Damjan Vukcevic. 2021. “Statistical Models of Repeated Categorical Ratings: The R Package Rater.”http://arxiv.org/abs/2010.09335. Ratcliff, Roger. 1978",
    "chunk_id": "Adv_cognitive_modelling_introduction_to_bayesian_data_analysis_for_cognitive_science_d478409d.json_chunk_25"
  },
  {
    "document_type": "online_article",
    "title": "Introduction to Bayesian Data Analysis for Cognitive Science",
    "author": "Bruno Nicenboim",
    "source": "https://bruno.nicenboim.me/bayescogsci/ch-mixture.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". 2021. “Statistical Models of Repeated Categorical Ratings: The R Package Rater.”http://arxiv.org/abs/2010.09335. Ratcliff, Roger. 1978. “A Theory of Memory Retrieval.”Psychological Review85 (2): 59.https://doi.org/ https://doi.org/10.1037/0033-295X. Ratcliff, Roger, Philip L. Smith, Scott D. Brown, and Gail McKoon. 2016. “Diffusion Decision Model: Current Issues and History.”Trends in Cognitive Sciences20 (4): 260–81.https://doi.org/https://doi.org/10.1016/j.tics.2016.01.007. Rouder, Jeffrey N, Jordan M Province, Richard D Morey, Pablo Gomez, and Andrew Heathcote. 2015. “The Lognormal Race: A Cognitive-Process Model of Choice and Latency with Desirable Psychometric Properties.”Psychometrika80 (2): 491–513.https://doi.org/10.1007/s11336-013-9396-3. Salvatier, John, Thomas V. Wiecki, and Christopher Fonnesbeck. 2016. “Probabilistic Programming in Python Using PyMC3.”PeerJ Computer Science2 (April): e55.https://doi.org/10.7717/peerj-cs.55. Schad, Daniel J., Michael J. Betancourt, and Shravan Vasishth. 2019. “Toward a Principled Bayesian Workflow in Cognitive Science.”arXiv Preprint.https://doi.org/10.48550/ARXIV.1904.12765. Talts, Sean, Michael J. Betancourt, Daniel P. Simpson, Aki Vehtari, and Andrew Gelman. 2018. “Validating Bayesian Inference Algorithms with Simulation-Based Calibration.”arXiv Preprint arXiv:1804.06788. Wickelgren, Wayne A. 1977. “Speed-Accuracy Tradeoff and Information Processing Dynamics.”Acta Psychologica41 (1): 67–85.https://doi.org/https://doi.org/10.1016/0001-6918(77)90012-9. Yackulic, Charles B., Michael Dodrill, Maria Dzul, Jamie S. Sanderlin, and Janice A. Reid. 2020. “A Need for Speed in Bayesian Population Models: A Practical Guide to Marginalizing and Recovering Discrete Latent States.”Ecological Applications30 (5): e02112.https://doi.org/https://doi.org/10.1002/eap.2112. Yellott, John I. 1967. “Correction for Guessing in Choice Reaction Time.”Psychonomic Science8 (8): 321–22.https://doi.org/10.3758/BF03331682. Yellott, John I. 1971",
    "chunk_id": "Adv_cognitive_modelling_introduction_to_bayesian_data_analysis_for_cognitive_science_d478409d.json_chunk_26"
  },
  {
    "document_type": "online_article",
    "title": "Introduction to Bayesian Data Analysis for Cognitive Science",
    "author": "Bruno Nicenboim",
    "source": "https://bruno.nicenboim.me/bayescogsci/ch-mixture.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". Yellott, John I. 1967. “Correction for Guessing in Choice Reaction Time.”Psychonomic Science8 (8): 321–22.https://doi.org/10.3758/BF03331682. Yellott, John I. 1971. “Correction for Fast Guessing and the Speed-Accuracy Tradeoff in Choice Reaction Time.”Journal of Mathematical Psychology8 (2): 159–99.https://doi.org/10.1016/0022-2496(71)90011-3. See section1.6.1.1in chapter1for a review on the concept of marginalization.↩︎ As mentioned above, other probabilistic languages that do not rely on Hamiltonian dynamics (exclusively) are able to deal with this. However, even when sampling discrete parameters is possible, marginalization is more efficient(Yackulic et al.2020): when\\(z_n\\)is omitted we are fitting a model with\\(n\\)fewer parameters.↩︎ Ollman’s original model was meant to be relevant only for means; Yellott(1967,1971)generalized it to a distributional form.↩︎",
    "chunk_id": "Adv_cognitive_modelling_introduction_to_bayesian_data_analysis_for_cognitive_science_d478409d.json_chunk_27"
  },
  {
    "document_type": "research_paper",
    "title": "If mathematical psychology did not exist we might need to invent it: A comment on theory building in psychology",
    "author": "",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Navarro-2021-If-mathematical-psychology-did-not-.pdf",
    "date_published": "2020-06-24",
    "keywords": "psychological theory, inductive generalization, mathematical psychology, cognitive modelling 12pt",
    "flag": "",
    "chunk_text": "If mathematical psychology did not exist we might need to invent it: A comment on theory building in psychology Danielle J. Navarro 1 1 School of Psychology, University of New South Wales Abstract It is commonplace, when discussing the subject of psychological theory, to write articles from the assumption that psychology differs from physical scences in that we have no theories that would support cumulative, incremental science. In this brief paper I discuss one counterexample, namely Shepard’s (1987) law of generalization and the various Bayesian extensions that it ispired over the last three decades. Using Shepard’s law as a running example I argue that psychological theory building is not a statistical problem; matematical formalism is theoretically beneficial; measurement and theory have a complex relationship; rewriting old theory can yield new insights; and fnally, that theoretical growth can drive empirical work. Though generally suggesting that the tools of mathematical psychology are valuable to the psychological theorist, the paper also comments on some limitations to this approach. Keywords: psychological theory, inductive generalization, mathematical pschology, cognitive modelling Word count: 6077 in main text, 636 in references This manuscript grew out of numerous conversations with several people, most notably Berna Devezer, to whom I am deeply indebted and without whose thoughtful contribution this paper would not exist. I would also like to thank Richard Morey, Olivia Guest and an anonymous reviewer for thoughtful (and kind) comments on the initial version of this paper, which was submitted in a less-than-polished form due to the outbreak of COVID-19. Source material associated with this paper are available on GitHub (https://github.com/djnavarro/shepard-theory) and OSF (https://osf.io/7cvtk/) Correspondence concerning this article should be addressed to Danielle J. Navarro, School of Psychology, University of New South Wales, Kensington 2052, Sydney, Australia",
    "chunk_id": "Adv_cognitive_modelling_if_mathematical_psychology_did_not_exist_we_might_need_to_invent_it_a_comment_on_theory_building_in_psychology.json_chunk_1"
  },
  {
    "document_type": "research_paper",
    "title": "If mathematical psychology did not exist we might need to invent it: A comment on theory building in psychology",
    "author": "",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Navarro-2021-If-mathematical-psychology-did-not-.pdf",
    "date_published": "2020-06-24",
    "keywords": "psychological theory, inductive generalization, mathematical psychology, cognitive modelling 12pt",
    "flag": "",
    "chunk_text": ". Navarro, School of Psychology, University of New South Wales, Kensington 2052, Sydney, Australia. E-mail: d.navarro@unsw.edu.au MATHEMATICAL PSYCHOLOGICAL THEORY 2 Introduction In 1987 Roger Shepard published a brief paper in Science with the ambitious title “Toward a universal law of generalization for psychological science” (Shepard, 1987). Drawing on the empirical literature on stimulus generalization in several domains and species, he asserted the claim that the form of any stimulus generalization function should be approximately exponential in form, when measured with respect to an appropriately formulated stimulus representation. His paper begins with the following remark (p. 1317): The tercentenary of the publication, in 1687, of Newton’s “Principia” prompts the question of whether psychological science has any hope of achieving a law that is comparable in generality (if not in predictive accuracy) to Newton’s universal law of gravitation. Exploring the direction that currently seems most favorable for an affirmative answer, I outline empirical evidence an a theoretical rationale in support of a tentative candidate for a universal law of generalization Shepard’s claim was remarkable in scope. He drew on data from multiple species (e.g., humans, pigeons, rats) and stimulus domains (e.g., visual, auditory) data that had, until that point, been assumed to be quite different to one another. To spot the invariance that holds across these data sets, Shepard used statistical insights from the similarity modeling literature. He noted that the apparent noninvariance of observed stimulus generalization functions stemmed largely from the fact that response data had previously been analyzed with respect to the physical dissimilarities of the stimulus. When the same responses were plotted as a function of distance in a psychological space constructed by multidimensional scaling, he found that the form of the stimulus generalization was remarkably regular in shape",
    "chunk_id": "Adv_cognitive_modelling_if_mathematical_psychology_did_not_exist_we_might_need_to_invent_it_a_comment_on_theory_building_in_psychology.json_chunk_2"
  },
  {
    "document_type": "research_paper",
    "title": "If mathematical psychology did not exist we might need to invent it: A comment on theory building in psychology",
    "author": "",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Navarro-2021-If-mathematical-psychology-did-not-.pdf",
    "date_published": "2020-06-24",
    "keywords": "psychological theory, inductive generalization, mathematical psychology, cognitive modelling 12pt",
    "flag": "",
    "chunk_text": ". Taken by itself Shepard’s reanalysis would have been impressive. However, Shepard went on to provide a theoretical explanation for why we should expect to find this invariance. The theory was surprisingly simple: the learner presumes there exists some unknown cosequential region of the stimulus space across which roughly the same properties hold (e.g., things that look like apples will probably taste the same as one another). Encountering a single stimulus that entails a particular consequence, the learner’s task is to infer the loction, shape and size of the consequential region itself. Naturally this is an under-constrained problem, as there are an infinite number of possible regions that might correspond to the true consequential region. Nevertheless, Shepard showed that under a range of assumptions that the learner might make about the nature of consequential regions, the shape of the generalization function across the stimulus space ends up approximately exponential. A visual illustration of this idea is depicted in Figure 1. Although brief, Shepard’s paper has been influential in the cognitive science literature. It presented no new empirical data and in substance it is mostly devoted to the derivation of a formal relation between one unobservable quantity (psychological distance) and another (stimulus generalizability). The universal law featured prominently in a special issue of Brain and Behavior Sciences in 2001 and a first person retrospective (Shepard, 2004), and for my contribution to this special issue I use it as an example of theory building in MATHEMATICAL PSYCHOLOGICAL THEORY 3 Figure 1 . A schematic depiction of Shepard’s (1987) theory of stimulus generalization. The main panel depicts a two-dimensional psychological space, in which possible stimuli can vary along two stimulus dimensions (e.g., brightness, orientation)",
    "chunk_id": "Adv_cognitive_modelling_if_mathematical_psychology_did_not_exist_we_might_need_to_invent_it_a_comment_on_theory_building_in_psychology.json_chunk_3"
  },
  {
    "document_type": "research_paper",
    "title": "If mathematical psychology did not exist we might need to invent it: A comment on theory building in psychology",
    "author": "",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Navarro-2021-If-mathematical-psychology-did-not-.pdf",
    "date_published": "2020-06-24",
    "keywords": "psychological theory, inductive generalization, mathematical psychology, cognitive modelling 12pt",
    "flag": "",
    "chunk_text": ". The main panel depicts a two-dimensional psychological space, in which possible stimuli can vary along two stimulus dimensions (e.g., brightness, orientation). The black marker shows the location of a “consequential stimulus” (e.g., an unpleasant tasting fruit), and each of the grey rectangles represents one possible hypothesis about the range of possible stimuli that might also have this consequence (e.g., taste unpleasant). Not knowing which of these hypotheses represents the true extension of the “region of unpleasant fruits”, the learner “averages” across their uncertainty leading to the approximately-exponential generalization gradients plotted above and to the right. Note that the curves shown in this figure are jagged rather than smooth because only a sample of possible regions is depicted, and that for ease of exposition this figure represents a simplified version of Shepard’s (1987) theory. MATHEMATICAL PSYCHOLOGICAL THEORY 4 psychology. 1 The decision to focus on a single theoretical contribution is motivated by a desire to look at the particulars rather than speak solely in the abstract; and my decision to ignore disciplines outside of cognitive psychology is motivated by a desire to work toward what Flis (2019) calls “an indigenous epistemology”. If psychology is to make theoretical progress we must do so on our own terms. There are limits to what we can learn from the physical sciences. Some desiderata for scientific theories seem easy to list. A scientific theory should be independent of its creator, for instance. It is difficult to make much use of a theory otherwise. In practice this typically means a theory is mathematical or computational in nature. Similarly, psychological theories should of course make some connection with epirical data, giving an account of the generative mechanism that gave rise to those data. Theories should be usable, in the sense of providing other scientists guidance for future rsearch",
    "chunk_id": "Adv_cognitive_modelling_if_mathematical_psychology_did_not_exist_we_might_need_to_invent_it_a_comment_on_theory_building_in_psychology.json_chunk_4"
  },
  {
    "document_type": "research_paper",
    "title": "If mathematical psychology did not exist we might need to invent it: A comment on theory building in psychology",
    "author": "",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Navarro-2021-If-mathematical-psychology-did-not-.pdf",
    "date_published": "2020-06-24",
    "keywords": "psychological theory, inductive generalization, mathematical psychology, cognitive modelling 12pt",
    "flag": "",
    "chunk_text": ". Theories should be usable, in the sense of providing other scientists guidance for future rsearch. Other criteria could also be named, including falsifiability, simplicity, compatibility with existing literature, generalizability, predictive ability and so on. However, while it is easy to list desiderata and even easier to argue over which elements to such lists are the most important, such “discussions in the abstract” rarely provide much guidance to the would-be theoretician. From the perspective of the working scientist, it is perhaps more useful to give concrete examples, and to that end I return to an examination of Shepard’s (1987) paper and the mathematical psychology literature to which it belongs. There are five claims I wish to make: (1) theory building is not a statistical problem; (2) mathematical formalism is theoretically beneficial; (3) measurement and theory have a complex relationship; (4) rewriting old theory can yield new insights; and (5) theoretical growth can drive empirical work that might not otherwise have been considered worthwhile. Theory building is not a statistical problem Reading Shepard’s original 1987 paper and the 2004 retrospective, some surprising charateristics of his theoretical work stand out. First, the theoretical development was largely post hoc. The paper does not collect new data, and indeed the main empirical results rported in the paper were based on a reanalysis of existing data. Second, the paper reports no hypothesis tests. There are no p-values, no Bayes factors, nor any confidence intervals or their Bayesian equivalents. Third, the paper does not outline any specific predictions about future experiments. It makes a strong claim that the exponential law should hold broadly but does not prescribe how tests of this prediction should be constructed. Viewed through the lens of the methodological reform culture documented by Flis (2019) these properties might seem strange, and might even amount to a form of “questioable research practice”",
    "chunk_id": "Adv_cognitive_modelling_if_mathematical_psychology_did_not_exist_we_might_need_to_invent_it_a_comment_on_theory_building_in_psychology.json_chunk_5"
  },
  {
    "document_type": "research_paper",
    "title": "If mathematical psychology did not exist we might need to invent it: A comment on theory building in psychology",
    "author": "",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Navarro-2021-If-mathematical-psychology-did-not-.pdf",
    "date_published": "2020-06-24",
    "keywords": "psychological theory, inductive generalization, mathematical psychology, cognitive modelling 12pt",
    "flag": "",
    "chunk_text": ". Viewed through the lens of the methodological reform culture documented by Flis (2019) these properties might seem strange, and might even amount to a form of “questioable research practice”. For instance, in the current zeitgeist it is sometimes argued with considerable vigor (especially on informal forums such as academic twitter) that strong inferential claims cannot be justified without preregistered confirmatory tests. Shepard’s (1987) paper does not present any such tests, but makes sweeping claims nonetheless. Sim1 It should be noted that I am not going to discuss the empirical evidence for (or against) Shepard’s theory. It is not my intent to argue for any specific theory, so much as to describe some of the processes that go into constructing, extending and evaluating one. Most theories are, of course, wrong. I would not be surprised if Shepard’s work (or indeed my own) turns out to be misguided. That is not the point of this paper. The point is to present my views on what psychological theories are and how they can be useful. MATHEMATICAL PSYCHOLOGICAL THEORY 5 larly, one might wonder if his post hoc theorizing is a form of hypothesizing after results are known. The unwary reader might conclude that Shepard’s work is of questionable value: perhaps cognitive scientists have erred by according this paper such high status? Something seems awry in this description, and few researchers familiar with Shepard’s work would endorse it. The problem, I suggest, arises from a subtle way in which the preceding paragraph misrepresents the inferential problems scientists face. Methodological prescriptions relating to confirmatory tests (e.g. Wagenmakers, Wetzels, Borsboom, Maas, & Kievit, 2012) or post hoc hypotheses (e.g. Kerr, 1998) are narrow in scope: they have been developed to guide statistical inferences about empirical data, and as I have argued before (Navarro, 2019) it is an error to presume that the same logic can be applied to the evaluation of scientific theories",
    "chunk_id": "Adv_cognitive_modelling_if_mathematical_psychology_did_not_exist_we_might_need_to_invent_it_a_comment_on_theory_building_in_psychology.json_chunk_6"
  },
  {
    "document_type": "research_paper",
    "title": "If mathematical psychology did not exist we might need to invent it: A comment on theory building in psychology",
    "author": "",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Navarro-2021-If-mathematical-psychology-did-not-.pdf",
    "date_published": "2020-06-24",
    "keywords": "psychological theory, inductive generalization, mathematical psychology, cognitive modelling 12pt",
    "flag": "",
    "chunk_text": ". 2 To put it another way, the success of Shepard’s (1987) theoretical work in spite of the (apparent) failure to meet these statistical prescriptions tells us something about about what a theory is not. In my view neither empirical data nor statistical tests can be called a theoretical contribution, and prescriptions deemed sensible for empirical research or data analysis should not be considered suitable for the evaluation of psychological theory. I suggest that the theoretical value in Shepard’s paper was not the discovery of an exponential law but rather the explanation proposed for it, and theories need to be evaluated (in part) in terms of their explanatory value. For example, Shepard’s paper did not merely summarize data, it systematized an existing body of empirical findings. It separated aspects to the data that are invariant across studies from those that are not, sifting the wheat from the chaffso to speak. The sieve that enabled this was a mathematical theory describing regularities in stimulus generalization in terms of simpler primitives. Thus while Shepard’s theory asserts that the form of a generalization curve should be exponential, this exponential form is an entailment of his theory and not its substance. From a theoretical perspective this is important: if an exponential law were observed in a few terrestrial species with no deeper explanation provided, there would be little reson to believe that such a law might hold with any generality. Such inference would be statistically unjustifiable, even as a “tentative suggestion”. What Shepard does instead is note that an exponential law emerges as an entailment of sufficiently primitive rules that could be reasonably expected to hold in vastly different environments: I tentatively suggest that because these regularities reflect universal principles of natural kinds and of probabilistic geometry, natural selection may favor their increasingly close approximation in sentient organisms wherever they evolve. (Shepard, 1987, p",
    "chunk_id": "Adv_cognitive_modelling_if_mathematical_psychology_did_not_exist_we_might_need_to_invent_it_a_comment_on_theory_building_in_psychology.json_chunk_7"
  },
  {
    "document_type": "research_paper",
    "title": "If mathematical psychology did not exist we might need to invent it: A comment on theory building in psychology",
    "author": "",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Navarro-2021-If-mathematical-psychology-did-not-.pdf",
    "date_published": "2020-06-24",
    "keywords": "psychological theory, inductive generalization, mathematical psychology, cognitive modelling 12pt",
    "flag": "",
    "chunk_text": ". (Shepard, 1987, p. 1323) In other words, his claim to generality does not arise from any statistical quantification of the strength of evidence, but from the formal structure of the theory. Statistical evidence and 2 The reader may wonder then if I am constructing a “strawman” argument by implying that theory building might be dismissed on this basis. All I can say in response is that I have received reviews in recent years (including by open science advocates!) that have accused me of questionable research practice precisely because my theoretical work does not meet these statistical criteria. It is easy to claim that no-one would fall prey to the fallacy of conflating statistical with theoretical claims, but it does happen and I believe there is value to pointing out the error in the open literature rather than arguing it invisibly in the review process. MATHEMATICAL PSYCHOLOGICAL THEORY 6 theoretical generality are quite different things. Statistical tools can tell us what we might expect to happen were an experiment to be precisely replicated in precisely the same context; theoretical tools exist to tell us how to generalize from one context to another. Insofar as all meaningful inferences that a practical scientist cares about are to some extent an act of generalization across contexts, statistical inferences are insufficient to guide scientific judgment. Theory-based inferences are a necessity, not a luxury. Mathematical formalism is theoretically beneficial It is perhaps trite to say so, but the defining property of mathematical psychology is the emphasis on formal descriptions of human thought and behavior, either in the form of an abstract mathematical specification or a clearly defined computational model. To many psychologists it might seem strange that such a discipline even exists but as Luce (1995) puts it “mathematics becomes relevant to science whenever we uncover structure in what we are studying” (p. 2)",
    "chunk_id": "Adv_cognitive_modelling_if_mathematical_psychology_did_not_exist_we_might_need_to_invent_it_a_comment_on_theory_building_in_psychology.json_chunk_8"
  },
  {
    "document_type": "research_paper",
    "title": "If mathematical psychology did not exist we might need to invent it: A comment on theory building in psychology",
    "author": "",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Navarro-2021-If-mathematical-psychology-did-not-.pdf",
    "date_published": "2020-06-24",
    "keywords": "psychological theory, inductive generalization, mathematical psychology, cognitive modelling 12pt",
    "flag": "",
    "chunk_text": ". 2). If we believe that our empirical results have structure we should attempt to articulate what that structure is, as precisely as we are able. It is with this task that mathematical psychology is concerned. There are a number of reasons why formality is useful to the would-be theoretician, but first among them (in my view) is precision . Consider how Shepard’s law of generalization might have looked had he not sought the precision that mathematics affords. My attempt to describe the law itself verbally using ordinary English language and not substituting any mathematical words is as follows: If an intelligent agent encounters one thing that has a particular property, and encounters another thing and is uncertain whether it possesses that property, then all else being equal the agent will tend to treat those things similarly in regards to the unknown property to the extent that those two things are similar in regards to their known properties, and this tendency will fall away very quickly as this similarity decreases Except for that last part – which forms the substantive part of the exponential law – this seems like a commonsense intuition, but in the stated form it also sounds vacuous and perilously close to tautological. What precisely do I mean when I use the word “similarity”? As philosophers (Goodman, 1972) and psychologists (Medin, Goldstone, & Gentner, 1993) alike have noted, the term “similarity” is not well-defined and requires additional constraint to be psychologically meaningful. To make the theory workable, I must elaborate on this verbal definition and try to pin down what I mean by “similarity”. I will also need to pin down what I mean when I refer to the “tendency” to act a certain way. Very quickly one finds that it is difficult to work out what underlying theoretical claim is being made, if these claims are stated only in everyday language",
    "chunk_id": "Adv_cognitive_modelling_if_mathematical_psychology_did_not_exist_we_might_need_to_invent_it_a_comment_on_theory_building_in_psychology.json_chunk_9"
  },
  {
    "document_type": "research_paper",
    "title": "If mathematical psychology did not exist we might need to invent it: A comment on theory building in psychology",
    "author": "",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Navarro-2021-If-mathematical-psychology-did-not-.pdf",
    "date_published": "2020-06-24",
    "keywords": "psychological theory, inductive generalization, mathematical psychology, cognitive modelling 12pt",
    "flag": "",
    "chunk_text": ". Very quickly one finds that it is difficult to work out what underlying theoretical claim is being made, if these claims are stated only in everyday language. Even if the theoretical claim is not entirely vacuous – in this case, if there is some of substance buried within my claim that “the tendency falls away very quickly” – I cannot work out what the substance may be when my theory is stated in this fashion. In other words, without precision it is hard to know what tests and what inferences are licensed by the theory. Escaping this trap of vagueness is hard, and to illustrate how mathematical formalism MATHEMATICAL PSYCHOLOGICAL THEORY 7 can help it will be necessary to introduce some. 3 In this paper I’ll use g ( x, y ) to refer to the generalization function: specifically, g ( x, y ) is the probability that a newly encountered stimulus y shares a property that is already known to be possessed by a different stimulus x . Using this notation, Shepard’s claim can be written in the following form: g ( x, y ) = e − λ d ( x,y ) (1) where the constant e is approximately 2.718 and λ is an unknown parameter of little theretical interest. 4 The quantity of interest here is d ( x, y ) namely the “psychological distance” between stimulus x and stimulus y . Written like this, the theoretical claim starts to become clearer: if it is possible to measure both the psychological distance d ( x, y ) and the strength of generalization g ( x, y ) in a defensible way, then we should expect a very specific non-linear relationship to emerge between the two. Already some of the value of the theory should be clear. It tells us which measurement problems we need to solve. The value of this should not be understated: knowing what quantities need to be measured is of considerable importance to us as psychologists, and similarly knowing when approximate measurements are “good enough” is critical",
    "chunk_id": "Adv_cognitive_modelling_if_mathematical_psychology_did_not_exist_we_might_need_to_invent_it_a_comment_on_theory_building_in_psychology.json_chunk_10"
  },
  {
    "document_type": "research_paper",
    "title": "If mathematical psychology did not exist we might need to invent it: A comment on theory building in psychology",
    "author": "",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Navarro-2021-If-mathematical-psychology-did-not-.pdf",
    "date_published": "2020-06-24",
    "keywords": "psychological theory, inductive generalization, mathematical psychology, cognitive modelling 12pt",
    "flag": "",
    "chunk_text": ". In the generalization context, if the researcher can only obtain ordinal-scale information about psychological distances, then Shepard’s law yields no predictions at all about the corresponding generalizations. Indeed, to the extent that one goal in methodological reform is to encourage researchers to be more precise in stating the contexts to which we believe our results may generalize (Simons, Shoda, & Lindsay, 2017), it is to our advantage to have precisely stated theory to guide us. To comment sensibly on how an empirical result might be expected to generalize (or not) beyond the original context, one needs to know something about what properties of the sample or the study are projectible in the sense described by Goodman (1955). Formal theory helps by providing the researcher with guidance as to what matters and what does not. Indeed, Shepard’s description of the generalization problem facing every learner seems pointedly appropriate to the generality problem facing us as scientists: We generalize from one situation to another not because we cannot tell the difference between the two situations but because we judge that they are likely to belong to a set of situations having the same consequence. Generalization, which stems from uncertainty about the distribution of consequential stimuli in psychological space, is thus to be distinguished from failure of discrimination, which stems from uncertainty about the relative locations of individual stimuli in that space (Shepard 1987, p. 1322) 3 It is worth noting that doing so is often viewed as a risky proposition in psychology. In my experience journal editors and reviewers are less likely to accept a paper that contains formal exposition, and will often ask for such things to be removed, relegated to supplementary materials, appendices, or even recommend that papers be “sent to a more specialist journal”",
    "chunk_id": "Adv_cognitive_modelling_if_mathematical_psychology_did_not_exist_we_might_need_to_invent_it_a_comment_on_theory_building_in_psychology.json_chunk_11"
  },
  {
    "document_type": "research_paper",
    "title": "If mathematical psychology did not exist we might need to invent it: A comment on theory building in psychology",
    "author": "",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Navarro-2021-If-mathematical-psychology-did-not-.pdf",
    "date_published": "2020-06-24",
    "keywords": "psychological theory, inductive generalization, mathematical psychology, cognitive modelling 12pt",
    "flag": "",
    "chunk_text": ". Though I have been as guilty of this practice as anyone else, I am of the view that the hostility of institutional gatekeepers to mathematical methods in psychology is part of the very problem that needs to be addressed. 4 This is not quite true. The “specificity” parameter λ describes how quickly the generalization gradient falls away as a function of distance, and there are many situations in which the researcher may care primarily about how λ changes across contexts. However, those situations were not the focus of Shepard’s work. MATHEMATICAL PSYCHOLOGICAL THEORY 8 If we hope to make sound generalizations as scientists, we must know what theoretical space attaches to our empirical work: my modest suggestion is that formal mathematical theories are the method by which we can do so. Measurement and theory have a complicated relationship Let us turn next to the question of measurement and its relation to theory. If one hopes to obtain empirical support for a theoretical claim, it must be tethered in some way to observational or experimental data. To accomplish this, one must have an appropriate measurement tool. For example, one of the key insights in Shepard’s (1987) paper is the recognition that although stimulus generalization functions can be extremely irregular in form when we measure distance in “objective” terms, they are often very smooth when measured in more subjective terms: color generalizations are predictable with respect to the appropriate color space (e.g., Ekman, 1954), tones are regular when described in an appropriate perceptual space, etc. In retrospect this seems obvious, but at the time Sheard developed the theory he was faced with a substantive problem of how to extract the appropriate stimulus representation to which the theory might be applied",
    "chunk_id": "Adv_cognitive_modelling_if_mathematical_psychology_did_not_exist_we_might_need_to_invent_it_a_comment_on_theory_building_in_psychology.json_chunk_12"
  },
  {
    "document_type": "research_paper",
    "title": "If mathematical psychology did not exist we might need to invent it: A comment on theory building in psychology",
    "author": "",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Navarro-2021-If-mathematical-psychology-did-not-.pdf",
    "date_published": "2020-06-24",
    "keywords": "psychological theory, inductive generalization, mathematical psychology, cognitive modelling 12pt",
    "flag": "",
    "chunk_text": ". Setting aside the justifications for his choices, nonmetric multidimensional scaling (MDS; Kruskal, 1964) served as a measurement model for Shepard in 1987, and his analyses all use MDS-estimated psychological spaces to supply the relevant measure of distance. As this discussion illustrates, the measurement instrument and the theoretical dvelopment were tightly linked. Without MDS as a measurement tool Shepard would have found it almost impossible to formulate the empirical regularity of interest with any cofidence. However, it is equally clear that MDS is merely a tool used to help define the phenomenon to be explained. It can be used to supply an approximate measure of psychlogical distance d ( x, y ) between two stimuli, but it does not itself explain why a measure of stimulus generalization g ( x, y ) should diminish exponentially as a function of this distance. Though MDS and other latent variable models (e.g., factor analysis) can be useful tools for organizing our measurements in a statistically meaningful way, we ought not mistake them for psychological theory. To illustrate the latter point, it is notable that in the stimulus generalization literature it quickly became apparent that Shepard’s law applies even in situations where MDS does not: shortly after the publication of Shepard’s original paper, Russell (1988) demonstrated that the same law holds for stimuli defined in terms of discrete features as well as to the continuous spaces for which Shepard’s work was defined, a connection that was later extended by Tenenbaum and Griffiths (2001). While the theoretical framework could not have come into existence without the scaffolding provided by the MDS measurement model, it quickly outgrew any need for this support. Many of the generalization problems discussed by Tenenbaum and Griffiths cannot be described with respect to any metric space extracted by MDS, but are nevertheless consistent with Shepard’s theory",
    "chunk_id": "Adv_cognitive_modelling_if_mathematical_psychology_did_not_exist_we_might_need_to_invent_it_a_comment_on_theory_building_in_psychology.json_chunk_13"
  },
  {
    "document_type": "research_paper",
    "title": "If mathematical psychology did not exist we might need to invent it: A comment on theory building in psychology",
    "author": "",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Navarro-2021-If-mathematical-psychology-did-not-.pdf",
    "date_published": "2020-06-24",
    "keywords": "psychological theory, inductive generalization, mathematical psychology, cognitive modelling 12pt",
    "flag": "",
    "chunk_text": ". Many of the generalization problems discussed by Tenenbaum and Griffiths cannot be described with respect to any metric space extracted by MDS, but are nevertheless consistent with Shepard’s theory. In other words, while the measurement model supplied by MDS played a central role in developing theories of generalization, those theories are no longer dependent on MDS in any meaningful sense. MATHEMATICAL PSYCHOLOGICAL THEORY 9 Rewriting old theory can provide new insight The specific mathematical form that Shepard used to implement his ideas is not unique, and the theory can be rewritten in different notation. Previously, Cooper and Guest (2014) have argued that theoretical work need not be constrained to a particular “implementation” (or formalism), but is better captured by a more abstract notion of a “specification”. As a concrete example, it is worth considering the manner in which Shepard’s law was later reformulated by Tenenbaum and Griffiths as an (explicitly) Bayesian model, and the effect this rewriting had on how the theory could be applied. To illustrate what I mean here, it is worth considering how Bayesian cognitive models are typically described in the cognitive science literature. Nowadays it is grossly typical to introduce such a model by first saying “we propose to treat [psychological problem of interest] as a Bayesian inference problem”, and then introduce the formula for Bayes’ rule: P ( h | x ) = P ( x | h ) P ( h ) P ( x ) (2) It would then be explained that P ( h ) defines the learner’s prior degree of belief in some hypothesis h about the world, whereas P ( h | x ) is the posterior belief in that hypothesis after the learner encounters the information embodied by x , whatever x may happen to be in the specific application at hand. Next it would be noted that the likelihood term P ( x | h ) denotes the probability of the learner observing x if hypothesis h were true",
    "chunk_id": "Adv_cognitive_modelling_if_mathematical_psychology_did_not_exist_we_might_need_to_invent_it_a_comment_on_theory_building_in_psychology.json_chunk_14"
  },
  {
    "document_type": "research_paper",
    "title": "If mathematical psychology did not exist we might need to invent it: A comment on theory building in psychology",
    "author": "",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Navarro-2021-If-mathematical-psychology-did-not-.pdf",
    "date_published": "2020-06-24",
    "keywords": "psychological theory, inductive generalization, mathematical psychology, cognitive modelling 12pt",
    "flag": "",
    "chunk_text": ". Next it would be noted that the likelihood term P ( x | h ) denotes the probability of the learner observing x if hypothesis h were true. The normalizing constant P ( x ) is also explained, additional context is filled in, and the end result is an abstract specification for a mathematical model. 5 If one reads Shepard’s (1987) paper, one finds nothing of the kind. None of the “standard” notation is used and there is no explicit appeal to Bayes’ rule in the text. Instead, all that one finds is a discussion of “consequential regions” of unknown size, probability measures that are not entirely easy to understand for the casual reader, and so on. It does not look like a Bayesian model in the sense that cognitive modelers would easily recognize 30 years later. I can certainly attest to the fact that I did not perceive the connection to Bayesian learning until Tenenbaum and Griffiths (2001) recast Shepard’s formalism using different notation, expressing the same ideas rather differently. The theoretical contribution of the Tenenbaum and Griffiths (2001) paper is worth epanding on, because I think it was instrumental in allowing Shepard’s theory to be extended beyond the original stimulus generalization context. Where Shepard referred to the notion of a “consequential region” located within a psychological space – with all the geometric connotations that entails – Tenenbaum and Griffiths took a more general view and framed their analysis in terms of “consequential sets”. Moreover, any specific candidate for the true consequential set was labeled a “hypothesis” h and considered part of a broader “hypothesis space” H and the underlying problem of generalizing from one stimulus to another could be recast as Bayesian reasoning about (collections of) such hypotheses. 5 A complete discussion of Bayesian cognitive modelling is beyond the scope of this brief paper: see Perfors, Tenenbaum, Griffiths, and Xu (2011) for a tutorial introduction",
    "chunk_id": "Adv_cognitive_modelling_if_mathematical_psychology_did_not_exist_we_might_need_to_invent_it_a_comment_on_theory_building_in_psychology.json_chunk_15"
  },
  {
    "document_type": "research_paper",
    "title": "If mathematical psychology did not exist we might need to invent it: A comment on theory building in psychology",
    "author": "",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Navarro-2021-If-mathematical-psychology-did-not-.pdf",
    "date_published": "2020-06-24",
    "keywords": "psychological theory, inductive generalization, mathematical psychology, cognitive modelling 12pt",
    "flag": "",
    "chunk_text": ". 5 A complete discussion of Bayesian cognitive modelling is beyond the scope of this brief paper: see Perfors, Tenenbaum, Griffiths, and Xu (2011) for a tutorial introduction. MATHEMATICAL PSYCHOLOGICAL THEORY 10 The Bayesian reformulation of Shepard’s theory presented by Tenenbaum and Grifiths allowed them to generalize Shepard’s theory in three distinct ways. First, as mentioned earlier, they showed (much like Russell 1988) that Shepard’s theory could encompass stiuli that were not representable as points in a geometric space: in their notation, this is as accomplished by substituting a new hypothesis space H . Second, this formulation allowed the theory to naturally accommodate inductive generalization problems in which the learner has encountered more than one consequential stimulus. Earlier approaches for allowing the model to account for multi-item generalization (e.g., Shepard & Kannappan, 1991) were not quite so adaptable. Finally, this formalism called attention to a potentially limiting assumption in Sheard’s original paper. Shepard (1987, p. 1321) argued that “in the absence of any information to the contrary, an individual might best assume that nature selects the consequential region and the first stimulus independently”. This so-called “weak sampling” assumption places strong constraints on the inferences that the learner can make, and when formally instatiated within the model it leads to a situation in which the learner necessarily behaves like a naive falsificationist: the only role that observed stimuli x can play is indicating which hypotheses h are consistent with the observations and which are not. Nevertheless, this is by no means the only assumption a sensible reasoner might make, and by highlighting Shepard’s assumption more clearly, Tenenbaum and Griffiths (2001) allowed later work to explore alternative sampling models that allow the reasoner to use the stimulus information in a more sophisticated manner (e.g",
    "chunk_id": "Adv_cognitive_modelling_if_mathematical_psychology_did_not_exist_we_might_need_to_invent_it_a_comment_on_theory_building_in_psychology.json_chunk_16"
  },
  {
    "document_type": "research_paper",
    "title": "If mathematical psychology did not exist we might need to invent it: A comment on theory building in psychology",
    "author": "",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Navarro-2021-If-mathematical-psychology-did-not-.pdf",
    "date_published": "2020-06-24",
    "keywords": "psychological theory, inductive generalization, mathematical psychology, cognitive modelling 12pt",
    "flag": "",
    "chunk_text": ". Shafto, Goodman, & Griffiths, 2014; Hayes, Banner, Forrester, & Navarro, 2019). Each of these insights has led to new empirical and theoretical work, point I will expand upon in the next section. Theoretical growth can drive experimental innovation The final point I want to make pertains to the relationship between theoretical growth and empirical innovation. On occasions, I have heard it suggested that psychology needs to solve our empirical problems first and only then consider how to construct good theory. I am less than convinced by such claims, and hope to illustrate in this section why the two problems go hand in hand, as always using the stimulus generalization theories introduced by Shepard (1987) and Tenenbaum and Griffiths (2001) as my example. Looking at their paper in retrospect, one of the most important contributions made by the Bayesian formulation adopted by Tenenbaum and Griffiths (2001) is that it allowed the underlying theory to be applied in a much broader range of inductive problems. Sheard’s (1987) original construction, though purported to be a very general law itself, was formulated with respect to a narrow class of psychological problems: inductive generaliztion from a single observation. Moreover, because the origins of his work lay in the study of human perception and the animal learning literature, it was not immediately clear — at least it was not clear to me — how the theory should be extended to higher order cognition. The reformulation offered by Tenenbaum and Griffiths’ paper made it quite apparent that Shepard’s original theory is a special case of a broader class of Bayesian generalization moels. By abstracting away from the specific problem Shepard’s theory sought to explain and casting it in a language (Bayesian inference) that is naturally extensible to new problems, I was able to see how I could extend Shepard’s theory on my own. MATHEMATICAL PSYCHOLOGICAL THEORY 11 Perhaps the cleanest example of this interplay in my own research is the work prsented by Hayes et al",
    "chunk_id": "Adv_cognitive_modelling_if_mathematical_psychology_did_not_exist_we_might_need_to_invent_it_a_comment_on_theory_building_in_psychology.json_chunk_17"
  },
  {
    "document_type": "research_paper",
    "title": "If mathematical psychology did not exist we might need to invent it: A comment on theory building in psychology",
    "author": "",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Navarro-2021-If-mathematical-psychology-did-not-.pdf",
    "date_published": "2020-06-24",
    "keywords": "psychological theory, inductive generalization, mathematical psychology, cognitive modelling 12pt",
    "flag": "",
    "chunk_text": ". MATHEMATICAL PSYCHOLOGICAL THEORY 11 Perhaps the cleanest example of this interplay in my own research is the work prsented by Hayes et al. (2019). That paper was motivated by a puzzling finding presented by Lawson and Kalish (2009) in which people appeared to solve inductive reasoning problems differently depending on how the information in the reasoning problem was selected. At the time the original work was presented, no clear explanation for why people would do this was available, so we considered the possibility that — following Tenenbaum and Grifiths’ (2001) observation that from a statistical learning perspective inductive generalization ought to depend on the learner’s beliefs about how information is selected — the earlier results by Lawson and Kalish (2009) were the same kind of effect. The process I followed when adapting the theory to a new context may be informative. In my first pass at adapting the theory (Hayes, Banner, & Navarro, 2017), I constructed a model that was only very slightly different from the Tenenbaum and Griffiths version, and used it to derive qualitative predictions regarding what kind of empirical manipulations should be expected to modulate the effect reported by Lawson and Kalish (2009). We then undertook a series of experimental tests, reported by Hayes et al. (2019) showing that under some circumstances (not all) the effects predicted by (my trivial adaptation of) the Tenenbaum and Griffiths model occur almost exactly as expected. However, from my perspective this initial work was unsatisfying: because our new experimental results involved a very different design to the kind of “stimulus generalization” tasks with which Shepard was originally concerned, it was difficult to be certain which aspects of our data could be explained as a “sampling effect” and which could not",
    "chunk_id": "Adv_cognitive_modelling_if_mathematical_psychology_did_not_exist_we_might_need_to_invent_it_a_comment_on_theory_building_in_psychology.json_chunk_18"
  },
  {
    "document_type": "research_paper",
    "title": "If mathematical psychology did not exist we might need to invent it: A comment on theory building in psychology",
    "author": "",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Navarro-2021-If-mathematical-psychology-did-not-.pdf",
    "date_published": "2020-06-24",
    "keywords": "psychological theory, inductive generalization, mathematical psychology, cognitive modelling 12pt",
    "flag": "",
    "chunk_text": ". This led me to a develop a more substantive modification of Tenenbaum and Griffiths’ model, 6 and following the model evaluation procedure outlined in Navarro (2019) I was able to resolve much of this uncertainty: most of our experimental findings were indeed consistent with the theory, but some were emphatically not. By adopting a mathematically precise, theoretically motivated approach to exploring this phenomenon, we were able to obtain clarity about what we were seeing in our empirical data. I know of no other process that would have allowed me to do so. A word of warning In this paper I have argued that the toolkit provided by mathematical psychology can be a powerful aid to those seeking to build psychological theories. I would be remiss, however, if I did not comment on the limitations to this approach. As a mathematical psychologist studying human inductive reasoning what I want is a “mathematical theory of human reason” that explains the entire psychological process of human reasoning about underconstrained problems. However, my skill and knowledge are both limited and I cannot fathom what class of theoretical models might be applicable to the entire psychological process at hand. Nor can I think of a way to circumscribe the scientific problem in a fashion that allows me render the entire domain of human reason subject to any kind of direct measurement. This limitation has consequences. My experiment is a measurement 6 Crudely put, I modified the hypothesis space H : instead of each h corresponding to a single “consequetial set” indicating which stimuli possess an unknown property, the Hayes et al. (2019) model is probabilistic, and a hypothesis h is a function defined over the stimulus space that describes the probability with which stimuli possess an unknown property. MATHEMATICAL PSYCHOLOGICAL THEORY 12 tool that captures some aspects to human reasoning, but inevitably confounds it with the measurement of some other phenomena",
    "chunk_id": "Adv_cognitive_modelling_if_mathematical_psychology_did_not_exist_we_might_need_to_invent_it_a_comment_on_theory_building_in_psychology.json_chunk_19"
  },
  {
    "document_type": "research_paper",
    "title": "If mathematical psychology did not exist we might need to invent it: A comment on theory building in psychology",
    "author": "",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Navarro-2021-If-mathematical-psychology-did-not-.pdf",
    "date_published": "2020-06-24",
    "keywords": "psychological theory, inductive generalization, mathematical psychology, cognitive modelling 12pt",
    "flag": "",
    "chunk_text": ". MATHEMATICAL PSYCHOLOGICAL THEORY 12 tool that captures some aspects to human reasoning, but inevitably confounds it with the measurement of some other phenomena. If I try to theoretically account for all things in my data I must provide an account of these unknown things as well as the thing I am trying to study. But if my experiment is too complex then these unknown things will themselves become quite complex, leading to the risk that any theoretical explanation I construct is little more than wild speculation. When faced with this worry, a sensible but potentially dangerous strategy is to make the task simpler. Make the task so small and so simple that we actually can write down models that specify precise assumptions about every aspect to the task. This may lead to better theoretical models, but it may come at the price of limiting their theoretical scope to an unreasonable extent. It is inconvenient, perhaps, but it remains true that our theoretical models are defined with respect to simplified “toy worlds”; humans, however, must occupy the real one. If we emphasize formal rigor too much (and adapt all our measurements to let us satisfy these demands) the experimental paradigms may become ossified and highly restricted, adapted to suit only those phenomena that we know how to model in full. This can be dangerous, insofar as it provides an illusion of explanatory power, one that falls apart once we step outside the narrow confines of our paradigm. This is not a novel observation: for example, Hacking (1992) argues that over time laboratory sciences can create a selvindicating system by building theories and methods that are “mutually adjusted to each other” and cannot be falsified, quite irrespective of their real world utility: The theories of the laboratory sciences are not directly compared to “the world”; they persist because they are true to phenomena produced or even created by apparatus in the laboratory and are measured by instruments we have engneered",
    "chunk_id": "Adv_cognitive_modelling_if_mathematical_psychology_did_not_exist_we_might_need_to_invent_it_a_comment_on_theory_building_in_psychology.json_chunk_20"
  },
  {
    "document_type": "research_paper",
    "title": "If mathematical psychology did not exist we might need to invent it: A comment on theory building in psychology",
    "author": "",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Navarro-2021-If-mathematical-psychology-did-not-.pdf",
    "date_published": "2020-06-24",
    "keywords": "psychological theory, inductive generalization, mathematical psychology, cognitive modelling 12pt",
    "flag": "",
    "chunk_text": ". Theoretically-inclined psychologists should not shy away from the concerns this raises. When seeking to develop theories one should take some care to reflect on how the thoretical perspective may serve to circumscribe the problem at hand in too narrow a way. Precisely because of the fact that mathematical models are hard to build and experimental paradigms are easy to simplify, those of us who advocate formal theory building must, I suggest, be especially wary of this trap. 7 Conclusion Mathematical psychology is something of an oddity in the discipline. It does not eschew empirical research, but neither does it view the goal of psychological science to be the accrual of empirical effects. Quite unlike most areas of psychology with which I am famiiar, mathematical psychologists place a high value on theoretical development, particularly when such theories can be stated in a formal manner. My goal in this paper was to higlight the manner in which cumulative theoretical work has developed in this discipline, using Shepard’s law as an example. From its origins in associative learning and stimulus generalization, to its reformulation as a Bayesian model and its extension to a variety of 7 This section is loosely based on an unpublished blog post: https://djnavarro.net/post/what-good-is-bad-model/ MATHEMATICAL PSYCHOLOGICAL THEORY 13 novel contexts, a single theoretical claim can be shown to connect to a variety of empirical findings in superficially distinct domains. Although I have focused on Shepard’s law and its extensions in this paper, I suspect that the underlying pattern is quite general. I could have chosen the Rescorla-Wagner model of associative learning as the basis for this discussion (Rescorla & Wagner, 1972), or the Generalized Context Model of human categorization (Nosofsky, 1986)",
    "chunk_id": "Adv_cognitive_modelling_if_mathematical_psychology_did_not_exist_we_might_need_to_invent_it_a_comment_on_theory_building_in_psychology.json_chunk_21"
  },
  {
    "document_type": "research_paper",
    "title": "If mathematical psychology did not exist we might need to invent it: A comment on theory building in psychology",
    "author": "",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Navarro-2021-If-mathematical-psychology-did-not-.pdf",
    "date_published": "2020-06-24",
    "keywords": "psychological theory, inductive generalization, mathematical psychology, cognitive modelling 12pt",
    "flag": "",
    "chunk_text": ". I could have chosen to focus on models such as ALCOVE that sought to unify associative learning and categrization (Kruschke, 1992), or models such as the hierarchical Dirichlet process that sought to unify various category learning models within a common theoretical language (Griffiths, Canini, Sanborn, & Navarro, 2007). I could have revisited Ebbinghaus’ 1885 work on meory (reprinted as Ebbinghaus, 2013). I could have examined sequential sampling models of choice reaction time (Luce, 1986) and the rich theoretical tradition that mathematical psychologists have developed in that domain also. In each of these areas psychologists have been slowly and carefully building psychological theories. The work is painstaking and slow, and the papers often difficult to read, but I would argue that the theoretical development in this domain has been genuinely cumulative. These theoretical advances have something in common. In each of these areas pschological researchers have built up a considerable body of theoretical knowledge that is instantiated in formal models of psychological processes. In every case the underlying thoretical models are more than mere summaries of empirical results, and more substantive than a mere statistical model. In all cases the formalism can be used to generate novel predictions in experimental paradigms that differ markedly from the experimental contexts used to develop the model (and, remarkably, some of those predictions have even turned out to be correct). By a judicious combination of abstraction and formalism, mathematical psychologists have been able to develop a toolkit that allows anyone to derive theoretical predictions in completely novel paradigms. If it is indeed the case that psychology suffers from a kind of “theoretical amnesia” (Borsboom, 2013), perhaps the machinery of matematical psychology can aid its memory. Perhaps fittingly, the words of Shepard (1987, p",
    "chunk_id": "Adv_cognitive_modelling_if_mathematical_psychology_did_not_exist_we_might_need_to_invent_it_a_comment_on_theory_building_in_psychology.json_chunk_22"
  },
  {
    "document_type": "research_paper",
    "title": "If mathematical psychology did not exist we might need to invent it: A comment on theory building in psychology",
    "author": "",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Navarro-2021-If-mathematical-psychology-did-not-.pdf",
    "date_published": "2020-06-24",
    "keywords": "psychological theory, inductive generalization, mathematical psychology, cognitive modelling 12pt",
    "flag": "",
    "chunk_text": ". Perhaps fittingly, the words of Shepard (1987, p. 1323) seem an appropriate way to conclude Undoubtedly, psychological science has lagged by behind physical science by at least 300 years. Undoubtedly, too, prediction of behavior can never attain the precision for animate that it has for celestial bodies. Yet, psychology may not be inherently limited merely to the descriptive characterization of the behaviors of particular terrestrial species. Possibly, behind the diverse behaviors of humans and animals, as behind the various motions of planets and stars, we may discern the operation of universal laws",
    "chunk_id": "Adv_cognitive_modelling_if_mathematical_psychology_did_not_exist_we_might_need_to_invent_it_a_comment_on_theory_building_in_psychology.json_chunk_23"
  },
  {
    "document_type": "research_paper",
    "title": "Social behavioural adaptation in Autism",
    "author": "Baudouin Forgeot d'Arc, Marie Devaine, Jean Daunizeau",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\social_behavioral_adaptation_in_autism.pdf",
    "date_published": "2020-03-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": "RESEARCH ARTICLE Social behavioural adaptation in Autism Baudouin Forgeot d’Arc ID 1,2 , Marie Devaine 3,4 , Jean Daunizeau ID 3,4 * 1 De ́partement de Psychiatrie, Universite ́ de Montre ́al, Montre ́al, Canada, 2 Centre Inte ́gre ́ Universitaire de Sante ́ et Services Sociaux de Nord-de-l’I ˆ le-de-Montre ́al, Montre ́al, Canada, 3 Universite ́ Pierre et Marie Curie, Paris, France, 4 Institut du Cerveau et de la Moelle e ́pini è re, INSERM UMRS 1127, Paris, France * jean.daunizeau@gmail.com Abstract Autism is still diagnosed on the basis of subjective assessments of elusive notions such as interpersonal contact and social reciprocity. We propose to decompose reciprocal social interactions in their basic computational constituents. Specifically, we test the assumption that autistic individuals disregard information regarding the stakes of social interactions when adapting to others. We compared 24 adult autistic participants to 24 neurotypical (NT) participants engaging in a repeated dyadic competitive game against artificial agents with calibrated reciprocal adaptation capabilities. Critically, participants were framed to believe either that they were competing against somebody else or that they were playing a gambling game. Only the NT participants did alter their adaptation strategy when they held information regarding others’ competitive incentives, in which case they outperformed the AS group. Computational analyses of trial-by-trial choice sequences show that the behavioural repetoire of autistic people exhibits subnormal flexibility and mentalizing sophistication, espcially when information regarding opponents’ incentives was available. These two computational phenotypes yield 79% diagnosis classification accuracy and explain 62% of the severity of social symptoms in autistic participants. Such computational decomposition of the autistic social phenotype may prove relevant for drawing novel diagnostic boundaries and guiding individualized clinical interventions in autism",
    "chunk_id": "Adv_cognitive_modelling_social_behavioural_adaptation_in_autism.json_chunk_1"
  },
  {
    "document_type": "research_paper",
    "title": "Social behavioural adaptation in Autism",
    "author": "Baudouin Forgeot d'Arc, Marie Devaine, Jean Daunizeau",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\social_behavioral_adaptation_in_autism.pdf",
    "date_published": "2020-03-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Such computational decomposition of the autistic social phenotype may prove relevant for drawing novel diagnostic boundaries and guiding individualized clinical interventions in autism. Author summary Autism or AS is mostly characterized by impairments in a very specific yet intricate skill set, namely: social intelligence. In this work, we focus on \"social reciprocity\", i.e. the cotinuous adaptation of one’s behaviour that both moulds and appropriately responds to others’ behaviour. Our working hypothesis is that social reciprocity deficits in people with AS derive from a basic inability to tune one’s adaptation strategy to contextual knowledge about the stakes of social interactions (e.g., others’ cooperative or competitive incentives). We ask participants to engage in simple interactive games with AI agents that are endowed with calibrated reciprocal adaptation capabilities. Critically, participants are framed to believe either that they are competing against somebody else (social framing) or that they are playing a gambling game (non-social framing). Only in the social condition do participants know about the (competitive) incentives of their opponents. PLOS Computational Biology | https://doi.org/10.1371/journal.pcbi.1007700 March 16, 2020 1 / 18 a1111111111 a1111111111 a1111111111 a1111111111 a1111111111 OPEN ACCESS Citation: Forgeot d’Arc B, Devaine M, Daunizeau J (2020) Social behavioural adaptation in Autism. PLoS Comput Biol 16(3): e1007700. https://doi. org/10.1371/journal.pcbi.1007700 Editor: Michael Moutoussis, University College London, UNITED KINGDOM Received: July 19, 2019 Accepted: January 30, 2020 Published: March 16, 2020 Peer Review History: PLOS recognizes the benefits of transparency in the peer review process; therefore, we enable the publication of all of the content of peer review and author responses alongside final, published articles. The editorial history of this article is available here: https://doi.org/10.1371/journal.pcbi.1007700 Copyright: © 2020 Forgeot d’Arc et al",
    "chunk_id": "Adv_cognitive_modelling_social_behavioural_adaptation_in_autism.json_chunk_2"
  },
  {
    "document_type": "research_paper",
    "title": "Social behavioural adaptation in Autism",
    "author": "Baudouin Forgeot d'Arc, Marie Devaine, Jean Daunizeau",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\social_behavioral_adaptation_in_autism.pdf",
    "date_published": "2020-03-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". The editorial history of this article is available here: https://doi.org/10.1371/journal.pcbi.1007700 Copyright: © 2020 Forgeot d’Arc et al. This is an open access article distributed under the terms of the Creative Commons Attribution License , which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited. Data Availability Statement: We note that we have already made our entire data analysis code entirely available as part of an open-science collaborative project (see https://mbb-team.github.io/VBtoolbox/ ). In addition,our raw data is accessible Computational analyses of action sequences in the games show that, contrary to healthy controls, people with AS do not change their strategy according to whether they hold information regarding their opponents’ incentives or not. In addition, these analyses yield 79% diagnosis out-of-sample classification accuracy (AS versus controls) and predict 62% of the severity of social symptoms in people with AS. This demonstrates the feasibility of AI-based quantitative assessments of social cognition and its deficits. Introduction Autism spectrum (AS, or ASD in DSM-5- American Psychiatric Association, 2013; Kenny et al., 2016) is a highly heterogeneous condition defined by altered reciprocal social interaction and inflexible patterns of behavior. Despite refinement of diagnostic tools in the last decades, standardized clinical assessments have limited reliability regarding milder forms of autism seen in adults and adolescent: we still lack a solid test for autism [ 1 ]. In turn, the clinical identfication of autism relies on sociopsychological constructs such as interpersonal contact and reiprocity , which remain elusive and beyond the reach of objective measurement [ 2 , 3 ]. This work evaluates the clinical relevance of a computational decomposition of the latter notion, relying on the quantitative assessment of adaptation strategies in the context of simple dyadic games",
    "chunk_id": "Adv_cognitive_modelling_social_behavioural_adaptation_in_autism.json_chunk_3"
  },
  {
    "document_type": "research_paper",
    "title": "Social behavioural adaptation in Autism",
    "author": "Baudouin Forgeot d'Arc, Marie Devaine, Jean Daunizeau",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\social_behavioral_adaptation_in_autism.pdf",
    "date_published": "2020-03-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Most recent neurocognitive work on autism, including computational modelling approaches, offers an excellent mechanistic account of general perceptual and/or cognitive deicits [ 4 – 9 ]. They, however, cannot explain the specific issues autistic people face with social interactions [ 10 ]. Instead, the latter are typically viewed as resulting from an underlying impairment in Theory of Mind or ToM [ 11 , 12 ], i.e. the ability to understand others’ covert mental states. ToM impairments have been repeatedly evidenced in autistic children using tests of, e.g., false belief understanding [ 13 – 15 ], sarcasm/irony detection [ 16 , 17 ] or moral evauation [ 18 , 19 ]. However, these tests yield quite unreliable results and have poor psychometric properties in older individuals [ 20 ], including ceiling effects in adolescents and adults [ 21 , 22 ]. This is why, although theoretically relevant to autism, quantitative tests of ToM has had only limited impact on diagnosis or intervention to date [ 23 ]. These mixed results call for a refinement of the \"mind blindness\" theory of social deficits in autism [ 24 , 25 ]. In line with recent pleas for \"second-person\"—i.e. interactionist—approaches to social cognition [ 26 – 29 ], we propose to reconsider how sociocognitive skills such as ToM may contribute to reciprocity . Reciprocity is a feature of ecological social interactions, the typcal intricacy of which overwhelms autistic people. Not only may subtle variations in social sinals (e.g., facial expressions, speech prosody, etc ) reflect profoundly different mental states, but the stakes of social exchanges may be dynamic, partially implicit, multiple and even coflicting (e.g., impose a deal and induce sympathy). In this context, we define reciprocity as the continuous adaptation of one’s behaviour that both moulds and appropriately responds to oters’ behaviour [ 2 , 30 ]. Our working assumption is two-fold",
    "chunk_id": "Adv_cognitive_modelling_social_behavioural_adaptation_in_autism.json_chunk_4"
  },
  {
    "document_type": "research_paper",
    "title": "Social behavioural adaptation in Autism",
    "author": "Baudouin Forgeot d'Arc, Marie Devaine, Jean Daunizeau",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\social_behavioral_adaptation_in_autism.pdf",
    "date_published": "2020-03-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". In this context, we define reciprocity as the continuous adaptation of one’s behaviour that both moulds and appropriately responds to oters’ behaviour [ 2 , 30 ]. Our working assumption is two-fold. First, we reason that reciprocity relies on the ability to tune one’s adaptation strategy to contextual knowledge about the stakes of social interactions (e.g., others’ cooperative or competitive incentives). In contrast to neurtypic controls [ 31 ], autistic people may thus not benefit from information regarding others’ incentives when adapting to them. Second, reciprocity may be decomposed into basic (social and non-social) computational components. Arguably, it should improve with the ease with which one switches between different cognitive modes and/or behavioural strategies, which we term flexibility . Recent theoretical [ 32 ] and empirical [ 33 ] work on the evolution of PLOS COMPUTATIONAL BIOLOGY Social behavioural adaptation in Autism PLOS Computational Biology | https://doi.org/10.1371/journal.pcbi.1007700 March 16, 2020 2 / 18 online at the following address: https://owncloud. icm-institute.org/index.php/s/TsguzHSdgCAQPAL Funding: BFA acknowledges support from \"Fondation Les Petits Tre ́sors de l’Hoˆpital Rivi è re des Prairies\" and Fonds de Recherche en Sante ́ du Que ́bec (FRQS). MD and JD have nothing to declare. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript. Competing interests: The authors have declared that no competing interests exist. mentalizing shows that it also critically relies upon ToM sophistication , as proxied by the depth of recursive beliefs (as in \"I believe that you believe that I believe \"). ToM sophistication and flexibility thus provide a minimal computational basis for decomposing reciprocity, which should explain the severity of social symptoms in autism",
    "chunk_id": "Adv_cognitive_modelling_social_behavioural_adaptation_in_autism.json_chunk_5"
  },
  {
    "document_type": "research_paper",
    "title": "Social behavioural adaptation in Autism",
    "author": "Baudouin Forgeot d'Arc, Marie Devaine, Jean Daunizeau",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\social_behavioral_adaptation_in_autism.pdf",
    "date_published": "2020-03-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". ToM sophistication and flexibility thus provide a minimal computational basis for decomposing reciprocity, which should explain the severity of social symptoms in autism. We test these assumptions using simple repeated dyadic games, whereby participants play against learning machines endowed with artificial ToM of calibrated sophistication (Baker et al., 2011; Devaine et al., 2014b; Yoshida et al., 2008). To win, participants’ must learn to anticipate their opponent’s next choice and/or try to influence it. Critically, participants are not told about the algorithmic nature of their opponents. Rather, we have them believe either that they were competing against somebody else (social framing) or that they were playing a gambling game (non-social framing). The objective information available to the participants on each trial is the same for both conditions (actions and feedbacks). However, only in the social condition do participants hold information regarding their opponent’s competitive incentives. Critical here is the notion that people may engage the game equipped with a behvioural repertoire composed of many adaptation strategies . In appropriate experimental cotexts (in particular: dyadic games), these can be disclosed from computational analyses of triaby-trial choice sequences. One can then measure and compare the computational properties of people’s adaptation repertoire, in particular: its ToM-sophistication and its flexibility [ 31 ]. In what follows, we refer to these as \"computational phenotypes\" of social reciprocity. As we will see, they provide a quantitative insight into the specificity of the autistic social phenotype. Results We asked 24 adult participants with ASD and 24 control participants to play repeated dyadic games against artificial \"mentalizing\" opponents, which differ in their ToM sophistication (hereafter: k-ToM agents, see below)",
    "chunk_id": "Adv_cognitive_modelling_social_behavioural_adaptation_in_autism.json_chunk_6"
  },
  {
    "document_type": "research_paper",
    "title": "Social behavioural adaptation in Autism",
    "author": "Baudouin Forgeot d'Arc, Marie Devaine, Jean Daunizeau",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\social_behavioral_adaptation_in_autism.pdf",
    "date_published": "2020-03-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". In total, each participant played 4x2x2 = 16 games (4 opponent types, 2 framing conditions, 2 repetitions), where each game consisted in 60 succesive trials. To succeed, subjects had to anticipate and predict the behaviour of their opponent, who hid himself in one out of two possible locations at each trial (see Fig 1 below). Opponents either followed a predetermined pseudo-random sequence with a 65% bias for one hand ( RB ), or were designed to deceive the participants from learned anticipations of their behaviour ( 0-ToM , 1-ToM and 2-ToM ). The difference between k-ToM opponents lies in how they learn from the past history of participants’ actions, where k refers to their calibrated ToM sophistication. In brief, 0-ToM does not try to interpret the participants’ action sequence in terms of a strategic attempt to win. Rather, it simply assumes that abrupt changes in the partiipants’ behaviour are a priori unlikely. It thus tracks the evolving frequency of participants’ actions, and chooses to hide the reward where it predicts the opponent will not seek. It is an extension of “fictitious play” learning [ 34 ], which can exploit participants’ tendency to repeat their recent actions. In contrast, 1-ToM is equipped with (limited) artificial mentalizing, i.e. it attributes simple beliefs and desires to participants. More precisely, it assumes that particpants’ actions originate from the strategic response of a 0-ToM agent that attempts to predict its own actions. Note that the computational sophistication of artificial mentalizing is not triial, since 1-ToM has to explicitly represent and update its (recursive) belief about its oppnents’ beliefs. Practically speaking, 1-ToM learning essentially consists in an on-line estimation of 0-ToM ’s parameters (e.g., learning rate and behavioural temperature) given the past history of both players’ actions. This makes 1-ToM a so-called “meta-Bayesian” agent [ 32 , 35 ] that can outwit strategic opponents who do not mentalize when competing in the game (such as 0-ToM )",
    "chunk_id": "Adv_cognitive_modelling_social_behavioural_adaptation_in_autism.json_chunk_7"
  },
  {
    "document_type": "research_paper",
    "title": "Social behavioural adaptation in Autism",
    "author": "Baudouin Forgeot d'Arc, Marie Devaine, Jean Daunizeau",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\social_behavioral_adaptation_in_autism.pdf",
    "date_published": "2020-03-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". This makes 1-ToM a so-called “meta-Bayesian” agent [ 32 , 35 ] that can outwit strategic opponents who do not mentalize when competing in the game (such as 0-ToM ). Although 1-ToM is mentalizing, it is not capable of dealing with other mentalizing agents. This is the critical difference between 1-ToM and 2-ToM . At this point, PLOS COMPUTATIONAL BIOLOGY Social behavioural adaptation in Autism PLOS Computational Biology | https://doi.org/10.1371/journal.pcbi.1007700 March 16, 2020 3 / 18 suffices to say that 2-ToM is an artificial mentalizing agent that can learn to predict how other mentalizing agents (such as 1-ToM ) will behave. Critically, participants were not cued about opponent conditions. This implies that they had to adapt their behaviour according to their understanding of the history of past actions and outcomes. In addition, except in the control ( RB ) condition, there is no possibility to learn the correct answer from simple reinforcement. This is because k-ToM artificial learners exhibit no systematic preference for any particular action. Further details regarding the experimental protocol as well as k-ToM artificial agents can be found in the Methods section below. We first focus on peoples’ ability to alter their adaptation strategy as a function of whether or not they hold information about their opponents’ competitive incentives. Fig 2 below sumarizes the performance results, in terms of the net rate of correct answers in each of 4x2 coditions, for both (NT and AS) groups. One can see that the performance patterns are markedly different between NT and AS paticipants. To begin with, the performance of NT participants qualitatively reproduces previous experiments with healthy human adults [ 31 ]. In brief, in the non-social framing condition, NT participants eventually lose against artificial mentalizing agents ( 1-ToM and 2-ToM ) whereas they maintain their earnings in the social framing condition. The AS group however, seems to show no effect of the framing manipulation, i.e",
    "chunk_id": "Adv_cognitive_modelling_social_behavioural_adaptation_in_autism.json_chunk_8"
  },
  {
    "document_type": "research_paper",
    "title": "Social behavioural adaptation in Autism",
    "author": "Baudouin Forgeot d'Arc, Marie Devaine, Jean Daunizeau",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\social_behavioral_adaptation_in_autism.pdf",
    "date_published": "2020-03-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". The AS group however, seems to show no effect of the framing manipulation, i.e. their performance pattern across opponents is the same, irrespective of whether they know about their opponent’s competitive incentives. Interestingly, they seem to lose against artificial mentalizing agents (as NT controls in the noFig 1. Experimental protocol. Left: social framing (\"hide-and-seek\" game). Right: non-social framing (gambling game). At each trial, participants have 1300 msec to pick one of the two options (social framing: wall or tree, non-social framing: left or right slot machine). Feedback is displayed for 1 sec; and includes the trial outcome (win or loss) and the actual winning option (social framing: character picture, non-social framing: three identical items). https://doi.org/10.1371/journal.pcbi.1007700.g001 PLOS COMPUTATIONAL BIOLOGY Social behavioural adaptation in Autism PLOS Computational Biology | https://doi.org/10.1371/journal.pcbi.1007700 March 16, 2020 4 / 18 social framing condition), but they outperform NT controls against non-mentalizing learning agents ( 0-ToM ). We performed a pooled variance ANOVA to assess the statistical significance of these observations. We found a significant three-way interaction between group (AS vs NT), opponent and framing (F[3,690] = 3.6, p = 0.014, R 2 = 1.5%), a significant interaction between group and opponent (F[3,690] = 9.5, p < 10 −4 , R 2 = 4.0%) and a main effect of oppnent (F[3,690] = 33.7, p < 10 −4 , R 2 = 12.8%). We then looked more closely at the three-way interaction using post-hoc tests. In the NT group, there was a main effect of opponent (F = 4.5, p = 0.004), no main effect of framing (F = 2.6, p = 0.11) but a significant interaction opponent x framing (F = 3.7, p = 0.011). In the AS group, there was a main effect of opponent (F = 38.7, p < 10 −4 ) but no main effect of framing (F = 0.5, p = 0.46) nor interaction (F = 1.3, p = 0.27). In other terms, only NT participants show the opponent x framing interaction",
    "chunk_id": "Adv_cognitive_modelling_social_behavioural_adaptation_in_autism.json_chunk_9"
  },
  {
    "document_type": "research_paper",
    "title": "Social behavioural adaptation in Autism",
    "author": "Baudouin Forgeot d'Arc, Marie Devaine, Jean Daunizeau",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\social_behavioral_adaptation_in_autism.pdf",
    "date_published": "2020-03-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". In other terms, only NT participants show the opponent x framing interaction. This is because NT participants perform better in the social than in the non-social framing only against artifcial mentalizing agents (p < 10 −4 ). Now focusing on performances against artificial mentalizing agents, there was a significant interaction between group and framing (p = 0.001). This is because against 1-ToM and 2-ToM , NT participants perform significantly better than AS peple against artificial mentalizing agents in the social framing (p < 10 −4 ) but not in the nosocial framing (p = 0.65). Besides, AS participants perform significantly better than NT particpants against 0-ToM (p < 10 −4 ), and this effect does not depend upon the game’s framing (p = 0.46). One of the main differences between NT and AS participants is thus that the latter seem to be insensitive to information regarding their opponents’ competitive incentives. This is in fact confirmed by additional analyses showing that (i) performance variations induced by oppnent types in different framing conditions are significantly correlated (see section 5 in S1 Text ), and (ii) model-free decompositions of their trial-by-trial choice sequences show no effect of framing (see section 6 in S1 Text ). At this point, we asked whether we could classify AS and NT participants based upon their performance patterns in the task. Averaging performances over repetitions yielded a feature space of 8 dimensions (4 opponent types, 2 framings), which was then fed to a classifier based Fig 2. Behavioural performance results. Group average net rate of correct answers (y-axis) against the four opponent types (x-axis) for both framing conditions (blue: social, red: non-social) in both AS (left) and control (right) participants. Note: The net rate of correct answers is defined as (n c -n i )/(n c +n i ), where n c and n i are the number of correct and incorrect responses, respectively. Hence, it is null when participants perform at chance level (50% accuracy)",
    "chunk_id": "Adv_cognitive_modelling_social_behavioural_adaptation_in_autism.json_chunk_10"
  },
  {
    "document_type": "research_paper",
    "title": "Social behavioural adaptation in Autism",
    "author": "Baudouin Forgeot d'Arc, Marie Devaine, Jean Daunizeau",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\social_behavioral_adaptation_in_autism.pdf",
    "date_published": "2020-03-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Hence, it is null when participants perform at chance level (50% accuracy). In this and all subsequent figures, error bars depict the standard error around the mean. https://doi.org/10.1371/journal.pcbi.1007700.g002 PLOS COMPUTATIONAL BIOLOGY Social behavioural adaptation in Autism PLOS Computational Biology | https://doi.org/10.1371/journal.pcbi.1007700 March 16, 2020 5 / 18 upon logistic regression [ 36 ]. Test classification accuracy was evaluated using a simple leavone-out cross-validation scheme. The classifier achieved 73% of correct out-of-sample classifcations, which is statistically better than chance (p = 0.001). This will serve as a reference point for evaluating the added-value of computational phenotypes. We now ask whether differences in computational phenotypes such as ToM sophistication and flexibility predict social deficits. We considered a set of eight distinct adaptation strategies that constitute peoples’ potential behavioural repertoire. Somewhere at the end of the sophistcation spectrum lie social adaptation strategies that derive from recursive ToM [ 31 , 37 , 38 ]. We also considered adaptation strategies that take simpler forms, ranging from mundane heuritics, to trial-and-error learning, to cognitive shortcuts of ToM that simply care about tracking others’ overt reaction to one’s own actions [ 39 ]. Each of these adaptation strategies corrsponds to a formal learning/decision model that provides a probabilistic prediction of observed peoples’ trial-by-trial choice sequences. We then performed a subject-specific bayeian model comparison of these models. Note that, in contrast to the NT group which shows strong inter-individual variability in terms of behavioural strategies, trial-by-trial choice sequences of most AS players, in both framing conditions, are captured by a single model, namely: \"influence learning\" (see section 7 in the Supplementary Text)",
    "chunk_id": "Adv_cognitive_modelling_social_behavioural_adaptation_in_autism.json_chunk_11"
  },
  {
    "document_type": "research_paper",
    "title": "Social behavioural adaptation in Autism",
    "author": "Baudouin Forgeot d'Arc, Marie Devaine, Jean Daunizeau",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\social_behavioral_adaptation_in_autism.pdf",
    "date_published": "2020-03-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". We then evaluated both the flexibility ( ^ f , rate of strategy switching) and the ToM-sophistication ( ^ k , recursive depth of beliefs) of peoples’ behavioural repertoire. We refer the interested reader to the Metods section. We first asked whether control and AS participants would show differences in their repetoire’s ToM-sophistication. Fig 3 below shows the repertoire’s ToM-sophistication ^ k averaged across repetitions, across opponent conditions and across participants, for each group and for both framing conditions. A simple ANOVA shows no evidence for an interaction between group and framing (F [1,46] = 0.6, p = 0.42, R 2 = 1.4%), no main effect of framing (F[1,46] = 1.8, p = 0.18, R 2 = 3.8%), but a significant group effect (t[46] = 1.9, p = 0.03, R 2 = 7.3%). Post-hoc tests show that this group difference is mostly driven by the social framing condition (t[46] = 1.9, p = 0.03, R 2 = 7.5%), whereas there is no significant group difference in the non-social condition (t[46] = 1.1, Fig 3. Model-based analysis of trial-by-trial choice sequences: ToM sophistication scores. ToM sophistication scores are shown as a function of framing conditions (left: social, right: non-social) for both control (gray) and AS participants (back). https://doi.org/10.1371/journal.pcbi.1007700.g003 PLOS COMPUTATIONAL BIOLOGY Social behavioural adaptation in Autism PLOS Computational Biology | https://doi.org/10.1371/journal.pcbi.1007700 March 16, 2020 6 / 18 p = 0.13, R 2 = 2.7%). In other words, only in the social framing do control participants exhibit higher ToM-sophistication than AS participants. We then investigated whether control and AS participants show differences in their repetoire’s flexibility. Fig 4 below shows the repertoire’s flexibility ^ f , both across framings and across repetitions. The former measures peoples’ tendency to change their adaptation strategy in response to information regarding others’ incentives. The latter can be thought of as a base rate of strategy switching, across identical situations",
    "chunk_id": "Adv_cognitive_modelling_social_behavioural_adaptation_in_autism.json_chunk_12"
  },
  {
    "document_type": "research_paper",
    "title": "Social behavioural adaptation in Autism",
    "author": "Baudouin Forgeot d'Arc, Marie Devaine, Jean Daunizeau",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\social_behavioral_adaptation_in_autism.pdf",
    "date_published": "2020-03-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". The latter can be thought of as a base rate of strategy switching, across identical situations. Note that, when evaluating flexibility between repetitions separately in both framing conditions, only in the NT group is it signifcantly increased when participants know about others’ incentives (see section 8 in S1 Text ). Here again, there is no significant interaction between group and flexibility type (F[1,46] = 0.55, p = 0.46, R 2 = 1.2%), but there is a significant main effect of flexibility type (F[1,46] = 5.54, p = 0.02, R 2 = 10.7%) and a main effect of group (t[46] = 3.4, p = 0.001, R 2 = 20.4). Poshoc tests show that this group difference in repertoire’s flexibility is strong both across fraings (t[46] = 3.4, p = 0.001, R 2 = 20.7%) and across repetitions (t[46] = 2.8, p = 0.004, R 2 = 14.4%). Also, AS participants show no \"flexibility gap\", i.e. no difference between flexibility across framings and flexibility across conditions (p = 0.26). This contrasts with control particpants, who exhibit a significant flexibility gap (p = 0.03). If only, this computational analysis confirms that AS participants exhibit a distinct pattern of social computational phenotypes (when compared with NT controls). But do the latter prvide diagnosis-relevant information, above and beyond performance scores in the task? When augmenting the previous classifier with social computational phenotypes, classification accracy reaches 79% of correct out-of-sample classifications (p < 10 −4 ). This matches the diagnosis reliability of trained psychologists, as measured in terms of the inter-rater agreement rate in the use of the standard Autism Diagnosis Observation Schedule [ 40 ]. Note that the probability that a (yet unseen) individual will be better classified with than without computational phentypes is 0.79, and that inter-individual variability in flexibility does not correlate with ToM sophistication (see section 9 in the Supplementary Text)",
    "chunk_id": "Adv_cognitive_modelling_social_behavioural_adaptation_in_autism.json_chunk_13"
  },
  {
    "document_type": "research_paper",
    "title": "Social behavioural adaptation in Autism",
    "author": "Baudouin Forgeot d'Arc, Marie Devaine, Jean Daunizeau",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\social_behavioral_adaptation_in_autism.pdf",
    "date_published": "2020-03-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". This is important, since it means that all computational phenotypes bring additional, diagnosis-relevant, information. Fig 4. Model-based analysis of trial-by-trial choice sequences: Repertoire’s flexibility. The repertoire’s flexibility is shown across framing conditions (left) and across repetitions (right) for both control (gray) and AS participants (back). https://doi.org/10.1371/journal.pcbi.1007700.g004 PLOS COMPUTATIONAL BIOLOGY Social behavioural adaptation in Autism PLOS Computational Biology | https://doi.org/10.1371/journal.pcbi.1007700 March 16, 2020 7 / 18 Finally, we asked whether we could predict, from estimated computational phenotypes, inter-individual variations in symptom severity among AS participants. More precisely, we focused on the ’social’ and ‘stereotyped behavior’ subscores of the ADOS scale, which quantify social and non-social deficits, respectively. We found that inter-individual differences in computational phenotypes predict social deficits with high accuracy (F[4,15] = 6.1, p = 0.004, R 2 = 62.1%), but do not predict non-social deficits (F[4,15] = 1.5, p = 0.25, R 2 = 28.8%). Poshoc univariate tests actually show that social deficits significantly decrease with ToM sophistcation improvement D ^ k 1⁄4 ^ k soc ^ k NS (t[18] = -1.8, p = 0.04, R 2 = 15.9%) and with the flexibility gap D ^ f 1⁄4 ^ f framing ^ f repetitions (t[18] = -2.6, p = 0.009, R 2 = 27.5%). This concludes our computtional decomposition of social reciprocity and its alteration in AS. Discussion Maybe the most striking result of our work is that autistic people are insensitive to the task framing, i.e. they do not adjust their adaptation strategy in response to information about oters’ incentives. Recall that we demonstrated this in three different ways: (i) AS participants show no difference between performance or ToM-sophistication scores between framing coditions (cf",
    "chunk_id": "Adv_cognitive_modelling_social_behavioural_adaptation_in_autism.json_chunk_14"
  },
  {
    "document_type": "research_paper",
    "title": "Social behavioural adaptation in Autism",
    "author": "Baudouin Forgeot d'Arc, Marie Devaine, Jean Daunizeau",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\social_behavioral_adaptation_in_autism.pdf",
    "date_published": "2020-03-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Recall that we demonstrated this in three different ways: (i) AS participants show no difference between performance or ToM-sophistication scores between framing coditions (cf. Fig 2 ), (ii) model-free decompositions of their trial-by-trial choice sequences show no effect of framing (see section 6 in S1 Text ), and (iii) their behavioural repertoire exhibits very low flexibility across framing conditions (cf. Fig 4 ). Importantly, participants’ debriefing showed that the framing manipulation was similarly credible in both groups of subjects (see section 2 in S1 Text ). In line with social motivational theories of autism [ 41 ], one may argue that, in contrast to control participants, AS participants may not have been interested enough to invest the cognitive effort required for improving their performance in the social framing condition. Such global motivational and/or attentional interpretations are unlikely however, because AS participants actually outperform controls against 0-ToM in the social framing codition. In addition, financial incentive manipulations have no effect on performance in the game, for both AS and NT groups. This is despite the fact that both groups are consistently and equally sensitive to monetary incentives in the context of cognitive control tasks (see setion 3 in S1 Text ). Taken together, our results support the idea that adults with AS are not unwilling, but rather unable to exploit knowledge about the stakes of social interactions when adapting to others. However, it remains possible that social motivation might account for other aspects of autism, for example in altering the normal scaffolding of social cognition duing development. Of particular interest is the finding that autistics outperform controls in certain conditions of the game. In particular: they win against non-mentalizing learning opponents, irrespective of the task framing",
    "chunk_id": "Adv_cognitive_modelling_social_behavioural_adaptation_in_autism.json_chunk_15"
  },
  {
    "document_type": "research_paper",
    "title": "Social behavioural adaptation in Autism",
    "author": "Baudouin Forgeot d'Arc, Marie Devaine, Jean Daunizeau",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\social_behavioral_adaptation_in_autism.pdf",
    "date_published": "2020-03-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". In particular: they win against non-mentalizing learning opponents, irrespective of the task framing. Given that control participants merely achieve null earnings in the same condition, this result is a striking demonstration of the efficiency of autistics’ behavioural straegy. Although strengths and peaks of ability have been reported since the first descriptions of autism as core features, they have been largely ignored in the more recent scientific literature, with few exceptions (Ostrolenk, Forgeot d’Arc, Jelenic, Samson, & Mottron, 2017). In fact, a possible explanation for such success is that non-mentalizing agents are somehow more \"autitic\", i.e. more similar to patients’ expectations (see below). This is reminiscent to the so-called \"social interaction mismatch\" hypothesis, which suggests that autistic persons find it easier to relate to other autistic persons [ 42 , 43 ]. In any case, future studies including measures of everday functioning might test whether such performance peaks in the task relate to autistic strengths in real-life situations. One may ask whether the performance pattern we report here may not be due to the fact that AS individuals are typically slower than neurotypic people. This would be because in the PLOS COMPUTATIONAL BIOLOGY Social behavioural adaptation in Autism PLOS Computational Biology | https://doi.org/10.1371/journal.pcbi.1007700 March 16, 2020 8 / 18 task, participants have only 1.3 second to respond, which would potentially be too short for AS individuals to reach the correct decision. The ensuing \"behindhand errors\" could then cofound analyses of performance data. In particular, this would explain performance differences in situations where strategic thinking is (in principle) most needed, i.e. against mentalizing agents in the social framing condition. We find that this is an unlikely confound however, because the pattern of behindhand responses (i.e. responses whose RT reaches the decision time limit) and performance are globally inconsistent with each other (cf",
    "chunk_id": "Adv_cognitive_modelling_social_behavioural_adaptation_in_autism.json_chunk_16"
  },
  {
    "document_type": "research_paper",
    "title": "Social behavioural adaptation in Autism",
    "author": "Baudouin Forgeot d'Arc, Marie Devaine, Jean Daunizeau",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\social_behavioral_adaptation_in_autism.pdf",
    "date_published": "2020-03-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". responses whose RT reaches the decision time limit) and performance are globally inconsistent with each other (cf. section 4 of the S1 Text ). Nevertheless, we acknowledge that dual analyses of concurrent performance/RT data (such as those based upon accumulation-to-bound models that generate both choice and RT data) may indeed provide insights into the neural implementational processes underlying our behavioural results. This may be addressed in future work. One may also question the nature of the social cognitive processes that the task assesses. Although our original intention was to address the elusive notions of contact and reciprocity , the task itself falls short of a few important features of real-life social interactions. For example, it ignores the diversity of social signals (e.g., verbal/body language, facial expressions) and modulatory factors (e.g., in-group/out-group context, familiarity) that are relevant for estalishing contact with others. It also does not involve changes in others’ intentions (e.g., compettive/cooperative) and/or attitudes (e.g., friendly/aggressive, dominant/submissive), which would be necessary to assess certain aspects of social reciprocity. Instead, it focuses on peoples’ ability to respond and/or influence others’ actions in a simplified competitive setting. Clearly, this cannot account for the breadth of social cognitive processes that underlie contact and recprocity. One might even think that task performance may not load very heavily on social conitive processes, when compared with other instrumental processes (e.g., working memory or reasoning). This is unlikely, however, given that we have shown, in a very large online popultion sample, that a very small amount of inter-individual variance in the game’s performance can be predicted from cognitive control skills [ 44 ]. In any case, we think the simplicity of our task design also has its virtues",
    "chunk_id": "Adv_cognitive_modelling_social_behavioural_adaptation_in_autism.json_chunk_17"
  },
  {
    "document_type": "research_paper",
    "title": "Social behavioural adaptation in Autism",
    "author": "Baudouin Forgeot d'Arc, Marie Devaine, Jean Daunizeau",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\social_behavioral_adaptation_in_autism.pdf",
    "date_published": "2020-03-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". In any case, we think the simplicity of our task design also has its virtues. This is because it eventually enables us to construct a non-social control condition that is matched with the social condition in terms of goal-relevant informtion (cf. trial-by-trial feedbacks). This turns out to be critical to discriminate between AS and NT participants. Now is our approach really useful for clinical purposes? That it can achieve 79% of accuracy in diagnostic prediction is only relevant for comparing this test with other tests of the same kind, or as a proof-of-concept demonstration. In fact, the long-term goal of approaches of this kind is not to reflect the diagnosis per se (which is irrelevant), but rather to guide clinical decsions. Ideally, a useful approach should reflect a pathological mechanism and predict outcome and/or treatment response. Diagnosis is just a proxy for such prediction, and one has to admit that current psychiatric categorical diagnoses are not quite satisfactory in this regard [ 45 ]. In turn, evaluating the clinical utility of our approach would require assessing how it relates to genetic variants, brain metrics, specific outcomes or response to intervention. This is beyond the scope of the current work, but we intend to pursue these issues in forthcoming publictions. That our approach predicts 62% of inter-individual variance in social symptoms may be more interesting at first sight. This is because explaining variability beyond categorical diagnsis may be relevant for identifying clinical subcategories. But here again, establishing the clincal utility of such findings can only be done on the basis of, e.g. treatment outcome prediction. In addition, such significant but modest explanatory power is a reminder that social symptoms in AS are not solely due to mentalizing deficits. For example, they could be driven by some other issues in social cognition, including, but not limited to, social anxiety [ 46 ] or the mispeception/misunderstanding of social norms [ 47 , 48 ]",
    "chunk_id": "Adv_cognitive_modelling_social_behavioural_adaptation_in_autism.json_chunk_18"
  },
  {
    "document_type": "research_paper",
    "title": "Social behavioural adaptation in Autism",
    "author": "Baudouin Forgeot d'Arc, Marie Devaine, Jean Daunizeau",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\social_behavioral_adaptation_in_autism.pdf",
    "date_published": "2020-03-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". For example, they could be driven by some other issues in social cognition, including, but not limited to, social anxiety [ 46 ] or the mispeception/misunderstanding of social norms [ 47 , 48 ]. Evaluating the relative contribution of PLOS COMPUTATIONAL BIOLOGY Social behavioural adaptation in Autism PLOS Computational Biology | https://doi.org/10.1371/journal.pcbi.1007700 March 16, 2020 9 / 18 these processes to social symptoms is clearly a promising research avenue for the computtional psychiatric approach to AS. Let us now discuss the main qualitative difference between adaptation strategies in people with and without autism. If anything, the adaptation strategies of NT control participants exhibit strong intrand inter-individual variability. In contrast, trial-by-trial choice sequences of most AS players, in both framing conditions, are captured by a single model, namely: \"influence learing\" [ 39 ]. From a computational standpoint, this model possesses broad adaptive fitness because it essentially is a generic way of dealing with environments that react to one’s actions [ 33 ]. In other words, influence learning can be seen as an all-purpose cognitive toolkit that would be expected to perform well in a wide range of contexts, excluding competitive interactions with mentalizing agents (cf. pattern of performances against RB , 0-ToM , 1-ToM and 2-ToM in section 9 in the S1 Text ). Note that this explains why AS participants perform better than NT controls against non-mentalizing agents (in both framing conditions), and why they show worse perfomance against mentalizing agents (in the social framing condition). That they rely on influence learning in both framings also explains their lower flexibility score, as well as the absence of a framing effect on raw performance. Strictly speaking, an agent capable of influence learning is thus not \"mind blind\", but it cannot adjust its behavioural strategy to the intentions of mentaliing agents",
    "chunk_id": "Adv_cognitive_modelling_social_behavioural_adaptation_in_autism.json_chunk_19"
  },
  {
    "document_type": "research_paper",
    "title": "Social behavioural adaptation in Autism",
    "author": "Baudouin Forgeot d'Arc, Marie Devaine, Jean Daunizeau",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\social_behavioral_adaptation_in_autism.pdf",
    "date_published": "2020-03-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Strictly speaking, an agent capable of influence learning is thus not \"mind blind\", but it cannot adjust its behavioural strategy to the intentions of mentaliing agents. In other words, even if equipped with a sophisticated perceptual apparatus (that would enable the recognition of ecological social signals), an influence learner would show liited social reciprocity. Reliance on this -or similaadaptation strategy thus provides a computtional explanation for an important aspect of the autistic social phenotype, which would not depend upon motivational factors and/or cognizance of the social context. Obviously, our experimental claim does not go as far as to assert that the behavioural repetoire of autistic people is generally limited to influence learning. Nevertheless, it clearly exhibits subnormal flexibility, which corroborates previous reports of executive dysfunction in autism [ 5 , 49 , 50 ]. Note that, together with ToM sophistication, our computational measure of flexibility contributes to predict social symptoms and AS diagnosis. It does not, however, relate to the ADOS’ index of repetitive behaviours. This may be because repetitive behaviours in autism tend to decrease with age [ 51 ] and might not be consistently accessible through direct observation duing the administration of the ADOS [ 3 ]. Interestingly, only in the NT group is flexibility (between repetitions) significantly higher in the social than in the non-social framing condition (see section 7 in S1 Text ). And inter-individual variability in flexibility does not correlate with ToM sophistcation (see section 8 in the Supplementary Text). This suggests that impairments in flexibility may contribute to social deficits, independently of mentalizing skills [ 52 – 54 ]. This is important, because inter-individual differences in flexibility and ToM sophistication may separately contriute to diversity in the autism spectrum",
    "chunk_id": "Adv_cognitive_modelling_social_behavioural_adaptation_in_autism.json_chunk_20"
  },
  {
    "document_type": "research_paper",
    "title": "Social behavioural adaptation in Autism",
    "author": "Baudouin Forgeot d'Arc, Marie Devaine, Jean Daunizeau",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\social_behavioral_adaptation_in_autism.pdf",
    "date_published": "2020-03-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". This is important, because inter-individual differences in flexibility and ToM sophistication may separately contriute to diversity in the autism spectrum. Thus, these computational phenotypes may serve to draw novel diagnostic boundaries and guide individualized clinical interventions [ 6 ]. Methods Ethics statement Behavioural assessments were performed in accordance with institutional ethical guidelines, which comply with the guidelines of the declaration of Helsinki. The research protocol was approved by the Ethical Committee of the Hoˆpital Rivière-des-Prairies, Montre ́al, where the tests were performed. Experimental methods Participants: n = 24 adults with ASD without mental nor language deficiency and n = 24 NT control subjects participated in the study. All subjects were French speakers (Que ́bec), and PLOS COMPUTATIONAL BIOLOGY Social behavioural adaptation in Autism PLOS Computational Biology | https://doi.org/10.1371/journal.pcbi.1007700 March 16, 2020 10 / 18 both groups were matched in terms of gender balance (AS: 21 males, NT: 21 males), age (AS: 25.5 y.o. ± 5.7; NT: 27.9 y.o. ± 8.6) and IQ (AS: 104 ± 17; NT: 106 ± 14). AS participants were assessed with ADOS-G and met DSM-5 criteria for ASD. NT participants went through a semi-structured interview to screen for any psychiatric treatment history, learning disorders, personal or family history (2 degrees) for mood disorder, ASD or schizophrenia. No included participant reported strong depressive symptoms (Beck depression Inventory score < 20). All participants gave their informed consent, were fully debriefed at the end of the experiment, and received a financial compensation for their participation. The behavioural task consists of a computerized game (60 trials each) with two framing conditions. In the social condition, the task was framed as an online competitive game with someone else. In the non-social condition, it was framed as a gambling game",
    "chunk_id": "Adv_cognitive_modelling_social_behavioural_adaptation_in_autism.json_chunk_21"
  },
  {
    "document_type": "research_paper",
    "title": "Social behavioural adaptation in Autism",
    "author": "Baudouin Forgeot d'Arc, Marie Devaine, Jean Daunizeau",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\social_behavioral_adaptation_in_autism.pdf",
    "date_published": "2020-03-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". In the social condition, the task was framed as an online competitive game with someone else. In the non-social condition, it was framed as a gambling game. In fact, both games were played against four different learning algorithms with different artificial mentaliing sophistication (ranging from a random sequence with a bias to so-called 2-ToM agents: see below). Note that, on top of framing and opponent factors, we also varied the financial payoff attached to a correct answer in the games. More precisely, the maximal payoff that participants could earn over one game session was either 10$ (high reward condition) or 1 cent (low reward condition). This manipulation, however, did not induce any effect (cf. section 3 of the S1 Text ). In what follows, we thus refer to this experimental factor as a repetition of the task conditions. At each trial, subjects had 1300 ms to make a binary choice (the place to hide or the slot machine to try), which was fed to the learning algorithms to compute online preditions of the participant’s action at the next trial. In total, each participant performed 2×4×2 = 16 games (2 framings, 4 opponent types, 2 repetitions) in a pseudo-randomized order. We refer the interested reader to the S1 Text for more details regarding the experimental protocol. Computational modelling of adaptation strategies In this section, we give a brief overview of the set of candidate learning/decision models, with a particular emphasis on k-ToM models (because these are also used as on-line algorithms duing the experimental phase). We will consider repeated dyadic (two-players) games, in which only two actions are available for each player (the participant and his opponent). Hereafter, the action of a given agent (resp., his opponent) is denoted by a self (resp., a op ). By convention, actions a op and a self take binary values encoding the first ( a = 1) and the second ( a = 0) avaiable options",
    "chunk_id": "Adv_cognitive_modelling_social_behavioural_adaptation_in_autism.json_chunk_22"
  },
  {
    "document_type": "research_paper",
    "title": "Social behavioural adaptation in Autism",
    "author": "Baudouin Forgeot d'Arc, Marie Devaine, Jean Daunizeau",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\social_behavioral_adaptation_in_autism.pdf",
    "date_published": "2020-03-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". By convention, actions a op and a self take binary values encoding the first ( a = 1) and the second ( a = 0) avaiable options. A game is defined in terms of its payoff table, whose entries are the player-specific utility U ( a self , a op ) of any combination of players’ actions at each trial. In particular, competitive social interactions simply reduce to anti-symmetric players’ payoff tables (see Table 1 below). According to Bayesian decision theory, agents aim at maximising expected payoff V = E [ U ( a self , a op )], where the expectation is defined in relation to the agent’s uncertain predictions about his opponent’s next move. This implies that the form of the decision policy is the same for all agents, irrespective of their ToM sophistication. Here, we consider that choices may exhibit small deviations from the rational decision rule, i.e. we assume agents employ the sTable 1. Competitive payoff table (hider’s payoff, seeker’s payoff). Participants play the role of the seeker, the oppnent is the hider. Hider Seeker a = 1 a = 0 a = 1 1,0 0,1 a = 0 0,1 1,0 https://doi.org/10.1371/journal.pcbi.1007700.t001 PLOS COMPUTATIONAL BIOLOGY Social behavioural adaptation in Autism PLOS Computational Biology | https://doi.org/10.1371/journal.pcbi.1007700 March 16, 2020 11 / 18 called \"softmax\" probabilistic policy: P ð a self 1⁄4 1 Þ 1⁄4 1 1 þ exp D V b ð 1 Þ where P ( a self = 1) is the probability that the agent chooses the action a self = 1, Δ V is the expected payoff difference (between actions a self = 1 and a self = 0), and β is the so-called behavioural \"temperature\" (which controls the magnitude of deviations from rationality)",
    "chunk_id": "Adv_cognitive_modelling_social_behavioural_adaptation_in_autism.json_chunk_23"
  },
  {
    "document_type": "research_paper",
    "title": "Social behavioural adaptation in Autism",
    "author": "Baudouin Forgeot d'Arc, Marie Devaine, Jean Daunizeau",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\social_behavioral_adaptation_in_autism.pdf",
    "date_published": "2020-03-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". The sigmoidal form of Eq 1 simply says that the probability of choosing the action a self = 1 increases with the expected payoff difference Δ V , which is given by: D V 1⁄4 p op ð U ð 1 ; 1 Þ U ð 0 ; 1 ÞÞ þ ð 1 p op Þð U ð 1 ; 0 Þ U ð 0 ; 0 ÞÞ 1⁄4 2 p op 1 ð 2 Þ where p op is the probability that the opponent will choose the action a op = 1, and the second line derives from inserting the above payoff matrix ( Table 1 ). In brief, Eq 2 simply says that participants are rewarded for correctly guessing where their opponent is hiding. Let us now summarize the mathematical derivation of k-ToM models, which essentially difer in how they estimate p op from the repeated observation of their opponent’s behaviour. We will see that k indexes a specific form of ToM sophistication, namely: the recursive depth of learners’ beliefs (as in \"I believe that you believe that I believe \"). Note that k-ToM ’s learning rule can be obtained recursively, starting with 0-ToM [ 32 ]. By convention, a 0-ToM agent does not attribute mental states to his opponent, but rather tracks his overt behavioural tendency without mentalizing. More precisely, 0-ToM agents siply assume that their opponents choose the action a op = 1 with probability p op = s ( x t ), where the unknown log-odds x t varies across trials t with a certain volatility σ 0 (and s is the sigmoid function). Observing his opponent’s choices gives 0-ToM information about the hidden state x , which can be updated trial after trial using Bayes rule, as follows: m 0 t m 0 t 1 þ S 0 t ð a op t s ð m 0 t 1 ÞÞ S 0 t 1 1 S 0 t 1 þ s 0 þ s ð m 0 t 1 Þð 1 s ð m 0 t 1 ÞÞ ð 3 Þ where m 0 t (resp. S 0 t ) is the approximate mean (resp. variance) of 0-ToM ’s posterior distribution p ð x 0 t j a op 1: t Þ . Inserting ^ p op t þ 1 1⁄4 E 1⁄2 s ð x t þ 1 Þj a op 1: t into Eq 1 now yields 0-ToM ’s decision rule. Here, the effective learning rate is the subjective uncertainty ∑ 0 , which is controlled by the volatility σ 0",
    "chunk_id": "Adv_cognitive_modelling_social_behavioural_adaptation_in_autism.json_chunk_24"
  },
  {
    "document_type": "research_paper",
    "title": "Social behavioural adaptation in Autism",
    "author": "Baudouin Forgeot d'Arc, Marie Devaine, Jean Daunizeau",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\social_behavioral_adaptation_in_autism.pdf",
    "date_published": "2020-03-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Here, the effective learning rate is the subjective uncertainty ∑ 0 , which is controlled by the volatility σ 0 . At the limit σ 0 ! 0, Eq 3 converges towards the (stationary) opponent’s choice frequency and 0-ToM essentially reproduce \"fictitious play\" strategies [ 34 ]. 0-ToM ’s learning rule is the starting point for a 1-ToM agent, who considers that she is faing a 0-ToM agent. This means that 1-ToM has to predict 0-ToM ’s next move, given his beliefs and the choices’ payoffs. The issue here is that 0-ToM ’s parameters (volatility σ 0 and explortion temperature β ) are unknown to 1-ToM and have to be learned, through their non-trivial effect on 0-ToM' s choices. At trial t +1, a 1-ToM agent predicts that 0-ToM will chose the action a op = 1 with probability p op ; 0 t þ 1 1⁄4 s v 0 ð x 0 t ; a 1: t Þ , where the hidden states x 0 t lumps σ 0 and β together and the mapping v 0 is derived from inserting 0- ToM’s learning rule ( Eq 3 ) into Eqs 1 and 2 . Similarly to 0-ToM agents, 1-ToM assumes that the hidden states x 0 t vary across trials with a certain volatility σ 1 , which yields a meta-Bayesian learning rule similar in form to 0-ToM ’s, but relying on first-order meta-beliefs (i.e. beliefs about beliefs). In brief, 1-ToM PLOS COMPUTATIONAL BIOLOGY Social behavioural adaptation in Autism PLOS Computational Biology | https://doi.org/10.1371/journal.pcbi.1007700 March 16, 2020 12 / 18 eventually learns how her ( 0-ToM ) opponent learns about herself, and acts accordingly (cf. Eqs 1 and 2 ). 1-ToM agents are well equipped to deal with situations of observational learning. However, when it comes to reciprocal social interactions, one may benefit from considering that others are also using ToM. This calls for learning strategies that rely upon higher-order meta-beliefs. By construction, k-ToM agents ( k 2) consider that their opponent is a κ -ToM agent with a lower ToM sophistication level (i.e.: κ < k )",
    "chunk_id": "Adv_cognitive_modelling_social_behavioural_adaptation_in_autism.json_chunk_25"
  },
  {
    "document_type": "research_paper",
    "title": "Social behavioural adaptation in Autism",
    "author": "Baudouin Forgeot d'Arc, Marie Devaine, Jean Daunizeau",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\social_behavioral_adaptation_in_autism.pdf",
    "date_published": "2020-03-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". By construction, k-ToM agents ( k 2) consider that their opponent is a κ -ToM agent with a lower ToM sophistication level (i.e.: κ < k ). Importantly, the sophistication level κ of k-ToM ’s opponent has to be learned, in addition to the hidden states x κ that control the opponent’s learning and decision making. The difficulty for a k-ToM agent is that she needs to consider different scenarios: each of her opponent’s possible sophistication level κ yields a specific proability p op ; k t þ 1 1⁄4 s v k ð x k t ; a 1: t Þ that she will choose action a op = 1. The ensuing meta-Bayesian learning rule entails updating k-ToM ’s uncertain belief about her opponent’s sophistication level κ and hidden states x κ : l k ; k t l k ; k t 1 p op ; k t X k 0 < k l k ; k 0 t 1 p op ; k 0 t 2 664 3 775 a op t l k ; k t 1 ð 1 p op ; k t Þ X k 0 < k l k ; k 0 t 1 ð 1 p op ; k 0 t Þ 2 664 3 775 1 a op t m k ; k t m k ; k t 1 þ l k t S k ; k t W k t 1 ð a op t s v k ð m k ; k t 1 ÞÞ S k ; k t 1⁄2ð S k ; k t 1 þ s k Þ 1 þ s 0 v k ð m k ; k t 1 Þ l k t W k t 1 T W k t 1 1 ð 4 Þ where l k ; k t is k-ToM ’s posterior probability that her opponent is κ -ToM , and W κ is the gradient of v κ with respect to the hidden states x κ . Eq 4 also captures 1- ToM’s learning rule, when seting l 1 ; 0 t ≜ 1 . Note that although the dimensionality of k-ToM ’s beliefs increases with k , k-ToM models do not differ in terms of the number of their free parameters. More precisely, k-ToM ’s learning and decision rules are entirely specified by their prior volatility σ k and behavioural temperature β . Formally speaking, only k-ToM agents with k 1 are mentalizing about others’ covert metal states, i.e. represent and update others’ beliefs. They can do this because they adopt the intentional stance [ 55 ], i.e. they assume that p op is driven by their opponent’s hidden beliefs and desires. More precisely, they consider that the opponent is himself a Bayesian agent, whose decision policy p op = P ( a op = 1) is formally similar to Eq 1",
    "chunk_id": "Adv_cognitive_modelling_social_behavioural_adaptation_in_autism.json_chunk_26"
  },
  {
    "document_type": "research_paper",
    "title": "Social behavioural adaptation in Autism",
    "author": "Baudouin Forgeot d'Arc, Marie Devaine, Jean Daunizeau",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\social_behavioral_adaptation_in_autism.pdf",
    "date_published": "2020-03-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". More precisely, they consider that the opponent is himself a Bayesian agent, whose decision policy p op = P ( a op = 1) is formally similar to Eq 1 . This makes k-ToM metBayesian learners [ 35 ] that relies upon recursive belief updating (\"I believe that you believe that I believe \"). Critically, the recursion depth k induces distinct ToM sophistication levels, whose differ in terms of how they react to the history of players’ actions in the game. With the exception of 0-ToM , we so far only described sophisticated learning models that are capable of (artificial) ToM. But clearly 0-ToM is not the only way people may learn in social contexts without mentalizing. We thus consider below other adaptation strategies that may populate peoples’ behavioural repertoire. First, let us consider a heuristic learning model, whose sophistication somehow lies in between 0-ToM and 1-ToM . In brief, \"influence learning\" adjusts a 0-ToM -like learning rule to account for how her own actions may influence her opponent’s behaviour [ 39 ]: p op t þ 1 1⁄4 p op t þ Z ð a op t p op t Þ |fflfflfflfflfflffl{zfflfflfflfflfflffl} prediction error þ l p op t ð 1 p op t Þð 1 2 a self t b s 1 ð p op t ÞÞ |fflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflffl{zfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflffl} } influence } adjustment term ð 5 Þ where η (resp. λ ) controls the relative weight of its prediction error (resp. the “influence” adjustment term). Numerical simulations show that, in a competitive game setting, Inf wins PLOS COMPUTATIONAL BIOLOGY Social behavioural adaptation in Autism PLOS Computational Biology | https://doi.org/10.1371/journal.pcbi.1007700 March 16, 2020 13 / 18 over 0-ToM but loses against k-ToM players with k 1. In other terms, although it is in princple able to adapt to reactive environments, Inf cannot successfully compete with learners endowed with mentalizing [ 33 ]",
    "chunk_id": "Adv_cognitive_modelling_social_behavioural_adaptation_in_autism.json_chunk_27"
  },
  {
    "document_type": "research_paper",
    "title": "Social behavioural adaptation in Autism",
    "author": "Baudouin Forgeot d'Arc, Marie Devaine, Jean Daunizeau",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\social_behavioral_adaptation_in_autism.pdf",
    "date_published": "2020-03-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". In other terms, although it is in princple able to adapt to reactive environments, Inf cannot successfully compete with learners endowed with mentalizing [ 33 ]. Second, participants may learn by trial and error, eventually reinforcing the actions that led to a reward. Such adaptation strategy is the essence of classical conditioning, which is typically modelled using reinforcement learning or RL [ 56 ]. In this perspective, participants would directly learn the value of alternative actions, which bypasses Eq 2 . More precisely, an RL agent would update the value of the chosen option in proportion to the reward prediction error, as follows: V i t þ 1 1⁄4 V i t þ a ð R t V i t Þ if action a self t 1⁄4 i was chosen V i t þ 1 1⁄4 V i t otherwise ð 6 Þ ( where R t 1⁄4 U ð a self t ; a op t Þ is the last reward outcome and α is the (unknown) learning rate. At the time of choice, RL agents simply tend to pick the most valuable option (cf. Eq 1 ). Third, an even simpler way of adapting one’s behaviour in operant contexts such as this one is to repeat one’s last choice if it was successful and alternate otherwise. This can be moeled by the following update in action values: V i t þ 1 1⁄4 R t if action a self t 1⁄4 i was chosen V i t þ 1 1⁄4 R t otherwise ð 7 Þ ( This strategy is called win-stay/lose-switch ( WS ), and is almost identical to the above RL model when the learning rate is α = 1. Despite its simplicity, WS can be shown to have remarable adaptive properties [ 57 ]. Last, the agent may simply act randomly, which can be modeled by fixing the value diffeence to zero ( Δ V = 0). Although embarrassingly simple, this probabilistic policy eventually prvents one’s opponent from controlling one’s expected earnings. It thus minimizes the risk of being exploited at the cost of providing chance-level expected earnings. It is the so-called \"Nash equilibrium\" of our \"hide and seek\" game",
    "chunk_id": "Adv_cognitive_modelling_social_behavioural_adaptation_in_autism.json_chunk_28"
  },
  {
    "document_type": "research_paper",
    "title": "Social behavioural adaptation in Autism",
    "author": "Baudouin Forgeot d'Arc, Marie Devaine, Jean Daunizeau",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\social_behavioral_adaptation_in_autism.pdf",
    "date_published": "2020-03-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". It thus minimizes the risk of being exploited at the cost of providing chance-level expected earnings. It is the so-called \"Nash equilibrium\" of our \"hide and seek\" game. Since we augment this model with a potential bias for one of the two alternative options (as all the above learning models), we refer to it as biased Nash or BN . Empirical estimates of computational phenotypes Our working hypothesis is that people may not always rely on the same adaptation strategy across different game sessions or conditions. Rather, they select a strategy from among a repetoire, whose flexibility and ToM sophistication define our computational phenotypes. The empirical estimation of these thus consists of three steps. First, we perform a statistical (Bayeian) comparison of learning models [ 58 ]. For each subject, we fit trial-by-trial actions sequences a 1:60 with each learning model ( m 2 { BN , WSLS , RL , 0-ToM , Inf , 1-ToM , 2-ToM , 3-ToM }) using a variational Bayesian approach [ 59 , 60 ]. This eventually yields 8x48x4x2x2 = 6144 model evidences p ( a 1:60 | m ) (8 models, 48 participants, 4 opponent conditions, 2 framing conditions, 2 repetitions). Second, we define the repertoire's flexibility ^ f ð 1 ; 2 Þ (between conditions 1 and 2) in terms of the posterior probability that a given participant employs different adaptation strategies across two conditions: ^ f ð 1 ; 2 Þ 1⁄4 p ð m ð 1 Þ 61⁄4 m ð 2 Þ j a ð 1 Þ 1:60 ; a ð 2 Þ 1:60 Þ 1⁄4 1 X m p ð m ð 1 Þ 1⁄4 m j a ð 1 Þ 1:60 Þ p ð m ð 2 Þ 1⁄4 m j a ð 2 Þ 1:60 Þ ð 8 Þ PLOS COMPUTATIONAL BIOLOGY Social behavioural adaptation in Autism PLOS Computational Biology | https://doi.org/10.1371/journal.pcbi.1007700 March 16, 2020 14 / 18 where m (1) (resp. m (1) ) is the participants’ adaptation strategy in the first (resp. second) condtion, p ð m ð 1 Þ 1⁄4 m j a ð 1 Þ 1:60 Þ (resp. p ð m ð 2 Þ 1⁄4 m j a ð 2 Þ 1:60 Þ ) is the probability that the participant had an adaptation strategy m given his trial-by-trial choice sequence a ð 1 Þ 1:60 (resp",
    "chunk_id": "Adv_cognitive_modelling_social_behavioural_adaptation_in_autism.json_chunk_29"
  },
  {
    "document_type": "research_paper",
    "title": "Social behavioural adaptation in Autism",
    "author": "Baudouin Forgeot d'Arc, Marie Devaine, Jean Daunizeau",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\social_behavioral_adaptation_in_autism.pdf",
    "date_published": "2020-03-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". p ð m ð 2 Þ 1⁄4 m j a ð 2 Þ 1:60 Þ ) is the probability that the participant had an adaptation strategy m given his trial-by-trial choice sequence a ð 1 Þ 1:60 (resp. a ð 2 Þ 1:60 ) in condition 1 (resp. condition 2). Note that we measure the repertoire's flexibility ^ f both across framings and across repetitions. Third, we define the repertoire's ToM-sophistication ^ k in terms of the expected depth of recursive belief update: ^ k 1⁄4 E 1⁄2 k j a 1:60 1⁄4 X k k p ð k j a 1:60 Þ ð 9 Þ where p ( k | a 1:60 ) = p ( m = \" k − ToM \"| a 1:60 ) is the posterior probability of model k-ToM given the participant’s trial-by-trial choice sequence a 1:60 . Note that we restrict the summation in Eq 9 to k-ToM models, because the depth k of recursive beliefs is not defined for the other learning models. Note that we measure the repertoire's ToM-sophistication ^ k in both framing conditions (social and non-social). All statistical analyses were performed using the VBA toolbox [ 36 ], which contains the above eight learning/decision models as well as the bayesian statistical machinery required for model inversion. Supporting information S1 Text. This document provides supplementary information regarding: the experimental protocol (section 1), the credibility of the framing manipulation (section 2), the effect of motivational manipulations on the game’s performance (section 3), differences in reaction times (section 4), model-free Volterra decompositions of trial-by-trial choice sequences (section 5), differences in adaptation strategies between AS and NT participants (section 6), the impact of the framing manipulation on the repertoire’s flexibility (section 7), the statistical relationships between computational phenotypes (section 8), and their relatioship with performance in the game (section 9). (DOCX) Acknowledgments Authors thank Alexandra Duquette and Patricia Jelenic for contributing with data collection, and Pr. Laurent Mottron for enabling the recruitment of ASD patients",
    "chunk_id": "Adv_cognitive_modelling_social_behavioural_adaptation_in_autism.json_chunk_30"
  },
  {
    "document_type": "research_paper",
    "title": "Social behavioural adaptation in Autism",
    "author": "Baudouin Forgeot d'Arc, Marie Devaine, Jean Daunizeau",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\social_behavioral_adaptation_in_autism.pdf",
    "date_published": "2020-03-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". (DOCX) Acknowledgments Authors thank Alexandra Duquette and Patricia Jelenic for contributing with data collection, and Pr. Laurent Mottron for enabling the recruitment of ASD patients. Author Contributions Conceptualization: Baudouin Forgeot d’Arc, Marie Devaine, Jean Daunizeau. Data curation: Marie Devaine. Formal analysis: Marie Devaine, Jean Daunizeau. Funding acquisition: Baudouin Forgeot d’Arc, Jean Daunizeau. Investigation: Baudouin Forgeot d’Arc, Marie Devaine, Jean Daunizeau. Methodology: Marie Devaine, Jean Daunizeau. Project administration: Baudouin Forgeot d’Arc, Jean Daunizeau. Resources: Baudouin Forgeot d’Arc, Marie Devaine, Jean Daunizeau. PLOS COMPUTATIONAL BIOLOGY Social behavioural adaptation in Autism PLOS Computational Biology | https://doi.org/10.1371/journal.pcbi.1007700 March 16, 2020 15 / 18 Software: Marie Devaine, Jean Daunizeau. Supervision: Jean Daunizeau. Validation: Marie Devaine, Jean Daunizeau. Visualization: Jean Daunizeau. Writing – original draft: Baudouin Forgeot d’Arc, Jean Daunizeau. Writing – review & editing: Baudouin Forgeot d’Arc, Jean Daunizeau.",
    "chunk_id": "Adv_cognitive_modelling_social_behavioural_adaptation_in_autism.json_chunk_31"
  },
  {
    "document_type": "online_article",
    "title": "Chapter 6 Model Quality Assessment",
    "author": "Riccardo Fusaroli",
    "source": "https://fusaroli.github.io/AdvancedCognitiveModeling2023/model-quality-assessment.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": "Building computational models is only the first step in understanding cognitive processes. We must rigorously evaluate whether our models actually capture meaningful patterns in behavior and provide reliable insights. This chapter introduces systematic approaches for assessing model quality, focusing on techniques that help us understand both the strengths and limitations of our cognitive models. This document covers: - generating and plotting priors (against posteriors) - generating and plotting predictive checks (prior and posterior ones) - prior sensitivity checks [I SHOULD RESTRUCTURE THE DOCUMENT SO THAT PRIOR PREDICTIVE CHECKS COME BEFORE PRIOR / POSTERIOR UPDATE CHECKS] As we try to understand our model, we might want to plot how the prior relates to the posterior, or - in other words, what has the model learned from looking at the data? We can do so by overlaying the prior and the posterior distributions, what is also called a “prior - posterior update check”. Stan does not automatically save the prior distribution, so we need to tell it to generate and save prior distributions in a convenient place so we can easily plot or use them at will from R. Luckily, Stan gives us a dedicated code chunk to do that: the generated quantities chunk. As before, we need to define the kind of variable we want to save, and then how to generate it. If we take the example of the random agent (with a bias), we have one parameter: theta. We can then generate theta according to the prior in generated quantities. While we are at this, we can also generate a nicer version of the posterior estimate for the theta parameter, now in probability scale (instead of log odds). However, prior and posterior estimates are not always the most immediate thing to understand. For instance, we might have trouble having a good grasp for how the uncertainty in the estimate will play out on 120 trials, or 6 trials, or however many trials we are planning for our experiment",
    "chunk_id": "Adv_cognitive_modelling_chapter_6_model_quality_assessment.json_chunk_1"
  },
  {
    "document_type": "online_article",
    "title": "Chapter 6 Model Quality Assessment",
    "author": "Riccardo Fusaroli",
    "source": "https://fusaroli.github.io/AdvancedCognitiveModeling2023/model-quality-assessment.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". For instance, we might have trouble having a good grasp for how the uncertainty in the estimate will play out on 120 trials, or 6 trials, or however many trials we are planning for our experiment. Luckily, we can ask Stan to run predictions from either priors or posteriors, or both: given the priors how many trials will have “right hand” choice? and given the posterior estimates? As we use complex models, the relation between prior/posterior estimates and predictions becomes less and less intuitive. Simulating their implications for the outcomes - also called prior/posterior predictive checks - becomes a very useful tool to adjust our priors and their uncertainty so that they reflect what we know of the outcome scale; as well as to assess whether the model (and its posterior estimates) can appropriately describe the data we observe, or there’s some bias there. More discussion of this can be found athttps://4ccoxau.github.io/PriorsWorkshop/. Prior predictive checks involve simulating data from our model using only the prior distributions, before seeing any actual data. This helps us understand what kinds of patterns our model assumes are possible before we begin fitting to real observations. These predictions should be assessed for: After fitting our models, posterior predictive checks help us determine whether the fitted model can reproduce key patterns in our observed data. We generate new data using parameters sampled from the posterior distribution and compare these simulations to our actual observations. For decision-making models, important patterns to check include: Now we load the data and plot it We can do the same for the memory model: generate prior distributions to overlay to the posteriors (prior-posterior update checks), generate predicted outcomes based on the priors (prior predictive checks) and on the posteriors (posterior predictive checks). N.B. prior and posterior predictions now depend on the value on memory. I identified 3 meaningful values for the memory value (e.g",
    "chunk_id": "Adv_cognitive_modelling_chapter_6_model_quality_assessment.json_chunk_2"
  },
  {
    "document_type": "online_article",
    "title": "Chapter 6 Model Quality Assessment",
    "author": "Riccardo Fusaroli",
    "source": "https://fusaroli.github.io/AdvancedCognitiveModeling2023/model-quality-assessment.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". N.B. prior and posterior predictions now depend on the value on memory. I identified 3 meaningful values for the memory value (e.g. 0.5, 0.7, 0.9) and used those to generate 3 prior and posterior predictive checks. Rigorous model assessment is essential for developing reliable insights into cognitive processes. The techniques covered in this chapter provide a systematic framework for validating our models and understanding their limitations. As we move forward to more complex models incorporating individual differences and learning mechanisms, these quality checks become increasingly important for ensuring our conclusions are well-supported by the evidence. In the next chapter, we’ll build on these foundations as we explore multilevel modeling approaches that can capture individual differences while maintaining population-level insights.",
    "chunk_id": "Adv_cognitive_modelling_chapter_6_model_quality_assessment.json_chunk_3"
  },
  {
    "document_type": "research_paper",
    "title": "How Computational Modeling Can Force Theory Building in Psychological Science",
    "author": "Unknown",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\guest-martin-2021-how-computational-modeling-can-force-theory-building-in-psychological-science.pdf",
    "date_published": "2021-07-03",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": "https://doi.org/10.1177/1745691620970585 Perspectives on Psychological Science 2021, Vol. 16(4) 789­–802 © The Author(s) 2021 Article reuse guidelines: sagepub.com/journals-permissions DOI: 10.1177/1745691620970585 www.psychologicalscience.org/PPS ASSOCIATION FOR PSYCHOLOGICAL SCIENCE Psychology is a science that attempts to explain human capacities and behaviors. This results in a wide range of research practices, from conducting behavioral and neuroscientific experiments to clinical and qualitative work. Psychology intersects with many other fields, creating interdisciplinary subfields across science, tecnology, engineering, mathematics, and the humanities. Here we focus on a distinction within psychological science that is underdiscussed: the difference in explaatory force between research programs that use formal, mathematical, and/or computational modeling and those that do not, or, more specifically, programs that explicitly state and define their models and those that do not. We start by explaining what a computational model is, how it is built, and how formalization is required at various steps along the way. We illustrate how specifing a model naturally results in better specified theories and therefore in better science. We give an example of a specified, formalized, and implemented computational model and use it to model an example in which intition is insufficient in determining a quantity. Next, we present our path model of how psychological science should be conducted to maximize the relationship between theory, specification, and data. The scientifiinference process is a function from theory to data—but this function must be more than a state function to have explanatory force. It is a path function that must step through theory, specification, and implementation before an interpretation can have explanatory force in relation to a theory",
    "chunk_id": "Adv_cognitive_modelling_how_computational_modeling_can_force_theory_building_in_psychological_science.json_chunk_1"
  },
  {
    "document_type": "research_paper",
    "title": "How Computational Modeling Can Force Theory Building in Psychological Science",
    "author": "Unknown",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\guest-martin-2021-how-computational-modeling-can-force-theory-building-in-psychological-science.pdf",
    "date_published": "2021-07-03",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". It is a path function that must step through theory, specification, and implementation before an interpretation can have explanatory force in relation to a theory. Our path-function model also enables us to evaluate claims about the process of doing psychological and cognitive science itself, Corresponding Author: Olivia Guest, Donders Centre for Cognitive Neuroimaging, Radboud University E-mail: olivia.guest@ru.nl How Computational Modeling Can Force Theory Building in Psychological Science Olivia Guest 1,2,3 and Andrea E. Martin 1,4 1 Donders Centre for Cognitive Neuroimaging, Radboud University; 2 Research Centre on Interactive Media, Smart Systems and Emerging Technologies (RISE), Nicosia, Cyprus; 3 Department of Experimental Psychology, University College London; and 4 Max Planck Institute for Psycholinguistics, Nijmegen, The Netherlands Abstract Psychology endeavors to develop theories of human capacities and behaviors on the basis of a variety of methodologies and dependent measures. We argue that one of the most divisive factors in psychological science is whether researchers choose to use computational modeling of theories (over and above data) during the scientific-inference process. Modeling is undervalued yet holds promise for advancing psychological science. The inherent demands of computational modeling guide us toward better science by forcing us to conceptually analyze, specify, and formalize intuitions that otherwise remain unexamined—what we dub open theory . Constraining our inference process through modeling enables us to build explanatory and predictive theories. Here, we present scientific inference in psychology as a path function in which each step shapes the next. Computational modeling can constrain these steps, thus advancing scientific inference over and above the stewardship of experimental practice (e.g., preregistration). If psychology continues to eschew computational modeling, we predict more replicability crises and persistent failure at coherent theory building",
    "chunk_id": "Adv_cognitive_modelling_how_computational_modeling_can_force_theory_building_in_psychological_science.json_chunk_2"
  },
  {
    "document_type": "research_paper",
    "title": "How Computational Modeling Can Force Theory Building in Psychological Science",
    "author": "Unknown",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\guest-martin-2021-how-computational-modeling-can-force-theory-building-in-psychological-science.pdf",
    "date_published": "2021-07-03",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". If psychology continues to eschew computational modeling, we predict more replicability crises and persistent failure at coherent theory building. This is because without formal modeling we lack open and transparent theorizing. We also explain how to formalize, specify, and implement a computational model, emphasizing that the advantages of modeling can be achieved by anyone with benefit to all. Keywords computational model, theoretical psychology, open science, scientific inference 790 Guest, Martin pinpointing where in the path questionable ways of conducting research occur, such as p -hacking (biasing data analysis or collection to force statistical modeling to return significant p values; e.g., Head et al., 2015). Finally, we believe psychological science needs to use modeling to address the structural problems in theory building that underlie the so-called replication crisis in, for example, social psychology (see Flis, 2019). We propose a core yet overlooked component of open science that computational modeling forces scientists to carry out: open theory . A Fork in the Path of Psychological Science Psychological scientists typically ascribe to a school of thought that specifies a framework, a theoretical postion, or at least some basic hypotheses that they then set out to test using inferential statistics (Meehl, 1967; Newell, 1973). Almost every article in psychological science can be boiled down to introduction, methods, analysis, results, and discussion. The way we approach science is nearly identical: We ask nature questions by collecting data and then report p values, more rarely Bayes factors or Bayesian inference, or some qualitative measure. Computational models do not feature in the majority of psychology’s scientific endeavors. Most pschological researchers are not trained in modeling beyond constructing statistical models of their data, which are typically applicable off the shelf",
    "chunk_id": "Adv_cognitive_modelling_how_computational_modeling_can_force_theory_building_in_psychological_science.json_chunk_3"
  },
  {
    "document_type": "research_paper",
    "title": "How Computational Modeling Can Force Theory Building in Psychological Science",
    "author": "Unknown",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\guest-martin-2021-how-computational-modeling-can-force-theory-building-in-psychological-science.pdf",
    "date_published": "2021-07-03",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Most pschological researchers are not trained in modeling beyond constructing statistical models of their data, which are typically applicable off the shelf. In contrast, a subset of researchers—formal, matematical, or computational modelers—take a different route in the idea-to-publication pipeline. They construct models of something other than the data directly; they create semiformalized or formalized versions of scietific theories, often creating (or least amending) their accounts along the way. Computational modelers are researchers who have the tools to be acutely aware of the assumptions and implications of the theory they are using to carry out their science. This awareness comes, ideally, from specification and formalization, but minmally, it also comes from the necessity of writing code during implementation. Involving modeling in a research program has the effect of necessarily changing the way the research process is structured. It changes the focus from testing hypotheses generated from an opaque idea or intuition (e.g., a theory that has likely never been written down in anything other than natural language, if that) to tesing a formal model of the theory as well as continuing to be able to generate and test hypotheses using empircal data. Computational modeling does this by forcing scientists to explicitly document an instance of what their theory assumes, if not what their theory is. In our view, the most crucial part of the process is creating a specification—but even just creating an implementation (programming code) leverages more explicitness than going from framework to hypothesis to data collection directly. What Is a Computational Model? And Why Build One? Let us calculate, without further ado, and see who is right",
    "chunk_id": "Adv_cognitive_modelling_how_computational_modeling_can_force_theory_building_in_psychological_science.json_chunk_4"
  },
  {
    "document_type": "research_paper",
    "title": "How Computational Modeling Can Force Theory Building in Psychological Science",
    "author": "Unknown",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\guest-martin-2021-how-computational-modeling-can-force-theory-building-in-psychological-science.pdf",
    "date_published": "2021-07-03",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". What Is a Computational Model? And Why Build One? Let us calculate, without further ado, and see who is right. —Gottfried Leibniz (Wiener, 1951) Gottfried Leibniz predicted computational modeling when he envisaged a characteristica universalis that allows scientists to formally express theories and data (e.g., formal languages, logic, programming languages) and a calculus ratiocinator that computes the logical consequences of theories and data (e.g., digital compuers; Cohen, 1954; Wiener, 1951). Computational modeing is the process by which a verbal description is formalized to remove ambiguity, as Leibniz correctly predicted, while also constraining the dimensions a theory can span. In the best of possible worlds, modeing makes us think deeply about what we are going to model (e.g., which phenomenon or capacity), in addtion to any data, both before and during the creation of the model and both before and during data colletion. It can be as simple as the scientist asking, “How do we understand brain and behavior in this context, and why?” By thinking through how to represent the data and model the experiment, scientists gain insight into the computational repercussions of their ideas in a much deeper and explicit way than by just collecting data. By providing a transparent genealogy for where predictions, explanations, and ideas for experiments come from, the process of modeling stops us from atheoretically testing hypotheses—a core value of open science. Open theorizing, in other words explicitly staing and formalizing our theoretical commitments, is done by default as a function of the process. Through modeling, even in, or especially in, failures we hone our ideas: Can our theory be formally specfied, and if not, why not? Thus, we may check whether what we have described formally still makes sense in light of our theoretical commitments",
    "chunk_id": "Adv_cognitive_modelling_how_computational_modeling_can_force_theory_building_in_psychological_science.json_chunk_5"
  },
  {
    "document_type": "research_paper",
    "title": "How Computational Modeling Can Force Theory Building in Psychological Science",
    "author": "Unknown",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\guest-martin-2021-how-computational-modeling-can-force-theory-building-in-psychological-science.pdf",
    "date_published": "2021-07-03",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". It aids both us as researchers communicating with each other and those who may wish to apply these ideas to their work ouside science (e.g., in industrial or clinical settings). One of the core properties of models is that they allow us to “safely remove a theory from the brain of its author” (A. J. Wills, personal communication, May 19, 2020; see also Wills et al., 2017; Wills & Pothos, Modeling Forces Theory Building 791 2012), thus allowing the ideas in one’s head to run on other computers. Modeling also allows us to compare models based on one theory with those based on another and compare different parameter values’ effects within a model, including damaging models in ways that would be unethical in human participants (e.g., “lesioning” artificial neural network models; see Guest et al., 2020). One of the only situations in which mutiple theories can be distinguished in a formal setting is when they can make sense of the available data (e.g., Levering et al., 2019; see also, however, Cox & Shiffrin, in press; Navarro, 2019; Wills & Pothos, 2012). We now walk the reader through building a comptational model from scratch to illustrate our argument and then present a path function of research in pschological science. We emphasize that often merely building a formal model of a problem is not enough— actually writing code to implement a computational model is required to understand the model itself. The pizza problem All models are wrong but some are more wrong than others. —based on Box (1976) and Orwell (1945) Imagine it is Friday night, and your favorite pizzeria has a special: two 12-in. pizzas for the price of one 18-in. pizza. Your definition of a good deal is one in which you purchase the most food. Is this a good deal? A Twitter post (Fermat’s Library, 2019) said “a useful counterintuitive fact: one 18 inch pizza has more ‘pizza’ than two 12 inch pizzas”—along with an image similar to Figure 1. The reaction to this tweet was largely suprise or disbelief",
    "chunk_id": "Adv_cognitive_modelling_how_computational_modeling_can_force_theory_building_in_psychological_science.json_chunk_6"
  },
  {
    "document_type": "research_paper",
    "title": "How Computational Modeling Can Force Theory Building in Psychological Science",
    "author": "Unknown",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\guest-martin-2021-how-computational-modeling-can-force-theory-building-in-psychological-science.pdf",
    "date_published": "2021-07-03",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". The reaction to this tweet was largely suprise or disbelief. For example, one follower replied, “But two pizzas are more than one” (Sykes, 2019). Why were people taken aback? When it comes to comparing the two options in Figure 1, although we all agree on how the area of a circle is defined, the results of the “true” model, that one 18-in. pizza has more surface and therefore is more food, are counterintuitive. Computational modeling can demonstrate how one cannot always trust one’s gut. To start, one must create (a) a verbal description, a coceptual analysis, and/or a theory; (b) a formal (or fomalizable) description, that is, a specification using mathematics, pseudocode, flowcharts, and so on; and (c) an executable implementation written in programing code (for an overview of these steps, see Fig. 2, red area). This process is the cornerstone of computtional modeling and by extension of modern scientific thought, enabling us to refine our gut instincts through experience. Experience is seeing our ideas being executed by a computer, giving us the chance to debug scientific thining in a very direct way. If we do not make our thinking explicit through formal modeling, and if we do not bother to execute (i.e., implement and run our specifiction through computational modeling), we can have massive inconsistencies in our understanding of our own model(s). We call this issue “the pizza problem.” Herein we model the most pizza for our buck—ovekill for scientific purposes but certainly not for pedgogical ones. For any formalized specification, including that for the pizza orders shown in Figure 1, simplifictions need to be made, so we choose to represent pizas as circles. Therefore, we define the amount of food φ per order option i as φ π i i i N R = 2 , (1) where i is the pizza-order option, N is the number of pizzas in the order, and the rest is the area of a circle",
    "chunk_id": "Adv_cognitive_modelling_how_computational_modeling_can_force_theory_building_in_psychological_science.json_chunk_7"
  },
  {
    "document_type": "research_paper",
    "title": "How Computational Modeling Can Force Theory Building in Psychological Science",
    "author": "Unknown",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\guest-martin-2021-how-computational-modeling-can-force-theory-building-in-psychological-science.pdf",
    "date_published": "2021-07-03",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". We also propose a pairwise decision rule: ω φ φ φ φ ( , ) , , , i j i j i j = >    if otherwise (2) where the output of the ω function is the order with the most food. This is the model that everyone would have claimed to have running in their heads, but they a b Two 12-in. Pizzas One 18-in. Pizza Area = 2 × π 6 2 = 226 in. 2 Area = π 9 2 = 254 in. 2 Fig. 1. The pizza problem. Something like comparing the two options presented here can appear counterintuitive, although we all learn the formula for the area of a circle in primary school. Compare (a) two 12-in. pizzas and (b) one 18-in. pizza (all three pizzas are to scale). Which order would you prefer? 792 Guest, Martin still were surprised—an expectation violation occurred— when faced with the actual results. How do we ensure we are all running the same model? We execute it on a computer that is not the human mind. To make this model computational, we move from specification to implementation (consider where we are in the path shown in Fig. 2). We notice Equation 1 is not wrong, but could be defined more usefully as φ π i j N j R = = ∑ 1 2 , (3) where j is the current pizza, allowing us to sum over all pizzas N within food order i . This change allows generalization of the model (both in the specification above and the implementation below) to account for different radii per order (i.e., in the future we can compare an 11-in. pizza plus a 13-in. pizza with one 18-in. pizza). One possible implementtion (in Python) of our pizza model looks like this: import numpy as np import math def food(ds): ' ' ' Amount of food in an order as a function of the diameters per pizza (eq. 3). ' ' ' return (math.pi * (ds/2)**2).sum() # Order option a in fig. 1, two 12 ' ' pizzas: two_pizzas = np.array([12, 12]) # Option b, one 18 ' ' pizza: one_pizza = np.array([18]) # Decision rule (eq",
    "chunk_id": "Adv_cognitive_modelling_how_computational_modeling_can_force_theory_building_in_psychological_science.json_chunk_8"
  },
  {
    "document_type": "research_paper",
    "title": "How Computational Modeling Can Force Theory Building in Psychological Science",
    "author": "Unknown",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\guest-martin-2021-how-computational-modeling-can-force-theory-building-in-psychological-science.pdf",
    "date_published": "2021-07-03",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". ' ' ' return (math.pi * (ds/2)**2).sum() # Order option a in fig. 1, two 12 ' ' pizzas: two_pizzas = np.array([12, 12]) # Option b, one 18 ' ' pizza: one_pizza = np.array([18]) # Decision rule (eq. 2): print(food(two_pizzas) > food(one_pizza)) Note that this implementation change, which we choose to percolate upward, editing our specification, does not affect the verbal description of the model. By the same token, a change in the code to use a for-loop in the defintion of the food() function would affect neither the specification nor the theory in this case. This is a core concept to grasp: the relationships between theory, specfication, and implementation—consider our movements up and down the path as depicted in Figure 2. Computational modeling, when carried out the way we describe herein, is quintessentially open science: Verbal descriptions of science, specifications, and implementations of models are transparent and thus open to replication and modification. If one disagrees with any of the formalisms, they can plug in another decision rule or definition of the amount of food or even another aspect of the order being evaluated (e.g., perhaps they prefer more crust than overall surface). Computational modeling—when done the way we describe, which requires the creation of specifications and implementations—affords open theorizing to go along with open data, open-source code, and so on. In contrast to merely stating two 12-in. pizzas offer more food than one 18-in. pizza, a computational model can Framework ACT-R, Connectionism, SOAR, Working Memory Theory Specification Implementation Hypothesis Data Prospect Theory, Rescorla-Wagner, SUSTAIN Mathematics, Natural Language, TLA + , Z Models Written in Code (e.g., C, Python, R) “Group A Will Be Faster Than Group B” ANOVA, Linear Regression, MVPA, SEM, t Test Fig. 2. One of many possible paths (in blue) that can be used to understand and describe how psychological research is carried out, with examples of models at each step shown on the left (in green)",
    "chunk_id": "Adv_cognitive_modelling_how_computational_modeling_can_force_theory_building_in_psychological_science.json_chunk_9"
  },
  {
    "document_type": "research_paper",
    "title": "How Computational Modeling Can Force Theory Building in Psychological Science",
    "author": "Unknown",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\guest-martin-2021-how-computational-modeling-can-force-theory-building-in-psychological-science.pdf",
    "date_published": "2021-07-03",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". 2. One of many possible paths (in blue) that can be used to understand and describe how psychological research is carried out, with examples of models at each step shown on the left (in green). Each research output within psychological science can be described with respect to the levels in this path. The three levels superimposed on a red background (theory, specification, implemetation) are those that are most often ignored or left out from research descriptions. ACT-R = adaptive control of thought–rational; SUSTAIN = supervised and unsupervised stratified adaptive incremental network; ANOVA = analysis of variance; MVPA = multivariate pattern analysis; SEM = structural equation modeling. Modeling Forces Theory Building 793 be generalized and can show our work clearly. Through writing code, we debug our scientific thinking. Model of Psychological Science Theory takes us beyond measurement in a way which cannot be foretold a priori , and it does so by means of the so-called intellectual experiments which render us largely independent of the defects of the actual instruments. —Planck (1936, p. 27) In this section, we describe an analytical view of pschological research, shown in Figure 2. Although other such models exist for capturing some aspect of the process of psychological science (e.g., Haig, 2018; Haslbeck et al., 2019; Kellen, 2019; van Rooij & Baggio, 2021), our model proposes a unified account that deonstrates how computational modeling can play a radcal and central role in all of psychological research. We propose that scientific outputs can be analyzed using the levels shown in the left column of Figure 2. Scientific inquiry can be understood as a function from theory to data and back again, and this function must pass through several states to gain explanatory force. The function can express a meaningful mapping, tranformation, or update between a theory at time t and that theory at time t + 1 as it passes through specifiction and implementation, which enforces a degree of formalization",
    "chunk_id": "Adv_cognitive_modelling_how_computational_modeling_can_force_theory_building_in_psychological_science.json_chunk_10"
  },
  {
    "document_type": "research_paper",
    "title": "How Computational Modeling Can Force Theory Building in Psychological Science",
    "author": "Unknown",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\guest-martin-2021-how-computational-modeling-can-force-theory-building-in-psychological-science.pdf",
    "date_published": "2021-07-03",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". We note that each level (in blue) can, but does not have to, involve the construction of a (computational) model for that level, with examples of models shown in the left column (in green) connected by a dotted line to their associated level. If a level is not well understood, making a model of that level helps to elucidate implicit assumptions, addressing “pizza problems.” A path function is a function in which the output depends on a path of transformations the input undegoes. Path functions are used in thermodynamics to describe heat and work transfer; an intuitive example is distance to a destination being dependent on the route and mode of transport taken. The path function moves from top to bottom in terms of dependencies, but the connections between each level and those adjcent are bidirectional (represented by large blue and small black arrows). Connections capture the adding or removing, loosening or tightening, of constraints that one level can impose on those above or below it. In our model depicted in Figure 2, the directionality of transitions is constrained only when moving dowward. Thus, at any point transitions moving upward are permissible, whereas moving downward is possible only if an expectation violation is resolved by first moing upward. Downward transitions can be thought of as functions in which the input is the current layer and the output is the next. Upward transitions are more complex and involve adjusting (e.g., a theory given some data) and can involve changes to levels along the way to obtain the required theory-level update. With respect to why we might want to move upward out of choice and recalling the case of the pizza model above, we updated the specification (changing Equation 1 to Equation 3) because we thought about the code/ implementation more deeply and decided it is worth updating our formal specification (Equation 3). Dowward motion is not allowed if a violation occurs (e.g., our model at the current step is not in line with our expectations)",
    "chunk_id": "Adv_cognitive_modelling_how_computational_modeling_can_force_theory_building_in_psychological_science.json_chunk_11"
  },
  {
    "document_type": "research_paper",
    "title": "How Computational Modeling Can Force Theory Building in Psychological Science",
    "author": "Unknown",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\guest-martin-2021-how-computational-modeling-can-force-theory-building-in-psychological-science.pdf",
    "date_published": "2021-07-03",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Dowward motion is not allowed if a violation occurs (e.g., our model at the current step is not in line with our expectations). Once this violation is resolved by moving to any step above, we may move downward, respecting the serial ordering of the levels. For example, when the data do not confirm the hypothesis, we must move upward and understand why and what needs to be amended in the levels above the hypothesis. Attempting to “fix” things at the hypothesis level is known as hypothesizing after the results are known (or HARKing; Kerr, 1998). In the case of the pizza model, an expecttion violation occurs when we realize that the one pizza is more food. At that point, we reevaluate our unspecfied/implicit model and move back up to the approprate level to create a more sensible account. At least implicitly, every scientific output is modeand theory-laden (i.e., contains theoretical and modeing commitments). By making these implicit models explicit via computational modeling the quality, usefuness, and verisimilitude of research programs can be secured and ascertained. The three levels with a red background in Figure 2 (theory, specification, and implementation) are those that we believe are left implicit in most of psychological research—this is espcially so in parts of psychological science that have been most seriously affected by the so-called repliction crisis. This tendency to ignore these levels results from the same process by which theory and hypothesis are conflated (Fried, 2020; Meehl, 1967; Morey et al., 2018) and by which models of the data are taken to be models of the theory: “theoretical amnesia” (Borsboom, 2013). When models of the data are seen as models of the theory, potentially bizarre situations can arise—eventually forcing dramatic rethinkings of (sub)fields (e.g., Jones & Love, 2011). Framework A framework is a conceptual system of building blocks for creating facsimiles of complex psychological systems (see Fig. 2, topmost level)",
    "chunk_id": "Adv_cognitive_modelling_how_computational_modeling_can_force_theory_building_in_psychological_science.json_chunk_12"
  },
  {
    "document_type": "research_paper",
    "title": "How Computational Modeling Can Force Theory Building in Psychological Science",
    "author": "Unknown",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\guest-martin-2021-how-computational-modeling-can-force-theory-building-in-psychological-science.pdf",
    "date_published": "2021-07-03",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Framework A framework is a conceptual system of building blocks for creating facsimiles of complex psychological systems (see Fig. 2, topmost level). A framework is typically 794 Guest, Martin described using natural language and figures but can also be implemented in code such as ACT-R (or adative control of thought–rational; Anderson & Lebiere, 1998) and SOAR (Newell, 1992). Some frameworks appear superficially simple or narrow, such as the cocept of working memory (Baddeley, 2010) or duasystems approaches (Dayan & Berridge, 2014; Kahneman, 2011), whereas others can be all-encompassing such as unified theories of cognition (Newell, 1990) or conectionism (McClelland et al., 1986). In the simplest case a framework is the context—the interpretation of the terms of a theory (Lakatos, 1976). Frameworks usually require descending further down the path before they can be computationally modeled (Hunt & Luce, 1992; Vere, 1992). Although it is possible to avoid explicit frameworks, it is “awkward and unduly laborious” (Suppes, 1967, p. 58) to work without one and thus depends on the next level down in the path to do all the heavy lifting. It is not the case that all psychological models are or can be evaluated against data directly. For example, ACT-R is certainly not such a model: We have to descend the path first, creating a specific theory, then a specification, then an implementation, and then geerate hypotheses before any data can be collected (see Cooper, 2007; Cooper et al., 1996). Theory A theory is a scientific proposition—described by a collection of natural-language sentences, mathematics, logic, and figures—that introduces causal relations with the aim of describing, explaining, and/or predicting a set of phenomena (Lakatos, 1976; see Fig. 2, second level)",
    "chunk_id": "Adv_cognitive_modelling_how_computational_modeling_can_force_theory_building_in_psychological_science.json_chunk_13"
  },
  {
    "document_type": "research_paper",
    "title": "How Computational Modeling Can Force Theory Building in Psychological Science",
    "author": "Unknown",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\guest-martin-2021-how-computational-modeling-can-force-theory-building-in-psychological-science.pdf",
    "date_published": "2021-07-03",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". 2, second level). Examples of psychological theories are prospect theory (Kahneman & Tversky, 1979), the Rescorla-Wagner model for Pavlovian conditioning (Rescorla & Wagner, 1972), and SUSTAIN (supervised and unsupervised stratified adaptive incremental network), an account of categrization (Love et al., 2004). To move to the next level and produce a specifiction for a psychological theory, we must posit a plasible mechanism for the specification model to define. As can be seen from our path, direct comparisons to data can happen only once a model is at the correct level. However, not all psychological models must be (or can be) evaluated against data directly. Theoretical computational models allow us to check whether our ideas, when taken to their logical conclusions, hold up (e.g., Guest & Love, 2017; Martin, 2016, 2020; Martin & Baggio, 2020; van Rooij, 2008). If a theory cannot lead to coherent specifications, it is our responsibility as scientists to amend or, more rarely, abandon it in favor of one that does. Specification A specification is a formal (or formalizable) description of a system to be implemented on the basis of a theory (Fig. 2, third level). It provides a means of discriminating between theory-relevant (i.e., closer to the core claims of the theory) and theory-irrelevant auxiliary assumtions (Cooper & Guest, 2014; Lakatos, 1976). Specifictions provide both a way to check whether a computational model encapsulates the theory and a way to create a model even if the theory is not clear enough, simply by constraining the space of possible computational moels. Specifications can be expressed in natural-language sentences, mathematics, logic, diagrams, and formal specification languages, such as Z notation (Spivey & Abrial, 1992) and TLA + (Lamport, 2015). The transition to code from specification has been automated in some cases in computer science (Monperrus et al., 2008)",
    "chunk_id": "Adv_cognitive_modelling_how_computational_modeling_can_force_theory_building_in_psychological_science.json_chunk_14"
  },
  {
    "document_type": "research_paper",
    "title": "How Computational Modeling Can Force Theory Building in Psychological Science",
    "author": "Unknown",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\guest-martin-2021-how-computational-modeling-can-force-theory-building-in-psychological-science.pdf",
    "date_published": "2021-07-03",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". The transition to code from specification has been automated in some cases in computer science (Monperrus et al., 2008). In psychological science, creating an implementation typically involves taking the specifiction implicitly embedded in a journal article and writing code that is faithful to it. Without specifications, we can neither debug our implementations nor properly test our theories (Cooper et al., 1996; Cooper & Guest, 2014; Miłkowski et al., 2018). Implementation An implementation is an instantiation of a model crated using anything from physical materials, (e.g., a scale model of an airplane; Morgan & Morrison, 1999), to software (e.g., a git repository; Fig. 2, fourth level). A computational implementation is a codebase written in one or more programming languages that constitutes a software unit and embodies a computational model. Although the concept of an implementation is simple to grasp—perhaps what most psychologists think when they hear the term model—it might appear to be the hardest step. This is arguably not the case. Provided one follows the steps in Figure 2, a large proportion of the heavy lifting is done by all the previous steps. In some senses, implementations are the most diposable and time-dependent parts of the scientific prcess illustrated in Figure 2. Very few programming languages stay in vogue for more than a decade, redering code older than even a few months in extreme cases unrunnable without amendments (Cooper & Guest, 2014; Rougier et al., 2017). This is not entirely damaging to our enterprise because the core scientific components we want to evaluate are theory and specfication. If the computational model is not reimplmentable given the specification, it poses serious questions for the theory (Cooper & Guest, 2014). This constitutes an expectation violation and must be Modeling Forces Theory Building 795 addressed by moving upward to whichever previous level can amend the issue",
    "chunk_id": "Adv_cognitive_modelling_how_computational_modeling_can_force_theory_building_in_psychological_science.json_chunk_15"
  },
  {
    "document_type": "research_paper",
    "title": "How Computational Modeling Can Force Theory Building in Psychological Science",
    "author": "Unknown",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\guest-martin-2021-how-computational-modeling-can-force-theory-building-in-psychological-science.pdf",
    "date_published": "2021-07-03",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". This constitutes an expectation violation and must be Modeling Forces Theory Building 795 addressed by moving upward to whichever previous level can amend the issue. However, it is premature to generalize from the success or failure of one implemetation if it cannot be recreated according to the specfication because we have no reason to assume it is embodying the theory. Whether code appropriately embodies a theory can be answered only by iterating through theory, specification, and implementation. Running our computational model’s code allows us to generate hypotheses. For example, if our model behaves in a certain way in a given task (e.g., has trouble categorizing some types of visual stimuli more than others), we can formulate a hypothesis to test this behavior. Alternatively, if we already know this phnomenon occurs, computational modeling is a useful way to check that our high-level understanding does indeed so far match our observations. If our implemetation displays behavior outside what is permitted by the specification and theory, then we need to adjust something because this constitutes a violation. It might be that the theory is underspecified and that this behaior should not be permissible, in which case we might need to change both the specification and the implmentation to match the theory (Cooper & Guest, 2014). Such a cycle of adjustments until the theory is captured by the code and the code is a strict subset of the theory are necessary parts of the scientific process. Loosening and tightening theory, specification, and implementtion never ends—it is the essence of theory develoment in science. Hypothesis A hypothesis is a narrow testable statement (Fig. 2, fifth level). Hypotheses in psychological science focus on properties of the world that can be measured and evalated by collecting data and running inferential statistics",
    "chunk_id": "Adv_cognitive_modelling_how_computational_modeling_can_force_theory_building_in_psychological_science.json_chunk_16"
  },
  {
    "document_type": "research_paper",
    "title": "How Computational Modeling Can Force Theory Building in Psychological Science",
    "author": "Unknown",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\guest-martin-2021-how-computational-modeling-can-force-theory-building-in-psychological-science.pdf",
    "date_published": "2021-07-03",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". 2, fifth level). Hypotheses in psychological science focus on properties of the world that can be measured and evalated by collecting data and running inferential statistics. Any sentence that can be directly tested statistically can be a hypothesis, for example, “the gender similarities hypothesis which states that most psychological gender differences are in the close to zero ( d ≤ 0.10) or small (0.11 < d < 0.35) range” (Hyde, 2005, p. 581). Hypothesis testing is unbounded without iterating through theory, specification, and implementation and creating computational models. The supervening levels constrain the space of possible hypotheses to be tested. Testing hypotheses in an ad hoc way—what we could dub hypohacking —is to the hypothesis layer what p -hacking is to the data layer (Head et al., 2015). Researchers can concoct any hypothesis, and given suficient data a significant result is likely to be found when comparing, for example, two theoretically basless groupings. Another way to hypohack is to atheretically run pilot studies until something works. When research is carried out this way, losing the significant p value (e.g., because of a failure to replicate) could be enough to destroy the research program. Any theories based on hypohacking will crumble if no bidirectional transitions in the path were carried out, especially within the steps highlighted in red in Figure 2. Having built a computational account researchers can avoid the confirmation bias of hypohacking, which cheats the path and skips levels. Data Data are observations collected from the real world or from a computational model (Fig. 2, sixth level). Data can take on many forms in psychological science, the most common being numerical values that represent variables as defined by our experimental design (e.g., reaction times, questionnaire responses, neuroimaging). Most undergraduate psychology students know some basic statistical modeling techniques",
    "chunk_id": "Adv_cognitive_modelling_how_computational_modeling_can_force_theory_building_in_psychological_science.json_chunk_17"
  },
  {
    "document_type": "research_paper",
    "title": "How Computational Modeling Can Force Theory Building in Psychological Science",
    "author": "Unknown",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\guest-martin-2021-how-computational-modeling-can-force-theory-building-in-psychological-science.pdf",
    "date_published": "2021-07-03",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Most undergraduate psychology students know some basic statistical modeling techniques. Tests such as analysis of variance, linear regression, multivariate patern analysis, structural equation modeling, the t test, and mixed-effects modeling (e.g., Davidson & Martin, 2013) are all possible inferential statistical models of data sets. Because data are theory-laden, they can never be free from, or understood outside of, the assumptions implicit in their collection (Feyerabend, 1957; Lakatos, 1976). For example, functional MRI (fMRI) data rest on our understanding of electromagnetism and of the blood-oxygen-level-dependent signal’s association with neural activation. If any of the scientific theories that support the current interpretation of fMRI data change then the properties of the data will also change. If the data model does not support the hypothesis (an expectation violation), we can reject the expermental hypothesis with a certain confidence. However, we cannot reject a theory with as much confidence. The same caution is advised in the inverse situation (Meehl, 1967). For example, a large number of studies have collected data on cognitive training over the past century, and yet consensus on its efficacy is absent (Katz et al., 2018). To escape these problems and undestand how data and hypothesis relate to our working theory we must ascend the path and contextualize our findings using computational modeling. These violtions cannot be addressed by inventing new hypoteses that conveniently fit our data (i.e., HARKing) but by asking what needs to change in our theoretical understanding. Harking back to pizza The pizza example (purposefully chosen in part because it is simple and devoid of psychological constructs, which bias reader’s opinions toward one formalism over 796 Guest, Martin another) can be decomposed readily into the six levels shown in Figure 2. At the framework level we have the concepts of pizza, food, and order because we want to compare the total amount of food per order",
    "chunk_id": "Adv_cognitive_modelling_how_computational_modeling_can_force_theory_building_in_psychological_science.json_chunk_18"
  },
  {
    "document_type": "research_paper",
    "title": "How Computational Modeling Can Force Theory Building in Psychological Science",
    "author": "Unknown",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\guest-martin-2021-how-computational-modeling-can-force-theory-building-in-psychological-science.pdf",
    "date_published": "2021-07-03",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". At the framework level we have the concepts of pizza, food, and order because we want to compare the total amount of food per order. These are the building blocks for any account that involves deciing between orders of food made up of pizzas, even if we disagree on which aspects of the order (e.g., money, speed of delivery), food (e.g., calories, ingredients), or pizza (e.g., crust, transportability) we will eventually formally model and empirically test. Then at the theory level, there are essentially two theories: the original (implicit) theory T 0 that the nuber of pizzas per order corresponds to the amount of food in that order and the post hoc corrected (explicit) T 0 that the surface areas of the pizzas per order corespond to the amount of food in that order. To get to T 1 , we created a specification, created an implementtion, and refined the specification—we discuss exactly how this happened using the path model of Figure 2. Before obtaining T 1 , we descended the path by going from basically framework to hypothesis (bypassing the red area completely; recall T 0 was not explicitly stated at all, let alone formalized, at the beginning) to geneate the very clear prediction (and thus testable hypotesis) that the order with two pizzas is more food than the order with one. Because we skipped the parts of the path that required formalizing our ideas (shown in red in Fig. 2), we are faced with an expectation violtion. We believed that two 12-in. pizzas are more food than one 18-in. pizza (recall Fig. 1), and we also believed that the food per order is a function of the surface area of the pizzas. Therefore, we realize our own ideas about the amount of food per order are incompatible with themselves (what we dub the pizza problem), as well as what we know about the world from other sources (imagine if we had weighed the pizzas per order, for example)",
    "chunk_id": "Adv_cognitive_modelling_how_computational_modeling_can_force_theory_building_in_psychological_science.json_chunk_19"
  },
  {
    "document_type": "research_paper",
    "title": "How Computational Modeling Can Force Theory Building in Psychological Science",
    "author": "Unknown",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\guest-martin-2021-how-computational-modeling-can-force-theory-building-in-psychological-science.pdf",
    "date_published": "2021-07-03",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Had this been a real research program (and not a fictional example), we would have descended all the way and collected empiical data on the pizzas by, for example, weighing them. This act of collecting observations would have further solidified the existence of an expectation violation because the two pizzas would have been found to, for example, have less mass, thus falsifying both our hypothesis and indirectly T 0 . At the point of an expectation violation, we decided to address the steps we skipped in the red area, so we moved upward to create a formal specification S 0 embodied by Equations 1 and 2. We then attempted to descend from S 0 to create an implementation I 0 , which led to refining our specification, thus creating S 1 (Equtions 2 and 3). We are now fully in the throes of formal and computational modeling by cycling through the steps shown in Figure 2 in red. Arguably—and this is one of the core points of this article—had we not ignored the steps in red and crated a theory, specification, and implementation expliitly, we would have been on better footing from the start. And so it is demonstrated that applying the path model adds information to the scientific-inference prcess. Still, we managed to document and update our less-than-useful assumptions by going back and fomally and computationally capturing our ideas. We should all strive not to ignore these vital steps by directly focusing on them, either ourselves or by maing sure the literature contains this explicit formal and computational legwork. What our path-function model offers We have denoted the boundaries and functions of levels within the scientific-inference process in psychological research—many should be familiar with similar layers of abstraction from computer science and levels of analysis from Marr and Poggio (1976)",
    "chunk_id": "Adv_cognitive_modelling_how_computational_modeling_can_force_theory_building_in_psychological_science.json_chunk_20"
  },
  {
    "document_type": "research_paper",
    "title": "How Computational Modeling Can Force Theory Building in Psychological Science",
    "author": "Unknown",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\guest-martin-2021-how-computational-modeling-can-force-theory-building-in-psychological-science.pdf",
    "date_published": "2021-07-03",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Simpler, more abstract descriptions appear higher up the path, whereas more complex descriptions of psychological science are lower down the path—for example, data are much less compressed as a description of an experment than is a hypothesis. Each level is a renormaliztion, or coarser description, of those below (DeDeo, 2018; Flack, 2012; Martin, 2020). Higher levels contain fewer exemplars than lower levels. Moving through the path of scientific inference is a form of dimensionality reduction or coordinate transformation. Not only are there often no substantive nor formalized theories for some data sets in practice (causing chaos; see Forscher, 1963), but the principle of multiple realizability (Putnam, 1967) also implies that for every theory there are infnitely many possible implementations consistent with it and data sets that can be collected to test it (Blokpoel, 2018). This helps to contextualize studies that show divergence in data-modeling decisions given the same hypotheses (e.g., Botvinik-Nezer et al., 2020; Silberzahn et al., 2018). Open theories (i.e., those developed explicitly, defined formally, and explored computationally, in line with Fig. 2) are more robust to failures of replication of any single study from which they might derive some support because of the specific way the path has been followed to develop and test them. For example, if the impetus or inspiration for theory development is a single study (that is thereafter found not to be replcable) because we then move to the red area, refine our ideas, and then drop back down to test them again, we will avoid dependence on a single (potentially prolematic) study. Failures to replicate can not only be detected but also explained and perhaps even drive Modeling Forces Theory Building 797 theory creation as opposed to just theory rejection",
    "chunk_id": "Adv_cognitive_modelling_how_computational_modeling_can_force_theory_building_in_psychological_science.json_chunk_21"
  },
  {
    "document_type": "research_paper",
    "title": "How Computational Modeling Can Force Theory Building in Psychological Science",
    "author": "Unknown",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\guest-martin-2021-how-computational-modeling-can-force-theory-building-in-psychological-science.pdf",
    "date_published": "2021-07-03",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Failures to replicate can not only be detected but also explained and perhaps even drive Modeling Forces Theory Building 797 theory creation as opposed to just theory rejection. Thus, building a theory explicitly as laid out in Figure 2, even if based on some hypand p -hacking, means once a phenomenon is detected we ascend the path and spend time formalizing our account (e.g., Fried, 2020). Our path model asks for formalization using specifications and implementations (or indeed anything more comprehensive than an individual study; see Head et al., 2015); thus, when our model is used, “sins” that are out of individual scientists’ control—such as questionable research practices (QRPs; see John et al., 2012) committed by other labs or publication bias comitted by the system as a whole—can be both discoered and controlled for in many cases. Thinking about our science with reference to Figure 2 allows us to discuss and decide where in the path claims about science are being made (i.e., not only allowing us to evaluate claims about the phenomena being examined, modeled, and so on, but also to evalate general claims about how we conduct research or about how not to conduct research). For example, the claim that “science is posthoc, with results, especially unexpected results, driving theory and new applictions” (Shiffrin, 2018) is not incompatible with guarding against HARKing because one cannot have an account of a phenomenon without having access to some data— anecdotal, observational, and/or experimental—that guide one to notice the phenomenon in the first case. Theories in psychology result from protracted thought about and experience with a human cognitive capacity. Scientists immerse themselves in deep thought about why and how their phenomena of study behave. This basic principle of developing theories is captured in the example of Wald’s investigation into optimally (and thus minimally because of weight) armoring aicraft to ensure pilots returned safely during World War II (Mangel & Samaniego, 1984)",
    "chunk_id": "Adv_cognitive_modelling_how_computational_modeling_can_force_theory_building_in_psychological_science.json_chunk_22"
  },
  {
    "document_type": "research_paper",
    "title": "How Computational Modeling Can Force Theory Building in Psychological Science",
    "author": "Unknown",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\guest-martin-2021-how-computational-modeling-can-force-theory-building-in-psychological-science.pdf",
    "date_published": "2021-07-03",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Planes returned after engaging with the Nazis with a smattering of bullet holes that were distributed in a specific way: More holes were present in the fuselage than in the engines, for example. Wald explained post hoc why and how the holes were correlated to survival. Contrary to what one might expect, areas with the least holes would benefit from armor. Wald theorized that planes in general were likely hit by bullets uniformly, unlike the planes in the data set; aircraft hit in the engines did not make it home and so were not present in the data set; and, therefore, armor should be placed over the engines, the area with the fewest bullet holes. This is not HARKing—this is formal modeling. Wald moved upward from the data (distribution of bullet holes) to a theory (survivor bias) and created an explicit formal model that could explain and predict the patterns of the bullets in planes that made it back safely. In many cases theory development involves analysis at the data level, as an inspiration or impetus, and then a lot of scientific activity within the levels: theory, specification, and implementation. This is why we do not impose any constraints on moving upward in Figure 2, only on moving downward. On the other hand, our path-function model allows us to pinpoint on which level QRPs are taking place and how to avoid them. Different QRPs occur at diffeent levels, for example, p -hacking at the data level, HARKing at the hypothesis level, and so on. HARKing does not resolve expectation violations that occur when the data meet the hypothesis—it is not, for example, theorizing after the results are known, which is part of the scientific practice of creating modeling accounts. To retrofit a hypothesis onto a data set does not costitute resolving a violation because this de novo hypothesis is not generated directly or indirectly by a theory",
    "chunk_id": "Adv_cognitive_modelling_how_computational_modeling_can_force_theory_building_in_psychological_science.json_chunk_23"
  },
  {
    "document_type": "research_paper",
    "title": "How Computational Modeling Can Force Theory Building in Psychological Science",
    "author": "Unknown",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\guest-martin-2021-how-computational-modeling-can-force-theory-building-in-psychological-science.pdf",
    "date_published": "2021-07-03",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". To retrofit a hypothesis onto a data set does not costitute resolving a violation because this de novo hypothesis is not generated directly or indirectly by a theory. If we start out with a hypothesis and collect data that reject our hypothesis, the violation has not occurred uniquely at the hypothesis level because the hypothesis has been generated (via the intervening levels) by the theory. This is essentially the opposite to conjuring a new hypothesis (HARKing) that exists only in the scentific literature because it has been “confirmed” by data—data collected to test a different hypothesis. It is at the data and hypothesis levels that preregitration and similar methods attempt to constrain science to avoid QRPs (e.g., Flis, 2019; Szollosi et al., 2019). To ensure scientific quality, however, we propose that prregistration is not enough because it serves only to constrain the data and hypothesis spaces. Researchers who wish to develop their formal account of a capacity must ascend the path instead of, or in addition to, for example, preregistering analysis plans. Preregistration cannot on its own evaluate theories. We cannot coheently describe and thus cannot sensibly preregister what we do not yet (formally and computationally) undestand. Indeed, theories can and should be computatioally embodied and pitted against each other without gathering or analyzing any new data. To develop, evalate, and stress-test theories, we need theory-level costraints on and discussions about our science. Figure 2 can serve as a first step in the right direction toward such an ideal. By the same token, our path model allows us to delineate and discuss where computational modeling itself has been compromised by QRPs occurring at the specification and implementation levels. A typical case of this is when authors report only partial results of implementing a specification of their theory; for exaple, only some implementations show the required or predicted patterns of behavior (Guest et al., 2020)",
    "chunk_id": "Adv_cognitive_modelling_how_computational_modeling_can_force_theory_building_in_psychological_science.json_chunk_24"
  },
  {
    "document_type": "research_paper",
    "title": "How Computational Modeling Can Force Theory Building in Psychological Science",
    "author": "Unknown",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\guest-martin-2021-how-computational-modeling-can-force-theory-building-in-psychological-science.pdf",
    "date_published": "2021-07-03",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". As 798 Guest, Martin mentioned, the solution is to cycle within the red area of Figure 2 to ensure theory-, specification-, and implementation-level details are indeed assigned to and described at the correct level. Failing to do that, we propose, is a type of QRP. Computational modeling can be seen as mediating between theory and data (Morgan & Morrison, 1999; Oberauer & Lewandowsky, 2019). Asking if we can build a model of our theory allows us to understand where our theoretical understanding is lacking. Claims are typically not falsifiable—not usually directly testable at the framework or theory level—but become more so as we move downward. We thus iterate through theory, specification, and implementation as required until we have achieved a modeling account that satisfies all of the various constraints imposed by empirical data, as well as collecting empirical data based on hypotheses generated from the computational model. Is an implmentation detail pivotal to a model working? Then it must be upgraded to a specification detail (Cooper et al., 1996; Cooper & Guest, 2014). Mutatis mutandis for details at the specification level and so on—meaning that details at every level can be upgraded (or dowgraded) as required. This process is even useful in the case of “false” models; that is, computational accounts that we do not agree with can still improve our undestanding of phenomena (e.g., Wimsatt, 2002; Winsberg, 2006). As mentioned, cycling through the steps in Figure 2 shines a direct light on what our theoretical commiments are in deep ways. Mathematically specifying and/ or computationally implementing models, for example, can demonstrate that accounts are identical or overlap even when their verbal descriptions (i.e., informal speifications) are seemingly divergent",
    "chunk_id": "Adv_cognitive_modelling_how_computational_modeling_can_force_theory_building_in_psychological_science.json_chunk_25"
  },
  {
    "document_type": "research_paper",
    "title": "How Computational Modeling Can Force Theory Building in Psychological Science",
    "author": "Unknown",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\guest-martin-2021-how-computational-modeling-can-force-theory-building-in-psychological-science.pdf",
    "date_published": "2021-07-03",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". This can result from (a) multiple theories being indeed more similar in essence than previously thought, paving the way for theoretical unification of a seemingly disjointed literture (e.g., Kelly et al., 2017), or (b) theories that are indeed different being less computationally explored and thus less constrained in their current state (e.g., Olsson et al., 2004). These kinds of discoveries about how we compartmentalize, understand, and predict human capacities are why iterating over—and thus refining—theory, specification, and implementation is vital. Research programs light on modeling do not have a clear grasp on what is going on in the area highlighted in red in Figure 2. These areas of psychological science might have many, often informal, theories, but this is not enough (Watts, 2017). Neither is more data—hoever open, they will never solve the issue of a lack of formal theorizing. Data cannot tell a scientific story; that role falls to theory, and theory needs formalization to be evaluated. Thus, whereas modelers often use the full scale of the path, reaping the benefits of formally testing and continuously improving their theories, those who eschew modeling miss out on fundamental scietific insights. By formalizing a research program, we can search and evaluate in a meticulous way the space of the account proposed (i.e., “theory-guided scientific exploration”; Navarro, 2019, p. 31). As shown using the pizza example, nonmodelers remain unaware of pizza problems and may not realize they are implicitly runing a different model (in their head) to what they specify. Discussion We hope to spark a dialogue on the radical role coputational modeling can play by forcing open theoriing. We also presented a case study in building a basic computational model, providing a useful guide to those who may not have modeled before. Models, especially when formalized and run on a digital computer, can shine a light on when our scientific expectations are violated",
    "chunk_id": "Adv_cognitive_modelling_how_computational_modeling_can_force_theory_building_in_psychological_science.json_chunk_26"
  },
  {
    "document_type": "research_paper",
    "title": "How Computational Modeling Can Force Theory Building in Psychological Science",
    "author": "Unknown",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\guest-martin-2021-how-computational-modeling-can-force-theory-building-in-psychological-science.pdf",
    "date_published": "2021-07-03",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Models, especially when formalized and run on a digital computer, can shine a light on when our scientific expectations are violated. To wit, we presented a path-function model of science, radically centering computational modeling at the core of psychological science. Computational models cannot replace, for example, data or verbal theories, but the process of creating a computational account is invaluable and informative. There are three routes that psychology can take, mirroring Newell (1973): The first is bifurcating between research programs that use modeling and those that do not; the second is uniting research programs inasmuch as they contain some modeling to force the creation, refinement, and rejection of theories; and the third is continuing to ask questions that are not secured to a sound theoretical mooring via computational modeling. These are not completely mutually exclusive possibilities— some components from each can be seen in the present. For bifurcation of the field, theoreticians, scientists who mostly inhabit the red area of Figure 2, will be free to practice modeling, for example, without having to run frequentist statistics on their models if inapprpriate. No constraints will be put on individual scietists to pick a side (e.g., Einstein was active in theoretical and experimental physics). Unlike it is now, it will be easy to publish work containing only modeling at the theory level without direct reference to data (something rare currently, although possible; e.g., Guest & Love, 2017; Martin, 2016, 2020). In the case of uniting research programs, mass cooeration to work on “larger experimental wholes” (Newell, 1973, p. 24) is perhaps realistic given projects that involve many labs are commonplace (e.g., BotviniNezer et al., 2020; Silberzahn et al., 2018). We advise cautious optimism because these collaborations are Modeling Forces Theory Building 799 operating only at the data and hypothesis levels, which are insufficient to force theory building",
    "chunk_id": "Adv_cognitive_modelling_how_computational_modeling_can_force_theory_building_in_psychological_science.json_chunk_27"
  },
  {
    "document_type": "research_paper",
    "title": "How Computational Modeling Can Force Theory Building in Psychological Science",
    "author": "Unknown",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\guest-martin-2021-how-computational-modeling-can-force-theory-building-in-psychological-science.pdf",
    "date_published": "2021-07-03",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". We advise cautious optimism because these collaborations are Modeling Forces Theory Building 799 operating only at the data and hypothesis levels, which are insufficient to force theory building. Nevertheless, such efforts might constitute the first step in undestanding the logistics of multilab projects. On the other hand, modelers often already currently work on a series of related experiments and publish them as a single experimental whole (Shiffrin, 2018). The third possibility, more of the same, is the most dire: “Maybe we should all simply continue playing our collective game of 20 questions. Maybe all is well and when we arrive in 1992 we will have homed in to the essential structure of the mind” (Newell, 1973, p. 24). Thus, the future holds more time wasting and crises. Some scientists will spend time attempting to replicate atheoretical hypotheses. However, asking nature 20 questions without a computational model leads to serious theoretical issues, even if the results are superficially deemed replicable (e.g., Devezer et al., 2019; Katz et al., 2018). A Way Forward Psychological science can change if we follow Figure 2 and radically update how we view the place of moeling. The first step is introspective: realizing that we all do some modeling—we subscribe to frameworks and theories implicitly. Without formalizing our assumtions in the same way we explicitly state the variables in hypothesis testing, we cannot communicate effciently. Some have even started to demand this shift in our thinking (e.g., Morey et al., 2018; Oberauer & Lewandowsky, 2019; Szollosi et al., 2019; Wills et al., 2017). The second step is pedagogical: explaining what modeling is and why it is useful. We must teach metees that modeling is neither extremely complex nor requires extra skills beyond those we already expect that they master, for example, programming, expermental design, literature review, and statistical-analysis techniques (e.g., Epstein, 2008; Wills et al., 2017; Wilson & Collins, 2019)",
    "chunk_id": "Adv_cognitive_modelling_how_computational_modeling_can_force_theory_building_in_psychological_science.json_chunk_28"
  },
  {
    "document_type": "research_paper",
    "title": "How Computational Modeling Can Force Theory Building in Psychological Science",
    "author": "Unknown",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\guest-martin-2021-how-computational-modeling-can-force-theory-building-in-psychological-science.pdf",
    "date_published": "2021-07-03",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". The third step is cooperative: working together as a field to center modeling in our scientific endeavors. Some believe the replication crisis is a measure of the scientific quality of a subfield, and given that it has affected areas of psychological science with less formal modeling, one possibility might be to ask these areas to model explicitly. By extension, modelers can begin to publish more in these areas (e.g., in consumer behavior; see Hornsby et al., 2019). To ensure experimental results can be replicated and reobserved, we must force theory building; replicability in part depends causally on things higher up the path (see also Oberauer & Lewandowsky, 2019). Data and experiments that cannot be replicated are clearly impotant issues. However, the same is true for theoretical accounts that cannot be instantiated or reinstantiated as code. Should results of preregistered studies count as stronger evidence than results of nonpreregistered stuies? Should results of computationally modeled studies count as stronger evidence than those of studies with only a statistical model? Just as the first question here has been actively discussed (e.g., Szollosi et al., 2019), the second should be as well. Thus, although it may superficially appear that we are at odds with the emphasis on the bottom few steps in our path model (hypothesis testing and data analysis; recall Fig. 2) by those who are investigating replicabiity, we are comfortable with this emphasis. We believe the proposals set out by some to automate or streamline the last few steps are part of the solution (e.g., Lakens & DeBruine, 2021; Poldrack et al., 2019). Such a divsion of labor might help to maximize the quality of theories and showcase the contrast—which Meehl (1967) and others have drawn attention to—between substantive theories and the hypotheses they generate",
    "chunk_id": "Adv_cognitive_modelling_how_computational_modeling_can_force_theory_building_in_psychological_science.json_chunk_29"
  },
  {
    "document_type": "research_paper",
    "title": "How Computational Modeling Can Force Theory Building in Psychological Science",
    "author": "Unknown",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\guest-martin-2021-how-computational-modeling-can-force-theory-building-in-psychological-science.pdf",
    "date_published": "2021-07-03",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". We imagine a “best of all possible” massively collabortive future in which scientists allow machines to carry out the least creative steps and thus set themselves free to focus exclusively on computational modeling, theory generation, and explanation. Transparency Action Editors: Travis Proulx and Richard Morey Advisory Editor: Richard Lucas Editor: Laura A. King Declaration of Conflicting Interests The author(s) declared that there were no conflicts of interest with respect to the authorship or the publication of this article. Funding O. Guest was supported by the Research Centre on Inteactive Media, Smart Systems and Emerging Technologies (RISE) under the European Union’s Horizon 2020 prgramme (Grant 739578) and the Republic of Cyprus through the Directorate General for European Programmes, Coodination and Development. A. E. Martin was supported by the Max Planck Research Group “Language and Computtion in Neural Systems” and by the Netherlands Organiztion for Scientific Research (Grant 016.Vidi.188.029). ORCID iD Olivia Guest https://orcid.org/0000-0002-1891-0972 Acknowledgments We thank Abeba Birhane, Sebastian Bobadilla Suarez, Christopher D. Chambers, Eiko Fried, Dermot Lynott, Esther Mondragón, Richard D. Morey, Karim N’Diaye, Nicolas P. 800 Guest, Martin Rougier, Richard M. Shiffrin, Loukia Tzavella, and Andy J. Wills for useful discussions and input on previous versions of the article.",
    "chunk_id": "Adv_cognitive_modelling_how_computational_modeling_can_force_theory_building_in_psychological_science.json_chunk_30"
  },
  {
    "document_type": "online_article",
    "title": "Introduction to Bayesian Data Analysis for Cognitive Science",
    "author": "Bruno Nicenboim",
    "source": "https://bruno.nicenboim.me/bayescogsci/ch-remame.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": "In this chapter, we introduce two relatively underutilized modeling approaches that are potentially very important for cognitive science: meta-analysis and measurement-error models. Meta-analysis can be very informative when carrying out systematic reviews, and measurement-error models are able to take into account uncertainty in one’s dependent or independent variable (or both). What’s common to these two classes of model is that they both assume that the\\(n\\)-th measured data point\\(y_n\\)has a location parameter, say\\(\\zeta_n\\)(pronouncedzeta en), that is measured with some uncertainty that can be represented by the standard error\\(SE_n\\)of the measurement\\(y_n\\): \\(y_n \\sim \\mathit{Normal}(\\zeta_n,SE_n)\\) In both classes of model, the goal is to obtain a posterior distribution of a latent parameter\\(\\zeta\\)which is assumed to generate the\\(\\zeta_n\\), with some standard deviation\\(\\tau\\). The parameter\\(\\tau\\)quantifies the noise in the measurement process or the between-study variability in a meta-analysis. \\(\\zeta_n \\sim \\mathit{Normal}(\\zeta,\\tau)\\) The main parameter of interest is usually\\(\\zeta\\), but the posterior distributions of\\(\\tau\\)and\\(\\zeta_n\\)can also be informative. The above model specification should remind you of the hierarchical models we saw in earlier chapters. Once a number of studies have accumulated on a particular topic, it can be very informative to synthesize the data. Here is a commonly used approach–a random-effects meta-analysis. The model is set up as follows. For each study\\(n\\), let effect\\(_n\\)be the effect of interest, and let\\(SE_n\\)be the standard error of the effect. A concrete example of a recent meta-analysis is the effect of similarity-based interference in sentence comprehension(Jäger, Engelmann, and Vasishth2017); when two nouns are more similar to each other, there is greater processing difficulty (i.e., longer reading times in milliseconds) when an attempt is made to retrieve one of the nouns to complete a linguistic dependency (such as a subject-verb dependency)",
    "chunk_id": "Adv_cognitive_modelling_introduction_to_bayesian_data_analysis_for_cognitive_science_84eef535.json_chunk_1"
  },
  {
    "document_type": "online_article",
    "title": "Introduction to Bayesian Data Analysis for Cognitive Science",
    "author": "Bruno Nicenboim",
    "source": "https://bruno.nicenboim.me/bayescogsci/ch-remame.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". The estimate of the effect and its standard error is the information we have from each study\\(n\\). First, load the data, and add an id variable that identifies each experiment. The effect size and standard errors were estimated from published summary statistics in the respective article. In some cases, this involved a certain amount of guesswork; the details are documented in the online material accompanyingJäger, Engelmann, and Vasishth (2017). We begin with the assumption that there is a true (unknown) effect\\(\\zeta_n\\)that lies behind each of these studies. Each of the observed effects has an uncertainty associated with it,\\(SE_n\\). We can therefore assume that each observed effect, effect\\(_n\\), is generated as follows: \\[\\begin{equation} \\text{effect}_n \\sim \\mathit{Normal}(\\zeta_n,SE_n) \\end{equation}\\] Each study is assumed to have a different true effect\\(\\zeta_n\\)because each study will have been carried out under different conditions: in a different lab with different protocols and workflows, with different subjects, possibly with different languages, with slightly different experimental designs, etc.45 Further, each of the true underlying effects\\(\\zeta_n\\)has behind it some true unknown value\\(\\zeta\\). The parameter\\(\\zeta\\)represents the underlying effect of similarity-based interference across experiments. Our goal is to obtain the posterior distribution of this overall effect. We can write the above statement as follows: \\[\\begin{equation} \\zeta_n \\sim\\mathit{Normal}(\\zeta,\\tau) \\end{equation}\\] \\(\\tau\\)is the between-study standard deviation; this expresses the assumption that there will be some variability between the true effects\\(\\zeta_n\\)",
    "chunk_id": "Adv_cognitive_modelling_introduction_to_bayesian_data_analysis_for_cognitive_science_84eef535.json_chunk_2"
  },
  {
    "document_type": "online_article",
    "title": "Introduction to Bayesian Data Analysis for Cognitive Science",
    "author": "Bruno Nicenboim",
    "source": "https://bruno.nicenboim.me/bayescogsci/ch-remame.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". To summarize the model: We can construct a hierarchical model as follows: \\[\\begin{equation} \\begin{aligned} \\text{effect}_n \\sim & \\mathit{Normal}(\\zeta_n, SE_n) \\quad n=1,\\dots, N_{studies}\\\\ \\zeta_n \\sim & \\mathit{Normal}(\\zeta, \\tau) \\\\ \\zeta \\sim & \\mathit{Normal}(0,100)\\\\ \\tau \\sim & \\mathit{Normal}_+(0,100) \\end{aligned} \\tag{11.1} \\end{equation}\\] The priors are based on domain knowledge; it seems reasonable to allow the effect to range a priori from\\(-200\\)to\\(+200\\)ms with probability\\(95\\)%. Of course, a sensitivity analysis is necessary (but skipped here). This model can be implemented inbrmsin a relatively straightforward way as shown below. We show the Stan version later in the chapter (section11.1.1.2); the Stan version presents some interesting challenges that can be useful for the reader interested in deepening their Stan modeling knowledge. First, define the priors: Fit the model as follows. Because of our relatively uninformative priors and the few data points, the models of this chapter require us to tune thecontrolparameter, increasingadapt_deltaandmax_treedepth. The posterior of\\(\\zeta\\)and\\(\\tau\\)are summarized below asInterceptandsd(Intercept). Thesigmaparameter does not play any role in this model, but appears in thebrmsoutput anyway. In the model specification,sigmawas explicitly removed by writingsigma = FALSE. For this reason, we can ignore that parameter in the model summary output above. Online sectionC.1explains what happens if we setsigma = TRUE. As theory predicts, the overall effect from these studies has a positive sign. One advantage of such a meta-analysis is that the posterior can now be used as an informative prior for a future study. This is especially important when doing an analysis using Bayes factors. But this meta-analysis posterior could also be used as an informative prior in a future experiment; that would allow the researcher to build on what is known so far from published studies",
    "chunk_id": "Adv_cognitive_modelling_introduction_to_bayesian_data_analysis_for_cognitive_science_84eef535.json_chunk_3"
  },
  {
    "document_type": "online_article",
    "title": "Introduction to Bayesian Data Analysis for Cognitive Science",
    "author": "Bruno Nicenboim",
    "source": "https://bruno.nicenboim.me/bayescogsci/ch-remame.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". But this meta-analysis posterior could also be used as an informative prior in a future experiment; that would allow the researcher to build on what is known so far from published studies. Another interesting by-product of a random-effects meta-analysis is the possibility of displaying a forest plot (Figure11.1). A forest plot shows the meta-analytic estimate (the parameterb_Interceptinbrms) alongside the original estimates effect\\(_n\\)(and their SE\\(_n\\)) and the posterior distributions of the\\(\\zeta_n\\)for each study (we reconstruct these estimates by addingb_Interceptto the parameters starting withr_inbrms). The original estimates are the ones fed to the model as data and the posterior distributions of the\\(\\zeta_n\\)are calculated, as in previous hierarchical models, after the information from all studies is pooled together. The\\(\\zeta_n\\)estimates are shrunken estimates of each study’s (unknown) true effect, shrunken towards the grand mean\\(\\zeta\\), and weighted by the standard error observed in each study\\(n\\). The\\(\\zeta_n\\)for a particular study is shrunk more towards the grand mean\\(\\zeta\\)when the study’s standard error is large (i.e., when the estimate is very imprecise). The code below shows how to build a forest plot step by step. First, change the format of the data so that it looks like the output ofbrms: Extract the meta-analytical estimate: For the pooled estimated effect (or fitted value) of the individual studies, we need the sum of the meta-analytical estimate (intercept) and each of the by-study adjustment. Obtain this with thefitted()function: Bind the observed effects, the meta-analytical estimate, and the fitted values of the studies together, and plot the data: FIGURE 11.1: Forest plot showing the original and the adjusted estimates computed from each study from the random-effects meta-analysis. The error bars on the original estimates show 95% confidence intervals, and those on the adjusted estimates show 95% credible intervals",
    "chunk_id": "Adv_cognitive_modelling_introduction_to_bayesian_data_analysis_for_cognitive_science_84eef535.json_chunk_4"
  },
  {
    "document_type": "online_article",
    "title": "Introduction to Bayesian Data Analysis for Cognitive Science",
    "author": "Bruno Nicenboim",
    "source": "https://bruno.nicenboim.me/bayescogsci/ch-remame.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". The error bars on the original estimates show 95% confidence intervals, and those on the adjusted estimates show 95% credible intervals. It is important to keep in mind that a meta-analysis is always going to yield biased estimates as long as we have publication bias: if a field has a tendency to allow only “big news” studies to be published, then the literature that will appear in the public domain will be biased, and any meta-analysis based on such information will be biased. Despite this limitation, a meta-analysis is still a useful way to synthesize the known evidence; one just has to remember that the estimate from the meta-analysis is almost certain to be biased. Even thoughbrmscan handle meta-analyses, fitting them in Stan allows us for more flexibility, which might be necessary in some cases. As a first attempt we could build a model that closely follows the formal specification given in Equation(11.1). Fit the model as follows: We see that there are warnings. As discussed in section9.1.2, we can use pairs plots to uncover pathologies in the sampling. Here we see the samples ofzetaandtauare highly correlated: We face a similar problem as we faced in section9.1.2, namely, the sampler cannot properly explore the neck of the funnel-shaped space, because of the strong correlation between the parameters. The solution is, as in section9.1.2, a non-centered parameterization. Re-write Equation(11.1)as follows: \\[\\begin{equation} \\begin{aligned} z_n & \\sim \\mathit{Normal}(0, 1)\\\\ \\zeta_n &= z_n \\cdot \\tau + \\zeta \\\\ \\text{effect}_n & \\sim \\mathit{Normal}(\\zeta_n, SE_n)\\\\ \\zeta &\\sim \\mathit{Normal}(0,100)\\\\ \\tau &\\sim \\mathit{Normal}_+(0,100) \\end{aligned} \\tag{11.2} \\end{equation}\\] This works because if\\(X \\sim\\mathit{Normal}(a, b)\\)and\\(Y \\sim \\mathit{Normal}(0, 1)\\), then\\(X = a + Y \\cdot b\\). You can re-visit section9.1.2for more details. Translate Equation(11.2)into Stan code as follows inmeta-analysis1.stan: The model converges with values virtually identical to the ones of thebrmsmodel",
    "chunk_id": "Adv_cognitive_modelling_introduction_to_bayesian_data_analysis_for_cognitive_science_84eef535.json_chunk_5"
  },
  {
    "document_type": "online_article",
    "title": "Introduction to Bayesian Data Analysis for Cognitive Science",
    "author": "Bruno Nicenboim",
    "source": "https://bruno.nicenboim.me/bayescogsci/ch-remame.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". Translate Equation(11.2)into Stan code as follows inmeta-analysis1.stan: The model converges with values virtually identical to the ones of thebrmsmodel. We can also reparameterize the model slightly differently, if we set\\(U_{n} \\sim\\mathit{Normal}(0 , SE_n)\\)then, \\[\\begin{equation} \\text{effect}_n = U_n + \\zeta_n \\end{equation}\\] Then, given that\\(\\zeta_n \\sim \\mathit{Normal}(\\zeta, \\tau)\\), \\[\\begin{equation} \\text{effect}_n \\sim \\mathit{Normal}(\\zeta, \\sqrt{SE^2 + \\tau^2}) \\tag{11.3} \\end{equation}\\] See online sectionC.1if it’s not clear why this reparameterization works. This is equivalent to thebrmsmodel wheresigma = TRUE. Parameterizing the model in this way causes us to lose the possibility of estimating the posterior of the true effect of the individual studies. Write this in Stan as follows; this code is available in the filemeta-analysis2.stanwithin thebcogscipackage: Fit the model: This summary could be reported in an article by displaying the posterior means and 95% credible intervals of the parameters. Measurement error models deal with the situation where some predictor or the dependent variable, or both, are observed with measurement error. This measurement error could arise because a variable is an average (i.e., its standard error can also be estimated), or because we know that our measurement is noisy due to limitations of our equipment (e.g., delays in the signal from the keyboard to the motherboard, impedance in the electrodes in an EEG system, etc.). As a motivating example, consider the following data fromNicenboim, Vasishth, et al. (2018). For each subject, we have the partial-credit unit (PCU) scores of an operation span task as a measure of their working memory capacity(Conway et al.2005)along with their standard error. In addition, the reading fluency of each subject is calculated from a separate set of data based on the mean reading speeds (character/second) in a rapid automatized naming task(RAN, Denckla and Rudel1976); the standard error of the reading speed is also available",
    "chunk_id": "Adv_cognitive_modelling_introduction_to_bayesian_data_analysis_for_cognitive_science_84eef535.json_chunk_6"
  },
  {
    "document_type": "online_article",
    "title": "Introduction to Bayesian Data Analysis for Cognitive Science",
    "author": "Bruno Nicenboim",
    "source": "https://bruno.nicenboim.me/bayescogsci/ch-remame.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". Of interest here is the extent of the association between working memory capacity (measured as PCU) and reading fluency (measured as reading speed in 50 characters per second). We avoid making any causal claims: It could be that our measure of working memory capacity really affects reading fluency or it could be the other way around. A third possibility is that there is a third variable (or several) that affects both reading fluency and working memory capacity. A treatment of causal inference in Bayesian models can be found in chapters 5 and 6 ofMcElreath (2020). At first glance, we see a relationship between mean PCU scores and mean reading speed; see Figure11.2. However, this relationship seems to be driven by two extreme data points on the top left corner of the plot. FIGURE 11.2: The relationship between (centered) mean PCU scores and mean reading speed. A simple linear model shows a somewhat weak association between mean reading speed and centered mean PCU. The priors are relatively arbitrary but they are in the right order of magnitude given that reading speeds are quite short and well below 1. Figure11.3(a) shows the posterior distribution of the slope in this model. Most of the probability mass is negative (94.525%), suggesting that a better PCU score is associated with slower reading speed rather than faster; that is, that a larger working memory capacity is associated with less reading fluency. This is not a very intuitive result and it could be the case that is driven by the two extreme data points. Rather than removing these data points, we’ll examine what happens when the uncertainty of the measurements is taken into account. Taking this uncertainty of the measurement is important; in many practical research problems, researchers will often take average measurements like these and examine the correlation between them. However, each of those data points is being measured with some error (uncertainty), but this error is being ignored when we take the averaged values",
    "chunk_id": "Adv_cognitive_modelling_introduction_to_bayesian_data_analysis_for_cognitive_science_84eef535.json_chunk_7"
  },
  {
    "document_type": "online_article",
    "title": "Introduction to Bayesian Data Analysis for Cognitive Science",
    "author": "Bruno Nicenboim",
    "source": "https://bruno.nicenboim.me/bayescogsci/ch-remame.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". However, each of those data points is being measured with some error (uncertainty), but this error is being ignored when we take the averaged values. Ignoring this uncertainty leads to over-enthusiastic inferences. A measurement-error model solves this issue. The measurement error model is stated as follows. There is assumed to be a true unobserved value\\(y_{n,TRUE}\\)for the dependent variable, and a true unobserved value\\(x_{n,TRUE}\\)for the predictor, where\\(n\\)is indexing the observation number. The observed values\\(y_n\\)and the predictor\\(x_n\\)are assumed to be generated with some error: \\[\\begin{equation} \\begin{aligned} y_n &\\sim\\mathit{Normal}(y_{n,TRUE},SE_{y_n}) \\\\ x_n &\\sim\\mathit{Normal}(x_{n,TRUE},SE_{x_n}) \\end{aligned} \\end{equation}\\] The regression is fit to the (unknown)truevalues of the dependent and independent variables: \\[\\begin{equation} y_{n,TRUE} \\sim\\mathit{Normal}(\\alpha + \\beta x_{n,TRUE},\\sigma) \\tag{11.4} \\end{equation}\\] In addition, there is also an unknown standard deviation (standard error) of the latent unknown means that generate the underlying PCU means. I.e., we assume that each of the observed centered PCU scores is normally distributed with an underlying mean,\\(\\chi\\), and a standard deviation\\(\\tau\\). This is very similar to the meta-analysis situation we saw earlier:\\(\\zeta_n \\sim\\mathit{Normal}(\\zeta,\\tau)\\), where\\(\\zeta_n\\)was the location parameter of each study, and\\(\\zeta\\)was the (unknown) location parameter representing the effect of interest, and\\(\\tau\\)was the between-study variability. \\[\\begin{equation} x_{n,TRUE} \\sim\\mathit{Normal}(\\chi,\\tau) \\end{equation}\\] The goal of the modeling is to obtain posterior distributions for the intercept and slope\\(\\alpha\\)and\\(\\beta\\)(and the residual error standard deviation\\(\\sigma\\)). We need to decide on priors for all the parameters now. We use relatively vague priors, which can still be considered regularizing priors based on our knowledge of the order of magnitude of the measurements",
    "chunk_id": "Adv_cognitive_modelling_introduction_to_bayesian_data_analysis_for_cognitive_science_84eef535.json_chunk_8"
  },
  {
    "document_type": "online_article",
    "title": "Introduction to Bayesian Data Analysis for Cognitive Science",
    "author": "Bruno Nicenboim",
    "source": "https://bruno.nicenboim.me/bayescogsci/ch-remame.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". We use relatively vague priors, which can still be considered regularizing priors based on our knowledge of the order of magnitude of the measurements. In situations where not much is known about a research question, one could use such vague priors. \\[\\begin{equation} \\begin{aligned} \\alpha &\\sim\\mathit{Normal}(0, 0.5)\\\\ \\beta &\\sim\\mathit{Normal}(0, 0.5)\\\\ \\chi &\\sim\\mathit{Normal}(0, 0.5)\\\\ \\sigma &\\sim\\mathit{Normal}_+(0, 0.5)\\\\ \\tau &\\sim\\mathit{Normal}_+(0, 0.5) \\end{aligned} \\tag{11.5} \\end{equation}\\] Inbrms, the model specification would be as follows: Here, the parameter with classmeanmeandsdmerefer to the unknown mean and standard deviation (standard error) of the latent unknown means that generate the underlying PCU means,\\(\\chi\\)and\\(\\tau\\)in Equation(11.5). Once we decide on the priors, we useresp_se(.)withsigma = TRUE(i.e, we don’t estimate\\(y_{n,TRUE}\\)explicitly) and we useme(c_meanpcu, se_pcu)to indicate that the dependent variablec_mean_pcuis measured with error andse_pcuis its SE. The posterior for the slope is plotted in Figure11.3(b); this figure shows that the association between PCU scores and reading speed is much weaker once measurement error is taken into account: The posterior is much more uncertain (much more widely distributed) than in the simple linear model we fit above (compare Figure11.3(b) with Figure11.3(a)), and the direction of the association is now unclear, with 61% of the probability mass below zero, rather than 95%. FIGURE 11.3: (a) Posterior distribution of the slope for the effect of centered mean PCU on mean reading speed (50 characters per second) in a model without measurement error (fit_indiv). (b) Posterior distribution of the slope for the same dependent variable (mean reading speed) and predictor (centered mean PCU) in a model that accounts for measurement error (fit_indiv_me)",
    "chunk_id": "Adv_cognitive_modelling_introduction_to_bayesian_data_analysis_for_cognitive_science_84eef535.json_chunk_9"
  },
  {
    "document_type": "online_article",
    "title": "Introduction to Bayesian Data Analysis for Cognitive Science",
    "author": "Bruno Nicenboim",
    "source": "https://bruno.nicenboim.me/bayescogsci/ch-remame.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". (b) Posterior distribution of the slope for the same dependent variable (mean reading speed) and predictor (centered mean PCU) in a model that accounts for measurement error (fit_indiv_me). Figure11.4visualizes the main reason why we have no clear association in the measurement error analysis: the two points at the top left part of the plot that were driving the effect have very large SE for the measurement of reading speed. The code to produce Figure11.4appears below and overlays several (250) regression lines that correspond to different samples of the posterior distribution with the measurements of reading speed and PCU. FIGURE 11.4: The relationship between centered mean PCU scores and mean reading speed accounting for measurement error. The error bars represent two standard errors. The regression lines are produced with 250 samples of the intercept and slope from the posterior distribution. Of course, the conclusion here cannot be that there is no association between PCU scores and reading speed. In order to claim an absence of an effect, we would need to use Bayes factors (see chapter13) or cross-validation (see chapter14). As it happened when we carried out the meta-analysis, the main difficulty for modeling measurement error models directly in Stan is that we need to reparameterize the models to avoid dependencies between samples of different parameters. The two changes that we need to do to the parameterization of our model presented in Equation(11.5)are the following. \\[\\begin{equation} \\begin{aligned} z_n & \\sim\\mathit{Normal}(0, 1)\\\\ x_{n,TRUE} &= z_n \\cdot \\tau + \\chi \\\\ x_n & \\sim \\mathit{Normal}(x_{n,TRUE}, SE_{x_n}) \\end{aligned} \\end{equation}\\] \\[\\begin{equation} y_{n} \\sim\\mathit{Normal}\\left(\\alpha + \\beta x_{n,TRUE},\\sqrt{SE_{y_n}^2 + \\sigma^2}\\right) \\end{equation}\\] We are now ready to write this in Stan; the code is in the model calledme.stan: Fit the model: The posterior distributions are similar to those that we obtained withbrms",
    "chunk_id": "Adv_cognitive_modelling_introduction_to_bayesian_data_analysis_for_cognitive_science_84eef535.json_chunk_10"
  },
  {
    "document_type": "online_article",
    "title": "Introduction to Bayesian Data Analysis for Cognitive Science",
    "author": "Bruno Nicenboim",
    "source": "https://bruno.nicenboim.me/bayescogsci/ch-remame.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". This chapter introduced two statistical tools that are potentially of great relevance to cognitive science: random-effects meta-analysis and measurement error models. Despite the inherent limitations of meta-analysis, these should be used routinely to accumulate knowledge through systematic evidence synthesis. Measurement errors can also prevent over-enthusiastic conclusions that are often made based on noisy data. Bürki, Audrey, Francois-Xavier Alario, and Shravan Vasishth. 2023. “When Words Collide: Bayesian Meta-Analyses of Distractor and Target Properties in the Picture-Word Interference Paradigm.”Quarterly Journal of Experimental Psychology76 (6): 1410–30.https://doi.org/https://doi.org/10.1177/17470218221114644. Bürki, Audrey, Shereen Elbuy, Sylvain Madec, and Shravan Vasishth. 2020. “What Did We Learn from Forty Years of Research on Semantic Interference? A Bayesian Meta-Analysis.”Journal of Memory and Language114.https://doi.org/10.1016/j.jml.2020.104125. Conway, Andrew R. A., Michael J. Kane, Michael F. Bunting, D. Zach Hambrick, Oliver Wilhelm, and Randall W. Engle. 2005. “Working Memory Span Tasks: A Methodological Review and User’s Guide.”Psychonomic Bulletin & Review12 (5): 769–86. Cox, Christopher Martin Mikkelsen, Tamar Keren-Portnoy, Andreas Roepstorff, and Riccardo Fusaroli. 2022. “A Bayesian Meta-Analysis of Infants’ Ability to Perceive Audio–Visual Congruence for Speech.”Infancy27 (1): 67–96. Denckla, Martha Bridge, and Rita G. Rudel. 1976. “Rapid ‘Automatized’ Naming (R.A.N.): Dyslexia Differentiated from Other Learning Disabilities.”Neuropsychologia14 (4): 471–79.https://doi.org/https://doi.org/10.1016/0028-3932(76)90075-0. Grant, Robert, and Gian Luca Di Tanna. 2025.Bayesian Meta-Analysis: A Practical Introduction. Cambridge University Press. Higgins, Julian, and Sally Green. 2008.Cochrane Handbook for Systematics Reviews of Interventions. New York: Wiley-Blackwell. Jäger, Lena A., Felix Engelmann, and Shravan Vasishth. 2017",
    "chunk_id": "Adv_cognitive_modelling_introduction_to_bayesian_data_analysis_for_cognitive_science_84eef535.json_chunk_11"
  },
  {
    "document_type": "online_article",
    "title": "Introduction to Bayesian Data Analysis for Cognitive Science",
    "author": "Bruno Nicenboim",
    "source": "https://bruno.nicenboim.me/bayescogsci/ch-remame.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". Higgins, Julian, and Sally Green. 2008.Cochrane Handbook for Systematics Reviews of Interventions. New York: Wiley-Blackwell. Jäger, Lena A., Felix Engelmann, and Shravan Vasishth. 2017. “Similarity-Based Interference in Sentence Comprehension: Literature review and Bayesian meta-analysis.”Journal of Memory and Language94: 316–39.https://doi.org/https://doi.org/10.1016/j.jml.2017.01.004. Mahowald, Kyle, Ariel James, Richard Futrell, and Edward Gibson. 2016. “A Meta-Analysis of Syntactic Priming in Language Production.”Journal of Memory and Language91: 5–27.https://doi.org/https://doi.org/10.1016/j.jml.2016.03.009. McElreath, Richard. 2020.Statistical Rethinking: A Bayesian Course with Examples in R and Stan. Boca Raton, Florida: Chapman; Hall/CRC. Nicenboim, Bruno, Timo B. Roettger, and Shravan Vasishth. 2018. “Using Meta-Analysis for Evidence Synthesis: The case of incomplete neutralization in German.”Journal of Phonetics70: 39–55.https://doi.org/https://doi.org/10.1016/j.wocn.2018.06.001. Nicenboim, Bruno, Shravan Vasishth, Felix Engelmann, and Katja Suckow. 2018. “Exploratory and Confirmatory Analyses in Sentence Processing: A case study of number interference in German.”Cognitive Science42 (S4).https://doi.org/10.1111/cogs.12589. Nicenboim, Bruno, Shravan Vasishth, and Frank Rösler. 2020. “Are Words Pre-Activated Probabilistically During Sentence Comprehension? Evidence from New Data and a Bayesian Random-Effects Meta-Analysis Using Publicly Available Data.”Neuropsychologia142.https://doi.org/10.1016/j.neuropsychologia.2020.107427. Spector, Tim D., and Simon G. Thompson. 1991. “The Potential and Limitations of Meta-Analysis.”Journal of Epidemiology and Community Health45 (2): 89. Sutton, Alexander J., Nicky J. Welton, Nicola Cooper, Keith R. Abrams, and A. E. Ades. 2012.Evidence Synthesis for Decision Making in Healthcare. Vol. 132. John Wiley & Sons. Turner, R. M., David J. Spiegelhalter, G. Smith, and Simon G. Thompson. 2008",
    "chunk_id": "Adv_cognitive_modelling_introduction_to_bayesian_data_analysis_for_cognitive_science_84eef535.json_chunk_12"
  },
  {
    "document_type": "online_article",
    "title": "Introduction to Bayesian Data Analysis for Cognitive Science",
    "author": "Bruno Nicenboim",
    "source": "https://bruno.nicenboim.me/bayescogsci/ch-remame.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". Abrams, and A. E. Ades. 2012.Evidence Synthesis for Decision Making in Healthcare. Vol. 132. John Wiley & Sons. Turner, R. M., David J. Spiegelhalter, G. Smith, and Simon G. Thompson. 2008. “Bias Modelling in Evidence Synthesis.”Journal of the Royal Statistical Society: Series A (Statistics in Society)172 (1): 21–47.https://doi.org/https://doi.org/10.1111/j.1467-985X.2008.00547.x. Vasishth, Shravan, Zhong Chen, Qiang Li, and Gueilan Guo. 2013. “Processing Chinese Relative Clauses: Evidence for the Subject-Relative Advantage.”PLoS ONE8 (10): 1–14.https://doi.org/https://doi.org/10.1371/journal.pone.0077006. In the current example, the dependent variable is either self-paced reading time or first-pass reading time from eyetracking. A possible criticism here is that these two different dependent measures should not appear in the same meta-analysis. Despite these being quite different dependent variables, the simplifying assumption we made was that the dependent measure, which is in milliseconds in both the self-paced reading studies and eyetracking studies, is a difference of means between two (sets of) conditions, and therefore gives an estimate of the effect of interest. An alternative approach would have been to standardize the effect size (Cohen’s d) in each study; but this would be difficult to carry out in this example as much of the published work did not provide the original data; in many of the cases, only summary statistics from the publication were available. Such standardized effect sizes would also be open to criticism, because the effect size in self-paced reading and eyetracking may also not be comparable.↩︎",
    "chunk_id": "Adv_cognitive_modelling_introduction_to_bayesian_data_analysis_for_cognitive_science_84eef535.json_chunk_13"
  },
  {
    "document_type": "online_article",
    "title": "09-BayesianModels",
    "author": "Riccardo Fusaroli",
    "source": "https://fusaroli.github.io/AdvancedCognitiveModeling2023/index.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": "Riccardo Fusaroli 2025-03-10 These course notes support the Advanced Cognitive Modeling course taught in the Master’s program in Cognitive Science at Aarhus University. The course represents a journey into how we can understand cognitive processes through the formalization and implementation of hypothesized mechanisms, their testing and validation. Advanced cognitive modeling focuses on three interrelated objectives that shape how we approach the modeling of cognitive processes: The first objective centers on understanding the thought process behind model development. Rather than simply providing a toolbox of existing scripts, we explore how cognitive models are conceptualized and constructed from the ground up. This approach ensures you develop the skills to create novel models for unique research questions. The second objective emphasizes mastering the Bayesian workflow essential for robust model development. This workflow encompasses simulation design, prior assessment, parameter recovery testing, and thorough model fit evaluation. These skills ensure your models are not just theoretically sound but also practically reliable and generalize way beyond cognitive modeling. The third objective focuses on developing advanced probabilistic modeling capabilities. Through hands-on experience with Stan, you will learn to implement increasingly sophisticated models while maintaining scientific rigor. The course follows a carefully structured progression that builds your modeling capabilities step by step: After a deepdive into the physics of pizza ovens, we begin with simple scenarios that introduce fundamental modeling concepts. Each subsequent chapter introduces new modeling techniques while building upon previous knowledge. This cumulative approach ensures you develop a deep understanding of both basic principles and advanced applications. The chapters include theoretical discussions paired with practical coding exercises",
    "chunk_id": "Adv_cognitive_modelling_09-bayesianmodels.json_chunk_1"
  },
  {
    "document_type": "online_article",
    "title": "09-BayesianModels",
    "author": "Riccardo Fusaroli",
    "source": "https://fusaroli.github.io/AdvancedCognitiveModeling2023/index.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". The chapters include theoretical discussions paired with practical coding exercises. During practical sessions, we work with real datasets, design models collaboratively, and implement them using modern statistical tools. This hands-on approach provides ample opportunity for questions and exploration. The course schedule maintains flexibility to adapt to the collective learning pace of each cohort. While we have clear learning objectives, we ensure everyone develops a solid foundation before moving to more advanced topics. To make the most of this course, students should prepare their technical environment and review fundamental concepts: Software Requirements: - R (version 4.4 or above) - RStudio (version 2024.12.0 or above) - brms package with proper configuration - cmdstanr package with complete installation Technical Prerequisites: - Working knowledge of R programming - Basic understanding of Bayesian statistics - Familiarity with cognitive science fundamentals Additional Resources: - Introduction to R and tidyverse:https://r4ds.had.co.nz/- A condensed Bayesian statistics primer (by Chris Cox and me):https://4ccoxau.github.io/PriorsWorkshop/ For comprehensive information: - Course syllabus: [TBA] - Lecture videos: [TBA] These notes represent an evolving resource that builds upon previous iterations of the course while incorporating new developments in the field. They are designed to serve both as a learning guide during the course and as a reference for your future research endeavors.",
    "chunk_id": "Adv_cognitive_modelling_09-bayesianmodels.json_chunk_2"
  },
  {
    "document_type": "online_article",
    "title": "Chapter 4 From verbal descriptions to formal models",
    "author": "Riccardo Fusaroli",
    "source": "https://fusaroli.github.io/AdvancedCognitiveModeling2023/from-verbal-descriptions-to-formal-models.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": "This chapter bridges the gap between verbal theories and computational implementations of cognitive models. Building on our observations of the matching pennies game, we now develop precise mathematical formulations that can generate testable predictions. After completing this chapter, you will be able to: Transform verbal descriptions of decision-making strategies into precise mathematical formulations, which implications can be more easily explored and that can be empirically tested Create computational implementations of these mathematical models as agent-based models in R Generate and analyze simulated data to understand model behavior under different conditions Moving from verbal to formal models represents a crucial step in cognitive science. When we describe behavior in words, ambiguities often remain hidden. For instance, a verbal description might state that players “tend to repeat successful choices.” But what exactly constitutes “tend to”? How strongly should past successes influence future choices? Mathematical formalization forces us to be precise about these specifications. By computationally implementing the our models, we are forced to make them very explicit in their assumptions; we become able to simulate the models in a variety of different situations and therefore better understand their implications So, what we’ll do throughout the chapter is to: choose two of the models and formalize them, that is, produce an algorithm that enacts the strategy, so we can simulate them. implement the algorithms as functions: getting an input and producing an output, so we can more easily implement them across various contexts (e.g. varying amount of trials, input, etc). See R4DataScience, if you need a refresher:https://r4ds.had.co.nz/functions.html implement a Random Bias agent (choosing “head” 70% of the times) and get your agents to play against it for 120 trials (and save the data) implement a Win-Stay-Lose-Shift agent (keeping the same choice if it won, changing it if it lost) and do the same",
    "chunk_id": "Adv_cognitive_modelling_chapter_4_from_verbal_descriptions_to_formal_models.json_chunk_1"
  },
  {
    "document_type": "online_article",
    "title": "Chapter 4 From verbal descriptions to formal models",
    "author": "Riccardo Fusaroli",
    "source": "https://fusaroli.github.io/AdvancedCognitiveModeling2023/from-verbal-descriptions-to-formal-models.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". scale up the simulation: have 100 agents for each of your strategy playing against both Random Bias and Win-Stay-Lose-Shift and save their data. figure out a good way to visualize the data to assess which strategy performs better, whether that changes over time and generally explore what the agents are doing. Remember a random agent is an agent that picks at random between “right” and “left” independently on what the opponent is doing. A random agent might be perfectly random (50% chance of choosing “right”, same for “left”) or biased. The variable “rate” determines the rate of choosing “right”. We can see that the bigger the bias in the random agent, the bigger the performance in the WSLS (the higher the chances the random agent picks the same hand more than once in a row). Now it’s your turn to follow a similar process for your 2 chosen strategies. Moving from verbal descriptions to formal computational models represents a crucial step in cognitive science. Through our work with the matching pennies game, we have seen how this transformation process requires careful consideration of theoretical assumptions, mathematical precision, and practical implementation details. The development of formal models forces us to be explicit about mechanisms that might remain ambiguous in verbal descriptions. When we state that an agent “learns from experience” or “responds to patterns,” we must specify exactly how these processes work. This precision not only clarifies our theoretical understanding but also enables rigorous empirical testing. Our implementation of different agent types - from simple random choice to more sophisticated strategies - demonstrates how computational modeling can reveal surprising implications of seemingly straightforward theories. Through simulation, we discovered that even basic strategies can produce complex patterns of behavior, especially when agents interact with each other over multiple trials",
    "chunk_id": "Adv_cognitive_modelling_chapter_4_from_verbal_descriptions_to_formal_models.json_chunk_2"
  },
  {
    "document_type": "online_article",
    "title": "Chapter 4 From verbal descriptions to formal models",
    "author": "Riccardo Fusaroli",
    "source": "https://fusaroli.github.io/AdvancedCognitiveModeling2023/from-verbal-descriptions-to-formal-models.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". Through simulation, we discovered that even basic strategies can produce complex patterns of behavior, especially when agents interact with each other over multiple trials. Perhaps most importantly, this chapter has established a foundational workflow for cognitive modeling: begin with careful observation, think carefully and develop precise mathematical formulations, implement these as computational models, and validate predictions against data. Don’t be afraid to make mistakes, or rethink your strategy and iterate the modeling process. This systematic approach will serve as our template as we progress to more complex cognitive phenomena in subsequent chapters. While our matching pennies models may seem simple compared to the rich complexity of human cognition, they exemplify the essential principles of good modeling practice: clarity of assumptions, precision in implementation, and rigorous validation against empirical data. These principles will guide our exploration of more sophisticated cognitive models throughout this course. For more advanced examples of models that can underly behavior in the Matching Pennies game check: Chapter 12 on reinforcement learning. the paper by Waade et al mentioned at the beginning of the chapter.",
    "chunk_id": "Adv_cognitive_modelling_chapter_4_from_verbal_descriptions_to_formal_models.json_chunk_3"
  },
  {
    "document_type": "online_article",
    "title": "Chapter 3 Building Models of Strategic Decision-Making",
    "author": "Riccardo Fusaroli",
    "source": "https://fusaroli.github.io/AdvancedCognitiveModeling2023/building-models-of-strategic-decision-making.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": "Becoming more aware of the issue involved in theory building (and assessment); Identifying a small set of verbal models that we can then formalize in mathematical cognitive models and algorithms for simulations and model fitting. In order to do computational models we need a phenomenon to study (and ideally some data), throughout the course you will be asked undergo several experiments, which provides specific behaviors to model. The matching pennies game provides a fun starting point for exploring cognitive modeling. This simple game allows us to examine how humans make decisions in strategic situations, while introducing fundamental concepts in model development and validation. Through this chapter, we will progress from observing actual gameplay behavior to developing formal models that capture decision-making processes. In the matching pennies game, two players engage in a series of choices. One player attempts to match the other’s choice, while the other player aims to achieve a mismatch, and they repeatedly play with each other. This is a prototypical example of interacting behaviors that are usually tackled by game theory, and bring up issues of theory of mind and recursivity. For an introduction see the paper: Waade, Peter T., et al. “Introducing tomsup: Theory of mind simulations using Python.” Behavior Research Methods 55.5 (2023): 2197-2231. The game proceeds as follows: This simple structure creates a rich environment for studying decision-making strategies, learning, and adaptation. If you are attending my class you have been (or will be) asked to participate in a matching pennies game. This game provides the foundation for our modeling efforts. By observing gameplay and collecting data, we can develop models that capture the cognitive processes underlying decision-making in strategic situations. Participants play 30 rounds as the matcher and 30 rounds as the hider, allowing us to observe behavior in both roles",
    "chunk_id": "Adv_cognitive_modelling_chapter_3_building_models_of_strategic_decision-making.json_chunk_1"
  },
  {
    "document_type": "online_article",
    "title": "Chapter 3 Building Models of Strategic Decision-Making",
    "author": "Riccardo Fusaroli",
    "source": "https://fusaroli.github.io/AdvancedCognitiveModeling2023/building-models-of-strategic-decision-making.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". Participants play 30 rounds as the matcher and 30 rounds as the hider, allowing us to observe behavior in both roles. While playing, participants track their scores, which can provide quantitative data for later analysis. Participants are also asked to reflect on their strategies and the strategies they believe their opponents are using, as that provides valuable materials to build models on. Through the careful observation and discussion of gameplay we do in class, several patterns typically emerge. For instance, players often demonstrate strategic adaptation, adjusting their choices based on their opponent’s previous moves. They may attempt to identify patterns in their opponent’s behavior while trying to make their own choices less predictable. The tension between exploitation of perceived patterns and maintenance of unpredictability creates fascinating dynamics for modeling. Below you can observe how a previous year of CogSci did against bots (computational agents) playing according to different strategies. Look at the plots below, where the x axes indicate trial, the y axes how many points the CogSci’ers scored (0 being chance, negative means being completely owned by the bots, positive owning the bot) and the different colors indicate different strategies employed by the bots. Strategy “-2” was a Win-Stay-Lose-Shift bot: when it got a +1, it repeated its previous move (e.g. right if it had just played right), otherwise it would perform the opposite move (e.g. left if it had just played right). Strategy “-1” was a biased Nash both, playing “right” 80% of the time. Strategy “0” indicates a reinforcement learning bot; “1” a bot assuming you were playing according to a reinforcement learning strategy and trying to infer your learning and temperature parameters; “2” a bot assuming you were following strategy “1” and trying to accordingly infer your parameters",
    "chunk_id": "Adv_cognitive_modelling_chapter_3_building_models_of_strategic_decision-making.json_chunk_2"
  },
  {
    "document_type": "online_article",
    "title": "Chapter 3 Building Models of Strategic Decision-Making",
    "author": "Riccardo Fusaroli",
    "source": "https://fusaroli.github.io/AdvancedCognitiveModeling2023/building-models-of-strategic-decision-making.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". That doesn’t look too good, ah? What about individual variability? In the plot below we indicate the score of each of the former students, against the different bots. Now, let’s take a bit of group discussion. Get together in groups, and discuss which strategies and cognitive processes might underlie your and the agents’ behaviors in the game. One thing to keep in mind is what a model is: a simplification that can help us make sense of the world. In other words, any behavior is incredibly complex and involves many complex cognitive mechanisms. So start simple, and if you think it’s too simple, progressively add simple components. Once your study group has discussed a few (during the PE), let’s discuss them. The transition from observing gameplay to building formal models requires careful consideration of multiple factors. We must identify which aspects of behavior to model explicitly while deciding which details can be abstracted away. When developing models of matching pennies behavior, we must address several key questions: What information do players use to make decisions? How do players integrate past experiences with current choices? What role does randomness play in decision-making? How do players adapt their strategies over time? Are there notions and models from previous cognitive science courses that can help us understand the behavior? These questions guide our model development process, helping us move from verbal theories to mathematical formulations. As participants we might not be aware of the strategy we use, or we might believe something erroneous. The exercise here is to act as researchers: what are the principles underlying the participants’ behaviors, no matter what the participants know or believe? Note that talking to participants and being participants helps developing ideas, but it’s not the end point of the process. Also note that as cognitive scientists we can rely on what we have learned about cognitive processes (e.g. memory)",
    "chunk_id": "Adv_cognitive_modelling_chapter_3_building_models_of_strategic_decision-making.json_chunk_3"
  },
  {
    "document_type": "online_article",
    "title": "Chapter 3 Building Models of Strategic Decision-Making",
    "author": "Riccardo Fusaroli",
    "source": "https://fusaroli.github.io/AdvancedCognitiveModeling2023/building-models-of-strategic-decision-making.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". Also note that as cognitive scientists we can rely on what we have learned about cognitive processes (e.g. memory). Another important component of the distinction is that participants leave in a rich world: they rely on facial expressions and bodily posture, the switch strategies, etc. On the other hand, the researcher is trying to identify one or few at most “simple” strategies. Rich bodily interactions and mixtures or sequences of multiple strategies are not a good place to start modeling. These aspects are a poor starting point for building your first model, and are often pretty difficult to fit to empirical data. Nevertheless, they are important intuitions that the researcher should (eventually?) accommodate. Based on observed behavior patterns and theoretical considerations, we can develop several candidate models of decision-making in the matching pennies game. The simplest model assumes players make choices randomly, independent of history or context. Players might simply be randomly choosing “head” or “tail” independently on the opponent’s choices and of how well they are doing. Choices could be fully at random (50% “head”, 50% “tail”) or biased (e.g. 60% “head”, 40% tail). While this may seem overly simplistic, it provides an important baseline for comparison and introduces key concepts in model specification. Another simple strategy is simply to follow the previous choice: if it was successful keep it, if not change it. This strategy is also called Win-Stay-Lose-Shift (WSLS). The model can be formalized as:\\[P(a_t = a_{t-1}) = \\begin{cases} p_w & \\text{if win at } t-1 \\ 1 - p_l & \\text{if loss at } t-1 \\end{cases}\\]where\\(a_t\\)represents the action at time\\(t\\), and\\(p_w\\)and\\(p_l\\)are the probabilities of staying after wins and losses respectively. Alternatively, one could do the opposite: Win-Shift-Lose-Stay. A more sophisticated approach considers how players track and respond to their opponent’s choice patterns",
    "chunk_id": "Adv_cognitive_modelling_chapter_3_building_models_of_strategic_decision-making.json_chunk_4"
  },
  {
    "document_type": "online_article",
    "title": "Chapter 3 Building Models of Strategic Decision-Making",
    "author": "Riccardo Fusaroli",
    "source": "https://fusaroli.github.io/AdvancedCognitiveModeling2023/building-models-of-strategic-decision-making.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". Alternatively, one could do the opposite: Win-Shift-Lose-Stay. A more sophisticated approach considers how players track and respond to their opponent’s choice patterns. This model maintains a running estimate of the opponent’s choice probabilities and updates these estimates based on observed choices. A player could not be able to keep in mind all previous trials, or decide to forget old trials, in case the biase shifts over time. So we could use only the last n trials, or do a weighted mean with weigths proportional to temporal closeness (the more recent, the higher the weight). Since there is a lot of leeway in how much memory we should keep of previous trials, we could also use a model that explicitly estimates how much players are learning on a trial by trial basis (high learning, low memory; low learning, high memory). This is the model of reinforcement learning, which we will deal with in future chapters. Shortly described, reinforcement learning assumes that each choice has a possible reward (probability of winning) and at every trial given the feedback received updates the expected value of the choice taken. The update depends on the prediction error (difference between expected and actual reward) and the learning rate. Reinforcement learning is a neat model, but can be problematic when playing against other agents: what the game is really about is not assessing the probability of the opponent choosing “head” generalizing from their past choices, but predicting what they will do. This requires making an explicit model of how the opponent chooses. k-ToM models will be dealt with in future chapters, but can be here anticipated as models assuming that the opponent follows a random bias (0-ToM), or models us as following a random bias (1-ToM), or models us modeling them as following a random bias (2-ToM), etc. Many additional strategies can be generated by combining former strategies",
    "chunk_id": "Adv_cognitive_modelling_chapter_3_building_models_of_strategic_decision-making.json_chunk_5"
  },
  {
    "document_type": "online_article",
    "title": "Chapter 3 Building Models of Strategic Decision-Making",
    "author": "Riccardo Fusaroli",
    "source": "https://fusaroli.github.io/AdvancedCognitiveModeling2023/building-models-of-strategic-decision-making.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". Many additional strategies can be generated by combining former strategies. Generating random output is hard, so if we want to confuse the opponent, we could act first choosing tail 8 times, and then switching to a WSLS strategy for 4 trials, and then choosing head 4 times. Or implementing any of the previous strategies and doing the opposite “to mess with the opponent”. As we discuss strategies, we can also identify several cognitive constraints that we know from former studies: in particular, memory, perseveration, and errors. Humans have limited memory and a tendency to forget that is roughly exponential. Models assuming perfect memory for longer stretches of trials are unrealistic. We could for instance use the exponential decay of memory to create weights following the same curve in the “keeping track of bias” models. Roughly, this is what reinforcement learning is doing via the learning rate parameter. Winning choice is not changed. People tend to have a tendency to perseverate with “good” choices independently of which other strategy they might be using. Humans make mistakes, get distracted, push the wrong button, forget to check whether they won or lost before. So a realistic model of what happens in these games should contain a certain chance of making a mistake. E.g. a 10% chance that any choice will be perfectly random instead of following the strategy. Such random deviations from the strategy might also be conceptualized as explorations: keeping the door open to the strategy not being optimal and therefore testing other choices. For instance, one could have an imperfect WSLS where the probability of staying if winning (or shifting if losing) is only 80% and not 100%. Further, these deviations could be asymmetric, with the probability of staying if winning is 80% and of shifting if losing is 100%; for instance if negative and positive feedback are perceived asymmetrically. Many of these models are simply extreme cases of others",
    "chunk_id": "Adv_cognitive_modelling_chapter_3_building_models_of_strategic_decision-making.json_chunk_6"
  },
  {
    "document_type": "online_article",
    "title": "Chapter 3 Building Models of Strategic Decision-Making",
    "author": "Riccardo Fusaroli",
    "source": "https://fusaroli.github.io/AdvancedCognitiveModeling2023/building-models-of-strategic-decision-making.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". Many of these models are simply extreme cases of others. For instance, WSLS is a reinforcement learning model with an extreme learning rate (reward replaces the formerly expected value without any moderation), which is also a memory model with a memory of 1 previous trial. k-ToM builds on reinforcement learning: at level 1 assumes the other is a RL agent. We discussed that there are techniques to consider the data generated by a mixture of models: estimating the probability that they are generated by model 1 or 2 or n. This probability can then be conditioned, according to our research question, to group (are people w schizophrenia more likely to employ model 1) or ID (are different participants using different models), or condition, orWe discussed that we often need lots of data to disambiguate between models, so conditioning e.g. on trial would in practice almost (?) never work. In a more traditional approach we would carefully set up the experiment to discriminate between hypotheses. For instance, if the hypothesis is that humans deploy ToM only when playing against intentional agents, we can set agents with increasing levels of k-ToM against humans, set up two framings (this is a human playing hide and seek, this is a slot machine), and assess whether humans perform differently. E.g. whether they perform better when thinking it’s a human. We analyze performance e.g. as binary outcome on a trial by trial base and condition its rate on framing and complexity. If framing makes a difference in the expected direction, we are good. If we do this properly, thanks to the clever experimental designs we set up, we can discriminate between hypotheses. And that is good. However, cognitive modeling opens additional opportunities. For instance, we can actually reconstruct which level of recursion the participants are enacting and if it changes over time. This might be very useful in the experimental setup, and crucial in more observational setups",
    "chunk_id": "Adv_cognitive_modelling_chapter_3_building_models_of_strategic_decision-making.json_chunk_7"
  },
  {
    "document_type": "online_article",
    "title": "Chapter 3 Building Models of Strategic Decision-Making",
    "author": "Riccardo Fusaroli",
    "source": "https://fusaroli.github.io/AdvancedCognitiveModeling2023/building-models-of-strategic-decision-making.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". This might be very useful in the experimental setup, and crucial in more observational setups. Cognitive modeling also allows us to discriminate between different cognitive components more difficult to assess by looking at performance only. For instance, why are participants performing less optimally when facing a supposedly non-intentional agent? Is their learning rate different? Is their estimate of volatility different? In other setups, e.g. a gambling context, we might observe that some participants (e.g. parkinson’s patients) are gambling away much. Is this due to changes in their risk-seeking propensities, loss aversion, or changes in the ability to actually learn the reward structure? Experimental setups help, but cognitive modeling can provide more nuanced and direct evidence.",
    "chunk_id": "Adv_cognitive_modelling_chapter_3_building_models_of_strategic_decision-making.json_chunk_8"
  },
  {
    "document_type": "research_paper",
    "title": "bayesian_workflow",
    "author": "",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\bayesian_workflow.pdf",
    "date_published": "2020-11-04",
    "keywords": "",
    "flag": "",
    "chunk_text": "Bayesian workflow ∗ Andrew Gelman † Aki Vehtari Daniel Simpson Charles C. Margossian † Bob Carpenter Yuling Yao † Lauren Kennedy Jonah Gabry † Paul-Christian Bürkner ∗∗ Martin Modrák †† 2 Nov 2020 Abstract The Bayesian approach to data analysis provides a powerful way to handle uncertainty in all observations, model parameters, and model structure using probability theory. Probabilistic programming languages make it easier to specify and fit Bayesian models, but this still leaves us with many options regarding constructing, evaluating, and using these models, along with many remaining challenges in computation. Using Bayesian inference to solve real-world problems requires not only statistical skills, subject matter knowledge, and programming, but also awareness of the decisions made in the process of data analysis. All of these aspects can be understood as part of a tangled workflow of applied Bayesian statistics. Beyond inference, the workflow also includes iterative model building, model checking, validation and troubleshooting of computational problems, model understanding, and model comparison. We review all these aspects of workflow in the context of several examples, keeping in mind that in practice we will be fitting many models for any given problem, even if only a subset of them will ultimately be relevant for our conclusions. Contents 1 Introduction 3 1.1 From Bayesian inference to Bayesian workflow 3 1.2 Why do we need a Bayesian workflow? 4 1.3 “Workflow” and its relation to statistical theory and practice 4 1.4 Organizing the many aspects of Bayesian workflow 6 1.5 Aim and structure of this article 8 ∗ We thank Berna Devezer, Danielle Navarro, Matthew West, and Ben Bales for helpful suggestions and the National Science Foundation, Institute of Education Sciences, Office of Naval Research, National Institutes of Health, Sloan Foundation, Schmidt Futures, the Canadian Research Chairs program, and the Natural Sciences and Engineering Research Council of Canada for financial support",
    "chunk_id": "Adv_cognitive_modelling_bayesian_workflow.json_chunk_1"
  },
  {
    "document_type": "research_paper",
    "title": "bayesian_workflow",
    "author": "",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\bayesian_workflow.pdf",
    "date_published": "2020-11-04",
    "keywords": "",
    "flag": "",
    "chunk_text": ". This work was supported by ELIXIR CZ research infrastructure project (MEYS Grant No. LM2015047) including access to computing and storage facilities. Much of Sections 10 and 11 are taken from Gelman (2019) and Margossian and Gelman (2020), respectively. † Department of Statistics, Columbia University, New York. Department of Computer Science, Aalto University, Espoo, Finland. Department of Statistical Sciences, University of Toronto. Center for Computational Mathematics, Flatiron Institute, New York. Monash University, Melbourne, Australia. ∗∗ Cluster of Excellence SimTech, University of Stuttgart, Germany. †† Institute of Microbiology of the Czech Academy of Sciences",
    "chunk_id": "Adv_cognitive_modelling_bayesian_workflow.json_chunk_2"
  },
  {
    "document_type": "research_paper",
    "title": "bayesian_workflow",
    "author": "",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\bayesian_workflow.pdf",
    "date_published": "2020-11-04",
    "keywords": "",
    "flag": "",
    "chunk_text": ". 1 arXiv:2011.01808v1 [stat.ME] 3 Nov 2020 2 Before fitting a model 8 2.1 Choosing an initial model 8 2.2 Modular construction 9 2.3 Scaling and transforming the parameters 9 2.4 Prior predictive checking 10 2.5 Generative and partially generative models 11 3 Fitting a model 12 3.1 Initial values, adaptation, and warmup 13 3.2 How long to run an iterative algorithm 13 3.3 Approximate algorithms and approximate models 14 3.4 Fit fast, fail fast 15 4 Using constructed data to find and understand problems 16 4.1 Fake-data simulation 16 4.2 Simulation-based calibration 18 4.3 Experimentation using constructed data 20 5 Addressing computational problems 22 5.1 The folk theorem of statistical computing 22 5.2 Starting at simple and complex models and meeting in the middle 22 5.3 Getting a handle on models that take a long time to fit 23 5.4 Monitoring intermediate quantities 24 5.5 Stacking to reweight poorly mixing chains 24 5.6 Posterior distributions with multimodality and other difficult geometry 25 5.7 Reparameterization 26 5.8 Marginalization 26 5.9 Adding prior information 26 5.10 Adding data 29 6 Evaluating and using a fitted model 30 6.1 Posterior predictive checking 30 6.2 Cross validation and influence of individual data points and subsets of the data 30 6.3 Influence of prior information 34 6.4 Summarizing inference and propagating uncertainty 36 7 Modifying a model 36 7.1 Constructing a model for the data 38 7.2 Incorporating additional data 38 7.3 Working with prior distributions 39 7.4 A topology of models 41 8 Understanding and comparing multiple models 42 8.1 Visualizing models in relation to each other 42 8.2 Cross validation and model averaging 44 8.3 Comparing a large number of models 45 2 9 Modeling as software development 45 9.1 Version control smooths collaborations with others and with your past self 46 9.2 Testing as you go 46 9.3 Making it essentially reproducible 47 9.4 Making it readable and maintainable 48 10 Example of workflow involving model building and expansion: Golf putting 49 10.1",
    "chunk_id": "Adv_cognitive_modelling_bayesian_workflow.json_chunk_3"
  },
  {
    "document_type": "research_paper",
    "title": "bayesian_workflow",
    "author": "",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\bayesian_workflow.pdf",
    "date_published": "2020-11-04",
    "keywords": "",
    "flag": "",
    "chunk_text": "46 9.2 Testing as you go 46 9.3 Making it essentially reproducible 47 9.4 Making it readable and maintainable 48 10 Example of workflow involving model building and expansion: Golf putting 49 10.1 First model: logistic regression 50 10.2 Modeling from first principles 50 10.3 Testing the fitted model on new data 51 10.4 A new model accounting for how hard the ball is hit 52 10.5 Expanding the model by including a fudge factor 53 10.6 General lessons from the golf example 55 11 Example of workflow for a model with unexpected multimodality: Planetary motion 56 11.1 Mechanistic model of motion 56 11.2 Fitting a simplified model 57 11.3 Bad Markov chain, slow Markov chain? 60 11.4 Building up the model 61 11.5 General lessons from the planetary motion example 61 12 Discussion 63 12.1 Different perspectives on statistical modeling and prediction 63 12.2 Justification of iterative model building 63 12.3 Model selection and overfitting 64 12.4 Bigger datasets demand bigger models 66 12.5 Prediction, generalization, and poststratification 66 12.6 Going forward 67 1",
    "chunk_id": "Adv_cognitive_modelling_bayesian_workflow.json_chunk_4"
  },
  {
    "document_type": "research_paper",
    "title": "bayesian_workflow",
    "author": "",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\bayesian_workflow.pdf",
    "date_published": "2020-11-04",
    "keywords": "",
    "flag": "",
    "chunk_text": ". Introduction 1.1. From Bayesian inference to Bayesian workflow If mathematical statistics is to be the theory of applied statistics, then any serious discussion of Bayesian methods needs to be clear about how they are used in practice. In particular, we need to clearly separate concepts of Bayesian inference from Bayesian data analysis and, critically, from full Bayesian workflow (the object of our attention). Bayesian inference is just the formulation and computation of conditional probability or probbility densities, p ( θ | y ) ∝ p ( θ ) p ( y | θ ) . Bayesian workflow includes the three steps of model building, inference, and model checking/improvement, along with the comparison of different models, not just for the purpose of model choice or model averaging but more importantly to better understand these models. That is, for example, why some models have trouble predicting certain aspects of the data, or why uncertainty estimates of important parameters can vary across models. Even when we have a model we like, it will be useful to compare its inferences to those from simpler and more complicated models as a way to understand what the model is doing. Figure 1 provides an 3 outline. An extended Bayesian workflow would also include pre-data design of data collection and measurement and after-inference decision making, but we focus here on modeling the data. In a typical Bayesian workflow we end up fitting a series of models, some of which are in retrospect poor choices (for reasons including poor fit to data; lack of connection to relevant substantive theory or practical goals; priors that are too weak, too strong, or otherwise inappropriate; or simply from programming errors), some of which are useful but flawed (for example, a regression that adjusts for some confounders but excludes others, or a parametric form that captures some but not all of a functional relationship), and some of which are ultimately worth reporting",
    "chunk_id": "Adv_cognitive_modelling_bayesian_workflow.json_chunk_5"
  },
  {
    "document_type": "research_paper",
    "title": "bayesian_workflow",
    "author": "",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\bayesian_workflow.pdf",
    "date_published": "2020-11-04",
    "keywords": "",
    "flag": "",
    "chunk_text": ". The hopelessly wrong models and the seriously flawed models are, in practice, unavoidable steps along the way toward fitting the useful models. Recognizing this can change how we set up and apply statistical methods. 1.2. Why do we need a Bayesian workflow? We need a Bayesian workflow, rather than mere Bayesian inference, for several reasons. • Computation can be a challenge, and we often need to work through various steps including fitting simpler or alternative models, approximate computation that is less accurate but faster, and exploration of the fitting process, in order to get to inferences that we trust. • In difficult problems we typically do not know ahead of time what model we want to fit, and even in those rare cases that an acceptable model has been chosen ahead of time, we will generally want to expand it as we gather more data or want to ask more detailed questions of the data we have. • Even if our data were static, and we knew what model to fit, and we had no problems fitting it, we still would want to understand the fitted model and its relation to the data, and that understanding can often best be achieved by comparing inferences from a series of related models. • Sometimes different models yield different conclusions, without one of them being clearly favourable. In such cases, presenting multiple models is helpful to illustrate the uncertainty in model choice. 1.3. “Workflow” and its relation to statistical theory and practice “Workflow” has different meanings in different contexts. For the purposes of this paper it should suffice that workflow is more general than an example but less precisely specified than a method. We have been influenced by the ideas about workflow in computing that are in the air, including statistical developments such as the tidyverse which are not particularly Bayesian but have a similar feel of experiential learning (Wickham and Groelmund, 2017)",
    "chunk_id": "Adv_cognitive_modelling_bayesian_workflow.json_chunk_6"
  },
  {
    "document_type": "research_paper",
    "title": "bayesian_workflow",
    "author": "",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\bayesian_workflow.pdf",
    "date_published": "2020-11-04",
    "keywords": "",
    "flag": "",
    "chunk_text": ". Many of the recent developments in machine learning have a similar plug-and-play feel: they are easy to use, easy to experiment with, and users have the healthy sense that fitting a model is a way of learning something from the data without representing a commitment to some probability model or set of statistical assumptions. Figure 2 shows our perspective on the development of statistical methodology as a process of increasing codification, from example to case study to workflow to method to theory. Not all methods will reach these final levels of mathematical abstraction, but looking at the history 4 Figure 1: Overview of the steps we currently consider in Bayesian workflow. Numbers in brackets refer to sections of this paper where the steps are discussed. The chart aims to show possible steps and paths an individual analysis may go through, with the understanding that any particular analysis will most likely not involve all of these steps. One of our goals in studying workflow is to understand how these ideas fit together so they can be applied more systematically. 5 Example · · · Case study · · · Workflow · · · Method · · · Theory Figure 2: Meta-workflow of statistical methodology, representing the way in which new ideas first appear in examples, then get formalized into case studies, codified as workflows, are given general implementation as algorithms, and become the subject of theories. of statistics we have seen new methods being developed in the context of particular examples, stylized into case studies, set up as templates or workflows for new problems, and, when possible, formalized, coded, and studied theoretically. One way to understand Figure 2 is through important ideas in the history of statistics that have moved from left to right along that path. There have been many ideas that started out as hacks or statistics-adjacent tools and eventually were formalized as methods and brought into the core of statistics",
    "chunk_id": "Adv_cognitive_modelling_bayesian_workflow.json_chunk_7"
  },
  {
    "document_type": "research_paper",
    "title": "bayesian_workflow",
    "author": "",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\bayesian_workflow.pdf",
    "date_published": "2020-11-04",
    "keywords": "",
    "flag": "",
    "chunk_text": ". There have been many ideas that started out as hacks or statistics-adjacent tools and eventually were formalized as methods and brought into the core of statistics. Multilevel modeling is a formalization of what has been called empirical Bayes estimation of prior distributions, expanding the model so as to fold inference about priors into a fully Bayesian framework. Exploratory data analysis can be understood as a form of predictive model checking (Gelman, 2003). Regularization methods such as lasso (Tibshirani, 1996) and horseshoe (Piironen et al., 2020) have replaced ad hoc variable selection tools in regression. Nonparametric models such as Gaussian processes (O’Hagan, 1978, Rasumussen and Williams, 2006) can be thought of as Bayesian replacements for procedures such as kernel smoothing. In each of these cases and many others, a framework of statistical methodology has been expanded to include existing methods, along the way making the methods more modular and potentially useful. The term “workflow” has been gradually coming into use in statistics and data science; see for example Liu et al. (2005), Lins et al. (2008), Long (2009), and Turner and Lambert (2015). Related ideas of workflow are in the air in software development and other fields of informatics; recent discussions for practitioners include Wilson et al. (2014, 2017). Applied statistics (not just Bayesian statistics) has become increasingly computational and algorithmic, and this has placed workflow at the center of statistical practice (see, for example, Grolemund and Wickham, 2017, Bryan, 2017, and Yu and Kumbier, 2020), as well as in application areas (for example, Lee et al., 2019, discuss modeling workflow in psychology research). “Bayesian workflow” has been expressed as a general concept by Savage (2016), Gabry et al. (2019), and Betancourt (2020a). Several of the individual components of Bayesian workflow were discussed by Gelman (2011) but not in a coherent way",
    "chunk_id": "Adv_cognitive_modelling_bayesian_workflow.json_chunk_8"
  },
  {
    "document_type": "research_paper",
    "title": "bayesian_workflow",
    "author": "",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\bayesian_workflow.pdf",
    "date_published": "2020-11-04",
    "keywords": "",
    "flag": "",
    "chunk_text": ". (2019), and Betancourt (2020a). Several of the individual components of Bayesian workflow were discussed by Gelman (2011) but not in a coherent way. In addition there has been development of Bayesian workflow for particular problems, as by Shi and Stevens (2008) and Chiu et al. (2017). In this paper we go through several aspects of Bayesian workflow with the hope that these can ultimately make their way into routine practice and automatic software. We set up much of our workflow in the probabilistic programming language Stan (Carpenter et al., 2017, Stan Development Team, 2020), but similar ideas apply in other computing environments. 1 1.4. Organizing the many aspects of Bayesian workflow Textbook presentations of statistical workflow are often linear, with different paths corresponding to different problem situations. For example, a clinical trial in medicine conventionally begins with 1 Wikipedia currently lists more than 50 probabilistic programming frameworks: en.wikipedia.org/wiki/ Probabilistic_programming. 6 a sample size calculation and analysis plan, followed by data collection, cleaning, and statistical analysis, and concluding with the reporting of p -values and confidence intervals. An observational study in economics might begin with exploratory data analysis, which then informs choices of transformations of variables, followed by a set of regression analyses and then an array of alternative specifications and robustness studies. The statistical workflow discussed in this article is more tangled than the usual data analysis workflows presented in textbooks and research articles. The additional complexity comes in several places and there are many sub-workflows inside the higher level workflow: 1. Computation to fit a complex model can itself be difficult, requiring a certain amount of experimentation to solve the problem of computing, approximating, or simulating from the desired posterior distribution, along with checking that the computational algorithm did what it was intended to do. 2",
    "chunk_id": "Adv_cognitive_modelling_bayesian_workflow.json_chunk_9"
  },
  {
    "document_type": "research_paper",
    "title": "bayesian_workflow",
    "author": "",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\bayesian_workflow.pdf",
    "date_published": "2020-11-04",
    "keywords": "",
    "flag": "",
    "chunk_text": ". 2. With complex problems we typically have an idea of a general model that is more complex than we can easily computationally fit (for example including features such as correlations, hierarchical structure, and parameters varying over time), and so we start with a model that we know is missing some important features, in the hope it will be computationally easier, with the understanding that we will gradually add in features. 3. Relatedly, we often consider problems where the data are not fixed, either because data collection is ongoing or because we have the ability to draw in related datasets, for example new surveys in a public opinion analysis or data from other experiments in a drug trial. Adding new data often requires model extensions to allow parameters to vary or to extend functional forms, as for example a linear model might fit well at first but then break down with data are added under new conditions. 4. Beyond all the challenges of fitting and expansion, models can often be best understood by comparing to inferences under alternative models. Hence our workflow includes tools for understanding and comparing multiple models fit to the same data. Statistics is all about uncertainty. In addition to the usual uncertainties in the data and model parameters, we are often uncertain whether we are fitting our models correctly, uncertain about how best to set up and expand our models, and uncertain in their interpretation. Once we go beyond simple preassigned designs and analysis, our workflow can be disorderly, with our focus moving back and forth between data exploration, substantive theory, computing, and interpretation of results. Thus, any attempt to organize the steps of workflow will oversimplify and many sub-workflows are complex enough to justify their own articles or book chapters. We discuss many aspects of workflow, but practical considerations—especially available time, computational resources and the severity of penalty for being wrong—can compel a practitioner to take shortcuts",
    "chunk_id": "Adv_cognitive_modelling_bayesian_workflow.json_chunk_10"
  },
  {
    "document_type": "research_paper",
    "title": "bayesian_workflow",
    "author": "",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\bayesian_workflow.pdf",
    "date_published": "2020-11-04",
    "keywords": "",
    "flag": "",
    "chunk_text": ". Such shortcuts can make interpretation of results more difficult, but we must be aware that they will be taken, and not fitting a model at all could be worse than fitting it using an approximate computation (where approximate can be defined as not giving exact summaries of the posterior distribution even in the limit of infinite compute time). Our aim in describing statistical workflow is thus also to explicitly understand various shortcuts as approximations to the full workflow, letting practitioners to make more informed choices about where to invest their limited time and energy. 7 1.5. Aim and structure of this article There is all sorts of tacit knowledge in applied statistics that does not always make it into published papers and textbooks. The present article is intended to put some of these ideas out in the open, both to improve applied Bayesian analyses and to suggest directions for future development of theory, methods, and software. Our target audience is (a) practitioners of applied Bayesian statistics, especially users of probbilistic programming languages such as Stan, and (b) developers of methods and software intended for these users. We are also targeting researchers of Bayesian theory and methods, as we believe that many of these aspects of workflow have been under-studied. In the rest of the paper we go more slowly through individual aspects of Bayesian workflow as outlined in Figure 1, starting with steps to be done before a model is fit (Section 2), through fitting, debugging and evaluating models (Sections 3–6), and then modifying models (Section 7) and understanding and comparing a series of models (Section 8). Sections 10 and 11 then go through these steps in two examples, one in which we add features step by step to a model of golf putting, and one in which we go through a series of investigations to resolve difficulties in fitting a simple model of planetary motion",
    "chunk_id": "Adv_cognitive_modelling_bayesian_workflow.json_chunk_11"
  },
  {
    "document_type": "research_paper",
    "title": "bayesian_workflow",
    "author": "",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\bayesian_workflow.pdf",
    "date_published": "2020-11-04",
    "keywords": "",
    "flag": "",
    "chunk_text": ". The first of these examples shows how new data can motivate model improvements, and also illustrates some of the unexpected challenges that arise when expanding a model. The second example demonstrates the way in which challenges in computation can point to modeling difficulties. These two small examples do not illustrate all the aspects of Bayesian workflow, but they should at least suggest that there could be a benefit to systematizing the many aspects of Bayesian model development. We conclude in Section 12 with some general discussion and our responses to potential criticism of the workflow. 2. Before fitting a model 2.1. Choosing an initial model The starting point of almost all analyses is to adapt what has been done before, using a model from a textbook or case study or published paper that has been applied to a similar problem (a strongly related concept in software engineering is software design pattern). Using a model taken from some previous analysis and altering it can be seen as a shortcut to effective data analysis, and by looking at the results from the model template we know in which direction of the model space there are likely to be useful elaborations or simplifications. Templates can save time in model building and computing, and we should also take into account the cognitive load for the person who needs to understand the results. Shortcuts are important for humans as well as computers, and shortcuts help explain why the typical workflow is iterative (see more in Section 12.2). Similarly, if we were to try to program a computer to perform data analysis automatically, it would have to work through some algorithm to construct models, and the building blocks of such an algorithm would represent templates of a sort. Despite the negative connotations of “cookbook analysis,” we think templates can be useful as starting points and comparison points to more elaborate analyses",
    "chunk_id": "Adv_cognitive_modelling_bayesian_workflow.json_chunk_12"
  },
  {
    "document_type": "research_paper",
    "title": "bayesian_workflow",
    "author": "",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\bayesian_workflow.pdf",
    "date_published": "2020-11-04",
    "keywords": "",
    "flag": "",
    "chunk_text": ". Despite the negative connotations of “cookbook analysis,” we think templates can be useful as starting points and comparison points to more elaborate analyses. Conversely, we should recognize that theories are not static, and the process of development of scientific theories is not the same as that of statistical models (Navarro, 2020). Sometimes our workflow starts with a simple model with the aim to add features later (modeling varying parameters, including measurement errors, correlations, and so forth). Other times we start 8 with a big model and aim to strip it down in next steps, trying to find something that is simple and understandable that still captures key features of the data. Sometimes we even consider multiple completely different approaches to modeling the same data and thus have multiple starting points to choose from. 2.2. Modular construction A Bayesian model is built from modules which can often be viewed as placeholders to be replaced as necessary. For example, we model data with a normal distribution and then replace this with a longer-tailed or mixture distribution; we model a latent regression function as linear and replace it with nonlinear splines or Gaussian processes; we can treat a set of observations as exact and then add a measurement-error model; we can start with a weak prior and then make it stronger when we find the posterior inference includes unrealistic parameter values. Thinking of components as placeholders takes some of the pressure offthe model-building process, because you can always go back and generalize or add information as necessary. The idea of modular construction goes against a long-term tradition in the statistical literature where whole models were given names and a new name was given every time a slight change to an existing model was proposed. Naming model modules rather than whole models makes it easier to see connections between seemingly different models and adapt them to the specific requirements of the given analysis project. 2.3",
    "chunk_id": "Adv_cognitive_modelling_bayesian_workflow.json_chunk_13"
  },
  {
    "document_type": "research_paper",
    "title": "bayesian_workflow",
    "author": "",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\bayesian_workflow.pdf",
    "date_published": "2020-11-04",
    "keywords": "",
    "flag": "",
    "chunk_text": ". Naming model modules rather than whole models makes it easier to see connections between seemingly different models and adapt them to the specific requirements of the given analysis project. 2.3. Scaling and transforming the parameters We like our parameters to be interpretable for both practical and ethical reasons. This leads to wanting them on natural scales and modeling them as independent, if possible, or with an interpretable dependence structure, as this facilitates the use of informative priors (Gelman, 2004). It can also help to separate out the scale so that the unknown parameters are scale-free. For example, in a problem in pharmacology (Weber et al., 2018) we had a parameter that we expected would take on values of approximately 50 on the scale of measurement; following the principle of scaling we might set up a model on log( θ/ 50) , so that 0 corresponds to an interpretable value ( 50 on the original scale) and a difference of 0 . 1 , for example, on the log scale corresponds to increasing or decreasing by approximately 10% . This sort of transformation is not just for ease of interpretation; it also sets up the parameters in a way that readies them for effective hierarchical modeling. As we build larger models, for example by incorporating data from additional groups of patients or additional drugs, it will make sense to allow parameters to vary by group (as we discuss in Section 12.5), and partial pooling can be more effective on scale-free parameters. For example, a model in toxicology required the volume of the liver for each person in the study. Rather than fitting a hierarchical model to these volumes, we expressed each as the volume of the person multiplied by the proportion of volume that the liver; we would expect these scale-free factors to vary less across people and so the fitted model can do more partial pooling compared to the result from modeling absolute volumes. The scaling transformation is a decomposition that facilitates effective hierarchical modeling",
    "chunk_id": "Adv_cognitive_modelling_bayesian_workflow.json_chunk_14"
  },
  {
    "document_type": "research_paper",
    "title": "bayesian_workflow",
    "author": "",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\bayesian_workflow.pdf",
    "date_published": "2020-11-04",
    "keywords": "",
    "flag": "",
    "chunk_text": ". The scaling transformation is a decomposition that facilitates effective hierarchical modeling. In many cases we can put parameters roughly on unit scale by using logarithmic or logit transformations or by standardizing, subtracting a center and dividing by a scale. If the center and scale are themselves computed from the data, as we do for default priors in regression coefficients 9 2 predictors 4 predictors 15 predictors 0.00 0.25 0.50 0.75 1.00 0.00 0.25 0.50 0.75 1.00 0.00 0.25 0.50 0.75 1.00 0 5000 10000 15000 Response mean (per data row) count Figure 3: Demonstration of the use of prior predictive checking to gain understanding of noobvious features of a model. The above graphs correspond to logistic regression models with 100 data points and 2 , 4 , or 15 binary covariates. In each case, the regression coefficients were given independent normal (0 , 1) prior distributions. For each model, we performed a prior predictive check, 1000 times simulating the vector of coefficients θ from the prior, then simulating a dataset y from the logistic model, and then summarizing this by the mean of the simulated data, ̄ y . Each plot shows the prior predictive distribution of this summary statistic, that is, the 1000 simulations of ̄ y . When the number of covariates in the model is small, this prior predictive distribution is spread out, indicating that the model is compatible with a wide range of regimes of data. But as the number of covariates increases, the posterior predictive distribution becomes concentrated near ̄ y = 0 or 1 , indicating that weak priors on the individual coefficients of the model imply a strong prior on this particular predictive quantity. If we wanted a more moderate prior predictive distribution on ̄ y , the prior on the coefficients would need to be strongly concentrated near zero. in rstanarm (Gabry et al., 2020a), we can consider this as an approximation to a hierarchical model in which the center and scale are hyperparameters that are estimated from the data",
    "chunk_id": "Adv_cognitive_modelling_bayesian_workflow.json_chunk_15"
  },
  {
    "document_type": "research_paper",
    "title": "bayesian_workflow",
    "author": "",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\bayesian_workflow.pdf",
    "date_published": "2020-11-04",
    "keywords": "",
    "flag": "",
    "chunk_text": ". in rstanarm (Gabry et al., 2020a), we can consider this as an approximation to a hierarchical model in which the center and scale are hyperparameters that are estimated from the data. More complicated transformations can also serve the purpose of making parameters more interpretable and thus facilitating the use of prior information; Riebler et al. (2016) give an example for a class of spatial correlation models, and Simpson et al. (2017) consider this idea more generally. 2.4. Prior predictive checking Prior predictive checks are a useful tool to understand the implications of a prior distribution in the context of a generative model (Box, 1980, Gabry et al., 2019; see also Section 7.3 for details on how to work with prior distributions). In particular, because prior predictive checks make use of simulations from the model rather than observed data, they provide a way to refine the model without using the data multiple times. Figure 3 shows a simple prior predictive check for a logistic regression model. The simulation shows that even independent priors on the individual coefficients have different implications as the number of covariates in the model increases. This is a general phenomenon in regression models where as the number of predictors increases, we need stronger priors on model coefficients (or enough data) if we want to push the model away from extreme predictions. A useful approach is to consider priors on outcomes and then derive a corresponding joint prior on parameters (see, e.g., Piironen and Vehtari, 2017, and Zhang et al., 2020). More generally, joint priors allow us to control the overall complexity of larger parameter sets, which helps generate more sensible prior predictions that would be hard or impossible to achieve with independent priors. 10 Figure 4: Prior predictive draws from the Gaussian process model with squared exponential cvariance function and different values of the amplitude parameter τ and the length scale parameter l . From Gelman et al. (2013)",
    "chunk_id": "Adv_cognitive_modelling_bayesian_workflow.json_chunk_16"
  },
  {
    "document_type": "research_paper",
    "title": "bayesian_workflow",
    "author": "",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\bayesian_workflow.pdf",
    "date_published": "2020-11-04",
    "keywords": "",
    "flag": "",
    "chunk_text": ". From Gelman et al. (2013). Figure 4 shows an example of prior predictive checking for three choices of prior distribution for a Gaussian process model (Rasmussen and Willams, 2006). This sort of simulation and graphical comparison is useful when working with any model and essential when setting up unfamiliar or complicated models. Another benefit of prior predictive simulations is that they can be used to elicit expert prior knowledge on the measurable quantities of interest, which is often easier than soliciting expert opinion on model parameters that are not observable (O’Hagan et al., 2006). Finally, even when we skip computational prior predictive checking, it might be useful to think about how the priors we have chosen would affect a hypothetical simulated dataset. 2.5. Generative and partially generative models Fully Bayesian data analysis requires a generative model—that is, a joint probability distribution for all the data and parameters. The point is subtle: Bayesian inference does not actually require the generative model; all it needs from the data is the likelihood, and different generative models can have the same likelihood. But Bayesian data analysis requires the generative model to be able to perform predictive simulation and model checking (Sections 2.4, 4.1, 4.2, 6.1, and 6.2), and Bayesian workflow will consider a series of generative models. For a simple example, suppose we have data y ∼ binomial ( n, θ ) , where n and y are observed and we wish to make inference about θ . For the purpose of Bayesian inference it is irrelevant if the data were sampled with fixed n (binomial sampling) or sampled until a specified number of successes occurred (negative binomial sampling): the two likelihoods are equivalent for the purpose of estimating θ because they differ only by a multiplicative factor that depends on y and n but not θ",
    "chunk_id": "Adv_cognitive_modelling_bayesian_workflow.json_chunk_17"
  },
  {
    "document_type": "research_paper",
    "title": "bayesian_workflow",
    "author": "",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\bayesian_workflow.pdf",
    "date_published": "2020-11-04",
    "keywords": "",
    "flag": "",
    "chunk_text": ". However, if we want to simulate new data from the predictive model, the two models are different, as the binomial model yields replications with a fixed value of n and the negative binomial model yields replications with a fixed value of y . Prior and posterior predictive checks (Sections 2.4 and 6.1) will look different under these two different generative models. This is not to say that the Bayesian approach is necessarily better; the assumptions of a generative model can increase inferential efficiency but can also go wrong, and this motivates much of our workflow. It is common in Bayesian analysis to use models that are not fully generative. For example, in regression we will typically model an outcome y given predictors x without a generative model 11 for x . Another example is survival data with censoring, where the censoring process is not usually modeled. When performing predictive checks for such models, we either need to condition on the observed predictors or else extend the model to allow new values of the predictors to be sampled. It is also possible that there is no stochastic generative process for some parts of the model, for example if x has been chosen by a deterministic design of experiment. Thinking in terms of generative models can help illuminate the limitations of what can be learned from the observations. For example, we might want to model a temporal process with a complicated autocorrelation structure, but if our actual data are spaced far apart in time, we might not be able to distinguish this model from a simpler process with nearly independent errors. In addition, Bayesian models that use improper priors are not fully generative, in the sense that they do not have a joint distribution for data and parameters and it would not be possible to sample from the prior predictive distribution. When we do use improper priors, we think of them as being placeholders or steps along the road to a full Bayesian model with a proper joint distribution over parameters and data",
    "chunk_id": "Adv_cognitive_modelling_bayesian_workflow.json_chunk_18"
  },
  {
    "document_type": "research_paper",
    "title": "bayesian_workflow",
    "author": "",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\bayesian_workflow.pdf",
    "date_published": "2020-11-04",
    "keywords": "",
    "flag": "",
    "chunk_text": ". When we do use improper priors, we think of them as being placeholders or steps along the road to a full Bayesian model with a proper joint distribution over parameters and data. In applied work, complexity often arises from incorporating different sources of data. For example, we fit a Bayesian model for the 2020 presidential election using state and national polls, partially pooling toward a forecast based on political and economic “fundamentals” (Morris, Gelman, and Heidemanns, 2020). The model includes a stochastic process for latent time trends in state and national opinion. Fitting the model using Stan yields posterior simulations which are used to compute probabilities for election outcomes. The Bayesian model-based approach is superficially similar to poll aggregations such as described by Katz (2016), which also summarize uncertainty by random simulations. The difference is that our model could be run forward to generate polling data; it is not just a data analysis procedure but also provides a probabilistic model for public opinion at the national and state levels. Thinking more generally, we can consider a progression from least to most generative models. At one extreme are completely non-generative methods which are defined simply as data summaries, with no model for the data at all. Next come classical statistical models, characterized by probability distributions p ( y ; θ ) for data y given parameters θ , but with no probability distribution for θ . At the next step are the Bayesian models we usually fit, which are generative on y and θ but include additional unmodeled data x such as sample sizes, design settings, and hyperparameters; we write such models as p ( y, θ | x ) . The final step would be a completely generative model p ( y, θ, x ) with no “left out” data, x",
    "chunk_id": "Adv_cognitive_modelling_bayesian_workflow.json_chunk_19"
  },
  {
    "document_type": "research_paper",
    "title": "bayesian_workflow",
    "author": "",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\bayesian_workflow.pdf",
    "date_published": "2020-11-04",
    "keywords": "",
    "flag": "",
    "chunk_text": ". The final step would be a completely generative model p ( y, θ, x ) with no “left out” data, x . In statistical workflow we can move up and down this ladder, for example starting with an unmodeled data-reduction algorithm and then formulating it as a probability model, or starting with the inference from a probability model, considering it as a data-based estimate, and tweaking it in some way to improve performance. In Bayesian workflow we can move data in and out of the model, for example taking an unmodeled predictor x and allowing it to have measurement error, so that the model then includes a new level of latent data (Clayton, 1992, Richardson and Gilks, 1993). 3. Fitting a model Traditionally, Bayesian computation has been performed using a combination of analytic calculation and normal approximation. Then in the 1990s, it became possible to perform Bayesian inference 12 for a wide range of models using Gibbs and Metropolis algorithms (Robert and Casella, 2011). The current state of the art algorithms for fitting open-ended Bayesian models include variational inference (Blei and Kucukelbir, 2017), sequential Monte Carlo (Smith, 2013), and Hamiltonian Monte Carlo (HMC; Neal, 2011, Betancourt, 2017a). Variational inference is a generalization of the expectation-maximization (EM) algorithm and can, in the Bayesian context, be considered as providing a fast but possibly inaccurate approximation to the posterior distribution. Variational inference is the current standard for computationally intensive models such as deep neural networks. Sequential Monte Carlo is a generalization of the Metropolis algorithm that can be applied to any Bayesian computation, and HMC is a different generalization of Metropolis that uses gradient computation to move efficiently through continuous probability spaces. In the present article we focus on fitting Bayesian models using HMC and its variants, as implemented in Stan and other probabilistic programming languages",
    "chunk_id": "Adv_cognitive_modelling_bayesian_workflow.json_chunk_20"
  },
  {
    "document_type": "research_paper",
    "title": "bayesian_workflow",
    "author": "",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\bayesian_workflow.pdf",
    "date_published": "2020-11-04",
    "keywords": "",
    "flag": "",
    "chunk_text": ". In the present article we focus on fitting Bayesian models using HMC and its variants, as implemented in Stan and other probabilistic programming languages. While similar principles should apply also to other software and other algorithms, there will be differences in the details. To safely use an inference algorithm in Bayesian workflow, it is vital that the algorithm provides strong diagnostics to determine when the computation is unreliable. In the present paper we discuss such diagnostics for HMC. 3.1. Initial values, adaptation, and warmup Except in the simplest case, Markov chain simulation algorithms operate in multiple stages. First there is a warmup phase which is intended to move the simulations from their possibly unrepresetative initial values to something closer to the region of parameter space where the log posterior density is close to its expected value, which is related to the concept of “typical set” in information theory (Carpenter, 2017). Initial values are not supposed to matter in the asymptotic limit, but they can matter in practice, and a wrong choice can threaten the validity of the results. Also during warmup there needs to be some procedure to set the algorithm’s tuning parameters; this can be done using information gathered from the warmup runs. Third is the sampling phase, which ideally is run until multiple chains have mixed (Vehtari et al., 2020). When fitting a model that has been correctly specified, warmup thus has two purposes: (a) to run through a transient phase to reduce the bias due to dependence on the initial values, and (b) to provide information about the target distribution to use in setting tuning parameters. In model exploration, warmup has a third role, which is to quickly flag computationally problematic models. 3.2. How long to run an iterative algorithm We similarly would like to consider decisions in the operation of iterative algorithms in the context of the larger workflow",
    "chunk_id": "Adv_cognitive_modelling_bayesian_workflow.json_chunk_21"
  },
  {
    "document_type": "research_paper",
    "title": "bayesian_workflow",
    "author": "",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\bayesian_workflow.pdf",
    "date_published": "2020-11-04",
    "keywords": "",
    "flag": "",
    "chunk_text": ". 3.2. How long to run an iterative algorithm We similarly would like to consider decisions in the operation of iterative algorithms in the context of the larger workflow. Recommended standard practice is to run at least until b R , the measure of mixing of chains, is less than 1.01 for all parameters and quantities of interest (Vehtari et al., 2020), and to also monitor the multivariate mixing statistic R ∗ (Lambert and Vehtari, 2020). There are times when earlier stopping can make sense in the early stages of modeling. For example, it might seem like a safe and conservative choice to run MCMC until the effective sample size is in the thousands or Monte Carlo standard error is tiny in comparison to the required precision for parameter interpretation—but if this takes a long time, it limits the number of models that can be fit in the exploration stage. More often than not, our model also has some big issues (especially coding errors) that become apparent after running only a few iterations, so that the remaining 13 Computation time Distance from target distribution MCMC algorithm Approximate algorithm Figure 5: Idealized sketch of the tradeoffbetween approximate algorithms and MCMC in Bayesian computation. If the goal is to get the best fit to the target distribution, MCMC should ultimately win out. But if we are currently fitting just one in a series of models, it can make sense to use approximate algorithms so as to be able to move through model space more rapidly. Which of these algorithms performs better depends on the time budget of the user and where the two curves intersect. computation is wasted. In this respect, running many iterations for a newly-written model is similar to premature optimization in software engineering. For the final model, the required number of iterations depends on the desired Monte Carlo accuracy for the quantities of interest. Another choice in computation is how to best make use of available parallelism, beyond the default of running 4 or 8 separate chains on multiple cores",
    "chunk_id": "Adv_cognitive_modelling_bayesian_workflow.json_chunk_22"
  },
  {
    "document_type": "research_paper",
    "title": "bayesian_workflow",
    "author": "",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\bayesian_workflow.pdf",
    "date_published": "2020-11-04",
    "keywords": "",
    "flag": "",
    "chunk_text": ". Another choice in computation is how to best make use of available parallelism, beyond the default of running 4 or 8 separate chains on multiple cores. Instead of increasing the number of iterations, effective variance reduction can also be obtained by increasing the number of parallel chains (see, e.g., Hoffman and Ma, 2020). 3.3. Approximate algorithms and approximate models Bayesian inference typically involves intractable integrals, hence the need for approximations. Markov chain simulation is a form of approximation where the theoretical error approaches zero as the number of simulations increases. If our chains have mixed, we can make a good estimate of the Monte Carlo standard error (Vehtari et al., 2020), and for practical purposes we often treat these computations as exact. Unfortunately, running MCMC to convergence is not always a scalable solution as data and models get large, hence the desire for faster approximations. Figure 5 shows the resulting tradeoff between speed and accuracy. This graph is only conceptual; in a real problem, the positions of these lines would be unknown, and indeed in some problems an approximate algorithm can perform worse than MCMC even at short time scales. Depending on where we are in the workflow, we have different requirements of our computed posteriors. Near the end of the workflow, where we are examining fine-scale and delicate features, we require accurate exploration of the posterior distribution. This usually requires MCMC",
    "chunk_id": "Adv_cognitive_modelling_bayesian_workflow.json_chunk_23"
  },
  {
    "document_type": "research_paper",
    "title": "bayesian_workflow",
    "author": "",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\bayesian_workflow.pdf",
    "date_published": "2020-11-04",
    "keywords": "",
    "flag": "",
    "chunk_text": ". Near the end of the workflow, where we are examining fine-scale and delicate features, we require accurate exploration of the posterior distribution. This usually requires MCMC. On the other hand, at the beginning of the workflow, we can frequently make our modeling decisions based 14 on large-scale features of the posterior that can be accurately estimated using relatively simple methods such as empirical Bayes, linearization or Laplace approximation, nested approximations like INLA (Rue et al., 2009), or even sometimes data-splitting methods like expectation propagation (Vehtari, Gelman, Siivola, et al., 2020), mode-finding approximations like variational inference (Kucukelbir et al., 2017), or penalized maximum likelihood. The point is to use a suitable tool for the job and to not try to knock down a retaining wall using a sculptor’s chisel. All of these approximate methods have at least a decade of practical experience, theory, and diagnostics behind them. There is no one-size-fits-all approximate inference algorithm, but when a workflow includes relatively well-understood components such as generalized linear models, multilevel regression, autoregressive time series models, or Gaussian processes, it is often possble to construct an appropriate approximate algorithm. Furthermore, depending on the specific approximation being used, generic diagnostic tools described by Yao et al. (2018a) and Talts et al. (2020) can be used to verify that a particular approximate algorithm reproduces the features of the posterior that you care about for a specific model. An alternative view is to understand an approximate algorithm as an exact algorithm for an approximate model. In this sense, a workflow is a sequence of steps in an abstract computational scheme aiming to infer some ultimate, unstated model. More usefully, we can think of things like empirical Bayes approximations as replacing a model’s prior distributions with a particular data-dependent point-mass prior",
    "chunk_id": "Adv_cognitive_modelling_bayesian_workflow.json_chunk_24"
  },
  {
    "document_type": "research_paper",
    "title": "bayesian_workflow",
    "author": "",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\bayesian_workflow.pdf",
    "date_published": "2020-11-04",
    "keywords": "",
    "flag": "",
    "chunk_text": ". More usefully, we can think of things like empirical Bayes approximations as replacing a model’s prior distributions with a particular data-dependent point-mass prior. Similarly a Laplace approximation can be viewed as a datdependent linearization of the desired model, while a nested Laplace approximation (Rue et al., 2009, Margossian et al., 2020a) uses a linearized conditional posterior in place of the posited conditional posterior. 3.4. Fit fast, fail fast An important intermediate goal is to be able to fail fast when fitting bad models. This can be considered as a shortcut that avoids spending a lot of time for (near) perfect inference for a bad model. There is a large literature on approximate algorithms to fit the desired model fast, but little on algorithms designed to waste as little time as possible on the models that we will ultimately abandon. We believe it is important to evaluate methods on this criterion, especially because inappropriate and poorly fitting models can often be more difficult to fit. For a simple idealized example, suppose you are an astronomer several centuries ago fitting ellipses to a planetary orbit based on 10 data points measured with error. Figure 6a shows the sort of data that might arise, and just about any algorithm will fit reasonably well. For example, you could take various sets of five points and fit the exact ellipse to each, and then take the average of these fits. Or you could fit an ellipse to the first five points, then perturb it slightly to fit the sixth point, then perturb that slightly to fit the seventh, and so forth. Or you could implement some sort of least squares algorithm. Now suppose some Death Star comes along and alters the orbit—in this case, we are purposely choosing an unrealistic example to create a gross discrepancy between model and data—so that your 10 data points look like Figure 6b. In this case, convergence will be much harder to attain",
    "chunk_id": "Adv_cognitive_modelling_bayesian_workflow.json_chunk_25"
  },
  {
    "document_type": "research_paper",
    "title": "bayesian_workflow",
    "author": "",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\bayesian_workflow.pdf",
    "date_published": "2020-11-04",
    "keywords": "",
    "flag": "",
    "chunk_text": ". In this case, convergence will be much harder to attain. If you start with the ellipse fit to the first five points, it will be difficult to take any set of small perturbations that will allow the curve to fit the later points in the series. But, more than that, even if you could obtain a least squares solution, any ellipse would be a terrible fit to the data. It’s just an inappropriate model. If you fit an ellipse to these data, you should want the fit to fail fast so you 15 Figure 6: Illustration of the need for “fit fast, fail fast”: (a) Idealized data representing measurments of planetary orbit which could be fit as an ellipse with measurement error, (b) Measurements of a hypothetical orbit that was perturbed by a Death Star. In the second example, it would be challenging to fit a single ellipse to the data—but we have no particular interest in an omnibus elliptical fit in any case. We would like any attempt to fit an ellipse to the second dataset to fail fast. can quickly move on to something more reasonable. This example has, in extreme form, a common pattern of difficult statistical computations, that fitting to different subsets of the data yields much different parameter estimates. 4. Using constructed data to find and understand problems The first step in validating computation is to check that the model actually finishes the fitting process in an acceptable time frame and the convergence diagnostics are reasonable. In the context of HMC, this is primarily the absence of divergent transitions, b R diagnostic near 1, and sufficient effective sample sizes for the central tendency, the tail quantiles, and the energy (Vehtari et al., 2020). However, those diagnostics cannot protect against a probabilistic program that is computed correctly but encodes a different model than the user intended. The main tool we have for ensuring that the statistical computation is done reasonably well is to actually fit the model to some data and check that the fit is good",
    "chunk_id": "Adv_cognitive_modelling_bayesian_workflow.json_chunk_26"
  },
  {
    "document_type": "research_paper",
    "title": "bayesian_workflow",
    "author": "",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\bayesian_workflow.pdf",
    "date_published": "2020-11-04",
    "keywords": "",
    "flag": "",
    "chunk_text": ". The main tool we have for ensuring that the statistical computation is done reasonably well is to actually fit the model to some data and check that the fit is good. Real data can be awkward for this purpose because modeling issues can collide with computational issues and make it impossible to tell if the problem is the computation or the model itself. To get around this challenge, we first explore models by fitting them to simulated data. 4.1. Fake-data simulation Working in a controlled setting where the true parameters are known can help us understand our data model and priors, what can be learned from an experiment, and the validity of the applied inference methods. The basic idea is to check whether our procedure recovers the correct parameter values when fitting fake data. Typically we choose parameter values that seem reasonable a priori and then simulate a fake dataset of the same size, shape, and structure as the original data. We next fit the model to the fake data to check several things. The first thing we check isn’t strictly computational, but rather an aspect of the design of the data. For all parameters, we check to see if the observed data are able to provide additional information 16 beyond the prior. The procedure is to simulate some fake data from the model with fixed, known parameters and then see whether our method comes close to reproducing the known truth. We can look at point estimates and also the coverage of posterior intervals. If our fake-data check fails, in the sense that the inferences are not close to the assumed parameter values or if there seem to be model components that are not gaining any information from the data (Lindley, 1956, Goel and DeGroot, 1981), we recommend breaking down the model. Go simpler and simpler until we get the model to work. Then, from there, we can try to identify the problem, as illustrated in Section 5.2",
    "chunk_id": "Adv_cognitive_modelling_bayesian_workflow.json_chunk_27"
  },
  {
    "document_type": "research_paper",
    "title": "bayesian_workflow",
    "author": "",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\bayesian_workflow.pdf",
    "date_published": "2020-11-04",
    "keywords": "",
    "flag": "",
    "chunk_text": ". Go simpler and simpler until we get the model to work. Then, from there, we can try to identify the problem, as illustrated in Section 5.2. The second thing that we check is if the true parameters can be recovered to roughly within the uncertainty implied by the fitted posterior distribution. This will not be possible if the data are not informative for a parameter, but it should typically happen otherwise. It is not possible to run a single fake data simulation, compute the associated posterior distribution, and declare that everything works well. We will see in the next section that a more elaborate setup is needed. However, a single simulation run will often reveal blatant errors. For instance, if the code has an error in it and fits the wrong model this will often be clear from a catastrophic failure of parameter recovery. The third thing that we can do is use fake data simulations to understand how the behavior of a model can change across different parts of the parameter space. In this sense, a statistical model can contain many stories of how the data get generated. As illustrated in Section 5.9, the data are informative about the parameters for a sum of declining exponentials when the exponents are well separated, but not so informative when the two components are close to each other. This sort of instability contingent on parameter values is also a common phenomenon in differential equation models, as can been seen in Section 11. For another example, the posterior distribution of a hierarchical model looks much different at the neck than at the mouth of the funnel geometry implied by the hierarchical prior. Similar issues arise in Gaussian process models, depending on the length scale of the process and the resolution of the data. All this implies that fake data simulation can be particularly relevant in the zone of the parameter space that is predictive of the data",
    "chunk_id": "Adv_cognitive_modelling_bayesian_workflow.json_chunk_28"
  },
  {
    "document_type": "research_paper",
    "title": "bayesian_workflow",
    "author": "",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\bayesian_workflow.pdf",
    "date_published": "2020-11-04",
    "keywords": "",
    "flag": "",
    "chunk_text": ". All this implies that fake data simulation can be particularly relevant in the zone of the parameter space that is predictive of the data. This in turn suggests a two-step procedure in which we first fit the model to real data, then draw parameters from the resulting posterior distribution to use in fake-data checking. The statistical properties of such a procedure are unclear but in practice we have found such checks to be helpful, both for revealing problems with the computation or model, and for providing some reassurance when the fake-data-based inferences do reproduce the assumed parameter value. To carry this idea further, we may break our method by coming up with fake data that cause our procedure to give bad answers. This sort of simulation-and-exploration can be the first step in a deeper understanding of an inference method, which can be valuable even for a practitioner who plans to use this method for just one applied problem. It can also be useful for building up a set of more complex models to possibly explore later. Fake-data simulation is a crucial component of our workflow because it is, arguably, the only point where we can directly check that our inference on latent variables is reliable. When fitting the model to real data, we do not by definition observe the latent variables. Hence we can only evaluate how our model fits the observed data. If our goal is not merely prediction but estimating the latent variables, examining predictions only helps us so much. This is especially true of overparameterized models, where wildly different parameter values can yield comparable predictions (e.g. Section 5.9 and Gelman et al, 1996). In general, even when the model fit is good, we should only draw 17 conclusions about the estimated latent variables with caution. Fitting the model to simulated data helps us better understand what the model can and cannot learn about the latent process in a controlled setting where we know the ground truth",
    "chunk_id": "Adv_cognitive_modelling_bayesian_workflow.json_chunk_29"
  },
  {
    "document_type": "research_paper",
    "title": "bayesian_workflow",
    "author": "",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\bayesian_workflow.pdf",
    "date_published": "2020-11-04",
    "keywords": "",
    "flag": "",
    "chunk_text": ". Fitting the model to simulated data helps us better understand what the model can and cannot learn about the latent process in a controlled setting where we know the ground truth. If a model is able to make good inference on fake-data generated from that very model, this provides no guarantee that its inference on real data will be sensible. But if a model is unable to make good inference on such fake data, then it’s hopeless to expect the model to provide reasonable inference on real data. Fake-data simulations provide an upper bound of what can be learned about a latent process. 4.2. Simulation-based calibration There is a formal, and at times practical, issue when comparing the result of Bayesian inference, a posterior distribution, to a single (true) point, as illustrated in Figure 7. Using a single fake data simulation to test a model will not necessarily “work,” even if the computational algorithm is working correctly. The problem here arises not just because with one simulation anything can happen (there is a 5% chance that a random draw will be outside a 95% uncertainty interval) but also because Bayesian inference will in general only be calibrated when averaging over the prior, not for any single parameter value. Furthermore, parameter recovery may fail not because the algorithm fails, but because the observed data are not providing information that could update the uncertainty quantified by the prior for a particular parameter. If the prior and posterior are approximately unimodal and the chosen parameter value is from the center of the prior, we can expect overcoverage of posterior intervals. A more comprehensive approach than what we present in Section 4.1 is simulation-based calibration (SBC; Cook et al., 2006, Talts et al., 2020)",
    "chunk_id": "Adv_cognitive_modelling_bayesian_workflow.json_chunk_30"
  },
  {
    "document_type": "research_paper",
    "title": "bayesian_workflow",
    "author": "",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\bayesian_workflow.pdf",
    "date_published": "2020-11-04",
    "keywords": "",
    "flag": "",
    "chunk_text": ". A more comprehensive approach than what we present in Section 4.1 is simulation-based calibration (SBC; Cook et al., 2006, Talts et al., 2020). In this scheme, the model parameters are drawn from the prior; then data are simulated conditional on these parameter values; then the model is fit to data; and finally the obtained posterior is compared to the simulated parameter values that were used to generate the data. By repeating this procedure several times, it is possible to check the coherence of the inference algorithm. The idea is that by performing Bayesian inference across a range of datasets simulated using parameters drawn from the prior, we should recover the prior. Simulation-based calibration is useful to evaluate how closely approximate algorithms match the theoretical posterior even in cases when the posterior is not tractable. While in many ways superior to benchmarking against a truth point, simulation-based calibration requires fitting the model multiple times, which incurs a substantial computational cost, especially if we do not use extensive parallelization. In our view, simulation-based calibration and truth-point benchmarking are two ends of a spectrum. Roughly, a single truth-point benchmark will possibly flag gross problems, but it does not guarantee anything. As we do more experiments, it is possible to see finer and finer problems in the computation. It is an open research question to understand SBC with a small number of draws. We expect that abandoning random draws for a more designed exploration of the prior would make the method more efficient, especially in models with a relatively small number of parameters. A serious problem with SBC is that it clashes somewhat with most modelers’ tendency to specify their priors wider than they believe necessary. The slightly conservative nature of weakly informative priors can cause the data sets simulated during SBC to occasionally be extreme. Gabry et al",
    "chunk_id": "Adv_cognitive_modelling_bayesian_workflow.json_chunk_31"
  },
  {
    "document_type": "research_paper",
    "title": "bayesian_workflow",
    "author": "",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\bayesian_workflow.pdf",
    "date_published": "2020-11-04",
    "keywords": "",
    "flag": "",
    "chunk_text": ". The slightly conservative nature of weakly informative priors can cause the data sets simulated during SBC to occasionally be extreme. Gabry et al. (2019) give an example in which fake air pollution datasets were simulated where the pollution is denser than a black hole. These extreme data sets can cause an algorithm that works well on realistic data to fail dramatically. But this isn’t really a problem with the computation so much as a 18 scenario 1 scenario 2 scenario 3 −3 0 3 6 9−3 0 3 6 9−3 0 3 6 9 0.00 0.25 0.50 0.75 1.00 μ Figure 7: Comparison of a posterior distribution to the assumed true parameter value. When fitting the model to simulated data, we can examine whether the posterior sample (blue histogram) comports with the true parameter value (red line). In scenario 1, the posterior is centered at the true value, which suggests the fit is reasonable. In scenario 2, the true parameter is now in the tail of the posterior distribution. It is unclear whether this indicates a fault in our inference. In scenario 3, the posterior is multimodal and it becomes evident that comparing the posterior to a single point cannot validate the inference algorithm. A more comprehensive approach, such as simulation-based calibration, can teach us more. 19 0 20 40 60 80 100 0 20 40 60 80 100 If nobody gets the treatment Midterm exam score Final exam score 0 20 40 60 80 100 0 20 40 60 80 100 Balanced treatment assignment Midterm exam score Final exam score Figure 8: Simulated data on 500 students from a hypothetical study of the effect of an educational intervention. problem with the prior. One possible way around this is to ensure that the priors are very tight. However, a pragmatic idea is to keep the priors and compute reasonable parameter values using the real data. This can be done either through rough estimates or by computing the actual posterior. We then suggest widening out the estimates slightly and using these as a prior for the SBC",
    "chunk_id": "Adv_cognitive_modelling_bayesian_workflow.json_chunk_32"
  },
  {
    "document_type": "research_paper",
    "title": "bayesian_workflow",
    "author": "",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\bayesian_workflow.pdf",
    "date_published": "2020-11-04",
    "keywords": "",
    "flag": "",
    "chunk_text": ". This can be done either through rough estimates or by computing the actual posterior. We then suggest widening out the estimates slightly and using these as a prior for the SBC. This will ensure that all of the simulated data will be as realistic as the model allows. 4.3. Experimentation using constructed data A good way to understand a model is to fit it to data simulated from different scenarios. For a simple case, suppose we are interested in the statistical properties of linear regression fit to data from alternative distributional forms. To start, we could specify data x i , i = 1 , , n , draw coefficients a and b and a residual standard deviation σ from our prior distribution, simulate data from y i ∼ normal ( a + bx i , σ ) , and fit the model to the simulated data. Repeat this 1000 times and we can check the coverage of interval estimates: that’s a version of simulation-based calibration. We could then fit the same model but simulating data using different assumptions, for example drawing independent data points y i from the t 4 distribution rather than the normal. This will then fail simulation-based calibration—the wrong model is being fit—but the interesting question here is, how bad will these inferences be? One could, for example, use SBC simulations to examine coverage of posterior 50% and 95% intervals for the coefficients. For a more elaborate example, we perform a series of simulations to understand assumptions and bias correction in observational studies. We start with a scenario in which 500 students in a class take a midterm and final exam. We simulate the data by first drawing students’ true abilities η i from a normal (50 , 20) distribution, then drawing the two exam scores x i , y i as independent normal ( η i , 10) distributions. This induces the two scores to have a correlation of 20 2 20 2 +5 2 = 0 . 94 ; we designed the simulation with this high value to make patterns apparent in the graphs. Figure 8a displays the result, along with the underlying regression line, E ( y | x )",
    "chunk_id": "Adv_cognitive_modelling_bayesian_workflow.json_chunk_33"
  },
  {
    "document_type": "research_paper",
    "title": "bayesian_workflow",
    "author": "",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\bayesian_workflow.pdf",
    "date_published": "2020-11-04",
    "keywords": "",
    "flag": "",
    "chunk_text": ". 94 ; we designed the simulation with this high value to make patterns apparent in the graphs. Figure 8a displays the result, along with the underlying regression line, E ( y | x ) . We then construct a hypothetical randomized experiment of a treatment performed after the midterm that would add 10 20 Pre−test score Pr (z=1) 0 20 40 60 80 100 0.0 0.5 1.0 (assigned to treatment group, z=1) (assigned to control group, z=0) 0 20 40 60 80 100 0 20 40 60 80 100 Unalanced treatment assignment Midterm exam score Final exam score Figure 9: Alternative simulation in which the treatment assignment is unbalanced, with less welperforming students being more likely to receive the treatment. points to any student’s final exam score. We give each student an equal chance of receiving the treatment or control. Figure 8b shows the simulated data and underlying regression lines. In this example we can estimate the treatment effect by simply taking the difference between the two groups, which for these simulated data yields an estimate of 10.7 with standard error 1.8. Or we can fit a regression adjusting for midterm score, yielding an estimate of 9 . 7 ± 0 . 6 . We next consider an unbalanced assignment mechanism in which the probability of receiving the treatment depends on the midterm score: Pr ( z = 1) = logit − 1 (( x − 50) / 10) . Figure 9a shows simulated treatment assignments for the 200 students and Figure 9a displays the simulated exam scores. The underlying regression lines are the same as before, as this simulation changes the distribution of z but not the model for y | x, z . Under this design, the treatment is preferentially given to the less well-performing students, hence a simple comparison of final exam scores will give a poor estimate. For this particular simulation, the difference in average grades comparing the two groups is − 13 . 8 ± 1 . 5 , a terrible inference given that the true effect is, by construction, 10",
    "chunk_id": "Adv_cognitive_modelling_bayesian_workflow.json_chunk_34"
  },
  {
    "document_type": "research_paper",
    "title": "bayesian_workflow",
    "author": "",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\bayesian_workflow.pdf",
    "date_published": "2020-11-04",
    "keywords": "",
    "flag": "",
    "chunk_text": ". For this particular simulation, the difference in average grades comparing the two groups is − 13 . 8 ± 1 . 5 , a terrible inference given that the true effect is, by construction, 10. In this case, though, the linear regression adjusting for x recovers the treatment effect, yielding an estimate of 9 . 7 ± 0 . 8 . But this new estimate is sensitive to the functional form of the adjustment for x . We can see this by simulating data from an alternative model in which the true treatment effect is 10 but the function E ( y | x, z ) is no longer linear. In this case we construct such a model by drawing the midterm exam score given true ability from normal ( η i , 10) as before, but transforming the final final exam score, as displayed in Figure 10. We again consider two hypothetical experiments: Figure 10a shows data from the completely randomized assignment, and Figure 10b displays the result using the unbalanced treatment assignment rule from Figure 9a. Both graphs show the underlying regression curves as well. What happens when we now fit a linear regression to estimate the treatment effect? The estimate from the design in Figure 10a is reasonable: even though the linear model is wrong and thus the resulting estimate is not fully statistically efficient, the balance in the design ensures that on average the specification errors will cancel, and the estimate is 10 . 5 ± 0 . 8 . But the unbalanced design has problems: even after adjusting for x in the linear regression, the estimate is 7 . 3 ± 0 . 9 . 21 0 20 40 60 80 100 0 20 40 60 80 100 Nonlinear model, balanced assignment Midterm exam score Final exam score 0 20 40 60 80 100 0 20 40 60 80 100 Nonlinear model, unbalanced assignment Midterm exam score Final exam score Figure 10: Again comparing two different treatment assignments, this time in a setting where the relation between final and midterm exam scores is nonlinear",
    "chunk_id": "Adv_cognitive_modelling_bayesian_workflow.json_chunk_35"
  },
  {
    "document_type": "research_paper",
    "title": "bayesian_workflow",
    "author": "",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\bayesian_workflow.pdf",
    "date_published": "2020-11-04",
    "keywords": "",
    "flag": "",
    "chunk_text": ". In the context of the present article, the point of this example is to demonstrate how simulation of a statistical system under different conditions can give us insight, not just about computational issues but also about data and inference more generally. One could go further in this particular example by considering varying treatment effects, selection on unobservables, and other complications, and this is generally true that such theoretical explorations can be considered indefinitely to address whatever concerns might arise. 5. Addressing computational problems 5.1. The folk theorem of statistical computing When you have computational problems, often there’s a problem with your model (Yao, Vehtari, and Gelman, 2020). Not always—sometimes you will have a model that is legitimately difficult to fit—but many cases of poor convergence correspond to regions of parameter space that are not of substantive interest or even to a nonsensical model. An example of pathologies in irrelevant regions of parameter space is given in Figure 6. Examples of fundamentally problematic models would be bugs in code or using a Gaussian-distributed varying intercept for each individual observation in a Gaussian or logistic regression context, where they cannot be informed by data. Our first instinct when faced with a problematic model should not be to throw more computational resources on the model (e.g., by running the sampler for more iterations or reducing the step size of the HMC algorithm), but to check whether our model contains some substantive pathology. 5.2. Starting at simple and complex models and meeting in the middle Figure 11 illustrates a commonly useful approach to debugging. The starting point is that a model is not performing well, possibly not converging or being able to reproduce the true parameter values in fake-data simulation, or not fitting the data well, or yielding unreasonable inferences",
    "chunk_id": "Adv_cognitive_modelling_bayesian_workflow.json_chunk_36"
  },
  {
    "document_type": "research_paper",
    "title": "bayesian_workflow",
    "author": "",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\bayesian_workflow.pdf",
    "date_published": "2020-11-04",
    "keywords": "",
    "flag": "",
    "chunk_text": ". The path toward diagnosing the problem is to move from two directions: to gradually simplify the 22 Figure 11: Diagram of advice for debugging. The asterisk on the lower right represents the scenario in which problems arise when trying to fit the desired complex model. The dots on the upper left represent successes at fitting various simple versions, and the dots on the lower right represent failures at fitting various simplifications of the full model. The dotted line represents the idea that the problems can be identified somewhere between the simple models that fit and the complex models that don’t. From Gelman and Hill (2007). poorly-performing model, stripping it down until you get something that works; and from the other direction starting with a simple and well-understood model and gradually adding features until the problem appears. Similarly, if the model has multiple components (e.g., a differential equation and a linear predictor for parameters of the equation), it is usually sensible to perform a sort of unit test by first making sure each component can be fit separately, using simulated data. We may never end up fitting the complex model we had intended to fit at first, either because it was too difficult to fit using currently available computational algorithms, or because existing data and prior information are not informative enough to allow useful inferences from the model, or simply because the process of model exploration lead us in a different direction than we had originally planned. 5.3. Getting a handle on models that take a long time to fit We generally fit our models using HMC, which can run slowly for various reasons, including expesive gradient evaluations as in differential equation models, high dimensionality of the parameter space, or a posterior geometry in which HMC steps that are efficient in one part of the space are too large or too small in other regions of the posterior distribution. Slow computation is often a sign of other problems, as it indicates a poorly-performing HMC",
    "chunk_id": "Adv_cognitive_modelling_bayesian_workflow.json_chunk_37"
  },
  {
    "document_type": "research_paper",
    "title": "bayesian_workflow",
    "author": "",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\bayesian_workflow.pdf",
    "date_published": "2020-11-04",
    "keywords": "",
    "flag": "",
    "chunk_text": ". Slow computation is often a sign of other problems, as it indicates a poorly-performing HMC. However the very fact that the fit takes long means the model is harder to debug. For example, we recently received a query in the Stan users group regarding a multilevel logistic regression with 35,000 data points, 14 predictors, and 9 batches of varying intercepts, which failed to finish running after several hours in Stan using default settings from rstanarm. We gave the following suggestions, in no particular order: • Simulate fake data from the model and try fitting the model to the fake data (Section 4.1). Frequently a badly specified model is slow, and working with simulated data allows us not to worry about lack of fit. 23 • Since the big model is too slow, you should start with a smaller model and build up from there. First fit the model with no varying intercepts. Then add one batch of varying intercepts, then the next, and so forth. • Run for 200 iterations, rather than the default (at the time of this writing). Eventually you can run for 2000 iterations, but there is no point in doing that while you’re still trying to figure out what’s going on. If, after 200 iterations, b R is large, you can run longer, but there is no need to start with 2000. • Put at least moderately informative priors on the regression coefficients and group-level variance parameters (Section 7.3). • Consider some interactions of the group-level predictors. It seems strange to have an additive model with 14 terms and no interactions. This suggestion may seem irrelevant to the user’s concern about speed—indeed, adding interactions should only increase run time—but it is a reminder that ultimately the goal is to make predictions or learn something about the underlying process, not merely to get some arbitrary pre-chosen model to converge. • Fit the model on a subset of your data. Again, this is part of the general advice to understand the fitting process and get it to work well, before throwing the model at all the data",
    "chunk_id": "Adv_cognitive_modelling_bayesian_workflow.json_chunk_38"
  },
  {
    "document_type": "research_paper",
    "title": "bayesian_workflow",
    "author": "",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\bayesian_workflow.pdf",
    "date_published": "2020-11-04",
    "keywords": "",
    "flag": "",
    "chunk_text": ". • Fit the model on a subset of your data. Again, this is part of the general advice to understand the fitting process and get it to work well, before throwing the model at all the data. The common theme in all these tips is to think of any particular model choice as provisional, and to recognize that data analysis requires many models to be fit in order to gain control over the process of computation and inference for a particular applied problem. 5.4. Monitoring intermediate quantities Another useful approach to diagnosing model issues is to save intermediate quantities in our computations and plot them along with other MCMC output, for example using bayesplot (Gabry et al., 2020a) or ArviZ (Kumar et al., 2019). These displays are an alternative to inserting print statements inside the code. In our experience, we typically learn more from a visualization than from a stream of numbers in the console. One problem that sometimes arises is chains getting stuck in out-of-the-way places in parameter space where the posterior density is very low and where it can be baffling why the MCMC algorithm does not drift back toward the region where the log posterior density is near its expectation and where most of the posterior mass is. Here it can be helpful to look at predictions from the model given these parameter values to understand what is going wrong, as we illustrate in Section 11. But the most direct approach is to plot the expected data conditional on the parameter values in these stuck chains, and then to transform the gradient of the parameters to the gradient of the expected data. This should give some insight as to how the parameters map to expected data in the relevant regions of the posterior distribution. 5.5. Stacking to reweight poorly mixing chains In practice, often our MCMC algorithms mix just fine",
    "chunk_id": "Adv_cognitive_modelling_bayesian_workflow.json_chunk_39"
  },
  {
    "document_type": "research_paper",
    "title": "bayesian_workflow",
    "author": "",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\bayesian_workflow.pdf",
    "date_published": "2020-11-04",
    "keywords": "",
    "flag": "",
    "chunk_text": ". 5.5. Stacking to reweight poorly mixing chains In practice, often our MCMC algorithms mix just fine. Other times, the simulations quickly move to unreasonable areas of parameter space, indicating the possibility of model misspecification, non-informative or weakly informative observations, or just difficult geometry. 24 But it is also common to be in an intermediate situation where multiple chains are slow to mix but they are in a generally reasonable range. In this case we can use stacking to combine the simulations, using cross validation to assign weights to the different chains (Yao, Vehtari, and Gelman, 2020). This will have the approximate effect of discarding chains that are stuck in out-of-the-way low-probability modes of the target distribution. The result from stacking is not necessarily equivalent, even asymptotically, to fully Bayesian inference, but it serves many of the same goals, and is especially suitable during the model exploration phase, allowing us to move forward and spend more time and energy in other part of Bayesian workflow without getting hung up on exactly fitting one particular model. In addition, non-uniform stacking weights, when used in concert with traceplots and other diagnostic tools, can help us understand where to focus that effort in an iterative way. 5.6. Posterior distributions with multimodality and other difficult geometry We can roughly distinguish four sorts of problems with MCMC related to multimodality and other difficult posterior geometries: • Effectively disjoint posterior volumes, where all but one of the modes have near-zero mass. An example appears in Section 11. In such problems, the minor modes can be avoided using judicious choices of initial values for the simulation, adding prior information or hard constraints for parameters or they can be pruned by approximately estimating the mass in each mode. • Effectively disjoint posterior volumes of high probability mass that are trivially symmetric, such as label switching in a mixture model",
    "chunk_id": "Adv_cognitive_modelling_bayesian_workflow.json_chunk_40"
  },
  {
    "document_type": "research_paper",
    "title": "bayesian_workflow",
    "author": "",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\bayesian_workflow.pdf",
    "date_published": "2020-11-04",
    "keywords": "",
    "flag": "",
    "chunk_text": ". • Effectively disjoint posterior volumes of high probability mass that are trivially symmetric, such as label switching in a mixture model. It is standard practice here to restrict the model in some way to identify the mode of interest; see for example Bafumi et al. (2005) and Betancourt (2017b). • Effectively disjoint posterior volumes of high probability mass that are different. For example in a model ofgene regulation(Modrák, 2018), some dataadmit twodistinct regulatoryregimes with opposite signs of the effect, while an effect close to zero has much lower posterior density. This problem is more challenging. In some settings, we can use stacking (predictive model averaging) as an approximate solution, recognizing that this is not completely general as it requires defining a predictive quantity of interest. A more fully Bayesian alternative is to divide the model into pieces by introducing a strong mixture prior and then fitting the model separately given each of the components of the prior. Other times the problem can be addressed using strong priors that have the effect of ruling out some of the possible modes. • A single posterior volume of high probability mass with an arithmetically unstable tail. If you initialize near the mass of the distribution, there should not be problems for most inferences. If there is particular interest in extremely rare events, then the problem should be reparameterized anyway, as there is a limit to what can be learned from the usual default effective sample size of a few hundred to a few thousand. 25 5.7. Reparameterization Generally, an HMC-based sampler will work best if its mass matrix is appropriately tuned and the geometry of the joint posterior distribution is relatively uninteresting, in that it has no sharp corners, cusps, or other irregularities. This is easily satisfied for many classical models, where results like the Bernstein-von Mises theorem suggest that the posterior will become fairly simple when there is enough data",
    "chunk_id": "Adv_cognitive_modelling_bayesian_workflow.json_chunk_41"
  },
  {
    "document_type": "research_paper",
    "title": "bayesian_workflow",
    "author": "",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\bayesian_workflow.pdf",
    "date_published": "2020-11-04",
    "keywords": "",
    "flag": "",
    "chunk_text": ". This is easily satisfied for many classical models, where results like the Bernstein-von Mises theorem suggest that the posterior will become fairly simple when there is enough data. Unfortunately, the moment a model becomes even slightly complex, we can no longer guarantee that we will have enough data to reach this asymptotic utopia (or, for that matter, that a Bernstein-von Mises theorem holds). For these models, the behavior of HMC can be greatly improved by judiciously choosing a parameterization that makes the posterior geometry simpler. For example, hierarchical models can have difficult funnel pathologies in the limit when groulevel variance parameters approach zero (Neal, 2011), but in many such problems these computtional difficulties can be resolved using reparameterization, following the principles discussed by Meng and van Dyk (2001); see also Betancourt and Girolami (2015). 5.8. Marginalization Challenging geometries in the posterior distribution are often due to interactions between paraeters. An example is the above-mentioned funnel shape, which we may observe when plotting the joint density of the group-level scale parameter, φ , and the individual-level mean, θ . By contrast, the marginal density of φ is well behaved. Hence we can efficiently draw MCMC samples from the marginal posterior, p ( φ | y ) = Z Θ p ( φ, θ | y ) dθ. To draw posterior draws with MCMC, Bayes’ rule teaches us we only need the marginal likelihood, p ( y | φ ) . It is then possible to recover posterior draws for θ by doing exact sampling from the conditional distribution p ( θ | φ, y ) , at a small computational cost. This marginalization strategy is notably used for Gaussian processes with a normal likelihood (e.g. Rasmussen and Williams, 2006, Betancourt, 2020b). In general, the densities p ( y | φ ) and p ( θ | φ, y ) are not available to us",
    "chunk_id": "Adv_cognitive_modelling_bayesian_workflow.json_chunk_42"
  },
  {
    "document_type": "research_paper",
    "title": "bayesian_workflow",
    "author": "",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\bayesian_workflow.pdf",
    "date_published": "2020-11-04",
    "keywords": "",
    "flag": "",
    "chunk_text": ". Rasmussen and Williams, 2006, Betancourt, 2020b). In general, the densities p ( y | φ ) and p ( θ | φ, y ) are not available to us. Exploiting the structure of the problem, we can approximate these distributions using a Laplace approximation, notably for latent Gaussian models (e.g., Tierney and Kadane, 1986, Rasmussen and Williams, 2006, Rue et al., 2009, Margossian et al., 2020b). When coupled with HMC, this marginalization scheme can, depending on the cases, be more effective than reparameterization, if sometimes at the cost of a bias; for a discussion on the topic, see Margossian et al. (2020a). 5.9. Adding prior information Often the problems in computation can be fixed by including prior information that is already available but which had not yet been included in the model, for example, because prior elicitation from domain experts has substantial cost (O’Hagan et al., 2006, Sarma and Kay, 2020) and we started with some template model and prior (Section 2.1). In some cases, running for more iterations can also help. But many fitting problems go away when reasonable prior information is added, which is not to say that the primary use of priors is to resolve fitting problems. We may have assumed (or hoped) that the data would sufficiently informative for all parts of the model, but with careful inspection or as the byproduct of computational diagnostics, we may find out 26 0 2 4 6 8 10 0.0 0.5 1.0 1.5 2.0 y = ( a 1 e − 0.1x + a 2 e − 2x ) × error x y 0 2 4 6 8 10 0.0 1.0 2.0 3.0 y = ( a 1 e − 0.1x + a 2 e − 0.2x ) × error x y Figure 12: Simulated data from the model, y = ( a 1 e − b 1 x + a 2 e − b 2 x ) ∗ error: (a) setting ( b 1 , b 2 ) = (0 . 1 , 2 . 0) , and (b) setting ( b 1 , b 2 ) = (0 . 1 , 0 . 2) . In addition, the dotted line in the second plot shows the curve, y = 1 . 8 e − 0 . 135 x , which almost exactly coincides with the true curve over the range of these data. It was easy to fit the model to the data in the left graph and recover the true parameter values",
    "chunk_id": "Adv_cognitive_modelling_bayesian_workflow.json_chunk_43"
  },
  {
    "document_type": "research_paper",
    "title": "bayesian_workflow",
    "author": "",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\bayesian_workflow.pdf",
    "date_published": "2020-11-04",
    "keywords": "",
    "flag": "",
    "chunk_text": ". 8 e − 0 . 135 x , which almost exactly coincides with the true curve over the range of these data. It was easy to fit the model to the data in the left graph and recover the true parameter values. For the data in the right graph, however, the observations did not provide information to reduce the uncertainty sufficiently, and and the model could only be stably fit using a prior distribution that provided that needed missing information. that this is not the case. In classical statistics, models are sometimes classified as identifiable or noidentifiable, but this can be misleading (even after adding intermediate categories such as partial or weak identifiability), as the amount of information that can be learned from observations depends also on the specific realization of the data that was actually obtained. In addition, “identification” is formally defined in statistics as an asymptotic property, but in Bayesian inference we care about inference with finite data, especially given that our models often increase in size and complexity as more data are included into the analysis. Asymptotic results can supply some insight into finitsample performance, but we generally prefer to consider the posterior distribution that is in front of us. Lindley (1956) and Goel and DeGroot (1981) discuss how to measure the information provided by an experiment as how different the posterior is from the prior. If the data are not informative on some aspects of the model, we may improve the situation by providing more information via priors. Furthermore, we often prefer to use a model with parameters that can be updated by the information in the data instead of a model that may be closer to the truth but where data are not able to provide sufficient information. In Sections 6.2–6.3 we discuss tools for assessing the informativeness of individual data points or hyperparameters. We illustrate with the problem of estimating the sum of declining exponentials with unknown decay rates",
    "chunk_id": "Adv_cognitive_modelling_bayesian_workflow.json_chunk_44"
  },
  {
    "document_type": "research_paper",
    "title": "bayesian_workflow",
    "author": "",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\bayesian_workflow.pdf",
    "date_published": "2020-11-04",
    "keywords": "",
    "flag": "",
    "chunk_text": ". We illustrate with the problem of estimating the sum of declining exponentials with unknown decay rates. This task is a well-known ill-conditioned problem in numerical analysis and also arises in applications such as pharmacology (Jacquez, 1972). We assume data y i = ( a 1 e − b 1 x i + a 2 e − b 2 x i ) × e ε i , for i = 1 , , n, with independent errors ε i ∼ normal (0 , σ ) . The coefficients a 1 , a 2 , and the residual standard deviation σ are constrained to be positive. The parameters b 1 and b 2 are also positive—these are supposed to be declining, not increasing, exponentials—and are also constrained to be ordered, b 1 < b 2 , so as to uniquely define the two model components. We start by simulating fake data from a model where the two curves should be cleanly distiguished, setting b 1 = 0 . 1 and b 2 = 2 . 0 , a factor of 20 apart in scale. We simulate 1000 data points 27 N = 1 N = 2 N = 8 −3 −2 −1 0 1 2 3 −3 −2 −1 0 1 2 3 −3 −2 −1 0 1 2 3 −2 −1 0 1 mu log(sigma) A N = 6 N = 9 N = 21 0.3 0.6 0.9 0.3 0.6 0.9 0.3 0.6 0.9 −3 −2 −1 log(theta[1]) log(sigma[1]) B Figure 13: Example of how adding data changes the geometry of the posterior distribution. (A) Normal likelihood as a function of mean μ and standard deviation σ with increasing number of available observations N drawn from the standard normal distribution. For N = 1 the likelihood increases without bounds and for N = 2 the geometry is still funnel-like which can cause computational problems. For N = 8 the funnel-like shape is mostly suppressed. (B) Practical example using an Lotka-Volterra model of population dynamics ( 8 parameters total) as described in Carpenter (2018), showing scatter plots of posterior samples of two parameters drawn from fitting the model in Stan. The fit with 6 data points shows a funnel-like shape. The red points indicate divergent transitions which signal that the sampler encountered difficult geometry and the results are not trustworthy",
    "chunk_id": "Adv_cognitive_modelling_bayesian_workflow.json_chunk_45"
  },
  {
    "document_type": "research_paper",
    "title": "bayesian_workflow",
    "author": "",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\bayesian_workflow.pdf",
    "date_published": "2020-11-04",
    "keywords": "",
    "flag": "",
    "chunk_text": ". The fit with 6 data points shows a funnel-like shape. The red points indicate divergent transitions which signal that the sampler encountered difficult geometry and the results are not trustworthy. Stan becomes able to fit the model when 9 data points are used, despite the slightly uneven geometry. The model is well behaved when fit to 21 data points. where the predictor values x are uniformly spaced from 0 to 10, and, somewhat arbitrarily, set a 1 = 1 . 0 , a 2 = 0 . 8 , σ = 0 . 2 . Figure 12a shows true curve and the simulated data. We then use Stan to fit the model from the data. The simulations run smoothly and the posterior inference recovers the five parameters of the model, which is no surprise given that the data have been simulated from the model we are fitting. But now we make the problem slightly more difficult. The model is still, by construction, true, but instead of setting ( b 1 , b 2 ) to (0 . 1 , 2 . 0) , we make them (0 . 1 , 0 . 2) , so now only a factor of 2 separates the scales of the two declining exponentials. The simulated data are shown in Figure 12b. But now when we try to fit the model in Stan, we get terrible convergence. The two declining exponentials have become very hard to tell apart, as we have indicated in the graph by also including the curve, y = 1 . 8 e − 0 . 135 x , which is essentially impossible to distinguish from the true model given these data. We can make this computation more stable by adding prior information. For example, default normal (0 , 1) priors on all the parameters does sufficient regularization, while still being weak if the model has been set up so the parameters are roughly on unit scale, as discussed in Section 2.3. In this case we are assuming this has been done. One could also check the sensitivity of the posterior inferences to the choice of prior, either by comparing to alternatives such as normal (0 , 0 . 5) and normal (0 , 2) or by differentiating the inferences with respect to the prior scale, as discussed in Section 6.3",
    "chunk_id": "Adv_cognitive_modelling_bayesian_workflow.json_chunk_46"
  },
  {
    "document_type": "research_paper",
    "title": "bayesian_workflow",
    "author": "",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\bayesian_workflow.pdf",
    "date_published": "2020-11-04",
    "keywords": "",
    "flag": "",
    "chunk_text": ". 5) and normal (0 , 2) or by differentiating the inferences with respect to the prior scale, as discussed in Section 6.3. Using an informative normal distribution for the prior adds to the tail-log-concavity of the 28 posterior density, which leads to a quicker MCMC mixing time. But the informative prior does not represent a tradeoffof model bias vs. computational efficiency; rather, in this case the model fitting is improved as the computation burden is eased, an instance of the folk theorem discussed in Section 5.1. More generally, there can be strong priors with thick tails, and thus the tail behavior is not guaranteed to be more log concave. On the other hand, the prior can be weak in the context of the likelihood while still guaranteeing a log-concave tail. This is related to the point that the informativeness of a model depends on what questions are being asked. Consider four steps on a ladder of abstraction: 1. Poor mixing of MCMC; 2. Difficult geometry as a mathematical explanation for the above; 3. Weakly informative data for some parts of the model as a statistical explanation for the above; 4. Substantive prior information as a solution to the above. Starting from the beginning of this ladder, we have computational troubleshooting; starting from the end, computational workflow. As another example, when trying to avoid the funnel pathologies of hierarchical models in the limit when group-level variance parameters approach zero, one could use zero-avoiding priors (for example, lognormal or inverse gamma distributions) to avoid the regions of high curvature of the likelihood; a related idea is discussed for penalized marginal likelihood estimation by Chung et al. (2013, 2014). Zero-avoiding priors can make sense when such prior information is available—such as for the length-scale parameter of a Gaussian process (Fuglstad et al., 2019)—but we want to be careful when using such a restriction merely to make the algorithm run faster",
    "chunk_id": "Adv_cognitive_modelling_bayesian_workflow.json_chunk_47"
  },
  {
    "document_type": "research_paper",
    "title": "bayesian_workflow",
    "author": "",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\bayesian_workflow.pdf",
    "date_published": "2020-11-04",
    "keywords": "",
    "flag": "",
    "chunk_text": ". At the very least, if we use a restrictive prior to speed computation, we should make it clear that this is information being added to the model. More generally, we have found that poor mixing of statistical fitting algorithms can often be fixed by stronger regularization. This does not come free, though: in order to effectively regularize without blurring the very aspects of the model we want to estimate, we need some subjecmatter knowledge—actual prior information. Haphazardly tweaking the model until computational problems disappear is dangerous and can threaten the validity of inferences without there being a good way to diagnose the problem. 5.10. Adding data Similarly to adding prior information, one can constrain the model by adding new data sources that are handled within the model. For example, a calibration experiment can inform the standard deviation of a response. In other cases, models that are well behaved for larger datasets can have computational issues in small data regimes; Figure 13 shows an example. While the funnel-like shape of the posterior in such cases looks similar to the funnel in hierarchical models, this pathology is much harder to avoid, and we can often only acknowledge that the full model is not informed by the data and a simpler model needs to be used. Betancourt (2018) further discusses this issue. 29 6. Evaluating and using a fitted model Once a model has been fit, the workflow of evaluating that fit is more convoluted, because there are many different things that can be checked, and each of these checks can lead in many directions. Statistical models can be fit with multiple goals in mind, and statistical methods are developed for different groups of users. The aspects of a model that needs to be checked will depend on the application. 6.1. Posterior predictive checking Posterior predictive checking is analogous to prior predictive checking (Section 2.4), but the parameter draws used in the simulations come from the posterior distribution rather than the prior",
    "chunk_id": "Adv_cognitive_modelling_bayesian_workflow.json_chunk_48"
  },
  {
    "document_type": "research_paper",
    "title": "bayesian_workflow",
    "author": "",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\bayesian_workflow.pdf",
    "date_published": "2020-11-04",
    "keywords": "",
    "flag": "",
    "chunk_text": ". While prior predictive checking is a way to understand a model and the implications of the specified priors, posterior predictive checking also allows one to examine the fit of a model to real data (Box, 1980, Rubin, 1984, Gelman, Meng, and Stern, 1996). When comparing simulated datasets from the posterior predictive distribution to the actual dataset, if the dataset we are analyzing is unrepresentative of the posterior predictive distribution, this indicates a failure of the model to describe an aspect of the data. The most direct checks compare the simulations from the predictive distribution to the full distribution of the data or a summary statistic computed from the data or subgroups of the data, especially for groupings not included in the model (see Figure 14). There is no general way to choose which checks one should perform on a model, but running a few such direct checks is a good safeguard against gross misspecification. There is also no general way to decide when a check that fails requires adjustments to the model. Depending on the goals of the analysis and the costs and benefits specific to the circumstances, we may tolerate that the model fails to capture certain aspects of the data or it may be essential to invest in improving the model. In general, we try to find “severe tests” (Mayo, 2018): checks that are likely to fail if the model would give misleading answers to the questions we care most about. Figure 15 shows a more involved posterior predictive check from an applied project. This example demonstrates the way that predictive simulation can be combined with graphical display, and it also gives a sense of the practical challenges of predictive checking, in that it is often necessary to come up with a unique visualization tailored to the specific problem at hand. 6.2",
    "chunk_id": "Adv_cognitive_modelling_bayesian_workflow.json_chunk_49"
  },
  {
    "document_type": "research_paper",
    "title": "bayesian_workflow",
    "author": "",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\bayesian_workflow.pdf",
    "date_published": "2020-11-04",
    "keywords": "",
    "flag": "",
    "chunk_text": ". 6.2. Cross validation and influence of individual data points and subsets of the data Posterior predictive checking is often sufficient for revealing model misfit, but as it uses data both for model fitting and misfit evaluation, it can be overly optimistic. In cross validation, part of the data is left out, the model is fit to the remaining data, and predictive performance is checked on the left-out data. This improves predictive checking diagnostics, especially for flexible models (for example, overparameterized models with more parameters than observations). Three diagnostic approaches using cross validation that we have found useful for further evalating models are 1. calibration checks using the cross validation predictive distribution, 2. identifying which observations or groups of observations are most difficult to predict, 30 3. identifying how influential particular observations are, that is, how much information they provide on top of other observations. In all three cases, efficient approximations to leave-one-out cross-validation using importance sampling can facilitate practical use by removing the need to re-fit the model when each data point is left out (Vehtari et al., 2017, Paananen et al., 2020). −40 0 40 80 y y rep A 0.5 1.0 1.5 2.0 T = sd T ( y rep ) T ( y ) B 0 10 20 0 2 4 6 Count y rep y C High Low 0 2 4 6 0 2 4 6 0 5 10 15 Count y rep y D Figure 14: Examples of diagnosing model misfit with simple posterior predictive checks as implmented in the bayesplot R package. In all plots y is plotted based on the input data and y rep based on the distribution of posterior simulations. (A) A “density” check for a normal distribution being fit to data simulated from a lognormal distribution: the tails of the y rep behave very differently than for y . (B) A “statistic” check for a binomial distribution being fit to data simulated from a beta-binomial distribution. Histogram of standard deviation (sd) of the y rep datasets is compared to sd of y",
    "chunk_id": "Adv_cognitive_modelling_bayesian_workflow.json_chunk_50"
  },
  {
    "document_type": "research_paper",
    "title": "bayesian_workflow",
    "author": "",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\bayesian_workflow.pdf",
    "date_published": "2020-11-04",
    "keywords": "",
    "flag": "",
    "chunk_text": ". (B) A “statistic” check for a binomial distribution being fit to data simulated from a beta-binomial distribution. Histogram of standard deviation (sd) of the y rep datasets is compared to sd of y . The check shows that the data have larger sd than what the model can handle. (C) A “bars” check for discrete data (note the switch of colors between y and y rep ). This check looks good: the distribution of frequencies of individual counts in y falls well within those in y rep . (D) The same model and data but with the check grouped by a covariate that was not included in the model but in fact influenced the response. The High subgroup systematically deviates from the range of y rep , indicating that there is an additional source of variability that the model fails to capture. Although perfect calibration of predictive distributions is not the ultimate goal of Bayesian inference, looking at how well calibrated leave-one-out cross validation (LOO-CV) predictive ditributions are, can reveal opportunities to improve the model. While posterior predictive checking often compares the marginal distribution of the predictions to the data distribution, leave-one-out cross validation predictive checking looks at the calibration of conditional predictive distributions. Under a good calibration, the conditional cumulative probability distribution of the predictive ditributions (also known as probability integral transformations, PIT) given the left-out observations are uniform. Deviations from uniformity can reveal, for example, under or overdispersion of the predictive distributions. Figure 16 shows an example from Gabry et al. (2019) where leave-one-out cross validation probability integral transformation (LOO-PIT) values are too concentrated near 31 Figure 15: Example of a posterior predictive check. The left column shows observed data from a psychology experiment, displayed as a 15 × 23 array of binary responses from each of 6 participants, ordered by row, column, and person",
    "chunk_id": "Adv_cognitive_modelling_bayesian_workflow.json_chunk_51"
  },
  {
    "document_type": "research_paper",
    "title": "bayesian_workflow",
    "author": "",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\bayesian_workflow.pdf",
    "date_published": "2020-11-04",
    "keywords": "",
    "flag": "",
    "chunk_text": ". The left column shows observed data from a psychology experiment, displayed as a 15 × 23 array of binary responses from each of 6 participants, ordered by row, column, and person. The right columns show 7 replicated datasets from the posterior predictive distribution of the fitted model. Each replicated dataset has been ordered, as this is part of the display. The check reveals some patterns in the observed that do not appear in the replications, indicating a aspect of lack of fit of model to data. From Gelman et al. (2013). the middle, revealing that the predictive distributions are overdispersed compared to the actual conditional observations. In addition to looking at the calibration of the conditional predictive distributions, we can also look at which observations are hard to predict and see if there is a pattern or explanation for why some are harder to predict than others. This approach can reveal potential problems in the data or data processing, or point to directions for model improvement (Vehtari et al., 2017, Gabry et al., 2019). We illustrate with an analysis of a survey of residents from a small area in Bangladesh that was affected by arsenic in drinking water. Respondents with elevated arsenic levels in their wells were asked if they were interested in switching to water from a neighbor’s well, and a series of models were fit to predict this binary response given household information (Vehtari et al., 2017). Figure 17 compares the pointwise log scores for two of the models. The scattered blue dots on the left side of Figure 17a and on the lower right of Figure 17b correspond to data points for which one of the models fits particularly poorly—that is, large negative contributions to the expected log predictive density",
    "chunk_id": "Adv_cognitive_modelling_bayesian_workflow.json_chunk_52"
  },
  {
    "document_type": "research_paper",
    "title": "bayesian_workflow",
    "author": "",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\bayesian_workflow.pdf",
    "date_published": "2020-11-04",
    "keywords": "",
    "flag": "",
    "chunk_text": ". We can sum all of the pointwise differences to yield an estimated difference in expected log predictive densities elpd loo of 16.4 with a standard error of just 4.4, but beyond that we can use this plot to find which data points create problems for the model, in this case 10–15 non-switchers with very high existing arsenic levels. In this particular example, we did not follow up on this modeling issue, because even more elaborate models that fit the data better do not change the conclusions and thus would not change any recommended actions in Bangladesh. Gabry et al. (2019) provide an example where LOO-CV indicated problems that motivated efforts to improve the statistical model. The above two approaches focus on the predictions, but we can also look at how parameter 32 Figure 16: Leave-one-out cross validation probability integral transformation (LOO-PIT) plot evaluating the calibration of predictions from a fitted model. Under perfect calibration, LOO-PIT values would be uniform. In this case the values are concentrated near the middle, indicating predictive distributions that are too wide. From Gabry et al. (2019). − 3 . 5 − 3 − 2 . 5 − 2 − 1 . 5 − 1 − 0 . 5 0 − 3 − 2 − 1 0 LOO 1 LOO 2 Didn’t switch Switched − 1 − 0 . 5 0 0 . 5 1 1 . 5 2 2 . 5 − 1 − 0 . 5 0 log(arsenic) LOO 1 − LOO 2 Didn’t switch Switched Figure 17: Logistic regression example, comparing two models in terms of their pointwise contribtions to leave one out (LOO) cross validation error: (a) comparing contributions of LOO directly; (b) plotting the difference in LOO as a function of a key predictor (the existing arsenic level). To aid insight, we have colored the data according to the (binary) output, with red corresponding to y = 1 and blue representing y = 0 . For any given data point, one model will fit better than another, but for this example the graphs reveal that the difference in LOO between the models arises from the linear model’s poor predictions for 10–15 particular data points. From Vehtari et al. (2017)",
    "chunk_id": "Adv_cognitive_modelling_bayesian_workflow.json_chunk_53"
  },
  {
    "document_type": "research_paper",
    "title": "bayesian_workflow",
    "author": "",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\bayesian_workflow.pdf",
    "date_published": "2020-11-04",
    "keywords": "",
    "flag": "",
    "chunk_text": ". From Vehtari et al. (2017). 33 inferences change when each data point is left out, which provides a sense of the influence of each observation. As with cross validation more generally, this approach has limitations if the data are clustered or otherwise structured so that multiple points would need to be removed to have an effect, but it can still be part of general Bayesian workflow, given that it is computationally inexpensive and can be valuable in many applied settings. Following this cross validation idea, the influence of an individual data point y i can be summarized according to properties of the distribution of the importance weights computed when approximating LOO-CV (see Vehtari et al., 2017 for details on the approximation and the corresponding implementation in the loo R package (Vehtari et al. 2020)). An alternative approach to importance weighting is to frame the removal of data points as a gradient in a larger model space. Suppose we have a simple independent likelihood, Q n i =1 p ( y i | θ ) , and we work with the more general form, Q n i =1 p ( y i | θ ) α i , which reduces to the likelihood of the original model when α i = 1 for all i . Leave-one-out cross validation corresponds to setting α i = 0 for one observation at a time. But another option, discussed by Giordano et al. (2018) and implemented by Giordano (2018), is to compute the gradient of the augmented log likelihood as a function of α : this can be interpreted as a sort of differential cross validation or influence function. Cross validation for multilevel (hierarchical) models requires more thought. Leave-one-out is still possible, but it does not always match our inferential goals. For example, when performing multilevel regression for adjusting political surveys, we are often interested in estimating opinion at the state level. A model can show real improvements at the state level with this being undetectable at the level of cross validation of individual observations (Wang and Gelman, 2016)",
    "chunk_id": "Adv_cognitive_modelling_bayesian_workflow.json_chunk_54"
  },
  {
    "document_type": "research_paper",
    "title": "bayesian_workflow",
    "author": "",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\bayesian_workflow.pdf",
    "date_published": "2020-11-04",
    "keywords": "",
    "flag": "",
    "chunk_text": ". A model can show real improvements at the state level with this being undetectable at the level of cross validation of individual observations (Wang and Gelman, 2016). Millar (2018), Merkle, Furr, and Rabe-Hesketh (2019), and Vehtari (2019) demonstrate different cross validation variants and their approximations in hierarchical models, including leave-one-unit-out and leavone-group-out. In applied problems we have performed a mix, holding out some individual observations and some groups and then evaluating predictions at both levels (Price et al., 1996). Unfortunately, approximating such cross validation procedures using importance sampling tends to be much harder than in the leave-one-out case. This is because more observations are left out at a time which implies stronger changes in the posterior distributions from the full to the subsetted model. As a result, we may have to rely on more costly model refits to obtain leave-one-unit-out and leave-one-group-out cross validation results. 6.3. Influence of prior information Complex models can be difficult to understand, hence the need for exploratory model analysis (Unwin et al., 2003, Wickham, 2006) and explainable AI (Chen et al., 2018, Gunning, 2017, Rudin, 2018), which complements methods for evaluating, comparing, and averaging models using a range of interrelated approaches, including cross validation, stacking, boosting, and Bayesian evaluation. In this section we discuss methods to understand how posterior inferences under a fitted model depend on the data and priors. A statistical model can be understood in two ways: generatively and inferentially. From the generative perspective, we want to understand how the parameters map to the data. We can perform prior predictive simulation to visualize possible data from the model (as in Figure 4). From the inferential perspective, we want to understand the path from inputs (data and prior distributions) to outputs (estimates and uncertainties)",
    "chunk_id": "Adv_cognitive_modelling_bayesian_workflow.json_chunk_55"
  },
  {
    "document_type": "research_paper",
    "title": "bayesian_workflow",
    "author": "",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\bayesian_workflow.pdf",
    "date_published": "2020-11-04",
    "keywords": "",
    "flag": "",
    "chunk_text": ". From the inferential perspective, we want to understand the path from inputs (data and prior distributions) to outputs (estimates and uncertainties). The most direct way to understand the influence of priors is to run sensitivity analysis by refitting 34 Figure 18: Example of static sensitivity analysis from a statistical model fit to a problem in toxicology. Each graph shows posterior simulation draws of the percent metabolized under two conditions (hence the clusters of points at the top and bottom of each graph), plotted vs. two of the parameters in the model. The plots reveal little sensitivity to either parameter on inference for percent metabolized under one condition, but strong sensitivity for the other. This sort of graph can be used to assess sensitivity to alternative prior distributions, without requiring the model to be re-fit. From Gelman, Bois, and Jiang (1996). the model with multiple priors, this can however be prohibitively expensive if the models take a long time to fit. However, there are some shortcuts. One approach is to compute the shrinkage between prior and posterior, for example, by compaing prior to posterior standard deviations for each parameter or by comparing prior and posterior quantiles. If the data relative to the prior are informative for a particular parameter, shrinkage for that parameter should be stronger. This type of check has been extensively developed in the literature; see, for example, Nott et al. (2020). Another approach is to use importance sampling to approximate the posterior of the new model using the posterior of old model, provided the two posteriors are similar enough for importance sampling to bridge (Vehtari et al., 2019, Paananen et al., 2020). And if they are not, this is also valuable information in itself (see Section 6.2)",
    "chunk_id": "Adv_cognitive_modelling_bayesian_workflow.json_chunk_56"
  },
  {
    "document_type": "research_paper",
    "title": "bayesian_workflow",
    "author": "",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\bayesian_workflow.pdf",
    "date_published": "2020-11-04",
    "keywords": "",
    "flag": "",
    "chunk_text": ". And if they are not, this is also valuable information in itself (see Section 6.2). Yet another approach is to perform static sensitivity analysis , which is a way to study sensitivity of posterior inferences to perturbations in the prior without requiring that the model be re-fit using alternative prior distributions (Gelman, Bois, and Jiang, 1996; see Figure 18 for an example). Each graph in Figure 18 shows posterior simulations revealing the posterior dependence of a quantity of interest (in this example, the percentage of a toxin that is metabolized by the body) as a function of a parameter in the model. Consider Figure 18 as four scatterplots, as each of the two graphs is really two plots supeimposed, one for a condition of low exposure to the toxin and one for high exposure. Each of these four plots can be interpreted in two ways. First, the direct interpretation shows the posterior correlation between the predictive quantity of interest (the percentage metabolized in the body) and a particular parameter (for example, the scaling coefficient of the toxin’s metabolism). Second, each scatterplot can be read indirectly to reveal sensitivity of the quantity plotted on the y -axis to the prior of the parameter plotted on the x -axis. The interpretation goes as follows: a change in the 35 prior distribution for the parameter plotted on the x -axis can be performed by reweighting of the points on the graph according to the ratio of the new prior to that used in the analysis. With these graphs, the importance weighing can be visualized implicitly: the impact of changes in the prior distribution can be seen based on the dependence in the scatterplot. The mapping of prior and data to posterior can also be studied more formally, as discussed in Section 6.2. 6.4. Summarizing inference and propagating uncertainty Bayesian inference is well suited for problems with latent variables and other settings with unresolable uncertainty",
    "chunk_id": "Adv_cognitive_modelling_bayesian_workflow.json_chunk_57"
  },
  {
    "document_type": "research_paper",
    "title": "bayesian_workflow",
    "author": "",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\bayesian_workflow.pdf",
    "date_published": "2020-11-04",
    "keywords": "",
    "flag": "",
    "chunk_text": ". 6.4. Summarizing inference and propagating uncertainty Bayesian inference is well suited for problems with latent variables and other settings with unresolable uncertainty. In addition, we often use hierarchical models that include batches of parameters representing variation. For example, when reporting the results from our election forecasting model, we are interested in uncertainty in the forecast votes and also variation among states. Unfortunately, the usual ways of displaying Bayesian inference do not fully capture the multiple levels of variation and uncertainty in our inferences. A table or even a graph of parameter estimates, uncertainties, and standard errors is only showing one-dimensional margins, while graphs of marginal posterior distributions are unwieldy for models with many parameters and also fail to capture the interplay between uncertainty and variation in a hierarchical model. To start with, we should follow general principles of good statistical practice and graph data and fitted models, both for the “exploratory data analysis” purpose of uncovering unexpected patterns in the data and also more directly to understand how the model relates to the data used to fit it. We illustrate some uses of graphical model exploration and summary from an analysis by Ghitza and Gelman (2020) of vote preferences in the 2016 U.S. presidential election. Figure 19 shows the estimated gender gap in support for the two candidates, first displayed as a map and then as a scatterplot. The map, which is the natural first step to visualizing these estimates, reveals some intriguing geographic patterns which are then explored in a more focused way in the scatterplot. Figure 20 evaluates the model by comparing to simpler county-level estimates. This example demonstrates a general workflow in exploratory graphics, in which the results from inferential summary motivates future exploration. Gabry et al",
    "chunk_id": "Adv_cognitive_modelling_bayesian_workflow.json_chunk_58"
  },
  {
    "document_type": "research_paper",
    "title": "bayesian_workflow",
    "author": "",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\bayesian_workflow.pdf",
    "date_published": "2020-11-04",
    "keywords": "",
    "flag": "",
    "chunk_text": ". This example demonstrates a general workflow in exploratory graphics, in which the results from inferential summary motivates future exploration. Gabry et al. (2019) present some of our ideas on graphics for Bayesian workflow, and some of this has been implemented in the R package bayesplot (Gabry et al., 2020b, see also Kay, 2020ab, Kumar, 2019). Probabilistic programming ultimately has the potential to allow random variables to manipulated like any other data objects, with uncertainty implicit in all the plots and calculations (Kerman and Gelman, 2004, 2007), but much more work needs to be done to turn this possibility into reality, going beyond point and interval estimation so that we can make full use of the models we fit. 7. Modifying a model Model building is a language-like task in which the modeler puts together existing components (linear, logistic, and exponential functions; additive and multiplicative models; binomial, Poisson, and normal distributions; varying coefficients; and so forth) in order to encompass new data and additional features of existing data, along with links to underlying processes of interest. As mentioned in Section 2.2, most parts of the models can be seen as placeholders that allow 36 Figure 19: From a model fit to survey data during the 2016 U.S. presidential election campaign: (a) estimate of the gender gap among white voters, (b) estimated gender gap plotted vs. Obama’s estimated county-level vote share in 2012 among white votes. The area of each circle is proportional to the number of voters in the county, and the colors on the map represent a range going from dark purple (no difference in voting patterns comparing white men and white women) through light gray (white women supporting Clinton 7.5 percentage points more than white men) to dark green (a white gender gap of 15 percentage points)",
    "chunk_id": "Adv_cognitive_modelling_bayesian_workflow.json_chunk_59"
  },
  {
    "document_type": "research_paper",
    "title": "bayesian_workflow",
    "author": "",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\bayesian_workflow.pdf",
    "date_published": "2020-11-04",
    "keywords": "",
    "flag": "",
    "chunk_text": ". The striking geographic patterns—a white gender gap that is low in much of the south and high in the west and much of the northeast and midwest—motivates the scatterplot, which reveals that the white gender gap tends to be highest in counties where the white vote is close to evenly split. From Ghitza and Gelman (2020). Figure 20: Evaluation of one aspect of the model shown in Figure 19, comparing county-level support for Clinton as estimated from two different models. We include this here to illustrate the way that graphical methods can be used to summarize, understand, evaluate, and compare fitted models. From Ghitza and Gelman (2020). 37 replacement or expansion. Alternatively we may find the need to use an approximate model or an approximate algorithm, as discussed in Section 3.3. Model expansion can come in response to new data, failures of models fit to existing data, or computational struggles with existing fitting procedures. For the election forecast described in Gelman, Hullman, et al. (2020), we started with the poll-aggregation model of Linzer (2013) which we had adapted in 2016 but with a notable failure of predictions in certain swing states, which we attributed to poor modeling of correlations of vote swings between states, along with nonsampling errors in the polls (Gelman and Azari, 2017). In our revision we expanded the model to include both these features. Sections 10 and 11 give extended examples of iterative model building and evaluation. 7.1. Constructing a model for the data In textbook treatments of statistics, the distribution of data given parameters is typically just given. In applications, though, we want to set up a data model based on some combination of fit to the data (as found in posterior predictive checks) and domain expertise. If the model is being chosen from a small menu, we would like to at least be open about that. Often the most important aspect of the data model is not its distributional form but how the data are linked to underlying parameters of interest",
    "chunk_id": "Adv_cognitive_modelling_bayesian_workflow.json_chunk_60"
  },
  {
    "document_type": "research_paper",
    "title": "bayesian_workflow",
    "author": "",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\bayesian_workflow.pdf",
    "date_published": "2020-11-04",
    "keywords": "",
    "flag": "",
    "chunk_text": ". Often the most important aspect of the data model is not its distributional form but how the data are linked to underlying parameters of interest. For example, in election forecasting, our model for polls includes terms for nonsampling error for individual polls and for polling averages, following Shirani-Mehr et al. (2018). A related challenge arises because data are typically preprocessed before they come to us, so that any generative model is necessarily an approximation. This can arise in meta-analysis or in settings where some large set of predictors have been combined into one or two numerical summaries using a machine learning algorithm or another dimensionality reduction technique. As always, we need to be concerned about data quality, and the most important aspect of the data model can be bias rather than what would traditionally be considered measurement error. Understanding this affects Bayesian workflow in that it can make sense to expand a model to allow for systematic error; we give an example in Section 10.5. 7.2. Incorporating additional data It is sometimes said that the most important aspect of a statistical method is not what it does with the data, but what data are used. A key part of Bayesian workflow is expanding a model to make use of more data. This can be as simple as adding regression predictors—but when more parameters are added, it can be necessary to assume that not all of them can have a big effect in the model at the same time. One way to see this is to consider the addition of a parameter as a relaxation of a prior distribution that was previously concentrated at zero. For example, we expanded our election model to account for political polarization by adding interaction terms to the regression, allowing the coefficients for the national economic predictor to be lower in recent years. It sometimes happens that we have two forms of measurement of similar data, thus requiring a generative model for both data sources",
    "chunk_id": "Adv_cognitive_modelling_bayesian_workflow.json_chunk_61"
  },
  {
    "document_type": "research_paper",
    "title": "bayesian_workflow",
    "author": "",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\bayesian_workflow.pdf",
    "date_published": "2020-11-04",
    "keywords": "",
    "flag": "",
    "chunk_text": ". It sometimes happens that we have two forms of measurement of similar data, thus requiring a generative model for both data sources. Sometimes this creates technical challenges, as when we are combining direct measurements on a sample with population summary statistics, or integrating measurements of different quality (for example, Lin et al., 1999), or when information is available on partial margins of a table (Deming and Stephan, 1940). In Weber et al. (2018), we fit a pharmacological model with direct data for a set of patients taking one drug but only average data 38 for a set of patients that had received a competitor’s product. In order to avoid the computational cost of modeling as latent data the outcomes of all the averaged patients, we devised an analytic method to approximate the relevant integral so that we could include the averaged data in the likelihood function. 7.3. Working with prior distributions Traditionally in Bayesian statistics we speak of noninformative or fully informative priors, but neither of these generally exist: a uniform prior contains some information, as it depends on the parameterization of the model; a reference prior depends on an assumed asymptotic regime for collecting new, fictional data (Berger et al., 2009); and even an informative prior rarely includes all available knowledge. Rather, we prefer to think of a ladder of possibilities: (improper) flat prior; super-vague but proper prior; very weakly informative prior; generic weakly informative prior; specific informative prior. For example, our election model includes random walk terms to allow variation in opinion at the state and national level. Each of these random walks has a standard deviation parameter corresponding to the unexplained variation (on the logit scale) in one day",
    "chunk_id": "Adv_cognitive_modelling_bayesian_workflow.json_chunk_62"
  },
  {
    "document_type": "research_paper",
    "title": "bayesian_workflow",
    "author": "",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\bayesian_workflow.pdf",
    "date_published": "2020-11-04",
    "keywords": "",
    "flag": "",
    "chunk_text": ". Each of these random walks has a standard deviation parameter corresponding to the unexplained variation (on the logit scale) in one day. This innovation standard deviation could be given a uniform prior, a super-vague but proper prior (for example, normal + (0 , 1000) , where we are using the notation normal + to represent the normal distribution truncated to be positive), a weak prior (for example, normal + (0 , 1) on the percentage scale, which would allow unrealistically large day-to-day changes on the order of 0.25 percentage points in the probability of support for a candidate, but would still keep the distribution away from extreme parameter values), or a more informative prior such as normal + (0 , 0 . 1) which does not encapsulate all our prior knowledge but does softly constrain this parameter to within a reasonable range. Our point here is that in choosing a prior, one is also choosing the amount of subject-matter information to include in the analysis. Another way to view a prior distribution, or a statistical model more generally, is as a constraint . For example, if we fit a linear model plus a spline or Gaussian process, y = b 0 + b 1 x + g ( x )+ error, where the nonlinear function g has bounded variation, then with a strong enough prior on the g , we are fitting a curve that is close to linear. The prior distribution in this example could represent prior information, or it could just be considered as part of the model specification, if there is a desire to fit an approximately linear curve. Simpson et al. (2017) provide further discussion on using prior distributions to shrink towards simpler models. This also leads to the more general point that priors are just like any other part of a statistical model in which they can serve different purposes. Any clear distinction between model and prior is largely arbitrary and often depends mostly on the conceptual background of the one making the distinction",
    "chunk_id": "Adv_cognitive_modelling_bayesian_workflow.json_chunk_63"
  },
  {
    "document_type": "research_paper",
    "title": "bayesian_workflow",
    "author": "",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\bayesian_workflow.pdf",
    "date_published": "2020-11-04",
    "keywords": "",
    "flag": "",
    "chunk_text": ". Any clear distinction between model and prior is largely arbitrary and often depends mostly on the conceptual background of the one making the distinction. The amount of prior information needed to get reasonable inference depends strongly on the role of the parameter in the model as well as the depth of the parameter in the hierarchy (Goel and DeGroot, 1981). For instance, parameters that mainly control central quantities (such as the mean or the median) typically tolerate vague priors more than scale parameters, which again are more forgiving of vague priors than parameters that control tail quantities, such as the shape parameter of a generalized extreme value distribution. When a model has a hierarchical structure, parameters that are closer to the data are typically more willing to indulge vague priors than parameters further down the hierarchy. In Bayesian workflow, priors are needed for a sequence of models. Often as the model becomes more complex, all of the priors need to become tighter. The following simple example of multilevel 39 data (see, for example, Raudenbush and Bryk, 2002) shows why this can be necessary. Consider a workflow where the data are y ij , i = 1 , , n j , j = 1 , , J . Here i indexes the observation and j indexes the group. Imagine that for the first model in the workflow we elect to ignore the group structure and use a simple normal distribution for the deviation from the mean. In this case some of the information budget will be spent on estimating the overall mean and some of it is spent on the observation standard deviation. If we have a moderate amount of data, the mean will be approximately ̄ y = P n i =1 y i /n regardless of how weak the prior is. Furthermore, the predictive distribution for a new observation will be approximately normal ( ̄ y, s ) , where s is the sample standard deviation. Again, this will be true for most sensible priors on the observation standard deviation, regardless of how vague they are",
    "chunk_id": "Adv_cognitive_modelling_bayesian_workflow.json_chunk_64"
  },
  {
    "document_type": "research_paper",
    "title": "bayesian_workflow",
    "author": "",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\bayesian_workflow.pdf",
    "date_published": "2020-11-04",
    "keywords": "",
    "flag": "",
    "chunk_text": ". Again, this will be true for most sensible priors on the observation standard deviation, regardless of how vague they are. If the next step in the workflow is to allow the mean to vary by group using a multilevel model, then the information budget still needs to be divided between the standard deviation and the mean. However, the model now has J + 1 extra parameters (one for each group plus one for the standard deviation across groups) so the budget for the mean needs to be further divided to model the group means, whereas the budget for the standard deviation needs to be split between the within group variation and the between group variation. But we still have the same amount of data, so we need to be careful to ensure that this model expansion does not destabilize our estimates. This means that as well as putting appropriate priors on our new parameters, we probably need to tighten up the priors on the overall mean and observation standard deviation, lest a lack of information lead to nonsense estimates. A related issue is the concentration of measure in higher-dimensional space. For example in regression with an increasing number of predictors, the prior on the vector of coefficients needs to have higher density near the mode if we want to keep most of the prior mass near the mode (as the volume further away from the mode increases faster as dimension increases; see, for example, Piironen and Vehtari, 2017). Consider linear or logistic regression and what happens to the prior on R 2 if the marginal prior on weights is fixed. If we want the prior on R 2 to stay fixed, the prior on weights needs to get tighter. Figure 21 uses prior predictive checking (see Section 2.4) to show how the usual weak prior on 26 weights in linear regression corresponds to a prior strongly favoring higher R 2 values, affecting also the posterior. From that perspective, weakly informative but independent priors may jointly be strongly informative if they appear in large numbers",
    "chunk_id": "Adv_cognitive_modelling_bayesian_workflow.json_chunk_65"
  },
  {
    "document_type": "research_paper",
    "title": "bayesian_workflow",
    "author": "",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\bayesian_workflow.pdf",
    "date_published": "2020-11-04",
    "keywords": "",
    "flag": "",
    "chunk_text": ". From that perspective, weakly informative but independent priors may jointly be strongly informative if they appear in large numbers. Priors must be specified for each model within a workflow. An expanded model can require additional thought regarding parameterization. For example, when going from normal ( μ, σ ) to a t -distribution t ν ( μ, σ ) with ν degrees of freedom, we have to be careful with the prior on σ . The scale parameter σ looks the same for the two models, but the variance of the t distribution is actually ν ν − 2 σ 2 rather than σ 2 . Accordingly, if ν is small, σ is no longer close to the residual standard deviation. In general, we need to think in terms of the joint prior over all the parameters in a model, to be assessed in the context of the generative model for the data, lest unfortunate cancellations or resonances lead to less stabilizing or more informative priors than the modeler actually wants (Gelman et al., 2017, Kennedy et al., 2019). As discussed in Section 2.4, prior predictive checking is a good general approach to exploring and understanding a prior distribution in the context of a particular data model. The above examples carry particular messages about priors but also a meta-message about how we think about workflow when constructing statistical models. Phrases such as “the information budget still needs to be divided” represent important but somewhat informal decisions we make 40 Posterior Prior 0 0.25 0.5 0.75 1 0 0.25 0.5 0.75 1 Bayesian R^2 Posterior Prior 0 0.25 0.5 0.75 1 0 0.25 0.5 0.75 1 Bayesian R^2 Posterior Prior 0 0.25 0.5 0.75 1 0 0.25 0.5 0.75 1 Bayesian R^2 Figure 21: Prior and posterior distribution of Bayesian R 2 for the regression predicting student grades from 26 predictors, using three different priors for the coefficients: (a) default weak prior, (b) normal prior scaled with the number of predictors, and (c) regularized horseshoe prior. From Section 12.7 of Gelman, Hill, and Vehtari (2020). about how much effort we put in to include prior information",
    "chunk_id": "Adv_cognitive_modelling_bayesian_workflow.json_chunk_66"
  },
  {
    "document_type": "research_paper",
    "title": "bayesian_workflow",
    "author": "",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\bayesian_workflow.pdf",
    "date_published": "2020-11-04",
    "keywords": "",
    "flag": "",
    "chunk_text": ". From Section 12.7 of Gelman, Hill, and Vehtari (2020). about how much effort we put in to include prior information. Such concerns are not always clear in articles or textbooks that present the final model as is, without acknowledging the tradeoffs and choices that have been made. 7.4. A topology of models Consider a class of models, for simplicity in some particular restricted domain such as autoregressive moving average (ARMA) models, binary classification trees, or linear regressions with some fixed set of input variables. The models in any of these frameworks can be structured as a partial ordering: for example, AR(1) is simpler than AR(2) which is simpler than ARMA(2,1), and MA(1) is also simpler than ARMA(2,1), but AR(1) and MA(1) are not themselves ordered. Similarly, tree splits form a partial ordering, and the 2 k possibilities of inclusion or exclusion in linear regression can be structured as the corners of a cube. As these examples illustrate, each of these model frameworks has its own topology or network structure as determined by the models in the class and their partial ordering. We speak of this as a topology of models rather than a probability space because we are not necessarily interested in assigning probabilities to the individual models. Our interest here is not in averaging over models but in navigating among them, and the topology refers to the connections between models and between parameters in neighboring models in the network. An example implementation of this idea is the Automatic Statistician (Hwang et al., 2016, Gharamani et al., 2019), which searches through models in specified but open-ended classes (for example, time series models and linear regression models), using inference and model criticism to explore the model and data space. We believe such algorithms can be better understood and, ultimately, improved, through a more formal understanding of the topology of models induced by a statistical modeling language",
    "chunk_id": "Adv_cognitive_modelling_bayesian_workflow.json_chunk_67"
  },
  {
    "document_type": "research_paper",
    "title": "bayesian_workflow",
    "author": "",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\bayesian_workflow.pdf",
    "date_published": "2020-11-04",
    "keywords": "",
    "flag": "",
    "chunk_text": ". We believe such algorithms can be better understood and, ultimately, improved, through a more formal understanding of the topology of models induced by a statistical modeling language. From another direction are menu-based packages such as Prophet (Taylor and Lethem, 2018) that allow users to put together models (in this case, for time series forecasting) from some set of building blocks. It is important in such packages not just to be able to build and fit these models but to understand each model in comparison to simpler or more complicated variants fit to the same data. 41 However, unlike combining variables, where in many cases a simple and often automated additive model is enough, here each model itself is a high dimensional object. The outputs from different models, as probabilistic random variables, can be added, multiplied, linearly mixed, lolinearly-mixed, pointwisely-mixed, etc, which is within the choice of model topology we need to specify. In addition, each model within a framework has its own internal structure involving parameters that can be estimated from data. And, importantly, the parameters within different models in the network can “talk with each other” in the sense of having a shared, observable meaning outside the confines of the model itself. In machine learning and applied statistics, two familiar examples with inferential quantities that are shared across models are forecasting and causal inference. In forecasting, an increasingly complicated set of procedures can be used for a particular predictive goal. And in causal inference, a treatment effect can be estimated using a series of regressions, starting from a simple difference and moving to elaborate interaction models adjusting for diffeences between observed treated and control groups. Recall that causal inferences are a special case of predictions involving counterfactuals; see, for example, Morgan and Winship (2014)",
    "chunk_id": "Adv_cognitive_modelling_bayesian_workflow.json_chunk_68"
  },
  {
    "document_type": "research_paper",
    "title": "bayesian_workflow",
    "author": "",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\bayesian_workflow.pdf",
    "date_published": "2020-11-04",
    "keywords": "",
    "flag": "",
    "chunk_text": ". Recall that causal inferences are a special case of predictions involving counterfactuals; see, for example, Morgan and Winship (2014). Thus, the topology of statistical or machine-learning models includes a partial ordering of models, and connections between parameters or functions of parameters and data across different models within the larger framework. Another twist is that prior distributions add a continuous dimension to the structure, bridging between models. 8. Understanding and comparing multiple models 8.1. Visualizing models in relation to each other The key aspect of Bayesian workflow, which takes it beyond Bayesian data analysis, is that we are fitting many models while working on a single problem. We are not talking here about model selection or model averaging but rather of the use of a series of fitted models to better understand each one. In the words of Wickham, Cook, and Hofmann (2015), we seek to “explore the process of model fitting, not just the end result.” We fit multiple models for several reasons, including: • It can be hard to fit and understand a big model, so we will build up to it from simple models. • When building our models, we make a lot of mistakes: typos, coding errors, conceptual errors (for example not realizing that the observations don’t contain useful information for some parts of the model), etc. • As we get more data, we typically expand our models accordingly. For example, if we’re doing pharmacology and we get data on a new group of patients, we might let certain parameters vary by group. • Often we fit a model that is mathematically well specified, but once we fit it to data we realize that there’s more we can do, so we expand it. • Relatedly, when we first fit a model, we often put it together with various placeholders. We’re often starting with weak priors and making them stronger, or starting with strong priors and relaxing them",
    "chunk_id": "Adv_cognitive_modelling_bayesian_workflow.json_chunk_69"
  },
  {
    "document_type": "research_paper",
    "title": "bayesian_workflow",
    "author": "",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\bayesian_workflow.pdf",
    "date_published": "2020-11-04",
    "keywords": "",
    "flag": "",
    "chunk_text": ". We’re often starting with weak priors and making them stronger, or starting with strong priors and relaxing them. 42 −2 −1 0 1 2 Complexity of model Inference for quantity of interest simpler more complex Figure 22: Hypothetical graph comparing inferences for a quantity of interest across multiple models. The goal here is not to perform model selection or model averaging but to understand how inference for a quantity of interest changes as we move from a simple comparison (on the left side of the graph) through the final model (on the right side of the graph), going through various intermediate alternatives. • We’ll check a model, find problems, and then expand or replace it. This is part of “Bayesian data analysis”; the extra “workflow” part is that we still keep the old model, not for the purpose of averaging but for the purpose of understanding what we are doing. • Sometimes we fit simple models as comparisons. For example, if you’re doing a big regression for causal inference, you’ll also want to do a simple unadjusted comparison and then see what the adjustments have done. • The above ideas are listed as being motivated by statistical considerations, but sometimes we’re jolted into action because of computational problems. Given that we are fitting multiple models, we also have to be concerned with researcher degrees of freedom (Simmons et al., 2011), most directly from overfitting if a single best model is picked, or more subtly that if we are not careful, we can consider our inferences from a set of fitted models to bracket some total uncertainty, without recognizing that there are other models we could have fit. This concern arises in our election forecasting model, where ultimately we only have a handful of past presidential elections with which to calibrate our predictions",
    "chunk_id": "Adv_cognitive_modelling_bayesian_workflow.json_chunk_70"
  },
  {
    "document_type": "research_paper",
    "title": "bayesian_workflow",
    "author": "",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\bayesian_workflow.pdf",
    "date_published": "2020-11-04",
    "keywords": "",
    "flag": "",
    "chunk_text": ". This concern arises in our election forecasting model, where ultimately we only have a handful of past presidential elections with which to calibrate our predictions. Figure 22 illustrates the basic idea: the diagram could represent, for example, a causal effect estimated with a sequence of increasingly complicated models, starting with a simple treatmencontrol comparison and proceeding through a series of adjustments. Even if the ultimate interest is only in the final model, it can be useful to understand how the inference changes as adjustments are added. Following the proposed workflow and exploring the topology of models can often lead us to multiple models that pass all the checks. Instead of selecting just one model, we can perform a multiverse analysis and use all of the models and see how the conclusions change across the models 43 Freq. frequentist all frequentist cLOF REN: BBS10 more frequent than BBS1 REN: BBS2 more frequent than BBS1 REN: BBS2,7,9 more frequent than BBS1,4,8 REN: BBSome genes differ CI: BBS7 more frequent than others CI: BBSome more frequent than BBS3 PD: BBS10 more frequent than BBS1 PD: BBS2 more frequent than BBS1 BBSome genes differ BBS4 most #phenotypes BBS4 top odds BBS3 less severe than Chaperonins BBS3 less severe than BBSome cLOF mutations more severe Freq. type Conclusion Main Secondary Problematic fits source source + cLOF source + filtered cLOF source + gene corr. source + no corr",
    "chunk_id": "Adv_cognitive_modelling_bayesian_workflow.json_chunk_71"
  },
  {
    "document_type": "research_paper",
    "title": "bayesian_workflow",
    "author": "",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\bayesian_workflow.pdf",
    "date_published": "2020-11-04",
    "keywords": "",
    "flag": "",
    "chunk_text": ". type Conclusion Main Secondary Problematic fits source source + cLOF source + filtered cLOF source + gene corr. source + no corr. source + narrow source + wide source + cLOF + ethnic group source + cLOF + wide source + cLOF (by gene) source + family source + cLOF + family source + filtered sex source + filtered age source + filtered cLOF + wide source + imputed sex source + imputed age source + imputed age + sex source + very narrow none ethnic group ethnicity cLOF cLOF (by gene) ethnic group + cLOF ethnicity + cLOF ethnic group + cLOF (by gene) ethnicity + cLOF (by gene) family filtered age + sex none + filtered cLOF cLOF + filtered age + sex cLOF (by gene) + filtered age + sex family + filtered age + sex + cLOF imputed age + sex Model components/modifications besides gene 0.05 1e−4 1e−8 p−value 0.01 0.10 0.50 0.90 0.99 Posterior prob. ND Figure 23: The results of a multiverse analysis from the supplementary material of Niederlová et al. (2019). The heat map shows statistical evaluation of selected conclusions about the relation between phenotypes (PD, CI, REN, HEART, LIV) and mutations in various genes of the BBSome (BBS01 - BBS8, cLOF - complete loss of function) using a set of Bayesian hierarchical logistic regression models and pairwise frequentist tests. Based on posterior predictive checks the Bayesian models were categorized as “Main” (passing all checks), “Secondary” (minor problems in some checks), and “Problematic fits,” though we see that most conclusions hold across all possible models. The models differ in both predictors that are included and priors (default/wide/narrow/very narrow). (Steegen et al., 2016, Dragicevic et al., 2019, Kale, Kay, and Hullman, 2019). Using multiverse analysis can also relieve some of the effort in validating models and priors: if the conclusions do not change it is less important to decide which model is “best.” Figure 23 shows an example of a possible output",
    "chunk_id": "Adv_cognitive_modelling_bayesian_workflow.json_chunk_72"
  },
  {
    "document_type": "research_paper",
    "title": "bayesian_workflow",
    "author": "",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\bayesian_workflow.pdf",
    "date_published": "2020-11-04",
    "keywords": "",
    "flag": "",
    "chunk_text": ". Other analytical choices (data preprocessing, response distribution, metric to evaluate, and so forth) can also be subject to multiverse analysis. 8.2. Cross validation and model averaging We can use cross validation to compare models fit to the same data (Vehtari et al., 2017). When performing model comparison, if there is non-negligible uncertainty in the comparison (Sivula et al., 2020), we should not simply choose the single model with the best cross validation results, as this would discard all the uncertainty from the cross validation process. Instead, we can maintain this information and use stacking to combine inferences using a weighting that is set up to minimize cross validation error (Yao et al., 2018b). We think that stacking makes more sense than traditional Bayesian model averaging, as the latter can depend strongly on aspects of the model that have minimal effect on predictions. For example, for a model that is well informed by the data and whose parameters are on unit scale, changing the prior on parameters from normal (0 , 10) to normal (0 , 100) will divide the marginal likelihood by roughly 10 k (for a model with k parameters) 44 while keeping all predictions essentially the same. In addition, stacking takes into account the joint predictions and works well when there are a large number of similar but weak models in the candidate model list. In concept, stacking can sometimes be viewed as pointwise model selection. When there are two models and the first model outperforms the second model 20% of the time, the stacking weights will be close to (0 . 2 , 0 . 8) . In light of this, stacking fills a gap between independent-error oriented machine learning validation and the grouped structure of modern big data. Model stacking is therefore also an indicator of heterogeneity of model fitting, and this suggests we can further improve the aggregated model with a hierarchical model, so that the stacking is a step toward model improvement rather than an end to itself",
    "chunk_id": "Adv_cognitive_modelling_bayesian_workflow.json_chunk_73"
  },
  {
    "document_type": "research_paper",
    "title": "bayesian_workflow",
    "author": "",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\bayesian_workflow.pdf",
    "date_published": "2020-11-04",
    "keywords": "",
    "flag": "",
    "chunk_text": ". In the extreme, model averaging can also be done so that different models can apply to different data points (Kamary et al., 2019, Pirš and Štrumbelj, 2019). In Bayesian workflow, we will fit many models that we will not be interested in including in any average; such “scaffolds” include models that are deliberately overly simple (included just for comparison to the models of interest) and models constructed for purely experimental purposes, as well as models that have major flaws or even coding errors. But even after these mistakes or deliberate oversimplifications have been removed, there might be several models over which to average when making predictions. In our own applied work we have not generally had many occasions to perform this sort of model averaging, as we prefer continuous model expansion, but there will be settings where users will reasonably want to make predictions averaging over competing Bayesian models, as in Montgomery and Nyhan (2010). 8.3. Comparing a large number of models There are many problems, for example in linear regression with several potentially relevant preditors, where many candidate models are available, all of which can be described as special cases of a single expanded model. If the number of candidate models is large, we are often interested in fining a comparably smaller model that has the same predictive performance as our expanded model. This leads to the problem of predictor (variable) selection. If we have many models making similar predictions, selecting one of these models based on minimizing cross validation error would lead to overfitting and suboptimal model choices (Piironen and Vehtari, 2017). In contrast, projection predictive variable selection has been shown to be stable and reliable in finding smaller models with good predictive performance (Piironen and Vehtari, 2017, Piironen et al., 2020, Pavone et al., 2020)",
    "chunk_id": "Adv_cognitive_modelling_bayesian_workflow.json_chunk_74"
  },
  {
    "document_type": "research_paper",
    "title": "bayesian_workflow",
    "author": "",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\bayesian_workflow.pdf",
    "date_published": "2020-11-04",
    "keywords": "",
    "flag": "",
    "chunk_text": ". While searching through a big model space is usually associated with the danger of overfitting, the projection predictive approach avoids it by examining only the projected submodels based on the expanded model’s predictions and not fitting each model independently to the data. In addition to variable selection, projection predictive model selection can be used for structure selection in generalized additive multilevel models (Catalina et al., 2020) and for creating simpler explanations for complex nonparametric models (Afrabandpey et al., 2020). 9. Modeling as software development Developing a statistical model in a probabilistic programming language means writing code and is thus a form of software development, with several stages: writing and debugging the model itself; the preprocessing necessary to get the data into suitable form to be modeled; and the later steps of 45 understanding, communicating, and using the resulting inferences. Developing software is hard. So many things can go wrong because there are so many moving parts that need to be carefully synchronized. Software development practices are designed to mitigate the problems caused by the inherent complexity of writing computer programs. Unfortunately, many methodologies veer offinto dogma, bean counting, or both. A couple references we can recommend that provide solid, practical advice for developers are Hunt and Thomas (1999) and McConnell (2004). 9.1. Version control smooths collaborations with others and with your past self Version control software, such as Git, should be should be the first piece of infrastructure put in place for a project. It may seem like a big investment to learn version control, but it’s well worth it to be able to type a single command to revert to a previously working version or to get the difference between the current version and an old version. It’s even better when you need to share work with others, even on a paper—work can be done independently and then automatically merged",
    "chunk_id": "Adv_cognitive_modelling_bayesian_workflow.json_chunk_75"
  },
  {
    "document_type": "research_paper",
    "title": "bayesian_workflow",
    "author": "",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\bayesian_workflow.pdf",
    "date_published": "2020-11-04",
    "keywords": "",
    "flag": "",
    "chunk_text": ". It’s even better when you need to share work with others, even on a paper—work can be done independently and then automatically merged. While version control keeps track of smaller changes in one model, it is useful to keep the clearly different models in different files to allow easy comparison of the models. Version control also helps to keep notes on the findings and decisions in the iterative model building, increasing transparency of the process. Version control is not just for code. It is also for reports, graphs, and data. Version control is a critical part of ensuring that all of these components are synchronized and, more importantly, that it is possible to rewind the project to a previous state. Version control is particularly useful for its ability to package up and label “release candidate” versions of models and data that correspond to milestone reports and publications and to store them in the same directory without resorting to the dreaded _final_final_161020.pdf -style naming conventions. When working on models that are used to guide policy decision making, a public version control repository increases transparency about what model, data, inference parameters, and scripts were used for specific reports. An excellent example of this is the Imperial College repository for models and scripts to estimate deaths and cases for COVID-19 (Flaxman et al., 2020). 9.2. Testing as you go Software design ideally proceeds top down from the goals of the end user back to the technical machinery required to implement it. For a Bayesian statistical model, top-down design involves at least the data input format, the probabilistic model for the data, and the prior, but may also involve simulators and model testing like simulation-based calibration or posterior predictive checks. Software development ideally works bottom up from well-tested foundational functions to larger functional modules. That way, development proceeds through a series of well-tested steps, at each stage building only on tested pieces",
    "chunk_id": "Adv_cognitive_modelling_bayesian_workflow.json_chunk_76"
  },
  {
    "document_type": "research_paper",
    "title": "bayesian_workflow",
    "author": "",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\bayesian_workflow.pdf",
    "date_published": "2020-11-04",
    "keywords": "",
    "flag": "",
    "chunk_text": ". That way, development proceeds through a series of well-tested steps, at each stage building only on tested pieces. The advantage to working this way as opposed to building a large program and then debugging it is the same as for incremental model development—it’s easier to track where the development went wrong and you have more confidence at each step working with well-tested foundations. The key to computational development, either in initial development or modifying code, is modularity. Big tangled functions are hard to document, harder to read, extraordinarily difficult to debug, and nearly impossible to maintain or modify. Modularity means building larger pieces 46 out of smaller trusted pieces, such as low-level functions. Whenever code fragments are repeated, they should be encapsulated as functions. This results in code that is easier to read and easier to maintain. As an example of a low-level function, predictors might be rescaled for a generalized linear model by implementing the standardization, z ( v ) = ( v − mean ( v )) / sd ( v ) . Although this function se ems simple, subtleties aris e, starting with the sd function , which is sometimes defined as sd ( v ) = p P n i =1 ( v i − mean ( v )) 2 /n and sometimes as sd ( v ) = p P n i =1 ( v i − mean ( v )) 2 / ( n − 1) . If this isn’t sorted out at the level of the standardization function, it can produce mysterious biases during inference. Simple tests that don’t rely on the sd () function will sort this out during function development. If the choice is the estimate that divides by n − 1 , there needs to be decision of what to do when v is a vector of length 1 . In cases where there are illegal inputs, it helps to put checks in the input-output routines that let users know when the problem arises rather than allowing errors to percolate through to mysterious divide-by-zero errors later. An implementation of cubic splines or an Euler solver for a differential equation is an example of a higher-level function that should be tested before it is used",
    "chunk_id": "Adv_cognitive_modelling_bayesian_workflow.json_chunk_77"
  },
  {
    "document_type": "research_paper",
    "title": "bayesian_workflow",
    "author": "",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\bayesian_workflow.pdf",
    "date_published": "2020-11-04",
    "keywords": "",
    "flag": "",
    "chunk_text": ". An implementation of cubic splines or an Euler solver for a differential equation is an example of a higher-level function that should be tested before it is used. As functions get more complicated, they become harder to test because of issues with boundary-condition combinatorics, more general inputs such as functions to integrate, numerical instability or imprecision over regions of their domain which may or may not be acceptable depending on the application, the need for stable derivatives, etc. 9.3. Making it essentially reproducible A lofty goal for any project is to make it fully reproducible in the sense that another person on another machine could recreate the final report. This is not the type of reproducibility that is considered in scientific fields, where the desire is to ensure that an effect is confirmed by new future data (nowadays often called “replicability” for a better distinction between the different notions). Instead this is the more limited (but still vital) goal of ensuring that one particular analysis is consistently done. In particular, we would want to be able to produce analyses and figures that are essentially equivalent to the original document. Bit-level reproducibility may not be possible, but we would still liken equivalence at a practical level. In the event that this type of reproduction changes the outcome of a paper, we would argue that the original results were not particularly robust. Rather than entering commands on the command line when running models (or entering commands directly into an interactive programming language like R or Python), write scripts to run the data through the models and produce whatever posterior analysis you need. Scripts can be written for the shell, R, Python, or any other programming language. The script should be self-contained in the sense that it should run in a completely clean environment or, ideally, on a different computer",
    "chunk_id": "Adv_cognitive_modelling_bayesian_workflow.json_chunk_78"
  },
  {
    "document_type": "research_paper",
    "title": "bayesian_workflow",
    "author": "",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\bayesian_workflow.pdf",
    "date_published": "2020-11-04",
    "keywords": "",
    "flag": "",
    "chunk_text": ". The script should be self-contained in the sense that it should run in a completely clean environment or, ideally, on a different computer. This means that the script(s) must not depend on global variables having been set, other data being read in, or anything else that is not in the script. Scripts are good documentation. It may seem like overkill if running the project is only a single line of code, but the script provides not only a way to run the code, but also a form of concrete documentation for what is being run. For complex projects, we often find that a well-constructed series of scripts can be more practical than one large R Markdown document or Jupyter notebook. Depending on long-term reproducibility needs, it’s important to choose the right tooling for the job at hand. To guarantee bit-level reproducibility, and sometimes even just to get a program to 47 run, everything from hardware, to the operating system, to every piece of software and setting must be specified with their version number. As time passes between the initial writing of the script and the attempt of reproduction, bit-level reproducibility can be almost impossible to achieve even if the environment is shipped with the script, as in a Docker container. 9.4. Making it readable and maintainable Treating programs and scripts like other forms of writing for an audience provides an important perspective on how the code will be used. Not only might others want to read and understand a program or model, the developers themselves will want to read and understand it later. One of the motivations of Stan’s design was to make models self-documenting in terms of variable usage (e.g., data or parameters), types (e.g., covariance matrix or unconstrained matrix) and sizes. This allows us to understand Stan code (or code of other statically typed probabilistic programming languages) to be understandable without the context of the data it is applied on",
    "chunk_id": "Adv_cognitive_modelling_bayesian_workflow.json_chunk_79"
  },
  {
    "document_type": "research_paper",
    "title": "bayesian_workflow",
    "author": "",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\bayesian_workflow.pdf",
    "date_published": "2020-11-04",
    "keywords": "",
    "flag": "",
    "chunk_text": ". This allows us to understand Stan code (or code of other statically typed probabilistic programming languages) to be understandable without the context of the data it is applied on. A large part of readability is consistency, particularly in naming and layout, and not only of programs themselves, but the directories and files in which they are stored. Another key principle in coding is to avoid repetition, instead pulling shared code out into functions that can be reused. Readability of code is not just about comments—it is also about naming and organization for readability. Indeed, comments can made code less readable. The best approach is to write readable code, not opaque code with comments. For example, we don’t want to write this: real x17; // oxygen level, should be positive when we can write this: real<lower = 0> oxygen_level; Similarly, we don’t want to do this: target += -0.5 * (y - mu)^2 / sigma^2; // y distributed normal(mu, sigma) when we can write, target += normal_lpdf(y | mu, sigma); Good practice is to minimize inline code comments and instead write readable code. As the above examples illustrate, clean code is facilitated by programming languages that gives users the tools they need to use. User-facing functions should be documented at the function level in terms of their argument types, return types, error conditions, and behavior—that’s the application programming interface (API) that users see instead of code internals. The problem with inline code comments aimed at developers is that they quickly go stale during development and wind up doing more harm than good. Instead, rather than documenting the actual code inline, functions should be reduced to manageable size and names should be chosen so that the code is readable. Longer variable names are not always better, as they can make the structure of the code harder to scan",
    "chunk_id": "Adv_cognitive_modelling_bayesian_workflow.json_chunk_80"
  },
  {
    "document_type": "research_paper",
    "title": "bayesian_workflow",
    "author": "",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\bayesian_workflow.pdf",
    "date_published": "2020-11-04",
    "keywords": "",
    "flag": "",
    "chunk_text": ". Longer variable names are not always better, as they can make the structure of the code harder to scan. Code documentation should be written assuming the reader understands the programming language well; as such, documentation is only called for when the code strays from idiomatic usage of the language or involves complex 48 Figure 24: Success rate of putts of professional golfers, from a small dataset appearing in Berry (1995). The error bars asso ciated with each point j in the graph are simple classical standard deviations, p ˆ p j (1 − ˆ p j ) /n j , where ˆ p j = y j /n j is the success rate for putts taken at distance x j . algorithms that need external documentation. When tempted to comment a long expression or block of code, instead consider replacing it with a well-named function. Related to readability is the maintainability of the workflow code. When fitting a series of similar models, a lot of modules will be shared between them (see Section 2.2) and so will be the corresponding code. If we had just copied all of the model code each time we wrote a new model, and then discovered an error in one of the shared modules, we would have to fix it in all models manually. This is again an error-prone process. Instead, it can be sensible not only to build models in a modular manner but also keep the corresponding code modular and load it into the models as needed. That way, fixing an error in a module requires changing code in just one rather than many places. Errors and other requirements for later changes will inevitably occur as we move through the workflow and it will save us a lot of time if we prepare our modeling code accordingly. 10. Example of workflow involving model building and expansion: Golf putting We demonstrate the basic workflow of Bayesian modeling using an example of a set of models fit to data on golf putting (Gelman, 2019). Figure 24 shows data from professional golfers on the proportion of successful putts as a function of (rounded) distance from the hole",
    "chunk_id": "Adv_cognitive_modelling_bayesian_workflow.json_chunk_81"
  },
  {
    "document_type": "research_paper",
    "title": "bayesian_workflow",
    "author": "",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\bayesian_workflow.pdf",
    "date_published": "2020-11-04",
    "keywords": "",
    "flag": "",
    "chunk_text": ". Figure 24 shows data from professional golfers on the proportion of successful putts as a function of (rounded) distance from the hole. Unsurprisingly, the probability of making the shot declines as a function of distance. 49 Figure 25: Golf data from Figure 24 along with fitted logistic regression and draws of the fitted curve, y = logit − 1 ( a + bx j ) , given posterior draws of ( a, b ) . Figure 26: Simple geometric model of golf putting, showing the range of angles with which the ball can be hit and still have a trajectory that goes entirely into the hole. Not to scale. 10.1. First model: logistic regression Can we model the probability of success in golf putting as a function of distance from the hole? Given usual statistical practice, the natural starting point would be logistic regression: y j ∼ binomial n j , logit − 1 ( a + bx j ) , for j = 1 , , J. Figure 25 shows the logistic fitted regression along with draws form the posterior distribution. Here we fit using a uniform prior on ( a, b ) which causes no problems given the large sample size. 10.2. Modeling from first principles We next fit the data using a simple mathematical model of the golf putting process. Figure 26 shows a simplified sketch of a golf shot. The dotted line represents the angle within which the ball of radius r must be hit so that it falls within the hole of radius R . This threshold angle is sin − 1 (( R − r ) /x ) . The graph is intended to illustrate the geometry of the ball needing to go into the hole. 50 Figure 27: Two models fit to the golf data. The geometry-based model fits much better than the logistic regression even while using one fewer parameter. The next step is to model human error. We assume that the golfer is attempting to hit the ball completely straight but that many small factors interfere with this goal, so that the actual angle follows a normal distribution centered at 0 with some standard deviation σ",
    "chunk_id": "Adv_cognitive_modelling_bayesian_workflow.json_chunk_82"
  },
  {
    "document_type": "research_paper",
    "title": "bayesian_workflow",
    "author": "",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\bayesian_workflow.pdf",
    "date_published": "2020-11-04",
    "keywords": "",
    "flag": "",
    "chunk_text": ". The probability the ball goes in the hole is then the probability that the angle is less than the threshold; that is, Pr ( | angle | < sin − 1 (( R − r ) /x )) = 2Φ sin − 1 (( R − r ) /x ) σ − 1 , where Φ is the cumulative normal distribution function. The only unknown parameter in this model is σ , the standard deviation of the distribution of shot angles. Fitting this model to the above data with a flat prior on σ yields a posterior estimate ˆ σ = 1 . 53 ◦ with standard error 0.02. Figure 27 shows the fitted model, along with the logistic regression fit earlier. The custom nonlinear model fits the data much better. This is not to say that the model is perfect—any experience of golf will reveal that the angle is not the only factor determining whether the ball goes in the hole—but it seems like a useful start, and it demonstrates the advantages of building up a model directly rather than simply working with a conventional form. 10.3. Testing the fitted model on new data Several years after fitting the above model, we were presented with a newer and more comprehensive dataset on professional golf putting (Broadie, 2018). For simplicity we just look here at the summary data, probabilities of the ball going into the hole for shots up to 75 feet from the hole. Figure 28 these new data, along with our earlier dataset and the already-fit geometry-based model from before, extending to the range of the new data. Comparing the two datasets in the range 0–20 feet, the success rate is similar for longer putts but is much higher than before for the short putts. This could be a measurement issue, if the distances 51 Figure 28: Checking the already-fit model to new golf putting data. At equivalent distances, the success rate is higher for the new data, which may represent improvement over time or just a difference in the datasets. In addition, the new data show a systematic model failure at higher distances, motivating a model improvement",
    "chunk_id": "Adv_cognitive_modelling_bayesian_workflow.json_chunk_83"
  },
  {
    "document_type": "research_paper",
    "title": "bayesian_workflow",
    "author": "",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\bayesian_workflow.pdf",
    "date_published": "2020-11-04",
    "keywords": "",
    "flag": "",
    "chunk_text": ". In addition, the new data show a systematic model failure at higher distances, motivating a model improvement. to the hole are only approximate for the old data, and it could also be that golfers are better than they used to be. Beyond 20 feet, the empirical success rates become lower than would be predicted by the old model. These are much more difficult attempts, even after accounting for the increased angular precision required as distance goes up. In addition, the new data look smoother, which perhaps is a reflection of more comprehensive data collection. 10.4. A new model accounting for how hard the ball is hit To get the ball in the hole, the angle is not the only thing you need to control; you also need to hit the ball just hard enough. Broadie (2018) added this to the geometric model by introducing another parameter corrsponding to the golfer’s control over distance. Supposing u is the distance that golfer’s shot would travel if there were no hole, Broadie assumes that the putt will go in if (a) the angle allows the ball to go over the hole, and (b) u is in the range [ x, x + 3] . That is the ball must be hit hard enough to reach the whole but not go too far. Factor (a) is what we have considered earlier; we must now add factor (b). Figure 29 illustrates the need for the distance as well as the angle of the shot to be in some range, in this case the gray zone which represents the trajectories for which the ball would reach the hole and stay in it. Broadie supposes that a golfer will aim to hit the ball one foot past the hole but with a multiplicative error in the shot’s potential distance, so that u = ( x + 1) · (1 + ε ) , where the error ε has a normal distribution with mean 0 and standard deviation σ distance . In statistics notation, this 52 Figure 29: Geometric model of golf putting, also including the constraint that the ball must be hit hard enough to reach the hole but not so hard that it hops over. Not to scale",
    "chunk_id": "Adv_cognitive_modelling_bayesian_workflow.json_chunk_84"
  },
  {
    "document_type": "research_paper",
    "title": "bayesian_workflow",
    "author": "",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\bayesian_workflow.pdf",
    "date_published": "2020-11-04",
    "keywords": "",
    "flag": "",
    "chunk_text": ". Not to scale. model is, u ∼ normal ( x +1 , ( x +1) σ distance ) , and the distance is acceptable if u ∈ [ x, x +3] , an event that has probability Φ 2 ( x +1) σ distance − Φ − 1 ( x +1) σ distance . Putting these together, the probability a shot goes in becomes, 2Φ sin − 1 (( R − r ) /x ) σ angle − 1 Φ 2 ( x +1) σ distance − Φ − 1 ( x +1) σ distance , where we have renamed the parameter σ from our earlier model to σ angle to distinguish it from the new σ distance parameter. The result is a model with two parameters, σ angle and σ distance . Even this improved geometrbased model is a gross oversimplification of putting, and the average distances in the binned data are not the exact distances for each shot. But it should be an advance on the earlier one-parameter model; the next step is to see how it fits the data. We first try to fit this model with flat priors, but the result is computationally unstable, so we assign weakly informative half-normal (0 , 1) priors. Even after this, we have poor convergence. Running 4 chains, each with 2000 iterations, yields high values of b R , indicating poor mixing and making us concerned about the model, following the folk theorem (see Section 5.1). In this case, rather than examining traceplots and otherwise studying the pathologies of the Markov chain simulation, we just directly to examine the fit of the model, as estimated using the crude estimates of the parameters obtained by averaging the simulations over the poorly-mixing chains. Figure 30a shows the result. The overall fit is not terrible, but there are problems in the middle of the curve, and after some thought we realized that the model is struggling because the binomial likelihood is constraining it too strongly at the upper left part of the curve where the counts are higher. Look at how closely the fitted curve hugs the data at the very lowest values of x . Figure 30b displays the data, which was given to us in binned form, for putts from the shortest distances",
    "chunk_id": "Adv_cognitive_modelling_bayesian_workflow.json_chunk_85"
  },
  {
    "document_type": "research_paper",
    "title": "bayesian_workflow",
    "author": "",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\bayesian_workflow.pdf",
    "date_published": "2020-11-04",
    "keywords": "",
    "flag": "",
    "chunk_text": ". Look at how closely the fitted curve hugs the data at the very lowest values of x . Figure 30b displays the data, which was given to us in binned form, for putts from the shortest distances. Because of the vary large sample sizes, the binomial model tries very hard to fit these probabilities as exactly as possible. The likelihood function gives by far its biggest weight to these first few data points. If we were sure the model was correct, this would be the right thing to do, but given inevitable model error, the result is a problematic fit to the entire curve. In addition, the poor MCMC convergence is understandable: there are no parameter values that fit all the data, and it is difficult for the chains to move smoothly between values that fit the bulk of the data and those that fit the first few data points. 10.5. Expanding the model by including a fudge factor As the data are binned, the individual putt distances have been rounded to the bin center values, which has the biggest effect in very short distances. We could incorporate a rounding error model 53 x n y 0.28 45198 45183 0.97 183020 182899 1.93 169503 168594 2.92 113094 108953 3.93 73855 64740 Figure 30: Working to understand the poor convergence of the expanded golf putting model that had showed poor convergence. (a) A graph of data and fitted model reveals problems with the fit near the middle of the curve, and we realized that the poor behavior of the Markov simulation arose from the model trying too hard to fit the data at the upper left of the curve. (b) Data for putts from the shortest distances, with x being the average distance for the putts in each bin (presumably 0–0.5 feet, 0.5–1.5 feet, 1.5–2.5, etc.). Sample sizes are very large in the initial bins, hence the binomial model tries to fit these points nearly exactly. for the putting distances, but we opt for a simpler error model",
    "chunk_id": "Adv_cognitive_modelling_bayesian_workflow.json_chunk_86"
  },
  {
    "document_type": "research_paper",
    "title": "bayesian_workflow",
    "author": "",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\bayesian_workflow.pdf",
    "date_published": "2020-11-04",
    "keywords": "",
    "flag": "",
    "chunk_text": ". Sample sizes are very large in the initial bins, hence the binomial model tries to fit these points nearly exactly. for the putting distances, but we opt for a simpler error model. To allow for a model that can fit reasonably well to all the data without being required to have a hyper-precise fit to the data at the shortest distances, we took the data model, y j ∼ binomial ( n j , p j ) , and added an independent error term to each observation. There is no easy way to add error directly to the binomial distribution— we could replace it with its overdispersed generalization, the beta-binomial, but this would not be appropriate here because the variance for each data point j would still be roughly proportional to the sample size n j , and our whole point here is to get away from that assumption and allow for model misspecification—so instead we first approximate the binomial data distribution by a normal and then add independent variance; thus: y j /n j ∼ normal p j , q p j (1 − p j ) /n j + σ 2 y . This model has its own problems and would fall apart if the counts in any cell were small enough, but it is transparent and easy to set up and code, and so we try it out, with the understanding that we can clean it up later on if necessary. After assigning independent half-normal (0 , 1) priors to all three parameters of this new model, it fits with no problem in Stan, yielding the posterior mean estimates σ angle = 1 . 02 ◦ , σ distance = 0 . 08 (implying that shots can be hit to an uncertainty of about 8% in distance), and σ y = 0 . 003 (implying that the geometric model sketched in figure 29 fits the aggregate success rate as a function of distance to an accuracy of 0.3 percentage points). 54 Figure 31: (a) With the additional error term added, the model sketched in Figure 29 provides an excellent fit to the expanded golf putting data. (b) The residuals from the fitted model are small and show no pattern, thus we see no obvious directions of improvement at this point",
    "chunk_id": "Adv_cognitive_modelling_bayesian_workflow.json_chunk_87"
  },
  {
    "document_type": "research_paper",
    "title": "bayesian_workflow",
    "author": "",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\bayesian_workflow.pdf",
    "date_published": "2020-11-04",
    "keywords": "",
    "flag": "",
    "chunk_text": ". (b) The residuals from the fitted model are small and show no pattern, thus we see no obvious directions of improvement at this point. Figure 31 shows the fitted model and the residuals, y j /n j − ˆ p j , as a function of distance. The fit is good, and the residuals show no strong pattern, also they are low in absolute value—the model predicts the success rate to within half a percentage point at most distances, suggesting not that the model is perfect but that there are no clear ways to develop it further just given the current data. There are various ways the model could be improved, most obviously by breaking down the data and allowing the two parameters to vary by golfer, hole, and weather conditions. As discussed earlier, a key motivation for model expansion is to allow the inclusion of more data, in this case classifying who was taking the shot and where. 10.6. General lessons from the golf example This was an appealing example in that a simple one-parameter model fit the initial dataset, and then the new data were fit by adding just one more parameter to capture uncertainty in distance as well as angle of the shot. A notable feature of the model expansion was that the binomial likelihood was too strong and made it difficult for the new model to fit all the data at once. Such problems of stickiness—which appear in the computation as well as with the inference—are implicit in any Bayesian model, but they can become more prominent when as sample size increases. This is an example of the general principle that bigger data need bigger models. In this case, we expanded our second model by adding an error term which had no underlying golf interpretation, but allowed the model to flexibly fit the data",
    "chunk_id": "Adv_cognitive_modelling_bayesian_workflow.json_chunk_88"
  },
  {
    "document_type": "research_paper",
    "title": "bayesian_workflow",
    "author": "",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\bayesian_workflow.pdf",
    "date_published": "2020-11-04",
    "keywords": "",
    "flag": "",
    "chunk_text": ". In this case, we expanded our second model by adding an error term which had no underlying golf interpretation, but allowed the model to flexibly fit the data. This is similar to how, in a multi-center trial, we might allow the treatment effect to vary by area, even if we are not particularly interested in this variation, just because this can capture otherwise unexplained aspects of the data, and it is also similar to the idea in classical analysis of variance of including a fully saturated interaction term to represent residual error. The golf example also illustrates the way that inferences from a sequence of models can be compared, both by graphing predictions along with data and by studying the way that parameter estimates change as the model is expanded. For example, when we add uncertainty in the distance of the shot, our estimate of the angular uncertainty decreases. Finally, we recognize that even the final fitted model is a work in progress, and so we want to work in a probabilistic programming 55 environment where we can expand it by allowing the parameters to vary by player and condition of the course. 11. Example of workflow for a model with unexpected multimodality: Planetary motion The previous example was relatively straightforward in that we built a model and gradually improved it. Next we consider a case study in which we start with a complicated model, encounter problems with our inference, and have to figure out what is going on. Section 3.4 alludes to measurements of a planet’s motion. Let us now investigate this example from a slightly different perspective. While simple in appearance, this problem illustrates many of the concepts we have discussed and highlights that the workflow draws on both statistical and field expertise. It also cautions us that the workflow is not an automated process; each step requires careful reasoning. For many problems we have encountered finding the right visualization tools is often the key to understand our model, its limitations, and how to improve it",
    "chunk_id": "Adv_cognitive_modelling_bayesian_workflow.json_chunk_89"
  },
  {
    "document_type": "research_paper",
    "title": "bayesian_workflow",
    "author": "",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\bayesian_workflow.pdf",
    "date_published": "2020-11-04",
    "keywords": "",
    "flag": "",
    "chunk_text": ". For many problems we have encountered finding the right visualization tools is often the key to understand our model, its limitations, and how to improve it. This example is no exception. We monitor various intermediate quantities as prescribed in Section 5.4, and make extensive use of predictive checks (Sections 2.4 and 6.1). 11.1. Mechanistic model of motion Instead of fitting an ellipse, we use a mechanistic model based on elementary notions of classical mechanics. This allows us to estimate quantities of physical interest, such as stellar mass, and more readily apply domain knowledge, as well as track the planet’s trajectory in space and time. We can describe the planet’s motion using Newton’s laws, which is a second-order differential equation or equivalently a system of two first-order differential equations, which yields Hamilton’s formulation: d q d t = p m d p d t = − k r 3 ( q − q ∗ ) , where • q ( t ) is the planet’s position vector over time, • p ( t ) is the planet’s momentum vector over time, • m is the planet’s mass (assumed to be 1 in some units), • k = GmM , with G = 10 − 3 , the gravitational constant in the appropriate units, and M the stellar mass; hence k = 10 − 3 M , • and r = p ( q − q ∗ ) T ( q − q ∗ ) is the distance between the planet and the star, with q ∗ denoting the star’s position (assumed to be fixed). 56 The planet moves on a plane, hence p and q are each vectors of length 2. The differential equations tell us that the change in position is determined by the planet’s momentum and that the change in momentum is itself driven by gravity. We would like to infer the gravitational force between the star and the planet, and in particular the latent variable k . Other latent variables include the initial position and momentum of the planet, respectively q 0 and p 0 , the subsequent positions of the planet, q ( t ) , and the position of the star, q ∗ . Realistically, an astronomer would use cylindrical coordinates but for simplicity we stick to Cartesian coordinates",
    "chunk_id": "Adv_cognitive_modelling_bayesian_workflow.json_chunk_90"
  },
  {
    "document_type": "research_paper",
    "title": "bayesian_workflow",
    "author": "",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\bayesian_workflow.pdf",
    "date_published": "2020-11-04",
    "keywords": "",
    "flag": "",
    "chunk_text": ". Realistically, an astronomer would use cylindrical coordinates but for simplicity we stick to Cartesian coordinates. We record the planet’s position over regular time intervals, and assume measurements q obs , 1 , , q obs ,n at times t 1 , , t n , where each observation q obs ,i is two-dimensional with independent normally distributed errors, q obs ,i ∼ N 2 ( q ( t i ) , σ 2 I ) . We follow our general workflow and fit the model using fake data to see if we can recover the assumed parameter values. We run an MCMC sampler for this model with Stan, which supports a numerical ordinary differential equation (ODE) solver. A first attempt fails dramatically: the chains do not converge and take a long time to run. This is an invitation to start with a simpler model, again working in the controlled setting offered by simulated data, where we know the true value of each parameter. 11.2. Fitting a simplified model Ideally, we would find a simplification which is more manageable but still demonstrates the issues our algorithm encounters. Our first simplified model only estimates k , with prior k ∼ normal + (0 , 1) , and an assumed true value of k = 1 . We set the other parameters of the model at m = 1 , q ∗ = (0 , 0) , q 0 = (1 , 0) , and p 0 = (0 , 1) . Since the parameter space is 1- dimensional, we can compute the posterior distribution using quadrature; nevertheless we use MCMC, because our goal is to understand the challenges that frustrate our sampling algorithm. We run 8 chains, each with 500 iterations for the warmup phase and 500 more for the sampling phase, and we see: • The run time varies widely between chains, ranging from ∼ 2 seconds to ∼ 2000 seconds. While not necessarily a concern in itself, this indicates the chains are behaving in substantially different ways. • b R for some parameters are large, implying that the chains have not mixed. Typically, we are comfortable with b R < 1 . 01 . When b R > 2 , this is an indication that the chains are not mixing well",
    "chunk_id": "Adv_cognitive_modelling_bayesian_workflow.json_chunk_91"
  },
  {
    "document_type": "research_paper",
    "title": "bayesian_workflow",
    "author": "",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\bayesian_workflow.pdf",
    "date_published": "2020-11-04",
    "keywords": "",
    "flag": "",
    "chunk_text": ". Typically, we are comfortable with b R < 1 . 01 . When b R > 2 , this is an indication that the chains are not mixing well. Faced with these issues, we examine the traceplots (Figure 32). The chains seem to be stuck at local modes and do not cohesively explore the posterior space. Some chains have much lower log posterior densities than others. When doing posterior predictive checks for these chains specifically, we find that the simulated data does not agree with the observations. For reasons we will uncover, the chains with the lowest log posterior and highest k also turn out to be the ones with the longest run times. Departing from Stan’s defaults, we also plot iterations during the warmup phase. The plot now clearly indicates that which mode each chain converges to is determined by its initial value, suggesting these modes are strongly attractive for the Markov chain. This is an important practical 57 log−posterior k 0 250 500 750 1000 0 250 500 750 1000 2 4 6 −3e+05 −2e+05 −1e+05 0e+00 chain 1 2 3 4 5 6 7 8 Figure 32: Traceplots for our simplified model of planetary motion. The chains fail to mix, and they converge to several different local modes, depending on their initial values. The varying log posterior suggests some modes are more consistent with the data than others. The shaded area represents samples during the warmup phase. point: the right plot can help us diagnose the problem almost instantaneously, but unfortunately, and despite our best efforts, the default plot need not be the right plot. It is important to figure out whether these modes describe a latent phenomenon of interest which we must account for in our analysis or whether they are caused by a mathematical artifact. Because we have the luxury of fitting a simplified model, we can exactly work out what is going on and use the gained insight for more elaborate models. Figure 33 plots the likelihood computed via a quadrature scheme and confirms the existence of local modes",
    "chunk_id": "Adv_cognitive_modelling_bayesian_workflow.json_chunk_92"
  },
  {
    "document_type": "research_paper",
    "title": "bayesian_workflow",
    "author": "",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\bayesian_workflow.pdf",
    "date_published": "2020-11-04",
    "keywords": "",
    "flag": "",
    "chunk_text": ". Figure 33 plots the likelihood computed via a quadrature scheme and confirms the existence of local modes. To understand how these modes arise, we may reason about the log likelihood as a function that penalizes distance between q obs and q ( k ) , the positions of the planet simulated for a certain value of k . Indeed, log p ( q obs | k ) = C − 1 2 σ || q obs − q ( k ) || 2 2 , where C is a constant that does not depend on k . Figure 34 displays the planet’s simulated motion given different values of k . Recall that k controls the strength of the gravitational interaction: a higher value implies a closer and shorter orbit. The assumed value is k = 1 . The other values of k fail to generate data consistent with the observed data. For k < 1 , the trajectory can drift arbitrarily far away from the observed ellipse. But for k > 1 , the simulated ellipse must be contained inside the observed ellipse, which bounds the distance between q obs and q . Finally, as we change k and rotate the ellipse, some of the observed and simulated positions happen to become relatively close, which induces local modes that appear as wiggles in the tail of the likelihood. The parameter values at the mode do not induce simulations that are in close agreement with the data; but they do better than neighboring parameter values, which is enough to create a bump in the likelihood. The tail modes are a mathematical artifact of the periodic structure of the data and do not characterize a latent phenomenon of interest. Moreover they only contribute negligible probability mass. Hence, any chain that does not focus on the dominating mode wastes our precious 58 −9e+05 −6e+05 −3e+05 0e+00 0.0 2.5 5.0 7.5 k log likelihood Figure 33: Log likelihood across various values of k for our simplified planetary motion model. There is a dominating mode near k = 1 , followed by local modes as k increases. These modes are due to the cyclical trajectory, which allows the possibility of approximate aliasing",
    "chunk_id": "Adv_cognitive_modelling_bayesian_workflow.json_chunk_93"
  },
  {
    "document_type": "research_paper",
    "title": "bayesian_workflow",
    "author": "",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\bayesian_workflow.pdf",
    "date_published": "2020-11-04",
    "keywords": "",
    "flag": "",
    "chunk_text": ". There is a dominating mode near k = 1 , followed by local modes as k increases. These modes are due to the cyclical trajectory, which allows the possibility of approximate aliasing. 0 1 2 −1.0 −0.5 0.0 0.5 1.0 q x q y k 0.5 1.0 1.6 2.16 3.00 Figure 34: Orbits simulated for various values of k for the planetary motion model. There is no strong degeneracy in k , but as this parameter changes, some of the simulated points by chance get closer to their observed counterparts, inducing wiggles in the tails of the log likelihood and creating local modes. For example, the 35 th observation (solid dot, on the k = 1 orbit) is closer to the corresponding position simulated with k = 2 . 2 (cross on the blue line) than the one obtained with k = 1 . 6 (cross on the green line). 59 computational resources. So, what can we do? Building stronger priors. One option is to build a more informative prior to reflect our belief that a high value of k is implausible; or that any data generating process that suggests the planet undergoes several orbits over the observation time is unlikely. When such information is available, stronger priors can indeed improve computation. This is unfortunately not the case here. A stronger prior would reduce the density at the mode, but the wiggles in the tail of the joint would persist. Paradoxically, with more data, these wiggles become stronger: the model is fundamentally multi-modal. Note also that our current prior, k ∼ normal + (0 , 1) , is already inconsistent with the values k takes at the minor modes. In principle we could go a step further and add a hard constraint on orbital time or velocity to remove the modes. Reweighting draws from each chain. One issue is that the Markov chains fail to transition from one mode to the other, meaning some chains sample over a region with a low probability mass. We can correct our Monte Carlo estimate using a re-weighting scheme, such as stacking",
    "chunk_id": "Adv_cognitive_modelling_bayesian_workflow.json_chunk_94"
  },
  {
    "document_type": "research_paper",
    "title": "bayesian_workflow",
    "author": "",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\bayesian_workflow.pdf",
    "date_published": "2020-11-04",
    "keywords": "",
    "flag": "",
    "chunk_text": ". We can correct our Monte Carlo estimate using a re-weighting scheme, such as stacking. This strategy likely gives us reasonable Monte Carlo estimates, but: (i) we will not comprehensively explore all the modes with 8 chains, so stacking should really be treated as discarding the chains stuck at local modes and (ii) we still pay a heavy computational price, as the chains in minor modes take up to ∼ 1000 times longer to run. Tuning the starting points. We did not specify the Markov chain’s starting points and instead relied on Stan’s defaults, which sample the initial point from a uniform( − 2 , 2) over the unconstrained space, that is, the starting points are drawn from log k (0) ∼ uniform( − 2 , 2) . This default, designed for unconstrained parameters on the unit scale, indulges values of k which are widely inconsistent with our prior and our domain expertise. In a non-asymptotic regime, the Markov chain does not always “forget” its starting point, and it is unlikely to do so here even if we run the chain for many many more iterations. We can therefore not ignore this tuning parameter of our algorithm. An alternative to the default is to sample k (0) from our prior, thereby imposing that the chains start in a range of values deemed reasonable. In this setup, the chains converge quickly and our computation focuses on the relevant region. Whether with stacking, tuned starting points, or perhaps another mean, we need to give MCMC a helping hand to avoid local modes. In general, ignoring non-converging chains is poor practice, so we want to highlight how the here presented process differs from that. First, we examine all the chains, using posterior predictive checks, and work out exactly how the local modes arise. We decisively demonstrate that they do not describe data generating processes of interest, nor do they contribute more than a negligible amount of probability mass. Only then do we redirect our computational resources to focus on the mode around which all the probability mass concentrates. 11.3",
    "chunk_id": "Adv_cognitive_modelling_bayesian_workflow.json_chunk_95"
  },
  {
    "document_type": "research_paper",
    "title": "bayesian_workflow",
    "author": "",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\bayesian_workflow.pdf",
    "date_published": "2020-11-04",
    "keywords": "",
    "flag": "",
    "chunk_text": ". Only then do we redirect our computational resources to focus on the mode around which all the probability mass concentrates. 11.3. Bad Markov chain, slow Markov chain? Recall that the chains that yielded the lowest log posteriors were also the ones that were the slowest—an instance of the folk theorem of statistical computing (see Section 5.1). We can in fact show that Hamilton’s equations become more difficult to solve as k increases. The intuition is the following: if the gravitational interaction is strong, then the planet moves at a much faster rate. 60 From a numerical perspective, this means each time step, d t , incurs a greater change in q ( t ) and the integrator’s step size must accordingly be adjusted. There is wisdom is this anecdote: an easy deterministic problem can become difficult in a Bayesian analysis. Indeed Bayesian inference requires us to solve the problem across a range of parameter values, which means we must sometimes confront unsuspected versions of the said problem. In our experience, notably with differential equation based models in pharmacology and epidemiology, we sometime require a more computationally expensive stiffsolver to tackle difficult ODEs generated during the warmup phase. Other times slow computation can alert us that our inference is allowing for absurd parameter values and that we need either better priors or more reasonable initial points. Unfortunately this goes against the “fail fast” principle outlined in Section 3.4. Our current tools tend to be much slower when the fit is bad, hence an important research topic in Bayesian computational workflow is to flag potential problems quickly to avoid wasting too much time on dead ends. 11.4. Building up the model Starting from the simplified model, we now gradually build our way back to the original model. This turns out to be not quite straightforward, but we can put what we have learned from the simplified model to good use",
    "chunk_id": "Adv_cognitive_modelling_bayesian_workflow.json_chunk_96"
  },
  {
    "document_type": "research_paper",
    "title": "bayesian_workflow",
    "author": "",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\bayesian_workflow.pdf",
    "date_published": "2020-11-04",
    "keywords": "",
    "flag": "",
    "chunk_text": ". This turns out to be not quite straightforward, but we can put what we have learned from the simplified model to good use. Most inference problems we encounter across the models we fit can be traced back to the interaction between the likelihood and the cyclical observations—an elementary notion, once grasped, but which would have been difficult to discover in a less simple setting than the one we used. Here is an example. In the complete model, we estimate the position of the star, q ∗ , and find that the chains converge to many different values, yielding simulations which, depending on the chain, agree or disagree with the observations. There is however, based on the traceplots, no obvious connection between the starting points and the neighborhoods of convergence. It is difficult to examine this type of connections because the model has now 7 parameters, some with strong posterior correlations. Fortunately, we can reason about the physics of the problem and realize that tweaking the star’s position, q ∗ , and implicitly, r , the star-planet distance, is not unlike modifying k . Recall that d p d t = − k r 3 ( q − q ∗ ) , whence both k and r control the gravitational interaction. We cannot do a quadrature across all 7 parameters of our model. Instead, we look at the conditional likelihood, wherein we keep all parameters ( k , q 0 , and p 0 ) fixed, except for q ∗ . In a sense, this amounts to investigating another simplification of our model. Figure 35 shows the suspected modes, thereby supporting our conjecture. At this point, with some level of confidence, we construct starting points to guide our Markov chains towards the dominating mode and obtain a good fit of the complete model. 11.5. General lessons from the planetary motion example When we fail to fit a model, examining a simplified model can help us understand the challenges that frustrate our inference algorithm",
    "chunk_id": "Adv_cognitive_modelling_bayesian_workflow.json_chunk_97"
  },
  {
    "document_type": "research_paper",
    "title": "bayesian_workflow",
    "author": "",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\bayesian_workflow.pdf",
    "date_published": "2020-11-04",
    "keywords": "",
    "flag": "",
    "chunk_text": ". 11.5. General lessons from the planetary motion example When we fail to fit a model, examining a simplified model can help us understand the challenges that frustrate our inference algorithm. In practice it is difficult to find a simplification which is 61 −4e+05 −2e+05 0e+00 −0.5 0.0 0.5 q ∗ x Conditional log likelihood −0.3 0.0 0.3 −0.5 0.0 0.5 q ∗ x q ∗ y −6e+05 −4e+05 −2e+05 0e+00 log likelihood Figure 35: For the planetary motion example, log conditional likelihood when varying the star’s position, q ∗ . Left: All parameters are kept fixed, except for the x -coordinate of q ∗ . Right: This time both coordinates of q ∗ are allowed to vary. The quadrature computation allows us to expose the multimodality of the problem. manageable and still exhibits the pathology we wish to understand. Reasoning about the topology surrounding our model, as alluded to in section 7.4, can help us in this process. A straightforward way of simplifying is to fix some of the model parameters. In the planetary motion example, we are confronted with a multi-modal posterior distribution. This geometry prevents our chains from cohesively exploring the parameter space and leads to biased Monte Carlo estimates. It is important to understand how these local modes arise and what their contribution to the posterior probability mass might be. We do so using posterior predictive checks. It is not uncommon for minor modes, with negligible probability mass, to “trap” a Markov chain. The possibility of such ill-fitting modes implies we should always run multiple chains, perhaps more than our current default of 4 . This case study also raises the question of what role starting points may play. Ideally a Markov chain forgets its initial value but in a non-asymptotic regime this may not be the case. This is not a widely discussed topic but nevertheless one of central importance for practitioners and thence for Bayesian workflow. Just as there is no universal default prior, there is no universal default initial point",
    "chunk_id": "Adv_cognitive_modelling_bayesian_workflow.json_chunk_98"
  },
  {
    "document_type": "research_paper",
    "title": "bayesian_workflow",
    "author": "",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\bayesian_workflow.pdf",
    "date_published": "2020-11-04",
    "keywords": "",
    "flag": "",
    "chunk_text": ". Just as there is no universal default prior, there is no universal default initial point. Modelers often need to depart from defaults to insure a numerically stable evaluation of the joint density and improve MCMC computation. At the same time we want dispersed initial points in order to have reliable convergence diagnostics and to potentially explore all the relevant modes. Like for other tuning parameters of an inference algorithm, picking starting points can be an iterative process, with adjustments made after a first attempt at fitting the model. We do not advocate mindlessly discarding misbehaving chains. It is important to analyze where this poor behavior comes from, and whether it hints at serious flaws in our model and in our inference. Our choice to adjust the initial estimates is based on: (a) the realization that the defaults are widely inconsistent with our expertise and (b) the understanding that the local modes do not describe a latent phenomenon of interest, as shown by our detailed analysis of how cyclical data interacts with a normal likelihood. 62 12. Discussion 12.1. Different perspectives on statistical modeling and prediction Consider three different ways to think about modeling and prediction: • Traditional statistical perspective. In textbooks, statistical inference is typically set up as a problem in which a model has been chosen ahead of time, and in the Bayesian context the goal is to accurately summarize the posterior distribution. Computation is supposed to be done as long as necessary to reach approximate convergence. • Machine learning perspective. In machine learning, the usual goal is prediction, not prameter estimation, and computation can stop when cross validation prediction accuracy has plateaued. • Model exploration perspective. In applied statistical work, much of our modeling effort is spent in exploration, trying out a series of models, many of which will have terrible fit to data, poor predictive performance, and slow convergence (see also Section 5.1)",
    "chunk_id": "Adv_cognitive_modelling_bayesian_workflow.json_chunk_99"
  },
  {
    "document_type": "research_paper",
    "title": "bayesian_workflow",
    "author": "",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\bayesian_workflow.pdf",
    "date_published": "2020-11-04",
    "keywords": "",
    "flag": "",
    "chunk_text": ". These three scenarios imply different inferential goals. In a traditional statistical modeling problem, it can make sense to run computation for a long time, using approximations only when absolutely necessary. Another way of saying this is that in traditional statistics, the approximation might be in the choice of model rather than in the computation. In machine learning, we want to pick an algorithm that trades offpredictive accuracy, generalizability, and scalability, so as to make use of as much data as possible within a fixed computational budget and predictive goal. In model exploration, we want to cycle through many models, which makes approximations attractive. But there is a caveat here: if we are to efficiently and accurately explore the model space rather than the algorithm space, we require any approximation to be sufficiently faithful as to reproduce the salient features of the posterior. The distinction here is not about inference vs. prediction, or exploratory vs. confirmatory analysis. Indeed all parameters in inference can be viewed as some quantities to predict, and all of our modeling can be viewed as having exploratory goals (Gelman, 2003). Rather, the distinction is how much we trust a given model and allow the computation to approximate. As the examples in Sections 10 and 11 illustrate, problems with a statistical model in hindsight often seem obvious, but we needed the workflow to identify them and understand the obviousness. Another important feature of these examples, which often happens with applied problems, is that particular challenges in modeling arise in the context of the data at hand: had the data been different, we might never have encountered these particular issues, but others might well have arisen. This is one reason that subfields in applied statistics advance from application to application, as new wrinkles become apparent in existing models",
    "chunk_id": "Adv_cognitive_modelling_bayesian_workflow.json_chunk_100"
  },
  {
    "document_type": "research_paper",
    "title": "bayesian_workflow",
    "author": "",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\bayesian_workflow.pdf",
    "date_published": "2020-11-04",
    "keywords": "",
    "flag": "",
    "chunk_text": ". This is one reason that subfields in applied statistics advance from application to application, as new wrinkles become apparent in existing models. A central motivation of this paper is to make more transparent the steps by which we can uncover and then resolve these modeling problems. 12.2. Justification of iterative model building We view the process of model navigation as the next transformative step in data science. The first big step of data science, up to 1900 or so, was data summarization , centering on the gathering of relevant data and summarizing through averages, correlations, least-squares fits, and the like. The 63 next big step, beginning with Gauss and Laplace and continuing to the present day, was modeling : the realization that a probabilistic model with scientific content could greatly enhance the value from any given dataset, and also make it more feasible to combine different sources of data. We are currently in the midst of another big step, computation : with modern Bayesian and machine learning methods, increases in algorithmic and computational efficiency have effected a qualitative improvement in our ability to make predictions and causal inferences. We would like to move beyond good practice and workflow in particular case studies, to a formulation of the process of model navigation, “facilitating the exploration of model space” (Devezer et al., 2019). In the ideal world we would build one perfect model and solve the math. In the real world we need to take into account the limitations of humans and computers, and this should be included in models of science and models of statistics (Navarro, 2019, Devezer et al., 2020). From a human perspective, our limited cognitive capabilities make it easier to learn gradually. Iterative model building starting from a simple model is gradual learning and helps us better understand the modeled phenomenon",
    "chunk_id": "Adv_cognitive_modelling_bayesian_workflow.json_chunk_101"
  },
  {
    "document_type": "research_paper",
    "title": "bayesian_workflow",
    "author": "",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\bayesian_workflow.pdf",
    "date_published": "2020-11-04",
    "keywords": "",
    "flag": "",
    "chunk_text": ". Iterative model building starting from a simple model is gradual learning and helps us better understand the modeled phenomenon. Furthermore, building a rich model takes effort, and it can be efficient in human time to start from a simpler model and stop when the model seems to be sufficiently good. We gave an example in Section 10. One goal of workflow is to make the process easier for humans even in the idealized setting where exact computation can be performed automatically. Iterating over a set of models is also useful from a computational standpoint. Given a proper posterior, computation in Bayesian inference is theoretically solved. In practice we must contend with finite computational resources. An algorithm for which asymptotic guarantees exist can fail when run for a finite time. There is no fully automated computation that yields perfect results, at least not across the vast range of models practitioners care about. Another goal of workflow is to avoid some computational problems and be able to efficiently diagnose the remaining ones. Here too deconstructing the model into simpler versions can be helpful: it is easier to understand computational challenges when there are fewer moving parts. Hence, even if a mathematical description of a model is given, correctly implementing the model tends to require iteration. Not only is iterative model building beneficial from a cognitive and computational standpoint, but the complexity of complicated computational models makes it difficult for the human user to disentangle computational concerns, modeling issues, data quality problems, and bugs in the code. By building models iteratively, we can employ software engineering techniques in our modeling procedure. Simple model components can be checked to make sure they act in an expected way before more complicated components are added. 12.3",
    "chunk_id": "Adv_cognitive_modelling_bayesian_workflow.json_chunk_102"
  },
  {
    "document_type": "research_paper",
    "title": "bayesian_workflow",
    "author": "",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\bayesian_workflow.pdf",
    "date_published": "2020-11-04",
    "keywords": "",
    "flag": "",
    "chunk_text": ". Simple model components can be checked to make sure they act in an expected way before more complicated components are added. 12.3. Model selection and overfitting A potential issue with the proposed iterative workflow is that model improvement is conditioned on discrepancy between the currently considered model and the data, and thus at least some aspects of the data are used more than once. This “double dipping” can in principle threaten the frequency properties of our inferences, and it is important to be aware of the possibility of overfitting arising from model selection, as considered for example by Fithian et al. (2015) and Loftus (2015). A related issue is the garden of forking paths, the idea that different models would have been fit had the data come out differently (Gelman and Loken, 2013). We do not advocate selecting the best fit among some such set of models. Instead, we describe a process of building to a more complex model taking the time to understand and justify each decision. 64 To put it in general terms: suppose we fit model M 1 , then a posterior predictive check reveals problems with its fit to data, so we move to an improved M 2 that, we hope, includes more prior information and makes more sense with respect to the data and the applied problem under study. But had the data been different, we would have been satisfied with M 1 . The steps of model checking and improvement, while absolutely necessary, represent an aspect of fitting to data that is not captured in the likelihood or the prior. This is an example of the problem of post-selection inference (Berk et al., 2013, Efron, 2013). Much of the research in this area has been on how to adjust p -values and confidence intervals to have appropriate frequency properties conditional on the entire fitting procedure, but Bayesian inferences are subject to this concern as well",
    "chunk_id": "Adv_cognitive_modelling_bayesian_workflow.json_chunk_103"
  },
  {
    "document_type": "research_paper",
    "title": "bayesian_workflow",
    "author": "",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\bayesian_workflow.pdf",
    "date_published": "2020-11-04",
    "keywords": "",
    "flag": "",
    "chunk_text": ". For example, here is the story of one of the adaptations we made in election forecasting (Gelman, Hullman, et al., 2020): A few weeks after we released our first model of the election cycle for The Economist , we were disturbed at the narrowness of some of its national predictions. In particular, at one point the model gave Biden 99% chance of winning the national vote. Biden was clearly in the lead, but 99% seemed like too high a probability given the information available at that time. Seeing this implausible predictive interval motivated us to refactor our model, and we found some bugs in our code and some other places where the model could be improved—including an increase in between-state correlations, which increased uncertainty of national aggregates. The changes in our model did not have huge effects—not surprisingly given that we had tested our earlier model on 2008, 2012, and 2016—but the revision did lower Biden’s estimated probability of winning the popular vote to 98%. This was still a high value, but it was consistent with the polling and what we’d seen of variation in the polls during the campaign. The errors we caught were real, but if we had not been aware of these particular problematic predictions, we might have never gone back to check. This data-dependence of our analysis implies a problem with a fully Bayesian interpretation of the probability statements based on the final model we settled on. And, in this case, model averaging would not resolve this problem: we would not want to average our final model with its buggy predecessor. We might want to average its predictions with those of some improved future model, but we can’t do that either, as this future model does not yet exist! That said, we think that Bayesian workflow as described here will avoid the worst problems of overfitting",
    "chunk_id": "Adv_cognitive_modelling_bayesian_workflow.json_chunk_104"
  },
  {
    "document_type": "research_paper",
    "title": "bayesian_workflow",
    "author": "",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\bayesian_workflow.pdf",
    "date_published": "2020-11-04",
    "keywords": "",
    "flag": "",
    "chunk_text": ". Taylor and Tibshirani (2015) warn of the problem of inference conditional on having “searched for the strongest associations.” But our workflow does not involve searching for optimallfitting models or making hard model selection under uncertainty. Rather, we use problems with fitted models to reassess our modeling choices and, where possible, include additional information. For our purposes, the main message we take from concerns about post-selection inference is that our final model should account for as much information as possible, and when we might be selecting among a large set of possible models, we instead embed these in a larger model, perform predictive model averaging, or use all of the models simultaneously (see Section 8). As discussed by Gelman, Hill, and Yajima (2012), we expect that would work better than trying to formally model the process of model checking and expansion. We also believe that our workflow enables practitioners to perform severe tests of many of the assumptions that underlie the models being examined (Mayo, 2018). Our claim is that often a 65 model whose assumptions withstood such severe tests is, despite being the result of data-dependent iterative workflow, more trustworthy than a preregistered model that has not been tested at all. On a slightly different tack, iterative model building is fully justified as a way to understand a fixed, complex model. This is an important part of workflow as it is well known that components in complex models can interact in complex ways. For example, Hodges and Reich (2010) describe how structured model components such as spatial effects can have complex interactions with linear covariate effects. 12.4. Bigger datasets demand bigger models Great progress has been made in recent decades on learning from data using methods developed in statistics, machine learning, and applied fields ranging from psychometrics to pharmacology",
    "chunk_id": "Adv_cognitive_modelling_bayesian_workflow.json_chunk_105"
  },
  {
    "document_type": "research_paper",
    "title": "bayesian_workflow",
    "author": "",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\bayesian_workflow.pdf",
    "date_published": "2020-11-04",
    "keywords": "",
    "flag": "",
    "chunk_text": ". Hierarchical Bayesian modeling, deep learning, and other regularization-based approaches are allowing researchers to fit larger, more complex models to real-world data, enabling information aggregation and partial pooling of inferences from different sources of data. While the proposed workflow offers advantages regardless of the size of the dataset, the case of big data deserves a special mention. “Big data” is sometimes defined as being too big to fit in memory on your machine, but here we use the term more generally to also include datasets that are so large that our usual algorithms do not run in reasonable time. In either case, the definition is relative to your current computing capacity and inferential goals. It is frequently assumed that big data can alleviate the need for careful modeling. We do not believe this is the case. Quantity does not always substitute for quality. Big data is messy data. Big data prioritizes availability over randomization, which means Big data is almost always observational rather than from designed experiments. Big data frequently uses available proxies rather than direct measurements of underlying constructs of interest. To make relevant inferences from big data, we need to extrapolate from sample to population, from control to treatment group, and from measurements to latent variables. All these steps require statistical assumptions and adjustment of some sort, which in the Bayesian framework is done using probability modeling and mathematical connections to inferential goals. For example, we might fit a multilevel model for data given respondents’ demographic and geographic characteristics and then poststratify to connect the predictions from this model to the goal of inference about the general population. Each of these steps of statistical extrapolation should be more effective if we adjust for more factors—that is, include more information—but we quickly reach a technical barrier",
    "chunk_id": "Adv_cognitive_modelling_bayesian_workflow.json_chunk_106"
  },
  {
    "document_type": "research_paper",
    "title": "bayesian_workflow",
    "author": "",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\bayesian_workflow.pdf",
    "date_published": "2020-11-04",
    "keywords": "",
    "flag": "",
    "chunk_text": ". Each of these steps of statistical extrapolation should be more effective if we adjust for more factors—that is, include more information—but we quickly reach a technical barrier. Models that adjust for many of factors can become hard to estimate, and effective modeling requires (a) regularization to get more stable estimates (and in turn to allow us to adjust for more factors), and (b) modeling of latent variables (for example parameters that vary by person when modeling longitudinal data), missingness, and measurement error. A key part of Bayesian workflow is adapting the model to the data at hand and the questions of interest. The model does not exist in isolation and is not specified from the outside; it emerges from engagement with the application and the available data. 12.5. Prediction, generalization, and poststratification The three core tasks of statistics are generalizing from sample to population, generalizing from control to treatment group, and generalizing from observed data to underlying constructs of interest. 66 In machine learning and causal inference, the terms “domain adaptation” and “transportability” have been used to represent the challenges of taking inference from a particular dataset and applying it in a new problem (Blitzer, Dredze, and Pereira, 2007, Pearl and Bareinboim, 2011). Many statistical tools have been developed over the years to attack problems of generalization, for example weighting and poststratification in sample surveys, matching and regression in causal inference, and latent variable modeling in areas such as psychometrics and econometrics where there is concern about indirect or biased observations",
    "chunk_id": "Adv_cognitive_modelling_bayesian_workflow.json_chunk_107"
  },
  {
    "document_type": "research_paper",
    "title": "bayesian_workflow",
    "author": "",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\bayesian_workflow.pdf",
    "date_published": "2020-11-04",
    "keywords": "",
    "flag": "",
    "chunk_text": ". Bayesian methods enter in various ways, including the idea of hierarchical modeling or patial pooling to appropriately generalize across similar but not identical settings, which has been rediscovered in many fields (e.g., Henderson, 1950, Novick et al., 1972, Gelman and Hill, 2007, Finkel and Manning, 2009, Daumé, 2009), regularization to facilitate the use of large nonparameric models (Hill, 2011), and multilevel modeling for latent variables (Skrondal and Rabe-Hesketh, 2004), and there are connections between transportability and Bayesian graph models (Pearl and Bareinboim, 2014). Bayesian workflow does not stop with inference for the fitted model. We are also interested in inferences for new real-world situations, which implies that the usual prior and data model is embedded in a larger framework including predictions and inferences for new settings, including potentially different modes of measurement and treatment assignments. Statistical models can also go into production, which provides future opportunities for feedback and improvement. Just as the prior can often only be understood in the context of the likelihood (Gelman et al., 2017, Kennedy et al., 2019), so should the model be understood in light of how it will be used. For example, Singer et al. (1999) and Gelman, Stevens, and Chan (2003) fit a series of models to estimate the effects of financial incentives on response rates in surveys. The aspects of these models that will be relevant for predicting effects for small incentives in mail surveys are different from what is relevant for predictions for large incentives in telephone surveys. This is related to the discussion of sensitivity analysis in Sections 6.3 and 8.1. For another illustration of this point, Rubin (1983) gives an example where the choice of transformation has minor effects on inference for the median of a distribution while having large effects on inference for the mean. 12.6",
    "chunk_id": "Adv_cognitive_modelling_bayesian_workflow.json_chunk_108"
  },
  {
    "document_type": "research_paper",
    "title": "bayesian_workflow",
    "author": "",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\bayesian_workflow.pdf",
    "date_published": "2020-11-04",
    "keywords": "",
    "flag": "",
    "chunk_text": ". 12.6. Going forward All workflows have holes, and we cannot hope to exhaust all potential flaws of applied data analysis. In the prior and posterior predictive check, a wrong model will pass the check silently for overfitting all output at the observed values. In simulation based calibration, an incorrect computation program can satisfy the diagnostics if the posterior stays in the prior. In cross validation, the consistency relies on conditional independence and stationarity of the covariates. In causal inference, there are always untestable causal assumptions, no matter how many models we have fit. More generally, statistics relies on some extrapolation, for which some assumption is always needed. To ultimately check the model and push the workflow forward, we often need to collect more data, along the way expanding the model, and an appropriate experiment design will be part of this larger workflow. This article has focused on data analysis: the steps leading from data and assumptions to scientific inferences and predictions. Other important aspects of Bayesian statistics not discussed here include design, measurement, and data collection (coming before the data analysis) and decision making and communication (coming after data analysis). We also have not gone into the details of computing environments or the social and economic aspects of collaboration, sharing of 67 data and code, and so forth. The list of workflow steps we have provided is too long to be a useful guide to practice. What can be done? Rather than giving users a 25-item checklist, we hope that we can clarify these processes so they can be applied in a structured or even automated framework. Our rough plan is as follows: • Abstract these principles from our current understanding of best practice, thus producing the present article. • Apply this workflow to some applied problems and write these up as case studies. • Implement as much of the workflow as possible in software tools for general application",
    "chunk_id": "Adv_cognitive_modelling_bayesian_workflow.json_chunk_109"
  },
  {
    "document_type": "research_paper",
    "title": "bayesian_workflow",
    "author": "",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\bayesian_workflow.pdf",
    "date_published": "2020-11-04",
    "keywords": "",
    "flag": "",
    "chunk_text": ". • Apply this workflow to some applied problems and write these up as case studies. • Implement as much of the workflow as possible in software tools for general application. Automating what can be automated should enable the statistician or applied researcher to go beyond button pushing and integrate data with domain expertise. The ultimate goal of this project is to enable ourselves and other data analysts to use statistical modeling more effectively, and to allow us to build confidence in the inferences and decisions that we come to. This article is a review, a survey of the territory, a reminder of methods we have used, procedures we have followed, and ideas we would like to pursue. To be useful to practitioners, we need worked examples with code. We would also like to provide more structure: if not a checklist, at least a some paths to follow in a Bayesian analysis. Some guidance is given in the Stan User’s Guide (Stan Development Team, 2020), and we are working on a book on Bayesian workflow using Stan to provide such a resource to novice and experienced statisticians alike. That said, we believe this paper has value as a first step toward putting the many different activities of Bayesian workflow under a single roof.",
    "chunk_id": "Adv_cognitive_modelling_bayesian_workflow.json_chunk_110"
  },
  {
    "document_type": "online_article",
    "title": "Chapter 8 Model Comparison in Cognitive Science",
    "author": "Riccardo Fusaroli",
    "source": "https://fusaroli.github.io/AdvancedCognitiveModeling2023/model-comparison-in-cognitive-science.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": "Cognitive science aims to understand the processes that give rise to human thought and behavior. To do this effectively, we often create formal models that represent our hypotheses about these underlying processes. However, human cognition is complex, and multiple theoretical accounts might plausibly explain the same observed behaviors. This is where model comparison becomes essential. Model comparison is the principled evaluation of competing models to determine which best explains observed data. Model comparison techniques as described here balance a model’s ability to fit existing data against its ability to generalize to new observations, helping us avoid the trap of overfitting. But remember, model comparison is not a fail-safe procedure to determine which model embodies the truth, as always we need to be careful, tentative and open about the probabilistic and fallible nature of our inference. After completing this chapter, you will be able to: Implement cross-validation techniques for comparing cognitive models using Stan Calculate and interpret expected log predictive density (ELPD) scores Assess model predictions through posterior and prior predictive checks Understand the strengths and limitations of different model comparison approaches Apply these techniques to compare competing cognitive models using real data Model comparison serves multiple purposes in cognitive science: Theory Testing: Different models often represent competing theoretical accounts of cognitive processes. Comparing their fit to data helps evaluate these theories. Parsimony: When multiple models can explain the data, more complex models should only be preferred if they are justified by better predictive performance. Generalization: By assessing how well different models predict new data, we can evaluate their ability to capture general patterns rather than just fitting to specific samples",
    "chunk_id": "Adv_cognitive_modelling_chapter_8_model_comparison_in_cognitive_science.json_chunk_1"
  },
  {
    "document_type": "online_article",
    "title": "Chapter 8 Model Comparison in Cognitive Science",
    "author": "Riccardo Fusaroli",
    "source": "https://fusaroli.github.io/AdvancedCognitiveModeling2023/model-comparison-in-cognitive-science.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". Generalization: By assessing how well different models predict new data, we can evaluate their ability to capture general patterns rather than just fitting to specific samples. Individual Differences: Model comparison can reveal whether different individuals or groups are better described by different cognitive strategies. This chapter demonstrates these principles using our matching pennies models as concrete examples. We’ll compare simple random choice models against more sophisticated memory-based approaches, showing how to rigorously evaluate which better explains observed behavior. Imagine having several models of what might be going on and wanting to know which is the best explanation of the data. For example: Model comparison defines a broad range of practices aimed at identifying the best model for a given dataset. What “best” means is, however, a non-trivial question. Ideally, “best” would mean the model describing the mechanism that actually generated the data. However, knowing the truth is a tricky proposition and we need to use proxies. There are many of such proxies in the literature, for instance Bayes Factors (see Nicenboim et al 2023,https://vasishth.github.io/bayescogsci/book/ch-comparison.html). In this course, we rely on predictive performance - this helps combat overfitting, but has limitations we’ll discuss at the end. In other words, this chapter will assess models in terms of their (estimated) ability to predict new (test) data. Remember that predictive performance is a very useful tool, but not a magical solution. It allows us to combat overfitting to the training sample (your model snuggling to your data so much that it fits both signal and noise), but it has key limitations, which we will discuss at the end of the chapter. To learn how to make model comparison, in this chapter, we rely on our usual simulation based approach to ensure that the method is doing what we want. We simulate the behavior of biased agents playing against the memory agents",
    "chunk_id": "Adv_cognitive_modelling_chapter_8_model_comparison_in_cognitive_science.json_chunk_2"
  },
  {
    "document_type": "online_article",
    "title": "Chapter 8 Model Comparison in Cognitive Science",
    "author": "Riccardo Fusaroli",
    "source": "https://fusaroli.github.io/AdvancedCognitiveModeling2023/model-comparison-in-cognitive-science.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". We simulate the behavior of biased agents playing against the memory agents. This provides us with data generated according to two different mechanisms: biased agents and memory agents. We can fit both models separately on each of the two sets of agents, so we can compare the relative performance of the two models: can we identify the true model generating the data (in a setup where truth is known)? This is what is usually called “model recovery” and complements nicely “parameter recovery”. In model recovery we assess whether we can identify the correct model, in parameter recovery we assess whether - once we know the correct model - we can identify the correct parameter values. Let’s get going. In this example, we have: Model 1 (Biased Agent): Makes choices with a consistent 80% bias toward the right option Model 2 (Memory Agent): Adjusts choices based on memory of previous patterns The critical insight is that both models can produce similar-looking data, making it difficult to determine which cognitive process generated the observed behavior by simple visual inspection. Formal model comparison techniques give us principled ways to evaluate which model better explains the data while accounting for model complexity and generalization ability. Cross-validation is a fundamental technique for comparing models based on their predictive performance. The core idea is simple: a good model should not only fit the observed data but also generalize well to new, unseen data. When we fit a model to data, there’s always a risk of overfitting - capturing noise or idiosyncrasies in the particular sample rather than the underlying pattern we care about. [MISSING: A QUICK ILLUSTRATION OF AN EXAMPLE] Cross-validation helps us find the optimal balance between fitting the training data and generalizing to new data",
    "chunk_id": "Adv_cognitive_modelling_chapter_8_model_comparison_in_cognitive_science.json_chunk_3"
  },
  {
    "document_type": "online_article",
    "title": "Chapter 8 Model Comparison in Cognitive Science",
    "author": "Riccardo Fusaroli",
    "source": "https://fusaroli.github.io/AdvancedCognitiveModeling2023/model-comparison-in-cognitive-science.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". [MISSING: A QUICK ILLUSTRATION OF AN EXAMPLE] Cross-validation helps us find the optimal balance between fitting the training data and generalizing to new data. When the datasets are small, as it is often the case in cognitive science, keeping a substantial portion of the data out - substantial enough to be representative of a more general population - is problematic as it risks starving the model of data: there might not be enough data for reliable estimation of the parameter values. This is where the notion of cross-validation comes in: we can split the dataset in k folds, let’s say k = 10. Then each fold is in turn kept aside as validation set, the model is fitted on the other folds, and its predictive performance tested on the validation set. Repeat this operation of each of the folds. This operation ensures that all the data can be used for training as well as for validation, and is in its own terms quite genial. However, this does not mean it is free of shortcomings. First, small validation folds might not be representative of the diversity of true out-of-sample populations - and there is a tendency to set k equal to the number of datapoints (leave-one-out cross validation). Second, there are many ways in which information could leak or contaminate across folds if the pipeline is not very careful (e.g. via data preprocessing scaling the full dataset, or hyper-parameter estimation). Third, and crucial for our case here, cross validation implies refitting the model k times, which for Bayesian models might be very cumbersome (I once had a model that took 6 weeks to run). The basic idea of cross-validation is to: There are several variations of cross-validation: In k-fold cross-validation, we: 1. Divide the data into k equally sized subsets (folds) 2. Use k-1 folds for training and the remaining fold for testing 3. Repeat k times, each time using a different fold as the test set 4",
    "chunk_id": "Adv_cognitive_modelling_chapter_8_model_comparison_in_cognitive_science.json_chunk_4"
  },
  {
    "document_type": "online_article",
    "title": "Chapter 8 Model Comparison in Cognitive Science",
    "author": "Riccardo Fusaroli",
    "source": "https://fusaroli.github.io/AdvancedCognitiveModeling2023/model-comparison-in-cognitive-science.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". Divide the data into k equally sized subsets (folds) 2. Use k-1 folds for training and the remaining fold for testing 3. Repeat k times, each time using a different fold as the test set 4. Average the k test performance metrics This visualization shows how 5-fold cross-validation works: Leave-one-out is a special case of k-fold cross-validation where k equals the number of data points. In each iteration, we: 1. Hold out a single observation for testing 2. Train on all other observations 3. Repeat for every observation 4. Average the performance metrics This approach can be very computationally intensive for large datasets or complex models. Cross-validation is especially important in Bayesian modeling for several reasons: However, cross-validation for Bayesian models presents two key challenges: Computational cost: Bayesian models fitted with MCMC can take hours or days to run, making it impractical to refit them k times for cross-validation Proper scoring: We need appropriate metrics for evaluating predictive performance in a Bayesian framework Next, we’ll see how these challenges are addressed. When comparing Bayesian models, we use the expected log predictive density (ELPD) as our metric. This measures how well the model predicts new data points on the log scale. For a single observation, the log predictive density is: \\[\\log p(y_i | y_{-i})\\] where\\(y_i\\)is the observation we’re trying to predict, and\\(y_{-i}\\)represents all other observations that were used for training. For the entire dataset, we sum across all observations: \\[\\text{ELPD} = \\sum_{i=1}^{n} \\log p(y_i | y_{-i})\\] The ELPD has several desirable properties: Computing the ELPD exactly requires fitting the model n times (for n data points), which brings us back to the computational challenge. For complex Bayesian models, true leave-one-out cross-validation (LOO-CV) is often computationally infeasible",
    "chunk_id": "Adv_cognitive_modelling_chapter_8_model_comparison_in_cognitive_science.json_chunk_5"
  },
  {
    "document_type": "online_article",
    "title": "Chapter 8 Model Comparison in Cognitive Science",
    "author": "Riccardo Fusaroli",
    "source": "https://fusaroli.github.io/AdvancedCognitiveModeling2023/model-comparison-in-cognitive-science.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". For complex Bayesian models, true leave-one-out cross-validation (LOO-CV) is often computationally infeasible. Pareto-smoothed importance sampling leave-one-out cross-validation (PSIS-LOO) provides an elegant solution by approximating LOO-CV using just a single model fit. When we fit a Bayesian model, we obtain samples from the posterior distribution\\(p(\\theta|y_1,,y_n)\\)- the distribution of model parameters given all observations. For LOO-CV, we need\\(p(\\theta|y_1,,y_{i-1},y_{i+1},,y_n)\\)- the distribution without the i-th observation. Importance sampling bridges this gap by reweighting the full posterior samples to approximate the LOO posterior. The importance weights for the i-th observation are: \\[w_i(\\theta) = \\frac{p(\\theta|y_1,,y_{i-1},y_{i+1},,y_n)}{p(\\theta|y_1,,y_n)} \\propto \\frac{1}{p(y_i|\\theta)}\\] By Bayes’ theorem, this simplifies to: w_i(θ) ∝ 1 / p(yi|θ) These weights effectively “undo” the influence of the i-th observation on the posterior. However, standard importance sampling can be unstable when: * The full posterior and LOO posterior differ substantially * Some importance weights become extremely large * The variance of the weights is high Pareto smoothing improves the reliability of importance sampling: The diagnostic parameter k from the Pareto fit helps assess reliability: * k < 0.5: Reliable estimation * 0.5 < k < 0.7: Somewhat reliable, proceed with caution * k > 0.7: Unreliable, consider using other methods for this observation These diagnostics help identify problematic observations that might require more attention or alternative methods",
    "chunk_id": "Adv_cognitive_modelling_chapter_8_model_comparison_in_cognitive_science.json_chunk_6"
  },
  {
    "document_type": "online_article",
    "title": "Chapter 8 Model Comparison in Cognitive Science",
    "author": "Riccardo Fusaroli",
    "source": "https://fusaroli.github.io/AdvancedCognitiveModeling2023/model-comparison-in-cognitive-science.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". The full PSIS-LOO method follows these steps: Fit the Bayesian model once to all available data For each observation i: Calculate raw importance weights using the log-likelihood: w_i(θ) ∝ 1/p(yi|θ) Apply Pareto smoothing to stabilize the largest weights Normalize the smoothed weights Use the weights to compute the expected log predictive density (ELPD) Sum the individual ELPD contributions to get the overall PSIS-LOO estimate [I NEED TO FIND A BETTER WAY TO EXPLAIN AND VISUALIZE!] The red circle represents our “left-out” data point, while the blue line shows the model fit using all data points (including that red circle). The red diamond shows the prediction we get when we actually refit the model without the red circle. When we fit a model (the blue line), each data point “pulls” the model fit toward itself to some degree. The red circle data point influenced the original model to bend slightly closer to it. This is why the red circle appears relatively close to the blue line—it helped shape that line! When we perform true leave-one-out cross-validation, we remove that red circle point completely and refit the model using only the remaining data. Without the “pull” from that point, the model (which we don’t directly show) follows a slightly different path determined solely by the other points. The prediction from this new model (the red diamond) naturally lands in a different position",
    "chunk_id": "Adv_cognitive_modelling_chapter_8_model_comparison_in_cognitive_science.json_chunk_7"
  },
  {
    "document_type": "online_article",
    "title": "Chapter 8 Model Comparison in Cognitive Science",
    "author": "Riccardo Fusaroli",
    "source": "https://fusaroli.github.io/AdvancedCognitiveModeling2023/model-comparison-in-cognitive-science.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". The prediction from this new model (the red diamond) naturally lands in a different position. This difference between the original model prediction and the leave-one-out prediction is exactly what makes cross-validation valuable: It reveals how much individual data points influence your model It gives a more honest assessment of how your model will perform on truly unseen data Large differences can help identify influential or outlier points The purple diamond (PSIS-LOO prediction) attempts to approximate where that red diamond would be without actually refitting the model, by mathematically down-weighting the influence of the left-out point—which is why it’s positioned close to the red diamond if the approximation is working well. Now that we understand the principles, let’s apply these techniques to compare cognitive models using a simulation-based approach. This approach has two key advantages: We’ll simulate data from two different model types: By fitting both models to data generated from each type of agent, we can evaluate whether our model comparison techniques correctly identify the true generating model. Now we need to implement our two competing models in Stan. Both will be multilevel (hierarchical) to account for individual differences among agents. The key feature for model comparison is that we’ll include alog_likcalculation in thegenerated quantitiesblock of each model. When comparing models, we need a way to quantify how well each model explains the observed data. The log-likelihood represents the logarithm of the probability that a model would generate the observed data given specific parameter values. Given certain values for our parameters (let’s say a bias of 0 and beta for memory of 1) and for our variables (let’s say the vector of memory values estimated by the agent on a trial by trial basis), the model will predict a certain distribution of outcomes, that is, a certain distribution of choices (n times right, m times left hand)",
    "chunk_id": "Adv_cognitive_modelling_chapter_8_model_comparison_in_cognitive_science.json_chunk_8"
  },
  {
    "document_type": "online_article",
    "title": "Chapter 8 Model Comparison in Cognitive Science",
    "author": "Riccardo Fusaroli",
    "source": "https://fusaroli.github.io/AdvancedCognitiveModeling2023/model-comparison-in-cognitive-science.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". Comparing this to the actual data, we can identify how likely the model is to produce it. In other words, the probability that the model will actually generate the data we observed out of all its possible outcomes. Remember that we are doing Bayesian statistics, so this probability needs to be combined with the probability of the parameter values given the priors on those parameters. This would give us aposterior likelihoodof the model’s parameter values given the data. The last step is that we need to work on a log scale. Working on a log scale is very useful because it avoids low probabilities (close to 0) being rounded down to exactly 0. By log-transforming the posterior likelihood, we now have thelog-posterior likelihood. Now, remember that our agent’s memory varies on a trial by trial level. In other words, for each data point, for each agent we can calculate separate values of log-posterior likelihood for each of the possible values of the parameters. That is, we can have a distribution of log-posterior likelihood for each data point. Telling Stan to calculate these distributions is straightforward: we add to thegenerated quantitiesblock the same log probability statements used in the model block, but save them to variables instead of adding them to the target. N.B. Some of you might be wandering: if Stan is already using the log-posterior probability in the sampling process, why do we need to tell it to calculate and save it? Fair enough point. But Stan does not save by default (to avoid clogging your computer with endless data) and we need the log posterior likelihood saved as “log_lik” in order to be able to use more automated functions later on. Here’s the Stan model for the biased agent (remember that we will add the log_lik part in the generated quantities block!). Let’s break down this Stan model: Data Block: Defines the input data - number of trials, number of agents, and the choice data matrix",
    "chunk_id": "Adv_cognitive_modelling_chapter_8_model_comparison_in_cognitive_science.json_chunk_9"
  },
  {
    "document_type": "online_article",
    "title": "Chapter 8 Model Comparison in Cognitive Science",
    "author": "Riccardo Fusaroli",
    "source": "https://fusaroli.github.io/AdvancedCognitiveModeling2023/model-comparison-in-cognitive-science.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". Let’s break down this Stan model: Data Block: Defines the input data - number of trials, number of agents, and the choice data matrix. Parameters Block: Specifies the parameters we want to estimate: thetaM: The population mean bias thetaSD: The population standard deviation of bias theta: Individual bias parameters for each agent Model Block: Defines the prior distributions and likelihood function: Priors for population parameters Individual parameters drawn from the population distribution Likelihood of observing the choice data given the parameters Generated Quantities Block: Calculates additional quantities of interest: Prior and posterior predictive samples Log-likelihood for each observation - this is crucial for model comparison The most important part for model comparison is the log_lik calculation in the generated quantities block. This computes the log probability of each observation given the model and its parameters, which we’ll use for comparing models. Now let’s implement our second model - the memory agent model: The memory agent model is more complex, but follows a similar structure: Data Block: Includes the same data as the biased model, plus the opponent’s choices. Parameters Block: Includes parameters for the memory model: biasM: Population mean baseline bias betaM: Population mean memory sensitivity tau: Population standard deviations z_IDs: Standardized individual parameters L_u: Cholesky factor of correlation matrix Transformed Parameters Block: Calculates derived quantities: memory: The memory state for each agent and trial IDs: Individual parameters for each agent Model Block: Defines priors and likelihood: Priors for population parameters Memory-based choice likelihood Generated Quantities Block: Calculates additional quantities: Prior and posterior predictive samples Log-likelihood for each observation The use of a non-centered parameterization for the individual parameters (through z_IDs and transformation) is a technique to improve sampling efficiency in hierarchical models",
    "chunk_id": "Adv_cognitive_modelling_chapter_8_model_comparison_in_cognitive_science.json_chunk_10"
  },
  {
    "document_type": "online_article",
    "title": "Chapter 8 Model Comparison in Cognitive Science",
    "author": "Riccardo Fusaroli",
    "source": "https://fusaroli.github.io/AdvancedCognitiveModeling2023/model-comparison-in-cognitive-science.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". This is important when estimating multilevel models with potentially correlated parameters. Now that we’ve defined our models, we’ll fit them to our simulated data and perform model comparison. We’ll fit both models to both types of data: Biased agent model fitted to biased agent data Biased agent model fitted to memory agent data Memory agent model fitted to biased agent data Memory agent model fitted to memory agent data Now that we’ve fit our models, we can use cross-validation techniques to compare them. We’ll start with PSIS-LOO since it’s computationally efficient, and then validate with true k-fold cross-validation. To better understand how our models perform, let’s visualize the pointwise differences in ELPD: It’s quite clear that the bulk of the data a equally well explained by the models. And the differences for the biased data are tricky to see in the plot. Yet, we can see that in memory data there are a non trivial amount of data points better explained by the memory model (the true underlying data-generating mechanism). Now let’s perform formal model comparison using the loo_compare function, which computes the difference in ELPD between models and the standard error of this difference: Here it is clear that formal model comparison can clearly pick the right model. Hurrah! While PSIS-LOO is efficient, we need to check how it relates with true cross-validation. First we create new stan models, which separates data into training and test data and include the ability to calculate log-likelihood for test data. This is crucial for cross-validation, as we need to evaluate the model’s performance on unseen data. These CV-ready models extend our original models with additional structures to handle test data and compute separate log-likelihoods for training and test observations. Now, let’s demonstrate how to implement k-fold cross-validation using these models (N.b",
    "chunk_id": "Adv_cognitive_modelling_chapter_8_model_comparison_in_cognitive_science.json_chunk_11"
  },
  {
    "document_type": "online_article",
    "title": "Chapter 8 Model Comparison in Cognitive Science",
    "author": "Riccardo Fusaroli",
    "source": "https://fusaroli.github.io/AdvancedCognitiveModeling2023/model-comparison-in-cognitive-science.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". Now, let’s demonstrate how to implement k-fold cross-validation using these models (N.b. we only fit both models to the memory data, I still need to implement the full comparison against biased data as well) Funnily enough cross-validation indicates the wrong model. While cross-validation and ELPD provide powerful tools for model comparison, it’s important to understand their limitations: Training vs. Transfer Generalization Cross-validation only assesses a model’s ability to generalize to new data from the same distribution (training generalization). It doesn’t evaluate how well models transfer to different contexts or populations (transfer generalization). Model Misspecification All models are wrong, but some are useful. Cross-validation helps identify which wrong model is most useful for prediction, but doesn’t guarantee we’ve captured the true generating process. Limited Data With limited data, cross-validation estimates can have high variance, especially for complex models. K-fold CV with small k can help mitigate this issue. Computational Cost True cross-validation requires refitting models multiple times, which can be prohibitively expensive for complex Bayesian models. PSIS-LOO offers an efficient approximation but may not always be reliable. Parameter vs. Predictive Focus Model comparison based on predictive performance might select different models than if we were focused on accurate parameter estimation. The “best” model depends on your goals. Compare the models on different subsets of the data (e.g., early vs. late trials). Does the preferred model change depending on which portion of the data you use? Experiment with different priors for the models. How sensitive are the model comparison results to prior choices? Implement a different model (e.g., win-stay-lose-shift) and compare it to the biased and memory models. Which performs best? Explore how the amount of data affects model comparison",
    "chunk_id": "Adv_cognitive_modelling_chapter_8_model_comparison_in_cognitive_science.json_chunk_12"
  },
  {
    "document_type": "online_article",
    "title": "Chapter 8 Model Comparison in Cognitive Science",
    "author": "Riccardo Fusaroli",
    "source": "https://fusaroli.github.io/AdvancedCognitiveModeling2023/model-comparison-in-cognitive-science.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". Which performs best? Explore how the amount of data affects model comparison. How many trials do you need to reliably identify the true model? Investigate the relationship between model complexity and predictive performance in this context. Are there systematic patterns in when simpler models are preferred? However, we need to think carefully about what we mean by “out of sample.” There are actually two distinct types of test sets we might consider: internal and external. Internal test sets come from the same data collection effort as our training data - for example, we might randomly set aside 20% of our matching pennies games to test on. While this approach helps us detect overfitting to specific participants or trials, it cannot tell us how well our model generalizes to truly new contexts. Our test set participants were recruited from the same population, played the game under the same conditions, and were influenced by the same experimental setup as our training participants. External test sets, in contrast, come from genuinely different contexts. For our matching pennies model, this might mean testing on games played: The distinction matters because cognitive models often capture not just universal mental processes, but also specific strategies that people adopt in particular contexts. A model that perfectly predicts behavior in laboratory matching pennies games might fail entirely when applied to high-stakes poker games, even though both involve similar strategic thinking. This raises deeper questions about what kind of generalization we want our models to achieve. Are we trying to build models that capture universal cognitive processes, or are we content with models that work well within specific contexts? The answer affects not just how we evaluate our models, but how we design them in the first place. In practice, truly external test sets are rare in cognitive science - they require additional data collection under different conditions, which is often impractical",
    "chunk_id": "Adv_cognitive_modelling_chapter_8_model_comparison_in_cognitive_science.json_chunk_13"
  },
  {
    "document_type": "online_article",
    "title": "Chapter 8 Model Comparison in Cognitive Science",
    "author": "Riccardo Fusaroli",
    "source": "https://fusaroli.github.io/AdvancedCognitiveModeling2023/model-comparison-in-cognitive-science.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". In practice, truly external test sets are rare in cognitive science - they require additional data collection under different conditions, which is often impractical. This means we must be humble about our claims of generalization. When we talk about a model’s predictive accuracy, we should be clear that we’re usually measuring its ability to generalize within a specific experimental context, not its ability to capture human cognition in all its diversity. This limitation of internal test sets is one reason why cognitive scientists often complement predictive accuracy metrics with other forms of model evaluation, such as testing theoretical predictions on new tasks or examining whether model parameters correlate sensibly with individual differences. These approaches help us build confidence that our models capture meaningful cognitive processes rather than just statistical patterns specific to our experimental setup. ***",
    "chunk_id": "Adv_cognitive_modelling_chapter_8_model_comparison_in_cognitive_science.json_chunk_14"
  },
  {
    "document_type": "online_article",
    "title": "Introduction to Bayesian Data Analysis for Cognitive Science",
    "author": "Bruno Nicenboim",
    "source": "https://bruno.nicenboim.me/bayescogsci/ch-custom.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": "Stan includes a large number of distributions, but what happens if we need a distribution that is not provided? In many cases, we can simply build a custom distribution by combining the ever-growing number of functions available in the Stan language. In previous chapters, when faced with response times, we assumed a log-normal distribution. The log-normal distribution moves the inferences relating to the location parameter into a multiplicative frame (see online sectionA.4). Another alternative, however, is to assume a “reciprocal”-normal distribution of response times. This is referred to hereafter as rec-normal in the text, and as the\\(\\mathit{RecNormal}\\)distribution in equations. That is, we may want to assume that the reciprocal of the response times are normally distributed. This assumption may be theoretically motivated(Harris et al.2014; Harris and Waddington2012)or it may arise from the application of the Box-Cox variance stabilizing transform procedure(Box and Cox1964). An example from psycholinguistics of a data analysis with a reciprocal transform of reading time data appears inWu, Kaiser, and Vasishth (2017). \\[\\begin{equation} \\begin{aligned} 1/y &\\sim \\mathit{Normal}(\\mu, \\sigma) \\\\ y &\\sim \\mathit{RecNormal}(\\mu, \\sigma) \\end{aligned} \\tag{10.1} \\end{equation}\\] An interesting aspect of the rec-normal is that it affords an interpretation of the location parameter in terms of rate or speed rather than time. Analogously to the case of the log-normal, neither the location\\(\\mu\\)nor the scale\\(\\sigma\\)are in the same scale as the dependent variable\\(y\\). These parameters are in the same scale as the transformed dependent variable (here,\\(1/y\\)) that is assumed to be normally distributed. By setting\\(\\mu = 0.002\\)and\\(\\sigma = 0.0004\\), data can be generated from the rec-normal that looks right-skewed and not unlike a distribution of response times. The code below shows some summary statistics of the generated data. Figure10.1shows the distribution generated with the code shown above",
    "chunk_id": "Adv_cognitive_modelling_introduction_to_bayesian_data_analysis_for_cognitive_science.json_chunk_1"
  },
  {
    "document_type": "online_article",
    "title": "Introduction to Bayesian Data Analysis for Cognitive Science",
    "author": "Bruno Nicenboim",
    "source": "https://bruno.nicenboim.me/bayescogsci/ch-custom.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". The code below shows some summary statistics of the generated data. Figure10.1shows the distribution generated with the code shown above. FIGURE 10.1: Distribution of synthetic data with a rec-normal distribution with parameters\\(\\mu = 0.002\\)and\\(\\sigma =0.0004\\). We can fit the rec-normal distribution to the response times in a simple model with a normal likelihood, by storing the reciprocal of the response times (1/RT) in the vector variablerecRT(rather than storing the “raw” response times): One issue here is that the parameters of the likelihood,muandsigmaare going to be very far away from the unit scale (\\(0.002\\)and\\(0.0004\\)respectively). Due to the way Stan’s sampler is built, parameters that are too small (much smaller than 1) or too large (much larger than 1) can cause convergence problems. A straightforward solution is to fit the normal distribution to parameters in reciprocal of seconds rather than milliseconds; this would make the parameters have values that are\\(1000\\)times larger (\\(2\\)and\\(0.4\\)respectively). We can do this using thetransformed parametersblock.41Although we usemuandsigmato fit the data, the priors are defined on the parametersmu_sandsigma_s(\\(\\mu_s\\)and\\(\\sigma_s\\)). Unless one can rely on previous estimates, finding good priors for\\(\\mu_s\\)and\\(\\sigma_s\\)is not trivial. To define appropriate priors, we would need to start with relatively arbitrary priors, inspect the prior predictive distributions, adjust the priors, and repeat the inspection of prior predictive distributions until these distributions start to look realistic",
    "chunk_id": "Adv_cognitive_modelling_introduction_to_bayesian_data_analysis_for_cognitive_science.json_chunk_2"
  },
  {
    "document_type": "online_article",
    "title": "Introduction to Bayesian Data Analysis for Cognitive Science",
    "author": "Bruno Nicenboim",
    "source": "https://bruno.nicenboim.me/bayescogsci/ch-custom.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". In the interest of conserving space, we skip this iterative process here, and assign the following priors: \\[\\begin{equation} \\begin{aligned} \\mu_s & \\sim \\mathit{Normal}(2, 1)\\\\ \\sigma_s & \\sim \\mathit{Normal}_+(0.4, 0.2) \\end{aligned} \\end{equation}\\] This model is implemented in the filenormal_recrt.stan, available in thebcogscipackage: Fit and display the summary of the previous model: Is a rec-normal likelihood more appropriate than a log-normal likelihood? As things stand, we cannot compare the models with these two likelihoods. This is because the dependent variables are different: we cannot compare reciprocal response times with untransformed response times on the millisecond scale. Model comparison with the Bayes factor or cross-validation can only compare models with the same dependent variables; see chapters12-14. If we do want to compare the reciprocal-normal likelihood and the log-normal likelihood, we have to set up the models with the two likelihoods in such a way that the dependent measure is on the raw millisecond scale in each model. This means that for the reciprocal normal likelihood, the model will receive as data raw reading times in milliseconds, and these will be treated as a transformed random variable from reciprocal reading times. This approach is discussed next, but requires knowledge of the Jacobian adjustment (seeRoss (2002)). To work with the original dependent variable (RTrather than1/RT) we need to perform achange of variables: If the random variable X represents the reciprocal reading times (\\(1/RT\\)), we can transform this random variable to a new one,\\(Y = 1/X = 1/(1/RT) = RT\\), yielding a transformed random variable\\(Y\\)which represents reading time",
    "chunk_id": "Adv_cognitive_modelling_introduction_to_bayesian_data_analysis_for_cognitive_science.json_chunk_3"
  },
  {
    "document_type": "online_article",
    "title": "Introduction to Bayesian Data Analysis for Cognitive Science",
    "author": "Bruno Nicenboim",
    "source": "https://bruno.nicenboim.me/bayescogsci/ch-custom.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". This change of variables requires an adjustment to the (unnormalized log) posterior probability to account for the distortion caused by the transform.42The probability must be scaled by aJacobianadjustment, which, in the univariate case as this one, is the absolute value of the derivative of the transform.43The absolute value of any number is represented by enclosing it in two vertical bars: e.g.,\\(|-2| = 2\\). \\[\\begin{equation} \\begin{aligned} p(\\mathit{RT}_n | \\mu, \\sigma )& = \\mathit{Normal}(1/\\mathit{RT}_n | \\mu, \\sigma) \\left| \\frac{\\mathrm{d}}{\\mathrm{d}\\mathit{RT}_n} 1/\\mathit{RT}_n \\right| = \\\\ & \\mathit{Normal}(1/\\mathit{RT}_n | \\mu, \\sigma) \\cdot \\left| - 1/\\mathit{RT}_n^2 \\right| = \\\\ & \\mathit{Normal}(1/\\mathit{RT}_n | \\mu, \\sigma) \\cdot 1/\\mathit{RT}_n^2 \\end{aligned} \\end{equation}\\] If we omit the Jacobian adjustment, we are essentially fitting a different and unnormalized probability density function (this will be shown later in this chapter). The discrepancy between the correct and incorrect posterior would depend on how large the Jacobian adjustment for our model is. Because Stan works in log space, rather than multiplying the Jacobian adjustment, we add its logarithm to the log-probability density (\\(\\log(1/\\mathit{RT}_n^2) = - 2 \\cdot \\log(\\mathit{RT}_n)\\)). The contribution to the log likelihood (of\\(\\mu\\)and\\(\\sigma\\)) with its adjustment based from an individual observation,\\(\\mathit{RT}_{n}\\), would be as follows. \\[\\begin{equation} \\log(\\mathit{Normal}(1/\\mathit{RT}_n | \\mu, \\sigma)) - 2 \\cdot \\log(\\mathit{RT}_n) \\end{equation}\\] We obtain the log likelihood based on all the\\(N\\)observations by summing the log likelihood of individual observations. \\[\\begin{equation} \\log \\mathcal{L} = \\sum_{n=1}^N \\log(\\mathit{Normal}(1/\\mathit{RT}_n | \\mu, \\sigma)) - \\sum_{n=1}^N 2 \\cdot \\log(\\mathit{RT}_n) \\end{equation}\\] In Stan, this summing up is done as follows. The functionnormal_lpdf()applied to a vector already returns the sum of the individual log-probability densities",
    "chunk_id": "Adv_cognitive_modelling_introduction_to_bayesian_data_analysis_for_cognitive_science.json_chunk_4"
  },
  {
    "document_type": "online_article",
    "title": "Introduction to Bayesian Data Analysis for Cognitive Science",
    "author": "Bruno Nicenboim",
    "source": "https://bruno.nicenboim.me/bayescogsci/ch-custom.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". The functionnormal_lpdf()applied to a vector already returns the sum of the individual log-probability densities. The Jacobian adjustment2*log(RT), which returns a vector of values, has to be summed up and added in manually (the term therefore becomes-sum(2*log(RT))). Before fitting the model with the change of variables, we are going to truncate the distribution. We didn’t encounter negative values in our synthetic data, but this was because the distribution was not too spread out; that is, the scale was much smaller than the location (\\(\\sigma << \\mu\\)). However, in principle we could end up generating negative values. For this reason, we truncate the underlying normal distribution (for more details, see online sectionA.2). The reciprocal truncated normal distribution has been argued to be an appropriate model of response times, neural inter-spike intervals, and latency distributions of saccades in a simple optimality model in which reward is maximized to yield an optimal response rate(Harris et al.2014; Harris and Waddington2012). Because we have\\(N\\)observations, the truncation consists of addinN * normal_lccdf(0 | mu, sigma)totarget; also see section8.4.1. The complete model,recnormal_rt.stan, including the truncation is as follows: Next, generate data from a reciprocal truncated normal distribution: Fit the model to the data: Print the posterior summary: We get the same results as before, but now we could potentially compare this model to one that assumes a log-normal likelihood, for example. An important question is the following: Does every transformation of a random variable require a Jacobian adjustment? Essentially, if we assign a distribution to a random variable and then transform it, this does not require a Jacobian adjustment. Alternatively, if we apply a transformation on a random variable first, and then assign a distribution to the transformed random variable afterwards, we have a change of variables. This requires a Jacobian adjustment",
    "chunk_id": "Adv_cognitive_modelling_introduction_to_bayesian_data_analysis_for_cognitive_science.json_chunk_5"
  },
  {
    "document_type": "online_article",
    "title": "Introduction to Bayesian Data Analysis for Cognitive Science",
    "author": "Bruno Nicenboim",
    "source": "https://bruno.nicenboim.me/bayescogsci/ch-custom.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". This requires a Jacobian adjustment. This is the reason why1 ./ RTrequires a Jacobian adjustment, but notmu_s,mu,sigma_s, orsigma_sin the previous model. As a last step, we can encapsulate our new distribution in a function, and also create a random number generator function. This is done in a block calledfunctions. To create a function, we need to specify the type of every argument and the type that the function returns. As a simple example, if we would like a function to center a vector, we would do it as follows: We want to create a log(PDF) function, similar to the native Stan functions that end in_lpdf. Our function will take as arguments a vectorRT, and real numbersmuandsigma. In_lpdffunctions, (some of) the arguments (e.g.,RT,mu, andsigma) can be vectorized, but the output of the function is always a real number: the sum of the log(PDF) evaluated at every value of the random variable at the left of the pipe. As we show below, to do that we just move the right hand side oftargetin our original model inside our new function. See the section entitled Further Reading at the end of this chapter for more about Stan functions. For our custom random number generator function (which should end with_rng), we have the added complication that the function is truncated. We simply generate random values from a normal distribution, do the reciprocal transformation and if the number is above zero, this number is returned; otherwise, a new number is drawn. This implementation may be inefficient when rejections occur frequently. Another, more complex implementation using the inverse CDF approach can be found inStan Development Team (2024)(section 21.10 of the User’s guide). The complete code can be found inrecnormal_rt_f.stan, and is also shown below: Fit the model to the simulated data: Print the summary: The model converged, but did it work? At the very least we expect that the simulated data that we used to test the model shows a very similar distribution to the posterior predictive distributions",
    "chunk_id": "Adv_cognitive_modelling_introduction_to_bayesian_data_analysis_for_cognitive_science.json_chunk_6"
  },
  {
    "document_type": "online_article",
    "title": "Introduction to Bayesian Data Analysis for Cognitive Science",
    "author": "Bruno Nicenboim",
    "source": "https://bruno.nicenboim.me/bayescogsci/ch-custom.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". This is because we are fitting the data with the same function that we use to generate the data. Figure10.2shows that the simulated data and the posterior predictive distributions are similar. FIGURE 10.2: A posterior predictive check offit_recin comparison with the simulated data. Our synthetic data set was generated by first defining aground truthvector of parameters\\(\\langle \\mu; \\sigma \\rangle\\). We would expect that the true values of the parameters\\(\\mu\\)and\\(\\sigma\\)should be well inside the bulk of the posterior distribution of our model. We investigate this by plotting the true values of the parameters together with their posterior distributions using the functionmcmc_recover_hist()ofbayesplotas shown below in Figure10.3. FIGURE 10.3: Posterior distributions of the parameters offit_rectogether with their true values. Even though this approach can capture serious misspecifications in our models, it has three important shortcomings. First, it’s unclear what we should conclude if the true value of a parameter is not in the bulk of its posterior distribution. Even in a well-specified model, if we inspect enough parameters we will find that for some parameters, the bulks of their respective marginal posterior distributions can be relatively far away from their true values. The second shortcoming is that if the posteriors that we obtain are very wide, it might not be clear what constitutes the bulk of the posterior distribution that needs to be inspected. The third shortcoming is that regardless of how a successful recovery of parameters is defined, we might be able to recover a posterior based on data generated from some parts of the parameter space, but not based on data generated from other parts of parameter space(Talts et al.2018). However, inspecting the entire parameter space is infeasible",
    "chunk_id": "Adv_cognitive_modelling_introduction_to_bayesian_data_analysis_for_cognitive_science.json_chunk_7"
  },
  {
    "document_type": "online_article",
    "title": "Introduction to Bayesian Data Analysis for Cognitive Science",
    "author": "Bruno Nicenboim",
    "source": "https://bruno.nicenboim.me/bayescogsci/ch-custom.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". However, inspecting the entire parameter space is infeasible. An alternative to our approach of plotting the true values of the parameters together with their posterior distributions is called simulation-based calibration(Talts et al.2018; Modrák et al.2023), which extends ideas ofCook, Gelman, and Rubin (2006). This is discussed next. Talts et al. (2018)suggest the simulation-based calibration as the procedure for validating a model. We check that the Bayesian computation isfaithfulin the sense that it is not biased. Our goal is to ensure that our model neither overestimates nor underestimates, nor does it possess incorrect precision in the parameters, given the data and priors. As initial steps, we employ two different implementations of the same statistical model: (1-2) a generator capable of directly simulating draws from the prior predictive distribution, and (3) a probabilistic program that, when combined with a posterior approximation algorithm (such as a Stan sampler), samples from the posterior distribution. Finally, (4-5) we verify that the results from both implementations have the same distribution conditional on the data. \\[\\begin{equation} \\tilde{\\Theta}_n \\sim p(\\boldsymbol{\\Theta}) \\end{equation}\\] Here,\\(p(\\boldsymbol{\\Theta})\\)represents a joint prior distributions of vector of parameters. In our previous example, the vector of parameters is\\(\\langle \\mu; \\sigma \\rangle\\), and the joint prior distribution is two independent distributions, a normal and a truncated normal. Crucially, the prior distributions should be meaningful; that is, one should use priors that are at least regularizing or weakly informative. The prior space plays a crucial role because it determines the parameter space where we will verify the correctness or faithfulness of the model",
    "chunk_id": "Adv_cognitive_modelling_introduction_to_bayesian_data_analysis_for_cognitive_science.json_chunk_8"
  },
  {
    "document_type": "online_article",
    "title": "Introduction to Bayesian Data Analysis for Cognitive Science",
    "author": "Bruno Nicenboim",
    "source": "https://bruno.nicenboim.me/bayescogsci/ch-custom.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". The prior space plays a crucial role because it determines the parameter space where we will verify the correctness or faithfulness of the model. Assuming 150 samples (from the priors), this step for our model would be as follows: \\[\\begin{equation} \\tilde{D}_n \\sim p(\\boldsymbol{D} | \\tilde{\\Theta}_n) \\end{equation}\\] The previous equation indicates that each data set\\(\\tilde{D}_n\\)is sampled from each of the generated parameters,\\(\\tilde{\\Theta}_n\\). Following our previous example, use the reciprocal truncated normal distribution to generate data sets of response times: Now,rt_tildeconsists of a list with 150 vectors of 500 observations each. Each list represents a simulated data, which corresponds to\\(\\tilde{D}_{n}\\). After fitting the same model to each data set, we should compare the recovered posterior distribution for each parameter of each simulated data set; that is,\\(p(\\Theta_n | \\tilde{D}_{n})\\), with the parameters that were used to generate the data,\\(\\tilde{\\Theta}_{n}\\). This comparison is represented byin the code below (that is, it is not yet implemented in the code shown below). This raises the question of how to compare the posterior distribution with the ground truth values of the parameters. The procedure shown before (1-3) defines a natural condition for assessing whether the computed posterior distributions match the exact posterior distributions(Talts et al.2018; Cook, Gelman, and Rubin2006). This condition is met if the generator, probabilistic program, and posterior approximation algorithm function match: The generator and the probabilistic program must accurately represent the same data-generating process, while the posterior approximation algorithm should yield samples that closely match the correct posterior for the probabilistic program, based on data simulated from the prior",
    "chunk_id": "Adv_cognitive_modelling_introduction_to_bayesian_data_analysis_for_cognitive_science.json_chunk_9"
  },
  {
    "document_type": "online_article",
    "title": "Introduction to Bayesian Data Analysis for Cognitive Science",
    "author": "Bruno Nicenboim",
    "source": "https://bruno.nicenboim.me/bayescogsci/ch-custom.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". Any discrepancy suggests a mismatch among the components(Modrák et al.2023).44 The next two steps describe a well-defined comparison of the exact posterior and prior distribution(different calibration checking methods differ in how exactly they test for mismatches between the distributions; Modrák et al.2023). Talts et al. (2018)demonstrate that the match between the exact posterior and prior can be evaluated by examining whether, for each element of\\(\\boldsymbol{\\Theta}\\)(e. g.,\\(\\langle \\mu; \\sigma \\rangle\\)), therank statisticsof the prior sample relative to\\(S\\)posterior samples will be uniformly distributed across\\([0, S]\\). In other words, for each sample of the prior (e.g.,\\(\\tilde{\\mu}_{n}\\)), we calculate the number of samples of the posterior that is smaller than the corresponding value of the parameter sampled, and we examine its distribution. A mismatch between the exact posterior and our posterior would show up as a non-uniform distribution. As a next step, we examine this new distribution visually using a histogram with\\(S + 1\\)possible ranks (from\\(0\\)to\\(S\\)). There are two issues that we need to take into account(Talts et al.2018): Regardless of our model, histograms will deviate from uniformity if the posterior samples are dependent. This can be solved bythinningthe samples of the posterior, that is removing a number of intermediate samples(Talts et al.2018recommend between 6 and 10). To reduce the noise in the histogram, we should have bins of equal size. If\\(S + 1\\)are divisible by a large power of\\(2\\), e.g,\\(1024\\), we will be able to re-bin the histogram easily with bins of equal size. We complete the code shown in step 3 by generating an ensemble of ranks statistics as well. Here we encapsulate steps 1 to 4 into a function. As a last step, we use a histogram for each parameter to identify deviations of uniformity",
    "chunk_id": "Adv_cognitive_modelling_introduction_to_bayesian_data_analysis_for_cognitive_science.json_chunk_10"
  },
  {
    "document_type": "online_article",
    "title": "Introduction to Bayesian Data Analysis for Cognitive Science",
    "author": "Bruno Nicenboim",
    "source": "https://bruno.nicenboim.me/bayescogsci/ch-custom.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". Here we encapsulate steps 1 to 4 into a function. As a last step, we use a histogram for each parameter to identify deviations of uniformity. If the posterior estimates are correct, then each of the\\(B\\)bins has a probability of\\(1/B\\)that a simulation (i.e., an individual rank) falls into it:\\(\\mathit{Binomial}(N_{sim}, 1/B)\\). This allow us to complement the histograms with confidence intervals, indicating where the variation expected from a uniform histogram should be. Use the code below to build the plot shown in Figure10.4. We can conclude that the implementation of our model (in the parameter space determined by the priors) is correct. FIGURE 10.4: Rank histograms of\\(\\mu\\)and\\(\\sigma\\)from the reciprocal truncated normal distribution. The dashed lines represent the 99% confidence interval. Next, we consider an example where simulation-based calibration can reveal a problem. Let’s assume that we made an error in the model implementation. We’ll fit anincorrectmodel: rather than the complete likelihood including the normal PDF and the truncation and Jacobian adjustments, we will fit only the normal PDF evaluated at the reciprocal of the response times, that istarget += normal_lpdf(1 ./ RT | mu, sigma);. Assessing the correctness of the model by looking at the recovery of the parameters is misleading in this case; this is evident from Figure10.5. One could conclude that the model is fine based on this plot, since the true values of the parameters are well inside the bulk of their posterior distributions. FIGURE 10.5: Posterior distributions of the parameters of an incorrect model (truncation and Jacobian adjustments missing) together with their true values. However, the rank histograms produced by the simulation-based calibration procedure in Figure10.6show very tall bins at the left and at the right of each histogram, exceeding the 99% CI. This is a very clear indication that there is a problem with the model specification: our incorrect model is overestimating\\(\\mu\\)and underestimating\\(\\sigma\\)",
    "chunk_id": "Adv_cognitive_modelling_introduction_to_bayesian_data_analysis_for_cognitive_science.json_chunk_11"
  },
  {
    "document_type": "online_article",
    "title": "Introduction to Bayesian Data Analysis for Cognitive Science",
    "author": "Bruno Nicenboim",
    "source": "https://bruno.nicenboim.me/bayescogsci/ch-custom.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". This is a very clear indication that there is a problem with the model specification: our incorrect model is overestimating\\(\\mu\\)and underestimating\\(\\sigma\\). This example illustrates the importance of simulation-based calibration. FIGURE 10.6: Rank histograms of\\(\\mu\\)and\\(\\sigma\\)from theincorrectimplementation of the reciprocal truncated normal distribution. The dashed lines represent the 99% confidence interval. In the previous sections, we have used only rank histograms. Even though histograms are a very intuitive means of visualization to assess model correctness, they might not be sensitive enough for small deviations(Talts et al.2018). Other visualizations might be better suited. Another limitation of histograms is that they are sensitive to the number of bins(Säilynoja, Bürkner, and Vehtari2022). One could bin the histograms multiple times, but this approach is difficult to interpret when there are many parameters, and can be vulnerable to multiple testing biases(Talts et al.2018). One alternative to rank histograms is visualizations based on the empirical cumulative density function of the ranks. This is briefly presented in online sectionB.7. Even though simulation-based calibration is a comprehensive approach to test model correctness, it has several drawbacks, regardless of the means of visualization: This approach requires fitting a model many times, which can be too time intensive for complex models. It’s worth bearing in mind that code with errors can sometimes show clear “catastrophic” failures in the recovery of the parameters. For this reason, one could start the verification of model correctness with a simple recovery of parameters(see Talts et al.2018; Gelman et al.2020), and then proceed with the simulation-based calibration procedure for at least some suspect aspects of the model (e.g., when working with a custom likelihood)",
    "chunk_id": "Adv_cognitive_modelling_introduction_to_bayesian_data_analysis_for_cognitive_science.json_chunk_12"
  },
  {
    "document_type": "online_article",
    "title": "Introduction to Bayesian Data Analysis for Cognitive Science",
    "author": "Bruno Nicenboim",
    "source": "https://bruno.nicenboim.me/bayescogsci/ch-custom.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". Another major limitation of simulation-based calibration is that it is concerned exclusively with the computational aspects of the analysis and offers no guarantee for any single observation. A complete Bayesian workflow should include prior and posterior predictive checks, see the online chapterFandSchad, Betancourt, and Vasishth (2020). Finally, it’s important to apply simulation-based calibration only after appropriate priors are set. This is important because only the priors determine the parameter space that will be inspected. Weak priors that may be good enough for estimation may nevertheless lead to a parameter space that is unrealistically large since, during the calibration stage, there are no independent data to constrain the space. This means that it is important to conduct prior predictive checks before assessing the correctness of the model with simulation-based calibration. There are cases when one needs a random variable with a distribution that is not included in Stan. Often one can find the PDF (or a CDF) derived in a paper, and one needs to implement it manually by writing the log PDF in the Stan language. Even though the exponential distribution is included in Stan, we demonstrate how we would include it step-by-step as if it weren’t available. This example extends the demonstration in section 22.1 of the User’s guide(Stan Development Team2024). The exponential distribution is used to model waiting times until a certain event occurs. Its PDF is the following: \\[\\begin{equation} f(x | \\lambda )={ \\begin{cases} \\lambda e^{-\\lambda x} & x\\geq 0,\\\\0&x<0. \\end{cases}} \\end{equation}\\] The parameter\\(\\lambda\\)is often called the rate parameter and must be positive. A higher value for the rate parameter leads to shorter waiting times on average. The mean of the distribution is\\(1/\\lambda\\). The exponential distribution has the key property of beingmemoryless",
    "chunk_id": "Adv_cognitive_modelling_introduction_to_bayesian_data_analysis_for_cognitive_science.json_chunk_13"
  },
  {
    "document_type": "online_article",
    "title": "Introduction to Bayesian Data Analysis for Cognitive Science",
    "author": "Bruno Nicenboim",
    "source": "https://bruno.nicenboim.me/bayescogsci/ch-custom.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". A higher value for the rate parameter leads to shorter waiting times on average. The mean of the distribution is\\(1/\\lambda\\). The exponential distribution has the key property of beingmemoryless. What this means is explained inRoss (2002)as follows: Suppose that\\(X\\)is a random variable with an exponential distribution as a PDF; the random variable represents the lifetime of an item (e.g.,\\(X\\)could represent the time it takes for a radioactive particle to completely decay). If the item is\\(t\\)time-units old, then the remaining life\\(s\\)of that item has the same probability distribution as the life of a new item. Mathematically, this amounts to stating that \\[\\begin{equation} P(X>s + t | X> t)= P(X>s) \\end{equation}\\] The implication of the memoryless property is that we do not need to know the age of an item to know what the distribution of its remaining life is. To give another example of memorylessness, the conditional probability that a certain event will happen in the next 100 ms is the same regardless of whether we have been already waiting 1000 ms, 10 ms, or 0 ms. Although the exponential distribution is not commonly used for modeling response times in cognitive science, it has been used in the past(Ashby and Townsend1980; Ashby1982). We focus on this distribution because of its simple analytical form. As a first step, we make our own version of the PDF in R, and then check that it integrates to one to verify that this is a proper distribution (and that we haven’t introduced a typo in the formula). To avoid underflow, that is getting a zero instead of a very small number, we’ll work in the log-scale. This will also be useful when we implement this function in Stan, thus the log PDF is \\[\\begin{equation} \\log(f(x| \\lambda ))= \\log(\\lambda) -\\lambda x \\end{equation}\\] where\\(x >0\\). Implement this function in R with the same arguments as thed*family of functions: iflog = TRUEthe output is a log density; call this new functiondexp2",
    "chunk_id": "Adv_cognitive_modelling_introduction_to_bayesian_data_analysis_for_cognitive_science.json_chunk_14"
  },
  {
    "document_type": "online_article",
    "title": "Introduction to Bayesian Data Analysis for Cognitive Science",
    "author": "Bruno Nicenboim",
    "source": "https://bruno.nicenboim.me/bayescogsci/ch-custom.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". Implement this function in R with the same arguments as thed*family of functions: iflog = TRUEthe output is a log density; call this new functiondexp2. Verify that this function integrates to one for some point values of its parameter\\(\\lambda\\)(here,\\(\\lambda = 1\\)and\\(\\lambda = 20\\)): To test our function, we’ll also need to generate random values from the exponential distribution. If the quantile function of the distribution exists, the inverse transform sampling is a relatively straightforward way to get pseudo random numbers sampled from a target distribution(for an accessible introduction to inverse sampling, see Lynch2007). Given a target distribution with a PDF\\(f\\), and a quantile function\\(F^{-1}\\)(the inverse of the CDF), the inverse transform sampling method consists of the following: In this case, the quantile function (the inverse of the CDF) is the following: \\[\\begin{equation} - \\log(1-p)/\\lambda \\end{equation}\\] Here is how one can derive this CDF and its inverse if they were not available to us. First, consider the fact that the CDF of the exponential distribution is as follows. The term\\(q\\)is some quantile of the distribution: \\[\\begin{equation} F(q) = \\int_0^q \\lambda \\exp(-\\lambda x)\\, \\mathrm{d}x \\end{equation}\\] We can solve this integral by using the\\(u\\)-substitution method(Salas, Etgen, and Hille2003). First, define \\[\\begin{equation} u = g(x) = -\\lambda x \\end{equation}\\] Then, the derivative\\(du/dx\\)is: \\[\\begin{equation} \\frac{\\mathrm{d}u}{\\mathrm{d}x} = -\\lambda \\end{equation}\\] This implies that\\(\\mathrm{d}u = - \\lambda \\mathrm{d}x\\), or that\\(- \\mathrm{d}u = \\lambda \\mathrm{d}x\\)",
    "chunk_id": "Adv_cognitive_modelling_introduction_to_bayesian_data_analysis_for_cognitive_science.json_chunk_15"
  },
  {
    "document_type": "online_article",
    "title": "Introduction to Bayesian Data Analysis for Cognitive Science",
    "author": "Bruno Nicenboim",
    "source": "https://bruno.nicenboim.me/bayescogsci/ch-custom.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". In the CDF, replace the term\\(\\lambda \\mathrm{d}x\\)with\\(-\\mathrm{d}u\\): \\[\\begin{equation} F(q) = \\int_0^q \\lambda \\exp(-\\lambda x)\\, \\mathrm{d}x = \\int_0^{-\\lambda q} (- \\exp(-\\lambda x)\\, \\mathrm{d}u) \\end{equation}\\] Rewriting\\(-\\lambda x\\)as\\(u\\), the CDF simplifies to: \\[\\begin{equation} F(q) = \\int_0^q \\lambda \\exp(-\\lambda x)\\, \\mathrm{d}x = \\int_0^q (- \\exp(u)\\, \\mathrm{d}u) \\end{equation}\\] We know from calculus that the integral of\\(-\\exp(u)\\)is\\(-\\exp(u)\\). So, the integral becomes: \\[\\begin{equation} F(q) = \\left[ - \\exp(u) \\right]_0^q \\end{equation}\\] Replacing\\(u\\)with\\(-\\lambda x\\), we get: \\[\\begin{equation} F(q) = \\left[ - \\exp(-\\lambda x) \\right]_0^q = 1- \\exp(-\\lambda q) \\end{equation}\\] Thus, we know that the CDF is\\(F(t) = 1- \\exp(-\\lambda q) = p\\), where\\(p\\)is the probability of observing the quantile\\(q\\)or some value smaller than\\(q\\). To derive the inverse of the CDF, solve the equation below for\\(q\\): \\[\\begin{equation} \\begin{aligned} p &= 1- e^{-\\lambda q}\\\\ p-1 &= - e^{-\\lambda q}\\\\ -p+1 &= e^{-\\lambda q}\\\\ \\log(1-p) &= -\\lambda q\\\\ - \\log(1-p)/\\lambda &= q\\\\ \\end{aligned} \\end{equation}\\] Write the quantile function (the inverse of the CDF) and the random number generator for the exponential distribution in R. To differentiate it from the built-in function in R, we will call itqexp2: The functions that we would use in a Stan model are relatively faithful to the R code, but follow Stan conventions: The expressionlog1m(p)is more arithmetically stable thanlog(1 - .)for values ofpclose to one, the functionexp_lpdf()stores the sum of the log(PDF) evaluated at each value of x, this would be analogous to doingsum(dexp2(x, lambda, log = TRUE)); the functionexp_rng()implements a non-vectorized version ofrexp2()and uses the auxiliary functionexp_icdf()(icdf stands for inverse CDF), which is similar toqexp2(). We are now ready to generate synthetic data and fit the distribution in Stan. Generate 1000 observations",
    "chunk_id": "Adv_cognitive_modelling_introduction_to_bayesian_data_analysis_for_cognitive_science.json_chunk_16"
  },
  {
    "document_type": "online_article",
    "title": "Introduction to Bayesian Data Analysis for Cognitive Science",
    "author": "Bruno Nicenboim",
    "source": "https://bruno.nicenboim.me/bayescogsci/ch-custom.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". We are now ready to generate synthetic data and fit the distribution in Stan. Generate 1000 observations. Useexponential.stan, which includes the function block shown earlier, and the following obligatory blocks: Fit the data with Stan. Print the summary: Carry out a quick check first, verifying that the true value of the parameter\\(\\lambda\\)is reasonably inside the bulk of the posterior distribution. This is shown in Figure10.7(a). Figure10.7(b) shows the results of the simulation-based calibration procedure, and shows that our implementation was correct. FIGURE 10.7: (a) Posterior distribution of the parameter\\(\\lambda\\)offit_exptogether with its true values as a black line. (b) Rank histogram of\\(\\lambda\\)and from our hand-made implementation of the exponential distribution. The dashed lines represent the 99% confidence interval. In this chapter, we learned how to create a PDF that is not provided by Stan. We learned how to do this by doing a change of variables (using the Jacobian adjustment) and by building the distribution from scratch in a function ending in_lpdf. We also learned how to verify the correctness of the new functions by recovering the true values of the parameters and by using simulation-based calibration. Jacobian adjustments in Bayesian models are a common source of confusion and there are several posts in blogs and study cases that try to shed light on them: Jacobian adjustments are also relevant for adjusting priors for order constraints, which is especially important for Bayes factors(Heck and Wagenmakers2016). A complete tutorial of simulation-based calibration using theSBCpackage was presented in the online event Stanconnect 2021, and it is available inhttps://www.martinmodrak.cz/post/2021-sbc_tutorial/. The ideas that predate this technique can be found inCook, Gelman, and Rubin (2006)and were extended inTalts et al. (2018). The use of ECDF-based visualizations is discussed inSäilynoja, Bürkner, and Vehtari (2022)",
    "chunk_id": "Adv_cognitive_modelling_introduction_to_bayesian_data_analysis_for_cognitive_science.json_chunk_17"
  },
  {
    "document_type": "online_article",
    "title": "Introduction to Bayesian Data Analysis for Cognitive Science",
    "author": "Bruno Nicenboim",
    "source": "https://bruno.nicenboim.me/bayescogsci/ch-custom.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". (2018). The use of ECDF-based visualizations is discussed inSäilynoja, Bürkner, and Vehtari (2022). The role of simulation-based calibration in the Bayesian workflow is discussed inSchad, Betancourt, and Vasishth (2020). Examples of the use of simulation-based calibration to validate novel models used in cognitive science areHartmann, Johannsen, and Klauer (2020)andBürkner and Charpentier (2020). The extension of this procedure to validate Bayes factors is discussed inSchad et al. (2021). Custom functions in general and custom probability functions are treated chapter 21 of the User’s guide(Stan Development Team2024). Adams, Robert A., and Christopher Essex. 2018.Calculus: A Complete Course. Pearson. Ashby, F. Gregory. 1982. “Testing the Assumptions of Exponential, Additive Reaction Time Models.”Memory & Cognition10 (2): 125–34. Ashby, F. Gregory, and James T. Townsend. 1980. “Decomposing the Reaction Time Distribution: Pure Insertion and Selective Influence Revisited.”Journal of Mathematical Psychology21 (2): 93–123. Box, George E. P., and David R. Cox. 1964. “An Analysis of Transformations.”Journal of the Royal Statistical Society. Series B (Methodological), 211–52. Bürkner, Paul-Christian, and Emmanuel Charpentier. 2020. “Modelling Monotonic Effects of Ordinal Predictors in Bayesian Regression Models.”British Journal of Mathematical and Statistical Psychology.https://doi.org/https://doi.org/10.1111/bmsp.12195. Cook, Samantha R., Andrew Gelman, and Donald B. Rubin. 2006. “Validation of Software for Bayesian Models Using Posterior Quantiles.”Journal of Computational and Graphical Statistics15 (3): 675–92.https://doi.org/10.1198/106186006X136976. Gelman, Andrew, Aki Vehtari, Daniel P. Simpson, Charles C. Margossian, Bob Carpenter, Yuling Yao, Lauren Kennedy, Jonah Gabry, Paul-Christian Bürkner, and Martin Modrák. 2020. “Bayesian Workflow.”arXiv Preprint arXiv:2011.01808. Harris, Christopher M., and Jonathan Waddington. 2012",
    "chunk_id": "Adv_cognitive_modelling_introduction_to_bayesian_data_analysis_for_cognitive_science.json_chunk_18"
  },
  {
    "document_type": "online_article",
    "title": "Introduction to Bayesian Data Analysis for Cognitive Science",
    "author": "Bruno Nicenboim",
    "source": "https://bruno.nicenboim.me/bayescogsci/ch-custom.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". 2020. “Bayesian Workflow.”arXiv Preprint arXiv:2011.01808. Harris, Christopher M., and Jonathan Waddington. 2012. “On the Convergence of Time Interval Moments: Caveat Sciscitator.”Journal of Neuroscience Methods205 (2): 345–56.https://doi.org/https://doi.org/10.1016/j.jneumeth.2012.01.017. Harris, Christopher M., Jonathan Waddington, Valerio Biscione, and Sean Manzi. 2014. “Manual Choice Reaction Times in the Rate-Domain.”Frontiers in Human Neuroscience8: 418.https://doi.org/10.3389/fnhum.2014.00418. Hartmann, Raphael, Lea Johannsen, and Karl Christoph Klauer. 2020. “rtmpt: An R Package for Fitting Response-Time Extended Multinomial Processing Tree Models.”Behavior Research Methods52 (3): 1313–38. Heck, Daniel W, and Eric-Jan Wagenmakers. 2016. “Adjusted Priors for Bayes Factors Involving Reparameterized Order Constraints.”Journal of Mathematical Psychology73: 110–16.https://doi.org/https://doi.org/10.1016/j.jmp.2016.05.004. Lynch, Scott Michael. 2007.Introduction to Applied Bayesian Statistics and Estimation for Social Scientists. New York, NY: Springer. Modrák, Martin, Angie H. Moon, Shinyoung Kim, Paul-Christian Bürkner, Niko Huurre, Kateřina Faltejsková, Andrew Gelman, and Aki Vehtari. 2023. “Simulation-Based Calibration Checking for Bayesian Computation: The Choice of Test Quantities Shapes Sensitivity.”Bayesian Analysis, 1–28.https://doi.org/10.1214/23-BA1404. Ross, Sheldon. 2002.A First Course in Probability. Pearson Education. Säilynoja, Teemu, Paul-Christian Bürkner, and Aki Vehtari. 2022. “Graphical Test for Discrete Uniformity and Its Applications in Goodness-of-Fit Evaluation and Multiple Sample Comparison.”Statistics and Computing32 (2): 1–21.https://doi.org/https://doi.org/10.1007/s11222-022-10090-6. Salas, Saturnino L., Garret J. Etgen, and Einar Hille. 2003.Calculus: One and Several Variables. Ninth. John Wiley & Sons. Schad, Daniel J., Michael J. Betancourt, and Shravan Vasishth. 2019",
    "chunk_id": "Adv_cognitive_modelling_introduction_to_bayesian_data_analysis_for_cognitive_science.json_chunk_19"
  },
  {
    "document_type": "online_article",
    "title": "Introduction to Bayesian Data Analysis for Cognitive Science",
    "author": "Bruno Nicenboim",
    "source": "https://bruno.nicenboim.me/bayescogsci/ch-custom.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". Salas, Saturnino L., Garret J. Etgen, and Einar Hille. 2003.Calculus: One and Several Variables. Ninth. John Wiley & Sons. Schad, Daniel J., Michael J. Betancourt, and Shravan Vasishth. 2019. “Toward a Principled Bayesian Workflow in Cognitive Science.”arXiv Preprint.https://doi.org/10.48550/ARXIV.1904.12765. Schad, Daniel J., Bruno Nicenboim, Paul-Christian Bürkner, Michael J. Betancourt, and Shravan Vasishth. 2021. “Workflow Techniques for the Robust Use of Bayes Factors.”arXiv Preprint arXiv:2103.08744. Stan Development Team. 2024. “Stan Modeling Language Users Guide and Reference Manual, Version 2.32.”https://mc-stan.org/docs/2_35/. Talts, Sean, Michael J. Betancourt, Daniel P. Simpson, Aki Vehtari, and Andrew Gelman. 2018. “Validating Bayesian Inference Algorithms with Simulation-Based Calibration.”arXiv Preprint arXiv:1804.06788. Wu, Fuyun, Elsi Kaiser, and Shravan Vasishth. 2017. “Effects of Early Cues on the Processing of Chinese Relative Clauses: Evidence for Experience-Based Theories.”Cognitive Science42: 1101–33. Yao, Yuling, Aki Vehtari, Daniel P. 2018. “Yes, but Did It Work?: Evaluating Variational Inference.” InInternational Conference on Machine Learning, 5581–90. PMLR. In this specific case, we could also transform the dependent variable first, but as will become clear later, we want to avoid changing our dependent variable.↩︎ Not every transformation is valid, univariate changes of variables must be monotonic and differentiable, multivariate changes of variables must be surjective and differentiable.↩︎ In the multivariate case, it is equal to the absolute determinant of the Jacobian, the matrix of all its first-order partial derivatives, of the transform; see section 6.7 ofRoss (2002), and p. 707 ofAdams and Essex (2018).↩︎ We are working under the assumption that Stan, which yields the posterior approximation, works correctly",
    "chunk_id": "Adv_cognitive_modelling_introduction_to_bayesian_data_analysis_for_cognitive_science.json_chunk_20"
  },
  {
    "document_type": "online_article",
    "title": "Introduction to Bayesian Data Analysis for Cognitive Science",
    "author": "Bruno Nicenboim",
    "source": "https://bruno.nicenboim.me/bayescogsci/ch-custom.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". 707 ofAdams and Essex (2018).↩︎ We are working under the assumption that Stan, which yields the posterior approximation, works correctly. In principle, if we assume that our model is correct, we can also use simulation-based calibration to examine whether our approximation to the posterior distribution is correct (that is, whether Stan’s sampler, or any posterior approximation method works correctly); for an example, seeYao et al. (2018).↩︎",
    "chunk_id": "Adv_cognitive_modelling_introduction_to_bayesian_data_analysis_for_cognitive_science.json_chunk_21"
  },
  {
    "document_type": "AU_course_page",
    "title": "Advanced Cognitive Modeling",
    "author": "Aarhus University",
    "source": "https://kursuskatalog.au.dk/en/course/129647/Advanced-Cognitive-Modeling",
    "flag": "",
    "date_published": "Unknown",
    "chunk_text": "Advanced Cognitive Modeling Spring semester 2025 Course Catalogue Save course ECTS 10 Forms of instruction Lecture etc. Form of examination Take-home assignment (Assign) Language of instruction English Level Master Location Aarhus Use arrow keys on your keyboard to explore Course content Read more see description of qualifications Description of qualifications Read more Purpose: The purpose of the course is 1) to develop student’s ability to understand theoretical models of cognitive function (e.g. memory, decision-making); 2) to develop student’s ability to work with formal mathematical and computational models of verbally stated theories; and 3) to apply formal cognitive models to data. This will provide students with a deeper knowledge of conceptual theories of cognition, and with skills in formalising theory and applying it to data. It will also prepare students to use theories from cognitive science in the development of software agents capable of performing simple cognitive tasks (i.e. artificial intelligence systems). The course includes 1) an introduction to general frameworks for formalising cognitive theories, including specific mathematical models; and 2) the application of advanced statistical methods for evaluating formal models of cognition, and for applying models to data. This course integrates conceptual and theoretical knowledge about cognitive functions with 1) formal modelling tools, and 2) statistical methods for fitting theory to data. The course builds on the decision-making course. The course places theoretical knowledge in cognitive science within the broader perspective of philosophical issues surrounding theory construction in cognitive science",
    "chunk_id": "Adv_cognitive_modelling_advanced_cognitive_modeling.json_chunk_1"
  },
  {
    "document_type": "AU_course_page",
    "title": "Advanced Cognitive Modeling",
    "author": "Aarhus University",
    "source": "https://kursuskatalog.au.dk/en/course/129647/Advanced-Cognitive-Modeling",
    "flag": "",
    "date_published": "Unknown",
    "chunk_text": ". The course places theoretical knowledge in cognitive science within the broader perspective of philosophical issues surrounding theory construction in cognitive science. Academic objectives: In the evaluation of the student’s performance, emphasis is placed on the extent to which the student is able to: Knowledge: - describe common mathematical and computational approaches to modelling cognition - explain the relationship between conceptual theories of cognition and mathematical/computational models - show how specific mathematical and computational models express conceptual theories - reflect on philosophical issues surrounding theory construction in cognitive science. Skills: - use advanced statistical methods to evaluate and compare different models when applied to the same data set - design simple software agents implementing theories of cognitive function. Competences: - formalise verbally stated conceptual theories of cognitive function. See all ECTS 10 Level Master Semester MA, 2nd semester Language of instruction English Hours - week - period Time and place will be announced no later than at the start of the semester here: https://timetable.au.dk/schedule Type of course Ordinary Primary programme Master's Degree Programme in Cognitive Science Department School of Communication and Culture Faculty Arts Location Aarhus STADS UVA code 147222U006 Copy UVA code Teaching Forms of instruction Lecture and classroom instruction Instructor See all Riccardo Fusaroli Institut for Kommunikation og Kultur - Kognitionsvidenskab Comments on the form of instruction Read more Lectures and classroom instruction Students produce a number of assignments during the course. At the start of the semester, the teacher will inform the students of the number of assignments, their form, length and deadlines both on Brightspace and orally. The assignments can provide the basis for various forms of feedback and further development related to the teaching, but the individual assignments are not assessed on a continuous basis",
    "chunk_id": "Adv_cognitive_modelling_advanced_cognitive_modeling.json_chunk_2"
  },
  {
    "document_type": "AU_course_page",
    "title": "Advanced Cognitive Modeling",
    "author": "Aarhus University",
    "source": "https://kursuskatalog.au.dk/en/course/129647/Advanced-Cognitive-Modeling",
    "flag": "",
    "date_published": "Unknown",
    "chunk_text": ". The assignments can provide the basis for various forms of feedback and further development related to the teaching, but the individual assignments are not assessed on a continuous basis. All or some of these assignments can provide the basis for the student’s exam. Language of instruction: The rules governing language of exam and teaching are stated in section 2.1 of the academic regulations. Literature Read more Will be announced on Brightspace at the start of the semester. Examination Form of examination Take-home assignment (Assign) Form of co-examination Internal co-examination Assessment Passed /failed Permitted exam aids Not specified Comments Read more Ordinary exam and re-examination: The exam consists of a portfolio containing 3-7 of assignments. The number of assignments as well as their form and eventual length will be announced on Brightspace by the teacher at the start of the semester. The portfolio may include products. Depending on their length, and subject to the teacher’s approval, these products can replace some of the standard pages in the portfolio. It must be possible to carry out an individual assessment. So if some parts of the portfolio have been produced by a group, it must be stated clearly which parts each student is responsible for, and which parts the group as a whole is responsible for. The complete portfolio must be submitted for assessment in WISEflow before the deadline set in the examination plan. Each student submits a portfolio.",
    "chunk_id": "Adv_cognitive_modelling_advanced_cognitive_modeling.json_chunk_3"
  },
  {
    "document_type": "online_article",
    "title": "Chapter 7 Individual Differences in Cognitive Strategies (Multilevel modeling)",
    "author": "Riccardo Fusaroli",
    "source": "https://fusaroli.github.io/AdvancedCognitiveModeling2023/individual-differences-in-cognitive-strategies-multilevel-modeling.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": "Our exploration of decision-making models has so far focused on single agents or averaged behavior across many agents. However, cognitive science consistentlyreveals that individuals differ systematically in how they approach tasks and process information. Some people may be more risk-averse, have better memory, learn faster, or employ entirely different strategies than others. This chapter introduces multilevel modeling as a powerful framework for capturing these individual differences while still identifying population-level patterns. Multilevel modeling (also called hierarchical modeling) provides a powerful framework for addressing this challenge. It allows us to simultaneously: Consider our matching pennies game: different players might vary in their strategic sophistication, memory capacity, or learning rates. Some may show strong biases toward particular choices while others adapt more flexibly to their opponents. Multilevel modeling allows us to capture these variations while still understanding what patterns hold across the population. Consider our matching pennies game: players might vary in their strategic sophistication, memory capacity, or learning rates. Some may show strong biases toward particular choices while others adapt more flexibly to their opponents. Multilevel modeling allows us to quantify these variations while still understanding what patterns hold across the population",
    "chunk_id": "Adv_cognitive_modelling_chapter_7_individual_differences_in_cognitive_strategies_(multilevel_modeling).json_chunk_1"
  },
  {
    "document_type": "online_article",
    "title": "Chapter 7 Individual Differences in Cognitive Strategies (Multilevel modeling)",
    "author": "Riccardo Fusaroli",
    "source": "https://fusaroli.github.io/AdvancedCognitiveModeling2023/individual-differences-in-cognitive-strategies-multilevel-modeling.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". Multilevel modeling allows us to quantify these variations while still understanding what patterns hold across the population. After completing this chapter, you will be able to: Understand how multilevel modeling balances individual and group-level information Distinguish between complete pooling, no pooling, and partial pooling approaches to modeling group and individual variation Use different parameterizations to improve model efficiency Evaluate model quality through systematic parameter recovery studies Apply multilevel modeling techniques to cognitive science questions Traditional approaches to handling individual differences often force a choice between two extremes: Treats all participants as identical by averaging or combining their data Estimates a single set of parameters for the entire group Ignores individual differences entirely Example: Fitting a single model to all participants’ data combined Analyzes each participant completely separately Estimates separate parameters for each individual Fails to leverage information shared across participants and can lead to unstable estimates Example: Fitting separate models to each participant’s data Multilevel modeling offers a middle ground through partial pooling. Individual estimates are informed by both individual-level data and the overall population distribution. Individual parameters are treated as coming from a group-level distribution Estimates are informed by both individual data and the population distribution Creates a balance between individual and group information Example: Hierarchical Bayesian model with parameters at both individual and group levels This partial pooling approach is particularly valuable when: Data per individual is limited (e.g., few trials per participant) Individual differences are meaningful but not completely independent We want to make predictions about new individuals from the same population Before diving into code, let’s understand the structure of our multilevel models using graphical model notation",
    "chunk_id": "Adv_cognitive_modelling_chapter_7_individual_differences_in_cognitive_strategies_(multilevel_modeling).json_chunk_2"
  },
  {
    "document_type": "online_article",
    "title": "Chapter 7 Individual Differences in Cognitive Strategies (Multilevel modeling)",
    "author": "Riccardo Fusaroli",
    "source": "https://fusaroli.github.io/AdvancedCognitiveModeling2023/individual-differences-in-cognitive-strategies-multilevel-modeling.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". These diagrams help visualize how parameters relate to each other and to the observed data. In this model, each agent has an individual bias parameter (θ) that determines their probability of choosing “right” (1) versus “left” (0). We are now conceptualizing our agents as being part of (sampled from) a more general population. This general population is characterized by a population level average parameter value (e.g. a general bias of 0.8 as we all like right hands more) and a certain variation in the population (e.g. a standard deviation of 0.1, as we are all a bit different from each other). Each biased agent’s bias is then sampled from that distribution. The key elements are: Population parameters: μ_θ (mean bias) and σ_θ (standard deviation of bias) Individual parameters: θ_i (bias for agent i) Observed data: y_it (choice for agent i on trial t) This model is more complex, with each agent having two parameters: a baseline bias (α) and a memory sensitivity parameter (β). The key elements are: Population parameters: μ_α, σ_α, μ_β, σ_β (means and standard deviations) Individual parameters: α_i (bias for agent i), β_i (memory sensitivity for agent i) Transformed variables: m_it (memory state for agent i on trial t) Observed data: y_it (choice for agent i on trial t) These graphical models help us understand how information flows in our models and guide our implementation in Stan. Again, it’s practical to work in log odds. Why? Well, it’s not unconceivable that an agent would be 3 sd from the mean. So a biased agent could have a rate of 0.8 + 3 * 0.1, which gives a rate of 1.1. It’s kinda impossible to choose 110% of the time the right hand. We want an easy way to avoid these situations without too carefully tweaking our parameters, or including exception statements (e.g. if rate > 1, then rate = 1). Conversion to log odds is again a wonderful way to work in a boundless space, and in the last step shrinking everything back to 0-1 probability space. N.B",
    "chunk_id": "Adv_cognitive_modelling_chapter_7_individual_differences_in_cognitive_strategies_(multilevel_modeling).json_chunk_3"
  },
  {
    "document_type": "online_article",
    "title": "Chapter 7 Individual Differences in Cognitive Strategies (Multilevel modeling)",
    "author": "Riccardo Fusaroli",
    "source": "https://fusaroli.github.io/AdvancedCognitiveModeling2023/individual-differences-in-cognitive-strategies-multilevel-modeling.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". if rate > 1, then rate = 1). Conversion to log odds is again a wonderful way to work in a boundless space, and in the last step shrinking everything back to 0-1 probability space. N.B. we model all agents with some added noise as we assume it cannot be eliminated from empirical studies. [MISSING: PARALLELIZE] Note that as the n of trials increases, the memory model matches the random model better and better Remember that the simulated parameters are: * biasM <- 0 * biasSD <- 0.1 * betaM <- 1.5 * betaSD <- 0.3 Prep the data Our first multilevel model focuses on the biased random agent. For each agent, we’ll estimate an individual bias parameter (theta) that determines their probability of choosing “right” versus “left”. These individual parameters will be modeled as coming from a population distribution with meanthetaMand standard deviationthetaSD. This approach balances two sources of information: 1. The agent’s individual choice patterns 2. The overall population distribution of bias parameters The model implements the following hierarchical structure: Population level: θm ~ Normal(0, 1), θsd ~ Normal+(0, 0.3) Individual level: θi ~ Normal(θm, θsd) Data level: yit ~ Bernoulli(logit−1(θi)) Let’s implement this in Stan: Besides the usual prior predictive checks, prior posterior update checks, posterior predictive checks, based on the population level estimates; we also want to plot at least a few of the single agents to assess how well the model is doing for them. [MISSING: PLOT MODEL ESTIMATES AGAINST N OF HEADS BY PARTICIPANT] Now we’ll implement a more complex model for the memory agent. This model has two parameters per agent: bias: baseline tendency to choose “right” (log-odds scale) beta: sensitivity to the memory of opponent’s past choices Like the random agent model, we’ll use a multilevel structure where individual parameters come from population distributions",
    "chunk_id": "Adv_cognitive_modelling_chapter_7_individual_differences_in_cognitive_strategies_(multilevel_modeling).json_chunk_4"
  },
  {
    "document_type": "online_article",
    "title": "Chapter 7 Individual Differences in Cognitive Strategies (Multilevel modeling)",
    "author": "Riccardo Fusaroli",
    "source": "https://fusaroli.github.io/AdvancedCognitiveModeling2023/individual-differences-in-cognitive-strategies-multilevel-modeling.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". However, this model presents some additional challenges: The hierarchical structure for this model is: Population level: μ_bias ~ Normal(0, 1), σ_bias ~ Normal+(0, 0.3) μ_beta ~ Normal(0, 0.3), σ_beta ~ Normal+(0, 0.3) Individual level: bias_i ~ Normal(μ_bias, σ_bias) beta_i ~ Normal(μ_beta, σ_beta) Transformed variables: Data level: Let’s implement this model. [MISSING: DAGS] Code, compile and fit the model When implementing multilevel models, we sometimes encounter sampling efficiency issues, especially when group-level variance parameters are small or data is limited. This creates a “funnel” in the posterior distribution that’s difficult for the sampler to navigate efficiently. Non-centered parameterization addresses this by reparameterizing individual parameters as standardized deviations from the group mean: Instead of: θi ~ Normal(μ, σ) We use: θi = μ + σ · zi, where zi ~ Normal(0, 1) This is conceptually similar to when we z-score variables in regression models. This approach separates the sampling of the standardized individual parameters (zi) from the group-level parameters (μ and σ), improving sampling efficiency. The transformation between these parameterizations is invertible, so the models are equivalent, but the non-centered version often performs better computationally. In our code, we implement this by: Sampling standardized individual parameters (biasID_z, betaID_z) Multiplying by group SD and adding group mean to get individual parameters To better understand the trade-offs between different modeling approaches, let’s implement and compare three ways of handling individual differences: Each approach has advantages and disadvantages: Let’s compare how these approaches perform with our memory agent data [MISSING: PARAMETER RECOVERY IN A MULTILEVEL FRAMEWORK (IND VS POP)] In this chapter, we’ve explored how multilevel modeling provides a principled approach to analyzing data with hierarchical structure",
    "chunk_id": "Adv_cognitive_modelling_chapter_7_individual_differences_in_cognitive_strategies_(multilevel_modeling).json_chunk_5"
  },
  {
    "document_type": "online_article",
    "title": "Chapter 7 Individual Differences in Cognitive Strategies (Multilevel modeling)",
    "author": "Riccardo Fusaroli",
    "source": "https://fusaroli.github.io/AdvancedCognitiveModeling2023/individual-differences-in-cognitive-strategies-multilevel-modeling.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". By implementing models for both biased agents and memory agents, we’ve seen how to: Multilevel modeling offers several key advantages for cognitive modeling (only some of which have been exemplified here): -Improved parameter estimationfor individuals with limited data -Detection of population-level patternswhile respecting individual differences -More efficient use of datathrough partial pooling of information -Capacity to model correlationsbetween different cognitive parameters The practical implementation challenges we’ve encountered—such as sampling difficulties with correlated parameters and the need for non-centered parameterization—are common in cognitive modeling applications. Developing familiarity with these techniques prepares you for implementing more complex models in your own research.",
    "chunk_id": "Adv_cognitive_modelling_chapter_7_individual_differences_in_cognitive_strategies_(multilevel_modeling).json_chunk_6"
  },
  {
    "document_type": "online_article",
    "title": "Chapter 10 Win-Stay-Lose-Shift: A Heuristic Decision Strategy",
    "author": "Riccardo Fusaroli",
    "source": "https://fusaroli.github.io/AdvancedCognitiveModeling2023/win-stay-lose-shift-a-heuristic-decision-strategy.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": "Win-Stay-Lose-Shift (WSLS) represents one of the simplest yet most fascinating decision-making strategies observed in both human and animal behavior. The core principle is intuitive: if an action leads to success, repeat it; if it leads to failure, try something else. Despite its simplicity, this strategy can produce sophisticated behavioral patterns and proves surprisingly effective in many scenarios. In this chapter, we’ll explore WSLS through computational modeling, building on our previous work with random agents. We’ll see how this apparently simple strategy can capture important aspects of learning and adaptation. Through careful implementation and testing, we’ll develop insights into both the strengths and limitations of WSLS as a model of decision-making. Our exploration will follow several key steps: Implementing the basic WSLS strategy in code Testing it against different opponents Scaling up to multiple agents Analyzing patterns in the resulting data The WSLS strategy differs significantly from our previous random agent models. Rather than making choices based on fixed probabilities, a WSLS agent: Remembers its previous choice Tracks whether that choice was successful Uses this information to determine its next move This creates an interesting form of path dependence - the agent’s choices are shaped by its history of interactions (and we need to ensure that memory is calculated for the correct trial and applied to the following trial). Let’s begin by loading the packages we’ll need for our analysis: Now we’ll set up a simulation environment where WSLS agents interact with random agents. The parameters we define here will shape our simulation. We’ll create 100 agents who each play 120 trials, allowing us to observe both individual behavior and broader patterns across many interactions",
    "chunk_id": "Adv_cognitive_modelling_chapter_10_win-stay-lose-shift_a_heuristic_decision_strategy.json_chunk_1"
  },
  {
    "document_type": "online_article",
    "title": "Chapter 10 Win-Stay-Lose-Shift: A Heuristic Decision Strategy",
    "author": "Riccardo Fusaroli",
    "source": "https://fusaroli.github.io/AdvancedCognitiveModeling2023/win-stay-lose-shift-a-heuristic-decision-strategy.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". We’ll create 100 agents who each play 120 trials, allowing us to observe both individual behavior and broader patterns across many interactions. Our WSLS agent implementation uses a parameterized approach where: alpha represents a baseline bias toward choosing one option over another betaWin represents the strength of the “stay” response after a win betaLose represents the strength of the “shift” response after a loss noise allows for occasional random deviations from the strategy This parameterization lets us explore variants of the WSLS strategy with different sensitivities to wins and losses. Next, we’ll define functions to implement our agent strategies: Now let’s generate the simulation data. We’ll simulate each agent playing against a random opponent, and track their choices, wins, and losses: Let’s process our data to create useful variables for analysis and visualization: Now let’s visualize the choice patterns of our agents to get a sense of their behavior: The visualization above shows how the choice patterns evolve over time for both the Random and WSLS agents. The random agents show an approximately stable choice pattern (though with individual biases), while the WSLS agents show more varied patterns as they adapt to their opponents. Let’s also examine how each strategy performs against its opponent: The performance plots reveal an interesting pattern. The WSLS agents generally maintain a winning percentage above 0.5 (the dashed line), indicating they can effectively exploit the biases in the random agents. This demonstrates a key strength of the WSLS strategy - it can adapt to and take advantage of predictable patterns in opponent behavior. Let’s check some key properties of our simulation to ensure it’s working as expected: The plot confirms that our win and lose indicators are mutually exclusive - when the win signal is active (±1), the lose signal is 0, and vice versa. This is important for the proper functioning of our WSLS model",
    "chunk_id": "Adv_cognitive_modelling_chapter_10_win-stay-lose-shift_a_heuristic_decision_strategy.json_chunk_2"
  },
  {
    "document_type": "online_article",
    "title": "Chapter 10 Win-Stay-Lose-Shift: A Heuristic Decision Strategy",
    "author": "Riccardo Fusaroli",
    "source": "https://fusaroli.github.io/AdvancedCognitiveModeling2023/win-stay-lose-shift-a-heuristic-decision-strategy.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". This is important for the proper functioning of our WSLS model. Now let’s check that the WSLS agents are indeed responding to win and lose signals as expected: This plot confirms that our WSLS agents are behaving as expected: The variation in probabilities reflects the individual differences in our agents’ parameters. Let’s first build a model to infer the parameters of a single WSLS agent. This will help us understand the basic mechanics before scaling up to the multilevel model: Now let’s define the Stan model for a single WSLS agent: Now let’s fit the model to our single agent’s data: Let’s examine the parameter estimates and convergence for the single agent model: The parameter recovery for our single agent looks good. The posterior distributions (blue) are centered around the true parameter values (dashed lines), showing that our model can accurately recover the underlying parameters that generated the agent’s behavior. The posteriors are also substantially narrower than the priors (red), indicating that the data is informative. [MISSING A FULL PARAMETER RECOVERY] Now let’s scale up to model all agents simultaneously with a multilevel (hierarchical) model. This allows us to estimate both population-level parameters and individual differences: Now let’s define the multilevel Stan model: Now let’s fit the multilevel model to all agents: Let’s examine convergence diagnostics to ensure our model has estimated the parameters reliably: The trace plots show the parameter values across iterations. Good mixing (chains overlapping without patterns) indicates convergence. Rank histograms near uniform also suggest good convergence, while U-shaped or inverted-U histograms would indicate poor mixing. Now let’s visualize how our knowledge about the parameters has been updated by the data: This visualization shows how our knowledge about the parameters has been updated by the data",
    "chunk_id": "Adv_cognitive_modelling_chapter_10_win-stay-lose-shift_a_heuristic_decision_strategy.json_chunk_3"
  },
  {
    "document_type": "online_article",
    "title": "Chapter 10 Win-Stay-Lose-Shift: A Heuristic Decision Strategy",
    "author": "Riccardo Fusaroli",
    "source": "https://fusaroli.github.io/AdvancedCognitiveModeling2023/win-stay-lose-shift-a-heuristic-decision-strategy.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". Now let’s visualize how our knowledge about the parameters has been updated by the data: This visualization shows how our knowledge about the parameters has been updated by the data. The prior distributions (pink) represent our knowledge before seeing the data, while the posterior distributions (blue) show what we learned after fitting the model to the data. Narrower posteriors centered near the true values indicate that our model effectively learned from the data. One of the key advantages of multilevel modeling is the ability to estimate parameters for individual agents. Let’s extract individual parameters and assess recovery: These scatter plots show how well our model recovers individual-level parameters. Points near the diagonal line (dashed) indicate accurate parameter recovery, while the red regression line shows the overall relationship between true and estimated values. High correlation coefficients suggest good recovery of individual differences. Posterior predictive checks help us assess whether our model can generate data that resembles the observed data: I’ll modify the posterior predictive checks chunk to use the regeneration_simulations flag for better efficiency. This will save the computed results and reload them if they already exist: rCopy# Posterior predictive checks with regeneration flag This posterior predictive check compares the observed choice patterns (solid lines) with those predicted by our model (dashed lines) for a few selected agents. Close alignment indicates that our model captures the key patterns in the data well. Finally, let’s compute Leave-One-Out Cross-Validation (LOO-CV) to assess our model’s predictive performance. We’ll also demonstrate how this could be used to compare our WSLS model with a simpler alternative: The LOO-CV computation provides an estimate of the model’s expected predictive accuracy. In a full analysis, we would compare this with alternative models to determine which provides the best balance of fit and generalizability",
    "chunk_id": "Adv_cognitive_modelling_chapter_10_win-stay-lose-shift_a_heuristic_decision_strategy.json_chunk_4"
  },
  {
    "document_type": "online_article",
    "title": "Chapter 10 Win-Stay-Lose-Shift: A Heuristic Decision Strategy",
    "author": "Riccardo Fusaroli",
    "source": "https://fusaroli.github.io/AdvancedCognitiveModeling2023/win-stay-lose-shift-a-heuristic-decision-strategy.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". In a full analysis, we would compare this with alternative models to determine which provides the best balance of fit and generalizability. This visualization shows the distribution of pointwise expected log predictive density (ELPD) values, with the mean indicated by the dashed line. Observations with higher ELPD values are better predicted by our model. A long left tail would suggest some observations are particularly difficult for the model to predict and in a real project we should explore what the issues are.",
    "chunk_id": "Adv_cognitive_modelling_chapter_10_win-stay-lose-shift_a_heuristic_decision_strategy.json_chunk_5"
  },
  {
    "document_type": "book",
    "title": "Computational modeling of cognition",
    "author": "Farell",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Farrell-2018-Computational-modeling-of-cognition.pdf",
    "date_published": "2018",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": "1 Introduction This introductory chapter pursues three principal goals. First, we show that computtional modeling is essential to ensure progress in cognitive science. Second, we provide an introduction to the abstract idea of modeling and its many and varied applications. Third, we survey some of the issues involved in the interpretation of model output, including in particular how models can help constrain scientists’ own thinking. 1.1 Models and Theories in Science Cognitive scientists seek to understand how the mind works. That is, we want to describe and predict people’s behavior, and we ultimately wish to explain it, in the same way that physicists predict the motion of an apple that is dislodged from its tree (and can accrately describe its downward path) and explain its trajectory (by appealing to gravity). For example, if you forget someone’s name when you are distracted seconds after being introduced to her, we would like to know what cognitive process is responsible for this failure. Was it lack of attention? Forgetting over time? Can we know ahead of time whether or not you will remember that person’s name? The central thesis of this book is that to answer questions such as these, cognitive scientists must rely on quantitative mathematical models, just like physicists who research gravity. We suggest that to expand our knowledge of the human mind, consideration of the data and verbal theorizing are insufficient on their own. This thesis is best illustrated by considering something that is (just a little) simpler and more readily understood than the mind. Have a look at the data shown in Figure 1.1, which represent the position of planets in the night sky over time",
    "chunk_id": "Adv_cognitive_modelling_farrell-2018-computational-modeling-of-cognition_page-1-21.json_chunk_1"
  },
  {
    "document_type": "book",
    "title": "Computational modeling of cognition",
    "author": "Farell",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Farrell-2018-Computational-modeling-of-cognition.pdf",
    "date_published": "2018",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Have a look at the data shown in Figure 1.1, which represent the position of planets in the night sky over time. How might one describe this peculiar pattern of motion? How would you explain it? The strange loops in the otherwise consistently curvilinear paths describe the famous “retrograde motion” of the planets – that is, their propensity to suddenly reverse diretion (viewed against the fixed background of stars) for some time before resuming their initial path. What explains retrograde motion? It took more than a thousand years for a satisfactory answer to that question to become available, when Copernicus replaced the geocentric Ptolemaic system with a heliocentric model. Today, we know that retrgrade motion arises from the fact that the planets travel at different speeds along their orbits; hence, as Earth “overtakes” Mars, for example, the red planet appears to reverse direction as it falls behind the speeding Earth. 4 Introduction Figure 1.1 An example of data that defy easy description and explanation without a quantitative model. Figure taken from Proceedings of the Royal Society of London. Series A, Mathematical and Physical Sciences, Vol. 336, No. 1604, A Symposium on Planetary Science in Celebration of the Quincentenary of Nicolaus Copernicus 1473–1543. (Jan. 15, 1974), pp. 105–114. Reprinted with permission. This example permits several conclusions that will be relevant throughout the remaider of this book. First, the pattern of data shown in Figure 1.1 defies description and explanation unless one has a model of the underlying process. It is only with the aid of a model that one can describe and explain planetary motion, even at a verbal level (readers who doubt this conclusion may wish to invite friends or colleagues to make sense of the data without knowing their source). Second, any model that explains the data is itself unobservable",
    "chunk_id": "Adv_cognitive_modelling_farrell-2018-computational-modeling-of-cognition_page-1-21.json_chunk_2"
  },
  {
    "document_type": "book",
    "title": "Computational modeling of cognition",
    "author": "Farell",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Farrell-2018-Computational-modeling-of-cognition.pdf",
    "date_published": "2018",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Second, any model that explains the data is itself unobservable. That is, although the Copernican model is readily communicated and represented (so readily, in fact, that we decided to omit the standard figure showing a set of concentric circles), it cannot be directly observed. Instead, the model is an abstract explanatory device that “exists” primarily in the minds of the people who use it to describe, predict, and explain the data. Third, there nearly always are several possible models that can explain a given data set. This point is worth exploring in a bit more detail. The overwhelming success of the heliocentric model often obscures the fact that, at the time of Copernicus’ discovery, there existed a fairly successful alternative, namely the geocentric model of Ptolemy shown in Figure 1.2. The model explained retrograde motion by postulating that while orbiting around the Earth, the planets also circle around a point along their orbit. On the additional assumption that the Earth is slightly offset from the center of the planets’ orbit, this model provides a reasonable account of the data, limiting the positional 1.1 Models and Theories in Science 5 Figure 1.2 The geocentric model of the solar system developed by Ptolemy. It was the predominant model for some 1,300 years. discrepancies between predicted and actual locations of, say, Mars to about 1 ◦ (Hoyle, 1974). Why, then, did the heliocentric model so rapidly and thoroughly replace the Ptolemaic system? 1 The answer to this question is quite fascinating and requires that we move toward a quantitative level of modeling. Conventional wisdom holds that the Copernican model replaced geocentric notions of the solar system because it provided a better account of the data. But what does “better” mean? Surely it means that the Copernican system predicted the motion of planets with less quantitative error – that is, less than the 1 ◦ error for Mars just mentioned – than its Ptolemaic counterpart? Intriguingly, this conventional wisdom is only partially correct",
    "chunk_id": "Adv_cognitive_modelling_farrell-2018-computational-modeling-of-cognition_page-1-21.json_chunk_3"
  },
  {
    "document_type": "book",
    "title": "Computational modeling of cognition",
    "author": "Farell",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Farrell-2018-Computational-modeling-of-cognition.pdf",
    "date_published": "2018",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Yes, the Copernican model predicted the planets’ motion in latitude better than the Ptolemaic theory, but this difference was slight compared to the overall success of both models in predicting motion in longitude (Hoyle, 1974). What gave Copernicus the edge, then, was not “goodness-of-fit” alone 2 but also the intrinsic elegance and simplicity of his model: compare the Copernican account by a set of concentric circles with the complexity of Figure 1.2, which only describes the motion of a single planet. There is an important lesson to be drawn from this fact: The choice among competing models – and remember, there are always several to choose from – inevitably involves an intellectual judgment in addition to quantitative examination. Of course, the quantitative performance of a model is at least as important as are its intellectual attributes. Coperncus would not be commemorated today had the predictions of his model been inferior to those of Ptolemy; it was only because the two competing models were on an essentially 1 Lest one think that the heliocentric and geocentric models exhaust all possible views of the solar system, it is worth clarifying that there is an infinite number of equivalent models that can adequately capture planetary motion because relative motion can be described with respect to any possible vantage point. 2 “Goodness-of-fit” is a term for the degree of quantitative error between a model’s predictions and the data; this important term and many others are discussed in detail in Chapter 2. 6 Introduction equal quantitative footing that other intellectual judgments, such as a preference for simplicity over complexity, came into play",
    "chunk_id": "Adv_cognitive_modelling_farrell-2018-computational-modeling-of-cognition_page-1-21.json_chunk_4"
  },
  {
    "document_type": "book",
    "title": "Computational modeling of cognition",
    "author": "Farell",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Farrell-2018-Computational-modeling-of-cognition.pdf",
    "date_published": "2018",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". 6 Introduction equal quantitative footing that other intellectual judgments, such as a preference for simplicity over complexity, came into play. If the Ptolemaic and Copernican models were quantitatively comparable, why do we use them to illustrate our central thesis that a purely verbal level of explanation for natral phenomena is insufficient and that all sciences must seek explanations at a quantittive level? The answer is contained in the crucial modification to the heliocentric model offered by Johannes Kepler nearly a century later. Kepler replaced the circular orbits in the Copernican model by ellipses with differing eccentricities (or “egg-shapedness”) for the various planets. By this straightforward mathematical modification, Kepler achieved a virtually perfect fit of the heliocentric model, with near-zero quantitative error. There no longer was any appreciable quantitative discrepancy between the model’s predictions and the observed paths of planets. Kepler’s model has remained in force essentially unchanged for more than four centuries. The acceptance of Kepler’s model permits two related conclusions, one that is obvious and one that is equally important but perhaps less obvious. First, if two models are equally simple and elegant (or nearly so), the one that provides the better quantitative account will be preferred. Second, the predictions of the Copernican and Keplerian models cannot be differentiated by verbal interpretation alone. Both models explain retrograde motion by the fact that Earth “overtakes” some planets during its orbit, and the differentiating feature of the two models – whether orbits are presumed to be circular or elliptical – does not entail any differences in predictions that can be appreciated by purely verbal analysis. That is, although one can talk about circles and ellipses (e.g. “one is round, the other one egg-shaped”), those verbalizations cannot be turned into testable predictions",
    "chunk_id": "Adv_cognitive_modelling_farrell-2018-computational-modeling-of-cognition_page-1-21.json_chunk_5"
  },
  {
    "document_type": "book",
    "title": "Computational modeling of cognition",
    "author": "Farell",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Farrell-2018-Computational-modeling-of-cognition.pdf",
    "date_published": "2018",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". That is, although one can talk about circles and ellipses (e.g. “one is round, the other one egg-shaped”), those verbalizations cannot be turned into testable predictions. Remember, Kepler reduced the error for Mars from 1 ◦ to virtually zero, and we challenge you to achieve this by verbal means alone. Let us summarize the points we have made so far: 1. Data never speak for themselves but require a model to be understood and to be explained. 2. Verbal theorizing alone ultimately cannot substitute for quantitative analysis. 3. There are always several alternative models that vie for explanation of data and we must select among them. 4. Model selection rests on both quantitative evaluation and intellectual and schoarly judgment. All of these points will be explored in the remainder of this book. We next turn our attention from the night sky to the inner workings of our mind. 1.2 Quantitative Modeling in Cognition 1.2.1 Models and Data Let’s try this again: Have a look at the data in Figure 1.3. Does it remind you of planetary motion? Probably not, but it should be at least equally challenging to discern 1.2 Quantitative Modeling in Cognition 7 Figure 1.3 Observed recognition scores as a function of observed classification confidence for the same stimuli (each number identifies a unique stimulus). See text for details. Figure reprinted from Nosofsky, R. M., Tests of an exemplar mode for relating perceptual classification and recognition memory, Journal of Experimental Psychology: Human Perception and Performance , 17 , 3–27, 1991, published by the American Psychological Association, reprinted with permission. a meaningful pattern in this case at it was in the example from astronomy. Perhaps the pattern will become recognizable if we tell you about the experiment conducted by Nosofsky (1991) from which these data are taken. In that experiment, people were trained to classify a small set of cartoon faces into two arbitrary categories",
    "chunk_id": "Adv_cognitive_modelling_farrell-2018-computational-modeling-of-cognition_page-1-21.json_chunk_6"
  },
  {
    "document_type": "book",
    "title": "Computational modeling of cognition",
    "author": "Farell",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Farrell-2018-Computational-modeling-of-cognition.pdf",
    "date_published": "2018",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". In that experiment, people were trained to classify a small set of cartoon faces into two arbitrary categories. We might call the two categories the Campbells and the MacDonalds, and their members might differ on a set of facial features such as length of nose and eye separation. On a subsequent transfer test, people were presented with a larger set of faces, including those used at training plus a number of new ones. For each face, people had to make two decisions. The first decision was which category the face belonged to and the confidence of that decision (called “classification” in the figure, shown on the X -axis). The second decision was whether or not the face had been shown during training (“recognition” on the Y -axis). Each data point in the figure, then, represents those two responses, averaged across participants, for a given face (identified by ID number, which can be safely ignored). The correlation between those two measures was found to be r = 0.36. Before we move on, see if you can draw some conclusions from the pattern in Figure 1.3. Do you think that the two tasks have much to do with each other? Or would you think that classification and recognition are largely unrelated and that knowledge of one response would tell you very little about what response to expect on the other 8 Introduction Figure 1.4 Observed and predicted classification (left panel) and recognition (right panel). Predictions are provided by the GCM; see text for details. Perfect prediction is represented by the diagonal lines. Figure reprinted from Nosofsky, R. M., Tests of an exemplar mode for relating perceptual classification and recognition memory, Journal of Experimental Psychology: Human Perception and Performance , 17 , 3–27, 1991, published by the American Psychological Association, reprinted with permission. task? After all, if r = 0.36, then knowledge of one response reduces uncertainty about the other one by only 13%, leaving a full 87% unexplained, right? Wrong",
    "chunk_id": "Adv_cognitive_modelling_farrell-2018-computational-modeling-of-cognition_page-1-21.json_chunk_7"
  },
  {
    "document_type": "book",
    "title": "Computational modeling of cognition",
    "author": "Farell",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Farrell-2018-Computational-modeling-of-cognition.pdf",
    "date_published": "2018",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". task? After all, if r = 0.36, then knowledge of one response reduces uncertainty about the other one by only 13%, leaving a full 87% unexplained, right? Wrong. There is at least one quantitative cognitive model (called the GCM and described a little later), which can relate those two types of responses with considerable certainty. This is shown in Figure 1.4, which separates classification and recognition judgments into two separate panels, each showing the relationship between observed responses (on the Y -axis) and the predictions of the GCM ( X -axis). To clarify, each point in Figure 1.3 is shown twice in Figure 1.4, once in each panel, and in each instance it is plotted as a function of the predicted response obtained from the model. The precision of predictions in each panel is remarkable: If the model’s predictions were 100% perfect, then all points would fall on the diagonal. They do not, but they come close (accounting for 96% and 92% of the variance in classification and recogntion, respectively). The fact that these accurate predictions were provided by the same model tells us that classification and recognition can be understood and related to each other within a common psychological theory. Thus, notwithstanding the low correlation between the two measures, there is an underlying model that explains how both tasks are related and permits accurate prediction of one response from knowledge of the other. This model will be presented in detail later in this chapter (Section 1.2.3); for now, it suffices to acknowledge that the model relies on the comparison between each test stimulus and all previously encountered exemplars in memory. The two figures enforce a compelling conclusion: “The initial scatterplot revealed little relation between classification and recognition performance. At that limited level of analysis, one might have concluded that there was little in common between the fundamental processes of classification and recognition",
    "chunk_id": "Adv_cognitive_modelling_farrell-2018-computational-modeling-of-cognition_page-1-21.json_chunk_8"
  },
  {
    "document_type": "book",
    "title": "Computational modeling of cognition",
    "author": "Farell",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Farrell-2018-Computational-modeling-of-cognition.pdf",
    "date_published": "2018",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". At that limited level of analysis, one might have concluded that there was little in common between the fundamental processes of classification and recognition. Under the guidance of the 1.2 Quantitative Modeling in Cognition 9 formal model, however, a unified account of these processes is achieved” (Nosofsky, 1991, p. 9). Exactly paralleling the developments in 16 th -century astronomy, data in contemporary psychology are ultimately only fully interpretable with the aid of a quanttative model. We can thus reiterate our first two conclusions from above and confirm that they apply to cognitive psychology as well, namely that data never speak for themselves, but require a model to be understood and to be explained , and that verbal theorizing alone cannot substitute for quantitative analysis . But what about the remaining earlier conclusions concerning model selection? Nosofsky’s (1991) modeling included a comparison between his favored exemplar model, whose predictions are shown in Figure 1.4, and an alternative “prototype” model. The details of the two models are not relevant here; it suffices to note that the prototype model compares a test stimulus to the average of all previously encountered exemplars, whereas the exemplar model performs the comparison one-by-one between the test stimulus and each exemplar and sums the result. 3 Nosofsky found that the prototype model provided a less satisfactory account of the data, explaining only 92% and 87% of the classification and recognition variance, respectively, or about 5% less than the exemplar model. Hence, the earlier conclusions about model selection apply in this instance as well: There were several alternative models, and the choice between them was based on clear quantitative criteria. Thus far, we initiated our discussion with the data and we then – poof! – revealed a quantitative model that spectacularly turned an empirical mystery or mess into theoretcal currency",
    "chunk_id": "Adv_cognitive_modelling_farrell-2018-computational-modeling-of-cognition_page-1-21.json_chunk_9"
  },
  {
    "document_type": "book",
    "title": "Computational modeling of cognition",
    "author": "Farell",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Farrell-2018-Computational-modeling-of-cognition.pdf",
    "date_published": "2018",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Thus far, we initiated our discussion with the data and we then – poof! – revealed a quantitative model that spectacularly turned an empirical mystery or mess into theoretcal currency. In many circumstances, this is what modelers might do: they are confronted with new data but have an existing model at hand, and they wish to examine how well the model can handle the data. In other circumstances, however, researchers might invert this process and begin with an idea “from scratch.” That is, you might believe that some psychological process is worthy of exploration and empirical test. The next chapter prvides an in-depth example of how one might proceed under those circumstances. Before we get into those details, however, we briefly describe how the large number of models and mode applications can be differentiated into two broad categories, namely models that simply describe data vs. models that explain the underlying cognitive processes. 1.2.2 Data Description Knowingly or not, we have all used models to describe or summarize data, and at first glance this appears quite straightforward. For example, we probably would not hesitate to describe the salaries of all 150 members of the Australian House of Representatives by their average because in this case there is little doubt that the mean is the proper “model” of the data (notwithstanding the extra allowances bestowed upon Ministers). Why would we want to “model” the data in this way? Because we are replacing the 3 Astute readers may wonder how the two could possibly differ. The answer lies in the fact that the similarity rule involved in the comparisons by the exemplar model is non-linear; hence, the summed individual similarities differ from that involving the average. This non-linearity turns out to be crucial to the model’s overall power. The fact that subtle matters of arithmetic can have such drastic consequences further reinforces the notion that purely verbal theorizing is of limited value",
    "chunk_id": "Adv_cognitive_modelling_farrell-2018-computational-modeling-of-cognition_page-1-21.json_chunk_10"
  },
  {
    "document_type": "book",
    "title": "Computational modeling of cognition",
    "author": "Farell",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Farrell-2018-Computational-modeling-of-cognition.pdf",
    "date_published": "2018",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". The fact that subtle matters of arithmetic can have such drastic consequences further reinforces the notion that purely verbal theorizing is of limited value. 10 Introduction data points ( N = 150 in this instance) with a single estimated “parameter.” 4 In this instance, the parameter is the sample mean, and reducing 150 points into one facilitates understanding and efficient communication of the data. However, we must not become complacent in light of the apparent ease with which we can model data by their average. As a case in point, consider U.S. President Bush’s 2003 statement in promotion of his tax cut, that “under this plan, 92 million Americans receive an average tax cut of $1,083.” Although this number, strictly speaking, was not incorrect, it arguably did not represent the best model of the proposed tax cut, given that 80% of taxpayers would receive less than this cut, and nearly half (i.e. some 45 million people) would receive less than $100 (Verzani, 2004). The distribution of tax cuts was so skewed (bottom 20% of income earners slated to receive $6 compared to $30,127 for the top 1%) that the median or a trimmed mean would have been the preferable model of the proposed legislation in this instance. Controversies about the proper model with which to describe data also arise in conitive science, although fortunately with more transparency than in the political arena. In fact, data description, by itself, can have considerable psychological impact. As a case in point, consider the debate on whether learning of a new skill is best understood as following a “Power Law” or is better described by an exponential improvement (Heathcote et al., 2000). There is no doubt that the benefits from practice accrue in a non-linear fashion: The first time you try your hands at a new skill (for example, creating an Ikebana arrangement), things take seemingly forever (and the output may not be worth writing home about)",
    "chunk_id": "Adv_cognitive_modelling_farrell-2018-computational-modeling-of-cognition_page-1-21.json_chunk_11"
  },
  {
    "document_type": "book",
    "title": "Computational modeling of cognition",
    "author": "Farell",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Farrell-2018-Computational-modeling-of-cognition.pdf",
    "date_published": "2018",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". The second and third time round, you will notice vast improvements, but eventually, after some dozens of trials, chances are that further improvements will be small indeed. What is the exact functional form of this pervasive empirical regularity? For several decades, the prevailing opinion had been that the effect of practice is best captured by a “Power law” – that is, by the function (shown here in its simplest possible form), RT = N − β , (1.1) where RT represents the time to perform the task, N represents the number of learning trials to date, and β is the learning rate. Parameters of models are often represented by Greek letters, and Appendix A lists these in full; in this case, β is the Greek letter Beta. Figure 1.5 shows sample data, taken from Palmeri (1997)’s Experiment 3, with the appropriate best-fitting power function superimposed as a dashed line. Participants judged the numerosity of random dot patterns that contained between 6 and 11 dots. Training extended over several days and each pattern was presented numerous times. The figure shows the training data for one participant and one particular pattern. Heathcote et al. (2000) argued that the data are better described by an exponential function given by (again in its simplest possible form), RT = e − α N , (1.2) 4 We will provide a detailed definition of what a parameter is in Chapter 2. For now, it suffices to think of a parameter as a number that carries important information and that determines the behavior of the model. 1.2 Quantitative Modeling in Cognition 11 Trial Number Response Time (ms) 0 50 100 150 1000 2000 3000 4000 5000 6000 7000 Figure 1.5 Sample power law learning function (solid line) and alternative exponential function (dashed line) fitted to the same data. Data are represented by dots and are taken from Palmeri (1997)’s Experiment 3 (Subject 3, Pattern 13)",
    "chunk_id": "Adv_cognitive_modelling_farrell-2018-computational-modeling-of-cognition_page-1-21.json_chunk_12"
  },
  {
    "document_type": "book",
    "title": "Computational modeling of cognition",
    "author": "Farell",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Farrell-2018-Computational-modeling-of-cognition.pdf",
    "date_published": "2018",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Data are represented by dots and are taken from Palmeri (1997)’s Experiment 3 (Subject 3, Pattern 13). To fit the data, the power and exponential functions were a bit more complex than described in Equations 1.1 and 1.2 because they additionally contained an asymptote ( A ) and a multiplier ( B ). Hence the power function took the form RT = A P + B P × ( N + 1 ) − β and the exponential function was RT = A E + B E × e − α N . where N is as before and α the learning rate. The best-fitting exponential function is shown by the dashed line in Figure 1.5; you will note that the two competing descritions or models do not appear to differ much. 5 The power function captures the data well, but so does the exponential function, and there is not much to tell between them: The residual mean-squared deviation (RMSD), which represents the average deviation of the data points from the predicted function, was 482.4 for the Power function copared to 526.9 for the exponential. Thus, in this instance the Power function fits “better” (by providing some 50 ms less error in its predictions than the exponential), but given that RT’s range from somewhere less than 1,000 ms to 7 seconds, this difference may not be considered particularly striking. So, why would this issue be of any import? Granted, we wish to describe the data by the appropriate model, but surely neither of the models in Figure 1.5 misrepresents essential features of the data anywhere near as much as U.S. President Bush did by reporting only the average implication of his proposed tax cut. The answer is that the choice of the correct descriptive model, in this instance, carries important implications about the psychological nature of learning. As shown in detail by Heathcote et al. (2000), the mathematical form of the exponential function necessarily implies that the 5 For now, we just present those “best-fitting” functions without explaining how they were obtained. We begin the discussion of how to fit models to data in Chapter 3",
    "chunk_id": "Adv_cognitive_modelling_farrell-2018-computational-modeling-of-cognition_page-1-21.json_chunk_13"
  },
  {
    "document_type": "book",
    "title": "Computational modeling of cognition",
    "author": "Farell",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Farrell-2018-Computational-modeling-of-cognition.pdf",
    "date_published": "2018",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". We begin the discussion of how to fit models to data in Chapter 3. 12 Introduction learning rate, relative to what remains to be learned, is constant throughout practice. That is, no matter how much practice you have had, learning continues by enhancing your performance by a constant fraction. By contrast, the mathematics of the power function imply that the relative learning rate is slowing down as practice increases. That is, although you continue to show improvements throughout, the rate of learning decreases with increasing practice. It follows that the proper characterization of skill acquisition data by a descriptive model, in and of itself, has considerable psychological implications (we do not explore those implications here; see Heathcote et al., 2000, for pointers to the background). Just to wrap up this example, Heathcote et al. (2000) concluded after re-analyzing a large body of existing data that the exponential function provided a better description of skill acquisition than the hitherto presumed “Power law.” For our purposes, their analysis permits the following conclusions. First, quantitative description of data, by itself, can have considerable psychological implications because it prescribes crucial features of the learning process. Second, the example underscores the importance of model selection that we alluded to earlier; in this instance, one model was chosen over another on the basis of strict quantitative criteria. We revisit this issue in Chapter 10. Third, the fact that Heathcote et al.’s model selection considered the data of individual subjects, rather than the average across participants, identifies a new issue – namely the most appropriate way in which to apply a model to the data from more than one individual – that we consider in Chapter 5. The selection among competing functions is not limited to the effects of practice. Debates about the correct descriptive function have also figured prominently in the study of forgetting",
    "chunk_id": "Adv_cognitive_modelling_farrell-2018-computational-modeling-of-cognition_page-1-21.json_chunk_14"
  },
  {
    "document_type": "book",
    "title": "Computational modeling of cognition",
    "author": "Farell",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Farrell-2018-Computational-modeling-of-cognition.pdf",
    "date_published": "2018",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". The selection among competing functions is not limited to the effects of practice. Debates about the correct descriptive function have also figured prominently in the study of forgetting. Does the rate of forgetting differ with the extent of learning? Is the rate of information loss constant over time? Although the complete pattern of results is fairly complex, two conclusions appear warranted (Wixted, 2004a). First, the degree of learning does not affect the rate of forgetting. Hence, irrespective of how much you cram for an exam, you will lose the information at the same rate – but of course this is not an argument against dedicated study; if you learn more, you will also retain more, irrespective of the fact that the rate of loss per unit time remains the same. Second, the rate of forgetting decelerates over time. That is, whereas you might lose some 30% of the information on the first day, on the second day the loss may be down to 20%, then 10%, and so on. Again, as in the case of practice, two conclusions are relevant here. First, quantitative comparison among competing descriptive models was required to choose the appropriate function (it is a Power function, or something very close to it). Second, although the shape of the “correct” function has considerable theoretical import because it may imply that memories are “consolidated” over time after study (see Wixted, 2004a; 2004b, for a detailed consideration, and see Brown and Lewandowsky, 2010, for a contrary view), the function itself has no psychological content. The mere description of data can also have psychological implications when the behavior it describes is contrasted to normative expectations (Luce, 1995). Normative behavior refers to how people would behave if they conformed to the rules of logic or probability. For example, consider the following syllogism involving two premises (P) and a conclusion (C). P1: All polar bears are animals. P2: Some animals are white",
    "chunk_id": "Adv_cognitive_modelling_farrell-2018-computational-modeling-of-cognition_page-1-21.json_chunk_15"
  },
  {
    "document_type": "book",
    "title": "Computational modeling of cognition",
    "author": "Farell",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Farrell-2018-Computational-modeling-of-cognition.pdf",
    "date_published": "2018",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". For example, consider the following syllogism involving two premises (P) and a conclusion (C). P1: All polar bears are animals. P2: Some animals are white. 1.2 Quantitative Modeling in Cognition 13 C: Therefore, some polar bears are white. Is this argument valid? There is a 75%–80% chance that you might endorse this conclusion (e.g. Helsabeck, 1975), even though it is logically false (to see why, replace “white” with “brown” in P2 and C). This example shows that people tend to violate normative expectations even in very simple situations. In this instance, the only descriptive model that is required to capture people’s behavior – and to notice the normative violation – is a simple proportion (i.e. 75%–80% of people commit this logical error). In other, more realistic instances, people’s normatively irrational behavior is best captured by a rather more complex descriptive model (e.g., Tversky and Kahneman, 1992). We have presented several descriptive models and have shown how they can inform psychological theorizing. One attribute of all those descriptive models is that they have no intrinsic psychological content ; for example, although the existence of an exponential practice function constrains possible learning mechanisms, the function itself has no psychological content. It is merely concerned with describing the data. For the remainder of this chapter, we will be considering models that explicitly have psychological content. In particular, we will be concerned with “process models,” which explain the cognitive processes that are presumed to underlie performance in the tasks characterized by the model. 1.2.3 Cognitive Process Models We begin our discussion by presenting a close-up of the exemplar model of categoriztion first presented in Section 1.2.1",
    "chunk_id": "Adv_cognitive_modelling_farrell-2018-computational-modeling-of-cognition_page-1-21.json_chunk_16"
  },
  {
    "document_type": "book",
    "title": "Computational modeling of cognition",
    "author": "Farell",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Farrell-2018-Computational-modeling-of-cognition.pdf",
    "date_published": "2018",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". 1.2.3 Cognitive Process Models We begin our discussion by presenting a close-up of the exemplar model of categoriztion first presented in Section 1.2.1. We choose this model, known as the Generalized Context Model (Nosofsky, 1986, GCM; see, e.g.), because it is one of the most influetial and successful existing models of categorization and because, despite its power, the GCM’s basic architecture is straightforward and readily implemented in something as simple as Microsoft Excel. We already know that GCM is an exemplar model. As implied by that name, GCM stores every category exemplar encountered during training in memory. We mentioned an experiment earlier in which people learned to classify cartoon faces; in GCM this procedure would be implemented by adding each stimulus to the pile of faces belonging to the same category. Remember that each response during training is followed by feedback, so people know whether a face belongs to a MacDonald or a Campbell at the end of each trial. Following training, GCM has thus built two sets of exemplars, one for each category, and all subsequent test stimuli are classified by referring to those memorized ensembles. This is where things get really interesting (and, refreshingly, a bit more complicated, but nothing you can’t handle). First, we need some terminology. Let us call a particular test stimulus i , and let us refer to the stored exemplars as the set J with members j = 1, 2, , J , hence j ∈ J . This notation may seem like a bit of an overkill at first glance, but in fact it is useful to clarify a few things at the outset that we will use for the remainder of the book. Note that we use lowercase letters (e.g., i , j , ) to identify specific elements of a set, and that the number of elements in that set is identified by the same uppercase letters ( I , J , ), 14 Introduction d d Figure 1.6 The representational assumptions underlying GCM",
    "chunk_id": "Adv_cognitive_modelling_farrell-2018-computational-modeling-of-cognition_page-1-21.json_chunk_17"
  },
  {
    "document_type": "book",
    "title": "Computational modeling of cognition",
    "author": "Farell",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Farrell-2018-Computational-modeling-of-cognition.pdf",
    "date_published": "2018",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Panel A shows stimuli that differ along one dimension only (line length), and panel B shows stimuli that differ along two dimensions (line length and angle). In both panels, a representative distance ( d ) between two stimuli is shown by the broken line. whereas the set itself is identified by the “Fraktur” version of the letter ( I , J , ). So, we have a single thing called i (or j , or whatever), which is one of I elements of a set I . We are now ready to consider the effects of presenting stimulus i . In a nutshell, a test stimulus “activates” all stored exemplars (remember; that’s j ∈ J ) to an extent that is determined by the similarity between i and each j . What exactly is similarity? GCM assumes that stimuli are represented in a perceptual space and that proximity within that space translates into similarity. To illustrate, consider the left panel (A) in Figure 1.6, which shows the perceptual representation of three hypothetical stimuli that differ along a single dimension – in this case line length. The broken line labeled d represents the distance between two of those stimuli. It is easy to see that the greater this distance is, the less similar the two stimuli are. Conversely, the closer together two stimuli are, the greater their similarity. Now consider panel B. Here again we have three hypothetical stimuli, but this time they differ along two dimensions simultaneously – namely, distance and angle. Panel B again shows the distance ( d ) between two stimuli, which is formally given by the following equation: d ij = K k = 1 | x ik − x jk | 2 1 2 , (1.3) where x ik is the value of dimension k for test item i (let’s say that’s the middle stimulus in Panel B of Figure 1.6) and x jk is the value of dimension k for the stored exemplar j (say, the right-most stimulus in the panel). The number of dimensions that enter into computation of the distance is arbitrary; the cartoon faces were characterized by 4 dimensions, but of course we cannot easily show more than two dimensions at a time",
    "chunk_id": "Adv_cognitive_modelling_farrell-2018-computational-modeling-of-cognition_page-1-21.json_chunk_18"
  },
  {
    "document_type": "book",
    "title": "Computational modeling of cognition",
    "author": "Farell",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Farrell-2018-Computational-modeling-of-cognition.pdf",
    "date_published": "2018",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Those dimensions were eye height, eye separation, nose length, and mouth height. 6 If you are unfamiliar with some of the terminology or symbols in Equation 1.3, please refer to Appendix B, which spells out some common mathematical notation. 6 For simplicity, we omit discussion of how these psychological distances relate to the physical measurement (e.g., line length in cm) of the stimuli; these issues are covered in Nosofsky (1986). 1.2 Quantitative Modeling in Cognition 15 An easy way to understand Equation 1.3 is by realizing that it merely restates the familiar Pythagorean theorem (i.e., d 2 = a 2 + b 2 ), where a and b are the thin solid lines in panel B of Figure 1.6 that are represented by the more general notation of dimensional differences (i.e., x ik − x jk ) in the equation. How, then, does distance relate to similarity? It is intuitively obvious that greater ditances imply lesser similarity, but GCM explicitly postulates an exponential relationship of the form: s ij = exp ( − c · d ij ) , (1.4) where c is a parameter and d ij the distance as just defined. The left panel (A) of Figure 1.7 visualizes this function, and shows how the activation of an exemplar (i.e., s ij ) declines as a function of the distance ( d ij ) between that exemplar and the test stimulus. You may recognize that this function looks much like the famous generalization gradient that is observed in most situations involving discrimination (in species ranging from pigeons to humans; Shepard, 1987). This similarity is no coincidence; rather, it motvates the functional form of the similarity function in Equation 1.4. This similarity funtion is central to GCM’s ability to generalize learned responses (i.e., cartoon faces seen during study) to novel stimuli (never-before-seen cartoon faces presented at test only). 1 2 3 4 5 6 7 8 9 10 0 0.1 0.2 0.3 0.4 0.5 0.6 Distance Activation Figure 1.7 The effects of distance on activation in the GCM. Activation (i.e., s ij ) is shown as a function of distance ( d ij )",
    "chunk_id": "Adv_cognitive_modelling_farrell-2018-computational-modeling-of-cognition_page-1-21.json_chunk_19"
  },
  {
    "document_type": "book",
    "title": "Computational modeling of cognition",
    "author": "Farell",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Farrell-2018-Computational-modeling-of-cognition.pdf",
    "date_published": "2018",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". 1 2 3 4 5 6 7 8 9 10 0 0.1 0.2 0.3 0.4 0.5 0.6 Distance Activation Figure 1.7 The effects of distance on activation in the GCM. Activation (i.e., s ij ) is shown as a function of distance ( d ij ). The parameter c (see Equation 1.4) is set to 0.5. 16 Introduction It turns out that there is little left to do: Having presented a mechanism by which a test stimulus activates an exemplar according to its proximity in psychological space, we now compute those activations for all memorized exemplars. That is, we compute the distance d ij between i and each j ∈ J as given by Equation 1.3 and derive from that the activation s ij as given by Equation 1.4. The next step is to convert of the entire set of resulting activations into an explicit decision: which category does the stimulus belong to? To accomplish this, the activations are summed separately across exemplars within each of the two categories. The relative magnitude of those two sums directly translates into response probabilities as follows: P ( R i = A | i ) = j ∈ A s ij j ∈ A s ij j ∈ B s ij , (1.5) where A and B refer to the two possible categories, and P ( R i = A | i ) means “the probabiity of classifying stimulus i into category A .” It follows that application of Equations 1.3 through 1.5 permits us to derive classification predictions from the GCM. It is those predictions that were plotted on the abscissa ( X -axis) in the left panel of the earlier Figure 1.4, and it is those predictions that were found to be in such close accord with the data. If this is your first exposure to quantitative explanatory models, the GCM may appear daunting at first glance. We therefore wrap up this section by taking a second tour through the GCM that connects the model more directly to the cartoon face experiment. Figure 1.8 shows the stimuli used during training. Each of those faces corresponds to a memorized exemplar j that is represented by a set of dimensional values { x j 1 , x j 2 , } , where each x jk is the numeric value associated with dimension k",
    "chunk_id": "Adv_cognitive_modelling_farrell-2018-computational-modeling-of-cognition_page-1-21.json_chunk_20"
  },
  {
    "document_type": "book",
    "title": "Computational modeling of cognition",
    "author": "Farell",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Farrell-2018-Computational-modeling-of-cognition.pdf",
    "date_published": "2018",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Each of those faces corresponds to a memorized exemplar j that is represented by a set of dimensional values { x j 1 , x j 2 , } , where each x jk is the numeric value associated with dimension k . For example, if the nose of exemplar j has length 5, then x j 1 = 5 on the assumption that the first dimension (arbitrarily) represents the length of the nose. Figure 1.8 Stimuli used in a classification experiment by Nosofsky (1991). Each row shows training faces from one of the two categories. Figure reprinted from Nosofsky, R. M., Tests of an exemplar mode for relating perceptual classification and recognition memory, Journal of Experimental Psychology: Human Perception and Performance , 17 , 3–27, 1991, published by the American Psychological Association, reprinted with permission. 1.3 Potential Problems: Scope and Falsifiability 17 To obtain predictions from the model, we then present test stimuli (those shown in Figure 1.8 but also new ones to test the model’s ability to generalize). Those test stimuli are coded in the same way as training stimuli; namely, by a set of dimensional values. For each test stimulus i we first compute the distance between it and exemplar j (Equation 1.3). We next convert that distance to an activation of the memorized exemplar j (Equation 1.4) before summing across exemplars within each category (Equation 1.5) to obtain a predicted response probability. Do this for each stimulus in turn, and bingo – you have the model’s complete set of predictions shown in Figure 1.4. How exactly are these computations performed? A whole range of options exists: if the number of exemplars and dimensions is small, a simple calculator, paper, and a pencil will do. More than likely, though, you will be using a commercial software package (such as a suitable worksheet in Excel) or a custom-designed computer program (e.g., written in a language such as MATLAB or R). We walk through some R code for this example in a later chapter",
    "chunk_id": "Adv_cognitive_modelling_farrell-2018-computational-modeling-of-cognition_page-1-21.json_chunk_21"
  },
  {
    "document_type": "book",
    "title": "Computational modeling of cognition",
    "author": "Farell",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Farrell-2018-Computational-modeling-of-cognition.pdf",
    "date_published": "2018",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". We walk through some R code for this example in a later chapter. Regardless of how we perform these computations, we are assuming that they represent an analogue of the processes used by people. That is, we presume that people remember exemplars and base their judgments on those memories alone, without access to rules or other abstractions. At this point, one can usefully ponder two questions. First, why would we focus on an experiment that involves rather artificial cartoon faces. Do these stimuli and the associated data and modeling have any bearing on classification of “real-life” stimuli? Yes, in several ways. Not only can the GCM handle performance with large and ill-defined perceptual categories (McKinley and Nosofsky, 1995), but recent extensions of the model have been successfully applied to the study of natural concepts, such as fruits and vegetables (Verbeemen et al., 2007). The GCM thus handles a wide variety of both artificial and naturalistic categorizations. Second, one might wonder about the motivation underlying the equations that define the GCM. Why is distance related to similarity via an exponential function (Equation 1.4)? Why are responses determined in the manner shown in Equation 1.5? It turns out that for any good model – and the GCM is a good model – the choice of mathematics is not at all arbitrary but derived from some deeper theoretical principle. For example, the distance-similarity relationship in the GCM incorporates our knowledge about the “universal law of generalization” (Shepard, 1987) and the choice of response implements a theoretical approach first developed by Luce (1963). What do you now know and what is left to do? You have managed to study your (possibly) first explanatory process model, and you should understand how the model can predict results for specific stimuli in a very specific experiment. However, there are a few obstacles that remain to be overcome, most of which relate to the how of applying the model to data",
    "chunk_id": "Adv_cognitive_modelling_farrell-2018-computational-modeling-of-cognition_page-1-21.json_chunk_22"
  },
  {
    "document_type": "book",
    "title": "Computational modeling of cognition",
    "author": "Farell",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Farrell-2018-Computational-modeling-of-cognition.pdf",
    "date_published": "2018",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". However, there are a few obstacles that remain to be overcome, most of which relate to the how of applying the model to data. Needless to say, those topics will be covered in subsequent chapters. 1.3 Potential Problems: Scope and Falsifiability Like all tools, modeling comes with its own set of limitations and potential problems. Here we focus on the related issues of model scope and model falsifiability – that is, how 18 Introduction much a model can handle and how easy it is to show that it is wrong. In later chapters, we take up additional, more subtle issues of interpretation. Suppose you are a venture capitalist and a scientist approaches you for funding to develop a new theory that will revolutionize gambling. A first version of the theory exists, and it has been extremely successful because it probabilistically characterized the outcomes of 20 successive rolls of a die. In quantitative terms, the theory anticipated each individual outcome with P = 1 / 6. Would you be impressed? We trust that you are not, because any theory that predicts any possible outcome with equal facility is of little scientific interest, even if it happens to be in complete accord with the data (e.g., Roberts and Pashler, 2000). This is quite obvious with our fictitious “theory” of gambling, but it is less obvious – though nonetheless equally applicable – with psychological theories. Let us reconsider one of the earlier examples: Nosofsky (1991) showed that an exemplar model (the GCM) can integrate people’s recognition and classification responses under a common theoretical umbrella (see Figure 1.4). We considered this to be impressive, especially because the GCM performed better than a competing prototype theory",
    "chunk_id": "Adv_cognitive_modelling_farrell-2018-computational-modeling-of-cognition_page-1-21.json_chunk_23"
  },
  {
    "document_type": "book",
    "title": "Computational modeling of cognition",
    "author": "Farell",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Farrell-2018-Computational-modeling-of-cognition.pdf",
    "date_published": "2018",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". We considered this to be impressive, especially because the GCM performed better than a competing prototype theory. But was our satisfaction justified? What if the exemplar model could have equally explained any other possible relationship between recognition and classification, and not just the one shown in Figure 1.3? What if we had fed the model some synthetic data in which recognition and classification were completely uncorrelated, and the model would have nonetheless been able to reproduce those data? Indeed, in that case, one would need to be quite concerned about the exemplar model’s viability as a testable and falsifiable psychological theory. 7 Fortunately, however, these concerns can be allayed by the fact that the exemplar model is at least in principle subject to falsification, as revealed by some of the results mentioned earlier that place limits on the GCM’s applicability (e.g., Little and Lewandowsky, 2009; Rouder and Ratcliff, 2004; Yang and Lewandowsky, 2004). Did you notice that we have just created a conundrum? On the one hand, it goes without saying that we want our theories to explain data. We want powerful theories, such as Kepler’s, that explain fundamental aspects of our universe. We want powerful theories, such as Darwin’s, to explain the diversity of life. On the other hand, we want the theories to be falsifiable – that is, we want to be assured that there are at least hypothetical outcomes that, if they are ever observed, would falsify a theory. For example, Darwin’s theory of evolution predicts a strict sequence in which species evolved; hence any observation to the contrary in the fossil record – e.g., human bones co-occurring with dinosaur remains in the same geological strata (e.g., Root-Bernstein, 1981) – would seriously challenge the theory",
    "chunk_id": "Adv_cognitive_modelling_farrell-2018-computational-modeling-of-cognition_page-1-21.json_chunk_24"
  },
  {
    "document_type": "book",
    "title": "Computational modeling of cognition",
    "author": "Farell",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Farrell-2018-Computational-modeling-of-cognition.pdf",
    "date_published": "2018",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". This point is sufficiently important to bear repetition: Even though we are convinced that Darwin’s theory of evolution, one of the most elegant and powerful achievements of human thought, is true, we simultaneously also want it to be falsifiable – falsifiable , not false. 8 Likewise, we are committed to 7 Throughout this book, we use the terms “falsifiable” and “testable” interchangeably to denote the same idea; namely, that at least in principle there are some possible outcome(s) that are incompatible with the theory’s predictions. 8 Despite its falsifiability, Darwin’s theory has a perfect track record of its predictions being uniformly confirmed; Coyne (2009) provides an insightful account of the impressive list of successes. 1.3 Potential Problems: Scope and Falsifiability 19 Figure 1.9 Four possible hypothetical relationships between theory and data involving two measures of behavior (A and B). Each panel describes a hypothetical outcome space permitted by the two measures. The shaded areas represent the predictions of a theory that differs in predictive scope (narrow and broad in top and bottom panels, respectively). The error bars represent the precision of the observed data (represented by the black dot). See text for details. Figure reprinted from Roberts, S. & Pashler, H., How persuasive is a good fit? A comment on theory testing, Psychological Review, 107 , 358–367, 2000, published by the American Psychological Association, reprinted with permission. the idea that the earth orbits around the sun rather than the other way around, but as scientists we accept that fact only because it is based on a theory that is falsifiable – again, falsifiable , not false. Roberts and Pashler (2000) considered the issue of falsifiability and scope with reerence to psychological models and provided an elegant graphical summary that is reproduced in Figure 1.9. The figure shows four hypothetical outcome spaces that are formed by two behavioral measures",
    "chunk_id": "Adv_cognitive_modelling_farrell-2018-computational-modeling-of-cognition_page-1-21.json_chunk_25"
  },
  {
    "document_type": "book",
    "title": "Computational modeling of cognition",
    "author": "Farell",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Farrell-2018-Computational-modeling-of-cognition.pdf",
    "date_published": "2018",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". The figure shows four hypothetical outcome spaces that are formed by two behavioral measures. What those measures represent is totally arbitrary – they could be trials to criterion in a memory experiment and a final recognition score, or any other pair of measures of interest. Within each panel, the dotted area represents all possible predictions that are within the scope of a psychological theory. The top row of panels represents some hypothetical theory whose predictions are constrained to a narrow range of outcomes; any outcome outside the dotted sliver would constitute contrary evidence, and only the narrow range of values within the sliver would constitute supporting evidence. Now compare that sliver to the bottom row of panels with its very generous dotted areas; the theory shown in the bottom row is compatible with nearly all possible outcomes. It follows that any observed outcome that falls within a dotted area would offer greater support for the 20 Introduction theory in the top row than the bottom row, simply because the likelihood of a match between data and predictions is far less likely – and hence more informative when it occurs (see Dunn, 2000, for a similar but more formalized view). Ideally, we would want our theories to occupy only a small region of the outcome space, but for all observed outcomes to fall within that region—as they do for Kepler’s and Darwin’s theories. Another important aspect of Figure 1.9 concerns the quality of the data, which is reresented by the columns of panels. The data (shown by the single black point bracketed by error bars) exhibit less variability in the left column than in the right. For now, we note briefly that support for the theory is thus strongest in the top left panel; beyond that, we defer discussion of the important role of data to Chapters 10 and 12. Those chapters will also provide another in-depth and more formal look at the issue of testability and falsifiability. 1.4 Modeling as a “Cognitive Aid” for the Scientist Science depends on reproducibility",
    "chunk_id": "Adv_cognitive_modelling_farrell-2018-computational-modeling-of-cognition_page-1-21.json_chunk_26"
  },
  {
    "document_type": "book",
    "title": "Computational modeling of cognition",
    "author": "Farell",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Farrell-2018-Computational-modeling-of-cognition.pdf",
    "date_published": "2018",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". 1.4 Modeling as a “Cognitive Aid” for the Scientist Science depends on reproducibility. That is why experimental method sections must offer sufficient detail to permit replication of a study (an ideal that, from experience, is often difficult to achieve, especially in brief 4,000-word research reports). That is also why replication of experimental findings is such a crucial issue and why concerns about the replicability of psychological findings have become an important and hotly debated research topic (e.g., Pashler and Wagenmakers, 2012). There is another aspect to reproducibility that is tacitly taken for granted by most researchers, but is rarely explored in the depth that it deserves: Scientists assume that we are all reasoning in the same way, and that all scientists have a shared understaning of whatever theory is under consideration. However, like it or not, communication among scientists resembles a game of “telephone” (also known as “Chinese whispers”), whereby theories and models are formulated by one researcher and recorded on paper before being read by the next scientist(s) who need(s) to understand them. Those new ideas may in turn be recorded in a further paper and so on. Each step in this chain involves cognitive reasoning, and is thus subject to the known limitations of human cognition – from our limited attentional capacity to the confirmation bias, to name but two (Evans, 1989). The implications of this inescapable reliance on human reasoning can be illustrated with the popular “spreading activation theory” (Anderson, 1996; Collins and Loftus, 1975) which postulates that concepts in memory (i.e., our knowledge of dog or cat ) are represented by an interconnected network of nodes. Nodes are activated upon stimulus presentation, and activation spreads through the connections to neighboring nodes",
    "chunk_id": "Adv_cognitive_modelling_farrell-2018-computational-modeling-of-cognition_page-1-21.json_chunk_27"
  },
  {
    "document_type": "book",
    "title": "Computational modeling of cognition",
    "author": "Farell",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Farrell-2018-Computational-modeling-of-cognition.pdf",
    "date_published": "2018",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Nodes are activated upon stimulus presentation, and activation spreads through the connections to neighboring nodes. In consequence, the theory can explain the well-known semantic priming effect: If people need to decide whether or not “nurse” constitutes an English word, they can do so more quickly if they have just seen the word “doctor” than if they have seen an unrelated item such as “bread” (e.g., Neely, 1976). According to spreading-activation theory, this faciitation arises because activation spreads from a node to its neighbors: Because “nurse” is semantically associated with “doctor,” both are located in the same neighborhood of the 1.4 Modeling as a “Cognitive Aid” for the Scientist 21 network and presentation of the former makes the latter more accessible once activation has spread. To understand and communicate the notion of spreading activation, several analgies might be used: Some researchers liken the spread to electricity passing through wires (Radvansky, 2006), whereas others liken it to water passing through pipes (as one of us has done in lectures to undergraduates). Which analogy is being adopted will determine people’s precise understanding of the operation of the model. The water analogy necessarily implies a relatively slow spread of activation, while an electricity analogy will imply almost instantaneous spreading of activation. As it turns out, the data agree with the electricity analogy in showing activation of distal concepts to be almost instantaneous (Ratcliff and McKoon, 1981). This problem – that the choice of analogy will affect a scientist’s understanding of her own model – will undoubtedly be compounded when theorizing involves groups of scholars who communicate with each other. What the group considers to be a shared understanding of a model may in fact be limited to a shared understanding of only some core features",
    "chunk_id": "Adv_cognitive_modelling_farrell-2018-computational-modeling-of-cognition_page-1-21.json_chunk_28"
  },
  {
    "document_type": "book",
    "title": "Computational modeling of cognition",
    "author": "Farell",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Farrell-2018-Computational-modeling-of-cognition.pdf",
    "date_published": "2018",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". What the group considers to be a shared understanding of a model may in fact be limited to a shared understanding of only some core features. In consequence, a researcher may believe that she is testing another scholar’s theory, but that other scholar may reject the test as being incisive because in their view the theory is actually predicting something different. The adverse implications of these ambiguities are obvious. Fortunately, they can be largely alleviated by using computational models in preference to verbal theorizing. A principal advantage of computational models is that we are forced to specify all parts of our theory. In the case of spreading activation, we must answer such questions as: Can activation flow backwards to immediately preceding nodes? Is the amount of activation unlimited? Is there any leakage of activation from nodes? Such questions have been answered in Anderson’s (1983b) implementation of spreading activation in a memory model based in the computational framework of his ACT (Adaptive Control of Thought) theory. This theory represents knowledge as units (or nodes) that are associated to each other to varying degrees. Closely related concepts (bread–butter) have strong connetions and concepts that are more distant (bread–flour) have weaker connections. When concepts are activated, the corresponding units comprise the contents of working meory. Units in working memory become sources of activation, and pass their activation on to other units to an extent that is proportional to their own activation and the connection strengths. The model has an effective limit on the amount of activation by assuming some loss of activation from the source units. The model also assumes that activation can flow back along activation pathways",
    "chunk_id": "Adv_cognitive_modelling_farrell-2018-computational-modeling-of-cognition_page-1-21.json_chunk_29"
  },
  {
    "document_type": "book",
    "title": "Computational modeling of cognition",
    "author": "Farell",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Farrell-2018-Computational-modeling-of-cognition.pdf",
    "date_published": "2018",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". The model has an effective limit on the amount of activation by assuming some loss of activation from the source units. The model also assumes that activation can flow back along activation pathways. The model uses these and other assumptions about encoding and retrieval to explain spreading activation and numerous other phenomena, such as serial order memory over the short term (Anderson and Matessa, 1997) and practice and spacing effects (Pavlik and Anderson, 2005, 2008). Detailed specifications of this type, which verbal theories omit altogether, render a computational model more readily communicable (e.g., by sharing the computer code with other scholars) and hence more testable and falsifiable. Computational models thus check whether our intuitions about the behavior of a theorized system match what actually arises from its realization. In the next chapter, 22 Introduction we take you through an example of model development that expands on the theme that computational models can serve as a “cognitive aid” for theorists. To foreshadow, we will present a model of how people make speeded decisions between two alternatives— “is the traffic light red or green?”—at a verbal level, and we will then show how your likely intuitions about the model’s predictions are actually wrong. In a later chapter (Chapter 12) we will discuss further how models can aid scientists in thinking and reasoning about their theories. 1.5 In Vivo Modeling: “Cognitive Aid” or “Cognitive Burden”? Nina R. Arnold (University of Mannheim) One popular class of models that aim to explain the underlying cognitive processes are multinomial processing tree (MPT) models (e.g., Batchelder and Riefer, 1999). These models estimate latent processes that are assumed to underlie observable outcome categories. Because MPT models do not make any assumptions about the particular nature of those latent processes, they can be applied to many different areas of cognitive research",
    "chunk_id": "Adv_cognitive_modelling_farrell-2018-computational-modeling-of-cognition_page-1-21.json_chunk_30"
  },
  {
    "document_type": "book",
    "title": "Computational modeling of cognition",
    "author": "Farell",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Farrell-2018-Computational-modeling-of-cognition.pdf",
    "date_published": "2018",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Because MPT models do not make any assumptions about the particular nature of those latent processes, they can be applied to many different areas of cognitive research. Regardless of the specific area, these models force modelers and researchers to make their assumptions about the underlying processes explicit. The models can then be drawn as a tree (hence “processing tree” models) that depicts a sequence of cognitive events that are linked by probabilistic transitions. Thus, MPT models are a good example for models that can be used to explain data with a computational model. It is hardly surprising that these models have been popular. However, to estimate model parameters that represent the underlying cognitive processes with a reasonable degree of certainty, a lot of data is needed. To achieve this, mostly researchers aggregate data over participants and items. This is not always plausible! While we may have somewhat control over the items (for example, through norms and pretests), it is more than likely that participants differ from one another – even if data are collected in a seemingly homogeneous pool of participants like first year psychology students. Think back to your first year in college: Were your classmates all alike? The alternative, to collect enough data to run a separate model for each participant, is rarely possible under most circumstances. Fortunately, clever researchers (e.g., Matzke et al., 2015; Smith and Batchelder, 2010) came up with the idea of a hierarchical structure that solves this problem: In a hierarchical model, each participant has its own MPT model but the individual model parameters stem from a common distribution. This structure has several advantages. However, it also comes with disadvantages; one disadvantage is that modeling becomes more complex than fitting aggregate data. Several years ago when I started my PhD, I went to a summer school to learn about hierarchical MPT modeling",
    "chunk_id": "Adv_cognitive_modelling_farrell-2018-computational-modeling-of-cognition_page-1-21.json_chunk_31"
  },
  {
    "document_type": "book",
    "title": "Computational modeling of cognition",
    "author": "Farell",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Farrell-2018-Computational-modeling-of-cognition.pdf",
    "date_published": "2018",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Several years ago when I started my PhD, I went to a summer school to learn about hierarchical MPT modeling. The model I chose to start with was an MPT model for decomposing the underlying processes in hindsight bias proposed by Erdfelder and Buchner (1998). The hindsight bias refers to the finding that once you have received 1.5 In Vivo 23 feedback about the correct answer to a question, your recollection about your own past answer is often biased toward the feedback (you always knew that the capital of Madagascar is Antananarivo, right?). The MPT models explains this hindsight bias in terms of both memory impairments and reconstruction biases. Unfortunately, it is one of the more complex MPT models. The most important thing I learned here was that when you try to learn a new method – start simple! I did not manage to implement the model at the summer school but I learned a lot about the basics of computational and hierarchical modeling and I kept trying. Back at my university I switched to a different MPT model and after a lot of work (and a few !@&%!&!@## words) I finally managed to implement my first hierarchical MPT model (Arnold et al., 2013). Over the years (and after a lot more !@&%!&!@##), I gained more insight into different hierarchical MPT modeling techniques and the underlying methods. I was able to implement hierarchical MPTs for different MPT models and with different underlying common distributions and see if they come to the same conclusions. (Normally, they do.) Finally, I turned back to the hindsight bias MPT model I started with. Having gathered more experience I was able to consider the special requirements of this model. It turns out that the model is especially tricky to work with because some categories often have very few (or even no) observations. I had learned that hierarchical MPT analyses are in principal viable, but you may face several problems",
    "chunk_id": "Adv_cognitive_modelling_farrell-2018-computational-modeling-of-cognition_page-1-21.json_chunk_32"
  },
  {
    "document_type": "book",
    "title": "Computational modeling of cognition",
    "author": "Farell",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Farrell-2018-Computational-modeling-of-cognition.pdf",
    "date_published": "2018",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". I had learned that hierarchical MPT analyses are in principal viable, but you may face several problems. However, these problems can be reduced when you have knowledge about parameters that can be resembled in the prior distributions and if you reduce model complexity where possible. Now let me get back to the question in the title: Is computational modeling an aid or a burden? Certainly, it can be very complicated and frustrating. But it also clarifies the underlying assumptions and helps you gather new insights. The important thing while learning is to start simple and sometimes vent your frustration aloud.",
    "chunk_id": "Adv_cognitive_modelling_farrell-2018-computational-modeling-of-cognition_page-1-21.json_chunk_33"
  },
  {
    "document_type": "research_paper",
    "title": "Building better theories",
    "author": "Clare Press",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\building_better_theories.pdf",
    "date_published": "2022-01-05",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": "Magazine ll 11. Yuan, K., Reckling, M., Ramirez, M.D.A., Djedidi, S., Fukuhara, I., Ohyama, T., Yokoyama, T., Bellingrath-Kimura, S.D., Halwani, M., Egamberdieva, D., and Ohkama-Ohtsu, N. (2020). Characterization of rhizobia for the improvement of soybean cultivation at cold conditions in Central Europe. Microbes Environ. 35 , ME19124 . 12. Carver, G.W. (1915). Alfalfa: The king of all fodder plants, successfully grown in Macon County, Ala. Bulletin 29 (Tuskegee, Alabama: Tuskegee Institute, Experiment Station), https://doi. org/10.5962/bhl.title.119705 . 13. Marino, D., Frendo, P., Ladrera, R., Zabalza, A., Puppo, A., Arrese-Igor, C., and González, E.M. (2007). Nitrogen fi xation control under drought stress. Localized or systemic? Plant Physiol. 143 , 1968–1974. 14. San ́ko-Sawczenko, I., Łotocka, B., Mielecki, J., Rekosz-Burlaga, H., and Czarnocka, W. (2019). Transcriptomic changes in Medicago truncatula and Lotus japonicus root nodules during drought stress. Int. J. Mol. Sci. 20 , 1204. 15. Bharadwaj, C., Tripathi, S., Soren, K.R., Thudi, M., Singh, R.K., Sheoran, S., Roorkiwal, M., Patil, B.S., Chitikineni, A., Palakurthi, R., et al. (2021). Introgression of “QTL-hotspot” region enhances drought tolerance and grain yield in three elite chickpea cultivars. Plant Genome 14 , e20076. 16. Marini, L., St-Martin, A., Vico, G., Baldoni, G., Berti, A., Blecharczyk, A., Malecka-Jankowiak, I., Morari, F., Sawinska, Z., and Bommarco, R. (2020). Crop rotations sustain cereal yields under a changing climate. Environ. Res. Lett. 15 , 124011. 17. Naab, J.B., Mahama, G.Y., Yahaya, I., and Prasad, P.V.V. (2017). Conservation agriculture improves soil quality, crop yield, and incomes of smallholder farmers in North Western Ghana. Front. Plant Sci. 8 , 996. 18. Stagnari, F., Maggio, A., Galieni, A., and Pisante, M. (2017). Multiple benefi ts of legumes for agriculture sustainability: An overview. Chem. Biol. Technol. Agric. 4 , 2. 19. Yu, H., Wang, F., Shao, M., Huang, L., Xie, Y., Xu, Y., and Kong, L. (2021)",
    "chunk_id": "Adv_cognitive_modelling_building_better_theories.json_chunk_1"
  },
  {
    "document_type": "research_paper",
    "title": "Building better theories",
    "author": "Clare Press",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\building_better_theories.pdf",
    "date_published": "2022-01-05",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". (2017). Multiple benefi ts of legumes for agriculture sustainability: An overview. Chem. Biol. Technol. Agric. 4 , 2. 19. Yu, H., Wang, F., Shao, M., Huang, L., Xie, Y., Xu, Y., and Kong, L. (2021). Effects of rotations with legume on soil functional microbial communities involved in phosphorus transformation. Front. Microbiol. 12 , 661100. 20. Roper, M.M., and Gupta, V.V.S.R. (2016). Enhancing non-symbiotic N 2 fi xation in agriculture. Open Agric. J. 10 , 7–27. 21. Carver, G.W. (1918). How to make sweet potato fl our, starch, sugar, bread and mock cocoanut. Bulletin 37 (Tuskegee, Alabama: Tuskegee Institute, Experiment Station), https://doi. org/10.5962/bhl.title.119800 . 22. Suiter Swantz IP staff (2017). George Washington Carver granted patent for the “Process of Producing Paints and Stains” (Suiter Swantz), https://suiter.com/patent-of-the-day-procespaints-stains-george-washington-carver/ . 23. Carver, G.W. (1935). How the farmer can save his sweet potatoes: And ways of preparing them for the table. Bulletin 38 (Tuskegee, Alabama: Tuskegee Institute Press, Experiment Station), https://doi.org/10.5962/bhl.title.119803 . 24. (1941) Art: Black Leonardo. Time, http:// content.time.com/time/subscriber/ article/0,33009,801330,00.html . 25. Carver, G.W. (1897). Progressive nature studies (Tuskegee, Alabama: Tuskegee Institute Print), https://doi.org/10.5962/bhl.title.45464 . 26. (2021). Growing concerns for COP26. Nat. Plants 7 , 1323. 27. Mabhaudhi, T., Chimonyo, V.G.P., Hlahla, S., Massawe, F., Mayes, S., Nhamo, L., and Modi, A.T. (2019). Prospects of orphan crops in climate change. Planta 250 , 695–708. Centre for Plant Sciences, School of Biology, University of Leeds, Leeds LS2 9JT, UK. E-mail: y.benitez-alfonso@leeds.ac.uk Building better theories Clare Press 1,2 , * , Daniel Yon 1 , and Cecilia Heyes 3,4 Science is made of ideas and data, theory and observation. Theories can tell us which data to collect, summarise masses of observations, and explore the space of potential explanations",
    "chunk_id": "Adv_cognitive_modelling_building_better_theories.json_chunk_2"
  },
  {
    "document_type": "research_paper",
    "title": "Building better theories",
    "author": "Clare Press",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\building_better_theories.pdf",
    "date_published": "2022-01-05",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Theories can tell us which data to collect, summarise masses of observations, and explore the space of potential explanations. Some theories, the ones that describe mechanisms, can even turn straw into gold — transforming data into explanations of the world around us. Given the central importance of theory, there are good reasons to worry about the lack of ideas in biology 1 , and the ‘theory crisis’ in the cognitive and behavioural sciences 2,3 . It has been argued that this lack of ‘novel ideas’ is slowing scientifi c progress 4 , but what can be done? In the long term, we need to look closely at how scientists are trained. Typically, students are taught a great deal about how to collect data and next to nothing about how to formulate and evaluate theory. We force feed techniques and statistics, but, like parental prudes, leave the kids to work out for themselves where theories come from. In the medium term, there is no shortage of detailed, technical advice for those with the freedom and inclination to make radical changes to their science — to get into formal modelling or interdisciplinary collaboration 5–7 — but even these changes can leave the core theoretical problems unresolved 8 . In the short term, we can all up our theoretical game by thinking a little harder about what theories are for, how they should be constructed, and which tests are worth the effort. In this My Word, we offer a checklist of seven questions we fi nd useful when formulating and testing our own theories, and when thinking through the work of others in our research fi elds. Theory has several functions 9 but, like many scientists, we want our work to contribute to explanation. Therefore, whenever we say ‘theory’ we mean mechanistic theory — the kind that has the potential to be explanatory 10 . Otherwise, we are broad-minded — a My word mechanistic theory may be labelled as such or as a ‘model’; it can be formal, for example computational/ mathematical, or informal, for example graphical/narrative",
    "chunk_id": "Adv_cognitive_modelling_building_better_theories.json_chunk_3"
  },
  {
    "document_type": "research_paper",
    "title": "Building better theories",
    "author": "Clare Press",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\building_better_theories.pdf",
    "date_published": "2022-01-05",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Without naming and shaming, we use examples from our own fi elds of research — social cognition, memory, perception, and action — areas where cognitive science meets neuroscience and evolution. What is the target? A theory needs a target or ‘explanandum’ — a phenomenon that exists or occurs in the natural world that the theory is designed to explain. There are very few constraints on the size of the target — classics include magnetism, oxidation, fermentation, and lava fl ow — but, whatever the size or aspect of the natural world, the target should show some signs of unity, of being a ‘thing’. Say you want to explain imitation. If you defi ne imitation loosely, to encompass all sorts of vaguely social learning, you are unlikely to come up with a successful theory because the cases are probably not produced by the same causal structure. It is unlikely that the same psychological or neurological mechanism enables snails to fi nd food by following the slime trails of other snails and enables people to learn calculus by reading textbooks. On the other hand, if you defi ne imitation tightly — for example, as copying behavioural topography, the way that parts of the body move relative to one another — there is a decent chance all cases are due to the same causal structure; that one mechanism allows imitation of scowls, arabesques and Fosbury Flops 11 . Obviously, the more you know about your target the better, and plenty of important research aims to characterise the target rather than to test theory. What are the triggers, modulators, and inhibitors? What happens when the system is damaged or operating under unusual conditions? How does the system function at different points in development and across species? Not-so-obviously, it is important to keep all this information in mind when formulating or assessing a theory",
    "chunk_id": "Adv_cognitive_modelling_building_better_theories.json_chunk_4"
  },
  {
    "document_type": "research_paper",
    "title": "Building better theories",
    "author": "Clare Press",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\building_better_theories.pdf",
    "date_published": "2022-01-05",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". If a theory works for deliberate but not automatic imitation, or for imitation in primates but not in birds, Magazine ll we need good reasons to regard these as distinct targets rather than areas where the theory fails. Scientists sometimes treat an effect — an impact of an independent variable on a dependent variable — as an explanatory target. This is risky because, although effects have signifi cant functions in science 12 , an effect rarely captures all and only the manifestations of a single causal structure. For example, many psychologists and neuroscientists are interested in the fi nding that perception is often attenuated during action; we cannot tickle ourselves. However, it is risky to use this ‘sensory attenuation’ effect as an explanatory target because it can arise via many different routes 13,14 . For instance, self-produced tickle might be perceptually attenuated by general gating mechanisms in the spine, predictive processes that ‘cancel out’ expected action outcomes, or because our attention is directed differently when we have to act and perceive simultaneously. The causes of sensory attenuation do not have the unity and specifi city needed to make it a good explanatory target. It may be better to focus theorising on understanding the targets (for example, prediction) that cause the effect, rather than the effect itself. Do I have a theory or just a prediction? ‘Hypothesis’: a neat word with messy consequences. Used as a synonym for both ‘theory’ and ‘prediction’, ‘hypothesis’ can hide the fact that theories and predictions are very different beasts 7 . Theories postulate entities and activities that produce and explain observable phenomena 10 . For example, Baddeley’s theory of working memory 15 explains short-term retention of information (the target) with reference to cognitive entities including the ‘central executive’ and ‘phonological loop’, and activities performed by these entities such as ‘updating’, ‘binding’ and ‘inhibiting’",
    "chunk_id": "Adv_cognitive_modelling_building_better_theories.json_chunk_5"
  },
  {
    "document_type": "research_paper",
    "title": "Building better theories",
    "author": "Clare Press",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\building_better_theories.pdf",
    "date_published": "2022-01-05",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". A prediction, on the other hand, is what you expect when you do an experiment or perform a new analysis of existing data. Predictions are sometimes derived from theories, but having a prediction is no guarantee that you have got a theory. Say we give a test of working memory to 5- and 7-year-old children. We might expect the 7-yeaolds to do better than the 5-year-olds by pure extrapolation — because previous work shows that 5-year-olds perform better than 3-year-olds on the very same test. These are empiricallbased rather than theory-based predictions, like expecting to wake up in the morning because we have done so in the past. Most of us do not have a theory of what causes waking (or sleeping), but we still bet when we go to sleep tonight that we will wake up tomorrow. Alternatively, we might derive our prediction for this experiment from Baddeley’s theory of working memory, which assigns a specifi c role to executive function in short-term retention. If we have evidence from previous work using different tests — assessing vigilance or inhibitory control, rather than memory — that executive function improves between the ages of 5 and 7, then we could make the theory-based prediction that 7-year-olds will do better than 5-yeaolds in our experiment. Empirically-based and theory-based predictions can be hard to tell apart. For example, psychopharmacologists often investigate how drugs that act on neurotransmitters alter cognition and behaviour. A psychopharmacologist might predict that administering the drug methylphenidate — which enhances the synaptic availability of dopamine — will enhance a volunteer’s ability to update working memory. Is this a theory-based prediction about the role of dopamine in working memory? It is tempting to think so, because working memory has been the focus of many theories, and regardless of the nature of the prediction the papers frequently refer to ‘dopaminergic mechanisms’",
    "chunk_id": "Adv_cognitive_modelling_building_better_theories.json_chunk_6"
  },
  {
    "document_type": "research_paper",
    "title": "Building better theories",
    "author": "Clare Press",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\building_better_theories.pdf",
    "date_published": "2022-01-05",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". However, it is sometimes an empirically-based prediction — derived only from previous results, not from a theory about how the system works. Such a theory might postulate that increased synaptic availability of dopamine destabilises representations, making them more amenable to insertions of new information. Is it a theory or a framework? A theory is bigger than a prediction and smaller than a framework. A framework is a way of thinking about all or part of the natural world. Theories generate predictions and live inside frameworks. As we are using the terms, theories should be testable, but frameworks can be useful even when no data could show that they are wrong. A nice illustration of this distinction comes from recent ideas in cognitive neuroscience surrounding the ‘Bayesian brain’. Scientists working within this framework suggest that the brain is fundamentally in the game of modelling the outside world — with all aspects of thought and behaviour arising as the brain combines probabilistic top-down expectations with the bottom-up evidence arriving at our senses 16 . The kernel of this idea has proved incredibly fertile, sprouting many specifi c theories that aim to explain diverse aspects of cognition. For example, Bayesian principles directly inspired the ‘strong prior’ theory of hallucinations, which posits that abnormal experiences like voichearing in psychosis emerge because patients give an unusually strong weight to top-down expectations when perceiving their surroundings 17 . Theories of this kind — derived from or inspired by an explicit framework — do make testable predictions. For instance, the ‘strong prior’ theory predicts that patients who hallucinate should also show a stronger reliance on top-down knowledge in other perceptual tasks 18 . But the framework lurking in the background may not be amenable to testing in the same way",
    "chunk_id": "Adv_cognitive_modelling_building_better_theories.json_chunk_7"
  },
  {
    "document_type": "research_paper",
    "title": "Building better theories",
    "author": "Clare Press",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\building_better_theories.pdf",
    "date_published": "2022-01-05",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". But the framework lurking in the background may not be amenable to testing in the same way. For example, proponents of the Bayesian brain framework have noted mathematical proofs which guarantee it is always possible to specify a set of prior beliefs that would make an observed thought or behaviour seem ‘Bayes optimal’ — that is, compliant with the overarching framework 19 . This means that, in principle , there is no result the framework cannot accommodate, and no pattern of possible results that could disprove it. Thus, our experiments are more likely to be fruitful when they aim to test theories rather than frameworks. Is the theory pointing at the target? There are good and not-so-good ways for a theory to fail. A theory fails in a good way when it makes plausible, testable predictions that are Magazine ll not confi rmed by the evidence (see below). It fails in a not-so-good way when, regardless of the evidence, the theory lacks the potential to explain its target. This sometimes happens when typologies are mistaken for theories. Typologies, such as the Linnean classifi cation of plants and animals, can help theory construction by organising and displaying the phenomena to be explained. However, by themselves typologies do not make predictions or offer explanations. Types of social learning — such as ‘response facilitation’ and ‘emulation’ — are routinely described as ‘mechanisms of social learning’, but they are defi ned purely by their stimulus inputs and behavioural outputs. They are names of effects rather than theories; they are not backed by accounts of the entities and activities in the mind/ brain that produce the input–output relationships. In other cases, a theory misses its target by postulating a causal structure that is as much in need of explanation and evidence as the target itself. When it is discovered, this problem is sometimes called ‘begging the question’",
    "chunk_id": "Adv_cognitive_modelling_building_better_theories.json_chunk_8"
  },
  {
    "document_type": "research_paper",
    "title": "Building better theories",
    "author": "Clare Press",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\building_better_theories.pdf",
    "date_published": "2022-01-05",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". When it is discovered, this problem is sometimes called ‘begging the question’. An obvious example would be a claim that diffi culty in recognising faces is caused by prosopagnosia — the name for diffi culty in recognising faces. However, begging the question can be surprisingly diffi cult to spot because the theoretical entities are typically described in a different language from the target. For example, a central challenge for an imitation mechanism is the conversion of information in one modality (visual inputs hitting the retina) into another (motor commands driving execution of a ‘corresponding’ action). It was recently suggested that mirror neurons solve the correspondence problem for imitation, but this proposal begs the question. Unless the theory tells us not just that but how mirror neurons convert visual input to motor output, the ‘explanation’ is as mysterious as the thing it is supposed to explain; the mirror neuron theory just moves the hard problem of imitation from behaviour into the brain. Is the theory new? Sometimes what appears to be a new theory turns out to be an old theory expressed in a new way ( Figure 1 ). For example, across the last century psychologists have theorised about mechanisms of associative learning — mechanisms that allow us to learn a ringing bell predicts an upcoming food pellet, or that stamping my foot on the pedal tends to make the car stop. The classic Rescorla–Wagner theory argues that animals like us form mental associations between events, adjusting the strength of these links based on patterns we experience (for example, strengthening the link between ‘bell ringing’ and ‘food delivery’ if these tend to co-occur). This account remains infl uential because of its ability to explain several experimental phenomena — such as ‘blocking’, where learning about one predictive event is slowed in the presence of another competing predictor",
    "chunk_id": "Adv_cognitive_modelling_building_better_theories.json_chunk_9"
  },
  {
    "document_type": "research_paper",
    "title": "Building better theories",
    "author": "Clare Press",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\building_better_theories.pdf",
    "date_published": "2022-01-05",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". In more recent years, however, alternative ‘Bayesian’ learning accounts have been offered, which suggest that learners use samples of experience to adjust graded beliefs in a ‘hypothesis space’ that represents how different events in our environment are related. These newer models also predict phenomena like ‘blocking’ — and thus account for the same experimental results. While the associative and Bayesian theories are formulated using different mathematical frameworks, both suggest that learning depends on the same kind of information (probabilistic co-occurrence). Are the Bayesian theories new? On the one hand, it seems not. Re-expressing an old idea (adjusting associative links) in a new language (updating probabilistic beliefs) does not in and of itself produce a new theory, if the new version can only predict (and account for) the same phenomena. On the other hand, it is possible that the process of reformulation ultimately generates new predictions — meaning that a new theory is born. In our example, reformulating associative learning in Bayesian terms encouraged theorists to build ideas around variance and uncertainty into the learning process. This leads to distinctive empirical predictions. For example, Bayesian models predict that we should learn faster when the world is more volatile — a prediction, since confi rmed, w ij a j = = 1 1 + e – i j ij i j j + w   a a Current Biology Figure 1. Translating theories. Scientifi c theories can be expressed in several ways. In our fi elds (psychology and neuroscience) theories are often expressed in the language of cognitive mechanisms, neural processes and fomal equations (or a combination thereof). Often, researchers translate theories from one of these languages into another: describing a cognitive model in neural terms, or reformulating a cognitive model as a computational one. While reformulation can have benefi ts, there is a danger that this process of translation leads us to think we have created a new theory",
    "chunk_id": "Adv_cognitive_modelling_building_better_theories.json_chunk_10"
  },
  {
    "document_type": "research_paper",
    "title": "Building better theories",
    "author": "Clare Press",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\building_better_theories.pdf",
    "date_published": "2022-01-05",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". While reformulation can have benefi ts, there is a danger that this process of translation leads us to think we have created a new theory. This may not be the case if we cannot use it to generate any new predictions (see main text ‘Is the theory new?’). Magazine ll which could not have been derived from the original Rescorla–Wagner theory. Re-expressions are useful if, like this, they generate new empirical predictions. Without this predictive novelty, re-expressions offer identical ideas 20 . Unfortunately, incentive structures that reward novelty and primacy in science discourage clear labelling. They make it tempting to present any reformulation as a new theory — giving the false, time-wasting impression that it can be tested against the original. These cosmetic reformulations can disguise old knowledge and lead to decades spent on identical research programmes that masquerade under different labels. Buyers beware 21 . What shall I test? We use a theory to generate an empirical prediction, and when the data are collected we confi rm or update the theory. Therefore, we should conduct those empirical tests that are most likely to inform the theories. What are they? ‘Underdetermination’ of theory by evidence means that a particular pattern of empirical results can always be explained by a range of actual or potential theories. To minimise this problem, we should test a theory’s most surprising predictions — the predictions that, if fulfi lled, will be inconsistent with the maximum number of alternative theories (‘risky testing’ 8 ; Figure 2 ). That is, assuming that all theories are based upon some preceding evidence and plausible assumptions, the most surprising predictions are usually those where theories deviate. Pitting theories against each other versus looking for confi rmation of only one should not be a pure matter of personal taste — as is often claimed. The latter is more likely to lead to the problem whereby the data do not shape the theoretical landscape",
    "chunk_id": "Adv_cognitive_modelling_building_better_theories.json_chunk_11"
  },
  {
    "document_type": "research_paper",
    "title": "Building better theories",
    "author": "Clare Press",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\building_better_theories.pdf",
    "date_published": "2022-01-05",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". The latter is more likely to lead to the problem whereby the data do not shape the theoretical landscape. For example, contrasting models of perceptual expectation disagree as to whether top-down predictions should dampen or sharpen representations in the sensory brain. Intriguingly, both dampening and sharpening models can predict a reduction in overall brain activity when our expectations come true (a generic prediction), meaning it is not particularly informative to look at global signal changes when trying to compare these theories. However, the accounts diverge sharply on whether the information content of sensory brain areas should increase or decrease when inputs are expected (distinctive prediction), meaning that experiments which use informatiobased measures of brain activity are more powerful for distinguishing between accounts 14 . Have I listened to Mother Nature? Many scientists love, and many philosophers loathe, Karl Popper’s idea that the hallmark of science is falsifi cation. Philosophers have turned against the principle of falsifi cation because it suggests that a set of observations could logically imply that a theory is wrong. This is implausible because the results of an empirical study depend, not only on the characteristics of the target system, but on a mass of auxiliary assumptions about the validity of measurement and analysis techniques, the proper implementation of the experimental design, and the absence of extraneous infl uences on the target system. Say we have a theory, X, implying that human newborns can imitate facial expressions, and we run an experiment testing the prediction that newborns will open their mouths more often when they see an adult opening her mouth rather than sticking out her tongue. The results are disappointing; the babies’ facial expressions do not vary with those of the adult",
    "chunk_id": "Adv_cognitive_modelling_building_better_theories.json_chunk_12"
  },
  {
    "document_type": "research_paper",
    "title": "Building better theories",
    "author": "Clare Press",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\building_better_theories.pdf",
    "date_published": "2022-01-05",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". The results are disappointing; the babies’ facial expressions do not vary with those of the adult. Does this mean theory X is wrong? It might, but it could also mean that our measure of facial movements was not subtle enough to pick up the difference between mouth opening and tongue protrusion in newborns, that we did not test enough babies, or that the babies were too uncomfortable or distracted to show us what they could do. Uncertainty about the causes of a negative result makes it diffi cult to hear Mother Nature — to work out whether she is whispering that our theory is wrong, or whether her voice is being drowned out by the clanking of our own empirical machinery. Fortunately, the uncertainty can be reduced in several ways. Of course, it helps to use measures that are known to be valid and reliable, and statistical procedures capable of estimating the likelihood of a hypothesis under particular patterns of data (for example, Bayesian statistics that signal whether there is support for the null or simply inconclusive evidence). But risky testing, a remedy that is often overlooked in discussions of ‘reproducibility’ and the ‘replication crisis’, is also crucial. It is easier to hear Mother Nature in a result predicted by an alternative theory, and risky testing makes research into a conversation rather than a monologue. When research groups test their theories against each other, the members of group A will always be on hand to point out potential interpretive problems when group B declares a loss for theory A or a win for theory B. Initially and at a Generic prediction Distinctive prediction Data from target Theory A Theory B Current Biology Figure 2. Risky testing. Theories differ from each other when they make different claims about the nature of their targets. However, two different theories can share common assumptions about the ‘shape’ of their targets (generic predictions) while making divergent predictions about other features (distinctive preditions)",
    "chunk_id": "Adv_cognitive_modelling_building_better_theories.json_chunk_13"
  },
  {
    "document_type": "research_paper",
    "title": "Building better theories",
    "author": "Clare Press",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\building_better_theories.pdf",
    "date_published": "2022-01-05",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". However, two different theories can share common assumptions about the ‘shape’ of their targets (generic predictions) while making divergent predictions about other features (distinctive preditions). Experiments designed to test these distinctive predictions tell us the most about which theories are likely to be true (see main text ‘What shall I test?’). Magazine ll personal level, these pointers may be unwelcome, but they can inspire more rigorous and creative tests, and deep collegiality among ‘rivals’. Healthy science involves ‘competition among the cooperators’ 22 . Persistent failure to listen when Mother Nature says ‘no’ can send science down blind alleys, wasting money and labour. An infl uential theory of cognitive development has survived for 40 years because frequent failures to fi nd imitation in newborns were attributed to more than 20 extraneous factors, including inadequate sample size, inappropriate statistical tests, and the kind of seat in which infants were tested. A recent meta-analysis 23 , fi nding no sign that these factors were modulating an underlying imitation effect, indicates the importance of letting go. It is tempting to protect one’s own theory with special pleading and post hoc hypotheses, but in the long term and for the scientifi c community as a whole, it is better to allow a cherished theory to fail in a good way (see 4 ) — to fall nobly in battle with the data. Conclusion If theories are like toothbrushes, with no one wanting to use someone else’s 24 , there are a lot of would-be theorists in science. Our hope is that this My Word will encourage aspirants to generate mechanistic theories that have unifi ed explanatory targets, are bigger than predictions, more testable than frameworks, and do not beg the question or imply that good old ideas are box fresh new ones. When theories with these characteristics are subjected to risky testing, and the results are interpreted by competing cooperators, the hay of venial science turns more rapidly into the gold of explanation.",
    "chunk_id": "Adv_cognitive_modelling_building_better_theories.json_chunk_14"
  },
  {
    "document_type": "online_article",
    "title": "Chapter 5 From simulation to model fitting",
    "author": "Riccardo Fusaroli",
    "source": "https://fusaroli.github.io/AdvancedCognitiveModeling2023/from-simulation-to-model-fitting.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": "This chapter introduces essential techniques for moving from theoretical models to empirical validation. Building on our implementation of decision-making agents, we now tackle the challenge of determining whether these models accurately describe observed behavior. After completing this chapter, you will be able to: Design and implement Bayesian parameter estimation for cognitive models using Stan Create and interpret prior and posterior predictive checks to validate model behavior Evaluate model quality through systematic parameter recovery studies Understanding human behavior requires more than just implementing plausible models - we must determine whether these models actually capture meaningful empirical patterns. Consider our biased agent model that tends to favor one choice over another. While we can specify different levels of bias in our simulations, real-world application requires determining what bias values best explain observed behavior, and for instance whether a pharmacological manipulation can affect the bias. Bayesian inference provides a powerful framework for this challenge. It allows us to: Express our prior beliefs about reasonable parameter values Update these beliefs based on observed data Quantify uncertainty in our parameter estimates Generate predictions that account for parameter uncertainty As usual we start with simulated data, where we know the underlying mechanisms and parameter values. Simulated data are rarely enough (empirical data often offer unexpected challenges), but they are a great starting point to stress test your model: does the model reconstruct the right parameter values? Does it reproduce the overall patterns in the data? Here we build a new simulation of random agents with bias and noise. The code and visualization is really nothing different from last chapter. N.B. Refer to the video and slides for the step by step build-up of the Stan code. Now we subset to a simple case, no noise and rate of 0.8, to focus on the Stan model",
    "chunk_id": "Adv_cognitive_modelling_chapter_5_from_simulation_to_model_fitting.json_chunk_1"
  },
  {
    "document_type": "online_article",
    "title": "Chapter 5 From simulation to model fitting",
    "author": "Riccardo Fusaroli",
    "source": "https://fusaroli.github.io/AdvancedCognitiveModeling2023/from-simulation-to-model-fitting.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". N.B. Refer to the video and slides for the step by step build-up of the Stan code. Now we subset to a simple case, no noise and rate of 0.8, to focus on the Stan model. We make it into the right format for Stan, build the Stan model, and fit it. Here we define the data and format it for Stan. Stan likes data as a list. Why a list? Well, dataframes (now tibbles) are amazing. But they have a big drawback: they require each variable to have the same length. Lists do not have that limitation, they are more flexible. So, lists. We’ll have to learn how to live with them. We write the stan code within the R code (so I can show it to you more easily), then we save it as a stan file, which can be loaded at a later stage in order to compile it. [Missing: more info on compiling etc.] Remember that the minimal Stan model requires 3 chunks, one specifying the data it will need as input; one specifying the parameters to be estimated; one specifying the model within which the parameters appear, and the priors for those parameters. Then we need to look more in the details at the quality of the estimation: * the markov chains * how the prior and the posterior estimates relate to each other (whether the prior is constraining the posterior estimate) As we can see from the posterior estimates and the prior posterior update check, our model is doing a decent job. It doesn’t exactly reconstruct the rate of 0.8, but 0.755 is pretty close and 0.8 is included within the credible interval. Now we build the same model, but using the log odds scale for the theta parameter, which will become useful later when we condition theta on variables and build multilevel models (as we can do what we want in a log odds space and it will always be bound between 0 and 1). We can see that the results are very similar. Now that we see that the model works in one case, we can run it through all possible rate and noise levels in the simulation. Here we’ll implement a better approach using parallelization, which is more efficient for complex models",
    "chunk_id": "Adv_cognitive_modelling_chapter_5_from_simulation_to_model_fitting.json_chunk_2"
  },
  {
    "document_type": "online_article",
    "title": "Chapter 5 From simulation to model fitting",
    "author": "Riccardo Fusaroli",
    "source": "https://fusaroli.github.io/AdvancedCognitiveModeling2023/from-simulation-to-model-fitting.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". Here we’ll implement a better approach using parallelization, which is more efficient for complex models. To parallelize, we rely on furrr, a neat R package that distributes parallel operations across cores. This approach becomes crucial with more complex models. First we need to define the function that will define the operations to be run on each core separately, here we simulate the data according to a seed, a n of trials, a rate and a noise, and then we fit the model to them. Second, we need to create a tibble of the seeds, n of trials, rate and noise values that should be simulated. Third, we use future_pmap_dfr to run the function on each row of the tibble above separately on a different core. Note that I set the system to split across 4 parallel cores (to work on my computer without clogging it). Do change it according to the system you are using. Note that if you have 40 “jobs” (rows of the tibble, sets of parameter values to run), using e.g. 32 cores will not substantially speed things more than using 20. There’s much to be said about the final plot, but for now let’s just say that it looks good. We can reconstruct in a nice ordered way true rate values. However, our ability to do so decreases with the increase in noise. So far no surprises. Wait, you say, shouldn’t we actually model the generative process, that is, include noise in the Stan model? Gold star, there! But let’s wait a bit before we get there, we’ll need mixture models. Now that we fitted the base model, we can move onto more complex models. For instance a memory model (including all previous trials). Here we rely on a generalized linear model kind of thinking: the theta is the expression of a linear model (bias + b1 * PreviousRate). To make the variable more intuitive we code previous rate - which is bound to a probability 0-1 space - into log-odds via a logit link/transformation",
    "chunk_id": "Adv_cognitive_modelling_chapter_5_from_simulation_to_model_fitting.json_chunk_3"
  },
  {
    "document_type": "online_article",
    "title": "Chapter 5 From simulation to model fitting",
    "author": "Riccardo Fusaroli",
    "source": "https://fusaroli.github.io/AdvancedCognitiveModeling2023/from-simulation-to-model-fitting.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". To make the variable more intuitive we code previous rate - which is bound to a probability 0-1 space - into log-odds via a logit link/transformation. In this way a previous rate with more left than right choices will result in a negative value, thereby decreasing our propensity to choose right; and one with more right than left choices will result in a positive value, thereby increasing our propensity to choose right. We can see that the model has now estimated both the bias and the role of previous memory. Bias should reflect the bias in the setup (0.5 which in log odds is 0), and the beta coefficient for memory (roughly 1). More on the quality checks of the models in the next chapter. So far we behaved like in GLM: we keep feeding to the model an external variable of memory, but what if we coded memory as an internal parameter? This opens up to further possibilities to model how long memory is kept and weighted by distance from the current moment, etc. Now that we know how to model memory as an internal state, we can play with making the update discount the past, setting a parameter that indicates after how many trials memory is lost, etc. The memory model we’ve implemented can be seen as part of a broader family of models that track and update beliefs based on incoming evidence. Let’s explore how it relates to some key frameworks. Our memory model updates beliefs about the probability of right-hand choices using a weighted average of past observations. This is conceptually similar to how a Kalman filter works, though simpler: Kalman filters maintain both an estimate and uncertainty about that estimate They optimally weight new evidence based on relative uncertainty Our model uses a fixed weighting scheme (1/trial or the forgetting parameter) The key difference is that Kalman filters dynamically adjust how much they learn from new evidence based on uncertainty, while our model uses a fixed learning scheme",
    "chunk_id": "Adv_cognitive_modelling_chapter_5_from_simulation_to_model_fitting.json_chunk_4"
  },
  {
    "document_type": "online_article",
    "title": "Chapter 5 From simulation to model fitting",
    "author": "Riccardo Fusaroli",
    "source": "https://fusaroli.github.io/AdvancedCognitiveModeling2023/from-simulation-to-model-fitting.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". The Rescorla-Wagner model of learning follows the form: V(t+1) = V(t) + α(λ - V(t)) where: V(t) is the current estimate α is the learning rate λ is the observed outcome (λ - V(t)) is the prediction error Our memory model with forgetting parameter follows a very similar structure: memory(t+1) = (1-forgetting) * memory(t) + forgetting * outcome(t) This can be rewritten as: memory(t+1) = memory(t) + forgetting * (outcome(t) - memory(t)) Making the parallel clear: our forgetting parameter acts as the learning rate α in Rescorla-Wagner. The HGF extends these ideas by: Tracking beliefs at multiple levels Allowing learning rates to vary over time Explicitly modeling environmental volatility Our model could be seen as the simplest case of an HGF where: We only track one level (probability of right-hand choice) Have a fixed learning rate (forgetting parameter) Don’t explicitly model environmental volatility Understanding these relationships helps us think about how models relate to each other and to extend our model: We could add uncertainty estimates to get Kalman-like behavior We could make the forgetting parameter dynamic to capture changing learning rates We could add multiple levels to track both immediate probabilities and longer-term trends Each extension would make the model more flexible but also more complex to fit to data. The choice depends on our specific research questions and available data. We can also model the memory agent in a Bayesian framework. This allows us to model the agent as (optimally) estimating a possible distribution of rates from the other’s behavior and keep all the uncertainty. Throughout this chapter, we’ve progressed from basic parameter estimation to increasingly sophisticated models of decision-making. We began with a simple biased agent model, demonstrating how Bayesian inference allows us to recover underlying parameters from observed behavior",
    "chunk_id": "Adv_cognitive_modelling_chapter_5_from_simulation_to_model_fitting.json_chunk_5"
  },
  {
    "document_type": "online_article",
    "title": "Chapter 5 From simulation to model fitting",
    "author": "Riccardo Fusaroli",
    "source": "https://fusaroli.github.io/AdvancedCognitiveModeling2023/from-simulation-to-model-fitting.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". We began with a simple biased agent model, demonstrating how Bayesian inference allows us to recover underlying parameters from observed behavior. We saw how we can transform parameters from one scale to another - here from probability-scale to log-odds parameterizations -, thus gaining flexibility that will prove valuable for more complex models. The transition to memory-based models illustrated how we can incorporate psychological theory into our statistical framework. We explored different approaches to modeling memory - from treating it as an external predictor to implementing it as an internal state variable that evolves over time. The final exploration of exponential forgetting demonstrated how we can capture more nuanced cognitive processes while maintaining mathematical tractability. This progression sets the stage for Chapter 12, where we’ll explore how these memory updating mechanisms relate to reinforcement learning models. The exponential discounting of past events we implemented here represents a simplified version of the learning mechanisms we’ll encounter in reinforcement learning. Several key principles emerged that will guide our future modeling work: The importance of systematic model validation through parameter recovery studies and prior-posterior checks. These techniques help ensure our models can meaningfully capture the processes we aim to study. The value of starting simple and gradually adding complexity. Each model we implemented built upon previous ones, allowing us to understand the impact of new components while maintaining a solid foundation. This principle will become particularly important when we tackle reinforcement learning models, where multiple parameters interact in complex ways to produce learning behavior. The relationship between mathematical convenience and psychological reality. The log-odds transformation, for instance, provides both computational benefits and psychological insights about how humans might represent probabilities",
    "chunk_id": "Adv_cognitive_modelling_chapter_5_from_simulation_to_model_fitting.json_chunk_6"
  },
  {
    "document_type": "online_article",
    "title": "Chapter 5 From simulation to model fitting",
    "author": "Riccardo Fusaroli",
    "source": "https://fusaroli.github.io/AdvancedCognitiveModeling2023/from-simulation-to-model-fitting.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". The log-odds transformation, for instance, provides both computational benefits and psychological insights about how humans might represent probabilities. Similarly, the memory updating rules we explored here foreshadow the prediction error calculations central to reinforcement learning and relates very tightly to other popular models like the Kalman filter and the Hierarchical Gaussian Filter. In the next chapters, we will build upon these foundations to tackle even more sophisticated cognitive models. Chapter 5 will introduce multilevel modeling, allowing us to capture individual differences while maintaining population-level insights. This will set the stage for exploring how different individuals might employ different strategies or show varying levels of memory decay in their decision-making processes. These individual differences become again relevant in future models where parameters like learning rate, or bias for social information can vary substantially across individuals.",
    "chunk_id": "Adv_cognitive_modelling_chapter_5_from_simulation_to_model_fitting.json_chunk_7"
  },
  {
    "document_type": "research_paper",
    "title": "Bayesian models of cognition",
    "author": "Nick Chater, Mike Oaksford, Ulrike Hahn and Evan Heit",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Chater-2010-Bayesian-models-of-cognition.pdf",
    "date_published": "2010-09-16",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": "Overview Bayesian models of cognition Nick Chater, 1 ∗ Mike Oaksford, 2 Ulrike Hahn 3 and Evan Heit 4 There has been a recent explosion in research applying Bayesian models to cognitive phenomena. This development has resulted from the realization that across a wide variety of tasks the fundamental problem the cognitive system confronts is coping with uncertainty. From visual scene recognition to on-line language comprehension, from categorizing stimuli to determining to what degree an argument is convincing, people must deal with the incompleteness of the information they possess to perform these tasks, many of which have important survival-related consequences. This paper provides a review of Bayesian models of cognition, dividing them up by the different aspects of cognition to which they have been applied. The paper begins with a brief review of Bayesian inference. This falls short of a full technical introduction but the reader is referred to the relevant literature for further details. There follows reviews of Bayesian models in Perception, Categorization, Learning and Causality, Language Processing, Inductive Reasoning, Deductive Reasoning, and Argumentation. In all these areas, it is argued that sophisticated Bayesian models are enhancing our understanding of the underlying cognitive computations involved. It is concluded that a major challenge is to extend the evidential basis for these models, especially to accounts of higher level cognition.  2010 John Wiley & Sons, Ltd. WIREs Cogn Sci 2010 1 811–823 INTRODUCTION F rom the point of view of the brain, nothing is certain. Sensory input is noisy and extremely partial: the structure of the environment must tentatively be inferred from unreliable scraps of information. Memory is also subject to distortion and interference; and our view of the past thus requires inferring a rich structure on the basis of a sketchy and unreliable record",
    "chunk_id": "Adv_cognitive_modelling_bayesian_models_of_cognition.json_chunk_1"
  },
  {
    "document_type": "research_paper",
    "title": "Bayesian models of cognition",
    "author": "Nick Chater, Mike Oaksford, Ulrike Hahn and Evan Heit",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Chater-2010-Bayesian-models-of-cognition.pdf",
    "date_published": "2010-09-16",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Memory is also subject to distortion and interference; and our view of the past thus requires inferring a rich structure on the basis of a sketchy and unreliable record. Linguistic input is notoriously ambiguous, underspecified, may be deliberately deceptive, and its significance can only be a matter of conjecture, rather than certainty. This uncertainty concerning what to believe is paralleled in similar, and equally severe, uncertainties concerning what we want, and how we should act. Yet the brain copes with such uncertainties with surprising ∗ Correspondence to: n.chater@ucl.ac.uk 1 Department of Cognitive, Perceptual and Brain Sciences and Centre for Economic Learning and Social Evolution (ELSE), UCL London, UK 2 Department of Psychological Science, Birkbeck College, University of London, London, UK 3 School of Psychology, Cardiff University, Cardiff, UK 4 Psychology Department, University of California, Merced, CA, USA DOI: 10.1002/wcs.79 ease—the external world, our memories of the past, and the meaning of people’s utterances, seem, introspectively at least, to be hearteningly stable. It is only in the light of careful experimental analysis that the frailty of such knowledge is revealed—so that perceptual illusions, 1 the unreliability of judgement and memory, 2 and the slipperiness of linguistic interpretation 3 seem, from an introspective point of view, rather unexpected. From this perspective, a fundamental information processing task of the brain is to weld scraps of information together to produce an integrated model of the external world; and to use this model to help determine action and choice. How can this be done? The Bayesian approach to cognition seeks to model this information processing problem using the mathematical calculus of uncertain inference: probability theory",
    "chunk_id": "Adv_cognitive_modelling_bayesian_models_of_cognition.json_chunk_2"
  },
  {
    "document_type": "research_paper",
    "title": "Bayesian models of cognition",
    "author": "Nick Chater, Mike Oaksford, Ulrike Hahn and Evan Heit",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Chater-2010-Bayesian-models-of-cognition.pdf",
    "date_published": "2010-09-16",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". How can this be done? The Bayesian approach to cognition seeks to model this information processing problem using the mathematical calculus of uncertain inference: probability theory. Each conjecture about the world is associated with a numerical degree of belief, defined to be on the interval between 0 and 1, where 1 corresponds to absolute certainty that the belief is true; and 0 corresponds to absolute certainty that it is false. These beliefs can be identified with probabilities; and a consistent cognitive agent is required to obey the rules of probability theory—at least, if the agent is to avoid paradoxical conclusions. This probabilistic perspective on the mind can be traced back to one of the origins of probability theory. Overview wires.wiley.com/cogsci Indeed, the very title of Bernoulli’s 4 seminal book Ars Conjectandi , ‘The Art of Conjecture’, embodies the idea that probability captures how people actually make conjectures; as well as providing a calculus for helping people to make conjectures more accurately. Thus, one important strand in the development of probability theory viewed it directly as a theory of thought, as well as a helpful mathematical calculus. The probabilistic approach can be adopted at three different levels, corresponding to Marr’s 5 three levels of explanation. Computational level explanation aims to specify the nature of the problem that the brain faces: the goals of the system and the structure of the environment in which these goals must be achieved. At the computational level, then, probabilistic methods are used to specify the problem that the brain faces. Thus, learning to control an arm, or use a language, might be viewed as problems of probabilistic inference, given certain prior assumptions; and in the light of data gleaned from experience",
    "chunk_id": "Adv_cognitive_modelling_bayesian_models_of_cognition.json_chunk_3"
  },
  {
    "document_type": "research_paper",
    "title": "Bayesian models of cognition",
    "author": "Nick Chater, Mike Oaksford, Ulrike Hahn and Evan Heit",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Chater-2010-Bayesian-models-of-cognition.pdf",
    "date_published": "2010-09-16",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Thus, learning to control an arm, or use a language, might be viewed as problems of probabilistic inference, given certain prior assumptions; and in the light of data gleaned from experience. Modern engineering, machine learning, and artificial intelligence typically view a wide range of information processing problems faced by the brain, from motor control, to speech perception, to object recognition from this probabilistic perspective. Algorithmic level explanation requires specifing the representations and computational operations over those representations that constitute cognition. Even if the brain faces probabilistic challenges, it may be that it solves them, using some set of heuristics or approximations which do not involve actually carrying out probabilistic calculations. On the other hand, though, the modern technology of probabilistic inference, as explored in state-of-the-art engineering and artificial intelligence systems, does provide a rich set of hypotheses about human cognition. Cognitive science is, after all, a process of reverse engineering; and reverse engineering inevitably draws on the best engineering solutions to the information processing problems that the brain faces. Finally, even if the brain is probabilistic at the computational and algorithmic levels, this does not necessarily imply that it is probabilistic at the third of Marr’s levels of explanation, the implementational level. Indeed, probabilistic algorithms used in speech engineering or computer vision run on the binary logic of digital computers. But some neuroscientists have begun to conjecture that the brain may be probabilistic at its very foundations—that individual neurons may convey probabilistic information, that neural populations may capture probability distributions, that basic neural processes might be understood as directly carrying out elementary probabilistic inference",
    "chunk_id": "Adv_cognitive_modelling_bayesian_models_of_cognition.json_chunk_4"
  },
  {
    "document_type": "research_paper",
    "title": "Bayesian models of cognition",
    "author": "Nick Chater, Mike Oaksford, Ulrike Hahn and Evan Heit",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Chater-2010-Bayesian-models-of-cognition.pdf",
    "date_published": "2010-09-16",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". 6 After providing a brief overview of Bayesian inference, in this rest of this article we survey some of the burgeoning research applying Bayesian moels to cognition and perception. Seven sections cover Bayesian models in Perception, Categorization, Learing and Causality, Language Processing, Inductive Reasoning, Deductive Reasoning, and Argumentation. BAYESIAN INFERENCE From a probabilistic standpoint, beliefs are a matter of degree. Each hypothesis, H i , can be associated with a degree of belief P ( H i ); and very modest consistency constraints require that these degrees of belief must obey the laws of probability. Thus, the probability distribution over the various H i can be viewed as characterizing prior beliefs. Suppose that H i has implications for the data we expect to encounter (e.g., H i states that the floodlights are on; which if true, makes sense sensory inputs—roughly, the bright ones—more likely than others). These implications can be captured by P ( D | H i ), the probability of the data, given the hypothesis. In the light of D , we need to update the priors P ( H i ) to P ( H i | D ), the probabilities of the hypotheses, given that the data is known. A simple identity of probability theory, Bayes’ theorem, shows how this can be done: P ( H i | D ) = P ( D | H i ) P ( H i ) P ( D ) The probability of the data P ( D ) is not, of course, known independently of the hypotheses that might generate that data—so in practice P ( D ) is typically expanded using the probabilistic identity: P ( D ) = j P ( D | H j ) P ( H j ) Because of the centrality of the problem of updating beliefs in the light of new information, Bayes’ Theorem has very broad application, so much so, indeed, that the interpretation of degrees of belief in terms of probabilities is often known as the Bayesian approach",
    "chunk_id": "Adv_cognitive_modelling_bayesian_models_of_cognition.json_chunk_5"
  },
  {
    "document_type": "research_paper",
    "title": "Bayesian models of cognition",
    "author": "Nick Chater, Mike Oaksford, Ulrike Hahn and Evan Heit",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Chater-2010-Bayesian-models-of-cognition.pdf",
    "date_published": "2010-09-16",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". If we quantify ‘degrees of belief’ numerically, as the Bayesian approach presupposes, why should the laws of probability theory, rather than some other principles, define the calculus of degrees of belief? From the point of view of cognitive science, there are two strong arguments for adopting a probabilistic approach. The first, mentioned above, is that violation of the laws of probability leads to paradoxical conclusions. Indeed, the laws of probability can be derived from a variety of plausible, modest, but WIREs Cognitive Science Bayesian models of cognition very different assumptions concerning how degrees of belief should behave. Perhaps the best known such derivation is the Dutch book theorem, 7 which shows that, under fairly general conditions, gamblers whose degrees of belief violate the laws of probability will happily accept a combination of bets which are, nonetheless, guaranteed to lose money, whatever their outcomes—which appears to be an unequivocally irrational choice. This type of argument suggests that, given that brains reason spectacularly well about uncertainty, it is unlikely systematically depart from the norms of good probabilistic reasoning by too much—any good uncertain reasoner is, the argument might go, to some degree a good Bayesian, that is, probabilistic, reasoner. In addition to this a priori line of argument, and perhaps more persuasive from the point of view of the practicing neuroscientist and cognitive scientist is that the Bayesian approach is widely used in engineering approaches to solving the types of problem faced by the brain. Thus, the fields of computer vision, speech recognition, computational linguistics, robotics, machine learning, information retrieval and expert systems, and many more, have seen a dramatic upsurge in the application of probabilistic methods",
    "chunk_id": "Adv_cognitive_modelling_bayesian_models_of_cognition.json_chunk_6"
  },
  {
    "document_type": "research_paper",
    "title": "Bayesian models of cognition",
    "author": "Nick Chater, Mike Oaksford, Ulrike Hahn and Evan Heit",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Chater-2010-Bayesian-models-of-cognition.pdf",
    "date_published": "2010-09-16",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". To the extent that the project of understanding the mind/brain is reverse engineering, that is, attempting to find the engineering principles that underpin neural and cognitive function, then any credible scientific theory has to be good engineering; and the Bayesian approach seems plausibly to pass this test. Below, we briefly describe the Bayesian approach to cognition in a number of domains, ranging from perception to learning about causal relations, to Bayesian models of higher-level reasoning and argumentation. PERCEPTION From a computational level perspective, the problem of perception is that of inferring the structure of the world from sensory input. This problem may seem to be ill-posed, because any given sensory input may have been generated by an infinity of possible states of the world. 8 From a probabilistic perspective, the infinity of possible interpretations is not in itself problematic. Rather, the challenge of probabilistic inference in perception is to assign probabilities to each of these possible interpretations, based not only on sensory input itself, but prior knowledge. This is a problem of Bayesian inference par excellence. The Bayesian approach in perception has its beginnings in Helmholtz’s 9 notion of ‘unconscious inference ’, although he did not explicitly use Bayes’ rule. 10 More recently, this perspective has become increasingly influential throughout the brain and cognitive sciences, as well as in computer vision. Moreover, the Bayesian approach is consistent with a broader tradition in perceptual research, the idea that perception is analysis-by-synthesis. 11 That is, the perceptual data is presumed to be analyzed (i.e., calculating P ( H | D )) from a knowledge of the perceptual data that would be generated by various possible scene interpretations (i.e., from a knowledge of P ( D | H ), and of course a prior distribution P ( H ) over the hypotheses concerning the scenes)—a transformation which requires the application of Bayes’ theorem",
    "chunk_id": "Adv_cognitive_modelling_bayesian_models_of_cognition.json_chunk_7"
  },
  {
    "document_type": "research_paper",
    "title": "Bayesian models of cognition",
    "author": "Nick Chater, Mike Oaksford, Ulrike Hahn and Evan Heit",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Chater-2010-Bayesian-models-of-cognition.pdf",
    "date_published": "2010-09-16",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". In practice, the process of finding an interpretation from which the perceptual data can reasonably be generated requires a combination of bottom-up and top-down perceptual inferences, 12 a process that can be captured computationally by recent methods such as Data-Driven Markov Chain Monte Carlo. 13 Thus, the Bayesian approach to perception requires that the perceptual system is able to generate sensory input, as well as being able to perceive it; and hence provides a natural explanation of the existence of imagery, consistent with some existing psychological theories, 14 and with experimental data indicating the influence of todown perceptual processes. 15 Bayesian models of perception have been subjected to direct experimental test in a number of domains (e.g., the integration of sensory cues 16 ). And a wide variety of computational models of empirical findings in perception have been put forward, ranging from low-level image intepretation, 17 shape from shading, 8,18 and shape from texture, 19 to boundaries interpolation. 20,21 There has also been an explosive growth in theories in the field of computational neroscience which view specific neural mechanisms as carrying out probabilistic computations, from lateral inhibition in the retina, 22 to the activity of single cells in the blow-fly, 23 or to populations of neurons including the accumulation of sensory evidence. 6 Indeed, it turns out that a large class of apparently non probabilistic models of perception can also be accommodated into the Bayesian framework. A long tradition in perception, often viewed as staning in direct opposition to the Bayesian approach, is based on simplicity: the perceptual system is assumed to choose an interpretation of sensory input that prvides a briefest encoding of the sensory data. Here, the starting point for the perceiver is a coding language: a representational system in which scenes, and the sensory inputs that they deliver, can be represented",
    "chunk_id": "Adv_cognitive_modelling_bayesian_models_of_cognition.json_chunk_8"
  },
  {
    "document_type": "research_paper",
    "title": "Bayesian models of cognition",
    "author": "Nick Chater, Mike Oaksford, Ulrike Hahn and Evan Heit",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Chater-2010-Bayesian-models-of-cognition.pdf",
    "date_published": "2010-09-16",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Here, the starting point for the perceiver is a coding language: a representational system in which scenes, and the sensory inputs that they deliver, can be represented. According to simplicity-based explanations, for exaple, Gestalt principles, such as common fate (grouping Overview wires.wiley.com/cogsci objects with the same movement together, such as a flock of birds) or good continuation (assuming aligment between items, even when occluded, typically indicates they should be grouped, or perhaps part of the same object, for example when the outline of an animal is seen through dense foliage), arise because of a preference for simple codes—codes which specify a single motion direction for the entire flock, rather than for each bird individually; or specify the position of a single occluded object, rather than independently coding the positions of each object fragment. Yet it turns out that simplicity-based approaches to perception 24–31 are mathematically equivalent to the Bayesian approach, under mild conditions. 32 The choice of coding language can be viewed as implicitly specifying a prior probability distribution—such that items that have a brief representation in the language have relatively high prior probability. CATEGORIZATION Understanding perceptual input involves the creation of categories. Categorization allows generalization from one category member to another; and also allows the formulation of abstract relations defined over categories, rather than concrete items. From a formal point of view, categorization is an aspect of high-level perception, where categorization of the items is in the scene is just one of many pieces of information that must be recovered from sensory input. In cognitive psychology, early theories of categorization focused on supervised categorization—that is, learning a category from a set of examples, labeled with their category",
    "chunk_id": "Adv_cognitive_modelling_bayesian_models_of_cognition.json_chunk_9"
  },
  {
    "document_type": "research_paper",
    "title": "Bayesian models of cognition",
    "author": "Nick Chater, Mike Oaksford, Ulrike Hahn and Evan Heit",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Chater-2010-Bayesian-models-of-cognition.pdf",
    "date_published": "2010-09-16",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". In cognitive psychology, early theories of categorization focused on supervised categorization—that is, learning a category from a set of examples, labeled with their category. The two main theoretical approaches both focused on similarity between the item to be classified to a prototypical category exemplar, 33,34 or alternatively to one of a set of category exemplars. 35 While initially formulated in probabilistic terms, both types of theory have increasingly been formulated from a Bayesian point of view. 36–40 Roughly speaking, the prototype view of categorization can be viewed as assuming that categories corresponds to the Gaussian (or similar) blobs, which may potentially overlap, in some feature space; and the problem of categorization is to work out, given an item, the probability distribution over the Gaussian blobs that may have generated it. According to the simplest formulation, we assume that the participant is certain that the new item is generated by one of the previous encountered categories; but in reality, of course, it is possible that a new item is generated by a category that has not been previously encountered. Thus one extension of the prototype approach, from a probabilistic point of view, is to allow that, in response to a new item, an agent may postulate a new category; and therefore that the number of categories may grow, perhaps unboundedly, as the number of items categorized increases. This type of ‘nonparametric’ categorization model is widely used in Bayesian models of categorization, from Anderson 41 through to Griffiths et al. 42 and Goodman et al. 43 . Exemplar models can then be seen as a limiting case of this class of model. 44 Viewing the problem of categorization as a matter of probabilistic inference provides more than an interesting notational variant of initial non probabilistic formulations. On the one hand, it provides a fresh perspective on the explanation for classic psychological data",
    "chunk_id": "Adv_cognitive_modelling_bayesian_models_of_cognition.json_chunk_10"
  },
  {
    "document_type": "research_paper",
    "title": "Bayesian models of cognition",
    "author": "Nick Chater, Mike Oaksford, Ulrike Hahn and Evan Heit",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Chater-2010-Bayesian-models-of-cognition.pdf",
    "date_published": "2010-09-16",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". On the one hand, it provides a fresh perspective on the explanation for classic psychological data. So, to take a simple example, the finding that people are usually able to classify more typical category members more rapidly than less typical category members 34 has a natural interpretation: that the features of prototypical items provide more unequivocal evidence for the specific category membership than do less prototypical items; and hence fewer such features needs to be processed, on average, for a category judgment to be made reliably. Moreover, the probabilistic framework provides a starting point for a wide range of generalizations, which may take account of the fact, for example, that a single item may be a member of multiple categories 45 ; that the prior assumptions that underpin categorization may be powerfully influenced by background theories 46 ; or that the relative importance of different features, and even the choice of appropriate features, may itself depend on the category being considered, and have to be learned. 45 LEARNING AND CAUSALITY Conditioning in animals has traditionally been conceived as a matter of the formation of associations, which might be presumed to form on the basis of, for example, the constant conjunction of two events, or their spatial and temporal proximity. Nonetheless, a wide variety of empirical findings has indicated that the animal may be viewed as an intelligent problem solver, 47 attempting to figure out the structure of the world, from available contingency data. Thus, for example, the discovery of blocking, 48 that once an animal has learned that an outcome is predicted by one cue, it is less liable to associate that outcome when the second cue is added; however reliable that second cue may be, may be suggest that the animal already has an ‘explanation’ of the outcome; and hence no further explanation, for example, in terms of the second cue, is required",
    "chunk_id": "Adv_cognitive_modelling_bayesian_models_of_cognition.json_chunk_11"
  },
  {
    "document_type": "research_paper",
    "title": "Bayesian models of cognition",
    "author": "Nick Chater, Mike Oaksford, Ulrike Hahn and Evan Heit",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Chater-2010-Bayesian-models-of-cognition.pdf",
    "date_published": "2010-09-16",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". To the extent that WIREs Cognitive Science Bayesian models of cognition the animal is regarded as making inferences about the structure of the environment from observed data concerning the arrival of lights, tones, food pellets, or shocks, the problem that the animal faces appears closely analogous to the general problem of scientific inference, and hence to be naturally modeled with a Bayesian framework. 49–51 From this point of view, well-known conditioning phenomena, such as that a contingency that has been reliably reinforced is extinguished more rapidly than a contingency that has been partially reinforced, has a natural probabilistic explanation. If a contingency is typically reliable, then after a few ‘extinction’ trials, there is already strong evidence that the state of the world has changed and that the strong tendency is no longer in operation; on the other hand, if the contingency is initially unreliable, then a few such trials are to be expected by chance, in a case, and hence the animal will be slower to reach the conclusion that the world has changed, and that the contingency is no longer in operation. This type of phenomenon is difficult to account for according to some mechanistic associative accounts, because the association formed by partial reinforcement is simply assumed to be weaker, and for this reason should be expected to be eliminated more rapidly. Similarly, a variety of probabilistic models have been put forward to explain human judgment of contingency and causality, when learning from experience. Cheng, 52 for example, has put forward a ‘probabilistic contrast’ model of human causal judgment, according to which the strength of a causal relationship is assumed to be measured by the contrast between probability of the effect, in the presence of the cause, and the probability of the effect in the absence of the cause",
    "chunk_id": "Adv_cognitive_modelling_bayesian_models_of_cognition.json_chunk_12"
  },
  {
    "document_type": "research_paper",
    "title": "Bayesian models of cognition",
    "author": "Nick Chater, Mike Oaksford, Ulrike Hahn and Evan Heit",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Chater-2010-Bayesian-models-of-cognition.pdf",
    "date_published": "2010-09-16",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Griffiths and Tenenbaum 53 have proposed a Bayesian model in which the existence of, and the nature of, a potential causal relationship between events is itself inferred from the observed data. This account aims to explain empirical data concerning both how the structure of causal relationships can be learned, as well as the strength of those relationships, which is the primary concern of Cheng’s model. Sloman and Lagnado, 54 moreover, have directly studied the role of intervention in human causal judgments. According to many standard philosophical accounts of causality, the existence of causal relation between two events A and B depends on counterfatual claims about whether, for example, B would still have occurred even if A had been ‘blocked’, leaving everything else unchanged as far as possible. Thus, for example, pressing the ‘alarm set’ button on the alarm clock appears to be causally related to the alarm clock going off many hours later, in view of our belief that, had the button not been pressed, the alarm would not have sounded. On the other hand, we do not assume that alarm clock sounding is caused by the chiming of the church clock next door, even if this regularly occurs very few seconds before, because we know that if some intervention occurred to stop the church clock is chiming, the alarm sounds nonetheless. It turns out that it is possible to construct a calculus of causal intervention within a probabilistic framework 55,56 ; and there has been recent experimental work attemping to determine how far this framework can provide a useful model of human causality judgments, when intervention is allowed. 54 Finally, there has been a very promising line of research in cognitive development, exploring Bayesian network models of contingency learning, causal learning, and learning from intervention, throughout development. 57 For example, Gopnik et al. 57 discuss a variety of experiments, 58,59 which demonstrate that pre-school children have the ability to learn causal structures",
    "chunk_id": "Adv_cognitive_modelling_bayesian_models_of_cognition.json_chunk_13"
  },
  {
    "document_type": "research_paper",
    "title": "Bayesian models of cognition",
    "author": "Nick Chater, Mike Oaksford, Ulrike Hahn and Evan Heit",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Chater-2010-Bayesian-models-of-cognition.pdf",
    "date_published": "2010-09-16",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". 57 For example, Gopnik et al. 57 discuss a variety of experiments, 58,59 which demonstrate that pre-school children have the ability to learn causal structures. In particular, this knowledge can be revealed by the nature of the interventions children choose to perform on the experimental apparatus embodying the causal relationships. This knowledge is independent of the frequency information available in the experimental set up and does not appear to be learnable within non-Bayesian frameworks. Note though, that contingency is a relatively weak source of information about causal relatioships. In observing the relationship between an object and its shadow, for example, the fact that the shadow has roughly the same shape as the object that casts it, that the shadow moves predictably when the object moves, and that, in many cases at least, the shadow and object connect smoothly at the object base, prvide powerful indications of the existence of a relatioship between the two; a trail of footprints in the sand can reasonably be causally attributed to the recent passage of feet purely in virtue of their shape and arrangement. Indeed, a variety of classic psychological demonstrations of ‘perceptual’ causality 60 and even causal relations underpinned by social interactions, 61 appear to be perceived essentially instantaneously, without requiring prior learning. A strength of the Bayesian approach is that it is, in principle, possible to build models which include richer representations of the physical structure of the environment, or prior knowledge about other aspects of the physical and social world, such that examples of this kind can readily be captured. Such work is at an early stage 62 ; but, for example, there has already been significant progress in constructing computational models of the Overview wires.wiley.com/cogsci attribution of intentions to an agent, from observing the agent’s behavior",
    "chunk_id": "Adv_cognitive_modelling_bayesian_models_of_cognition.json_chunk_14"
  },
  {
    "document_type": "research_paper",
    "title": "Bayesian models of cognition",
    "author": "Nick Chater, Mike Oaksford, Ulrike Hahn and Evan Heit",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Chater-2010-Bayesian-models-of-cognition.pdf",
    "date_published": "2010-09-16",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". 63 LANGUAGE PROCESSING Probabilistic approaches have also been influential in recent accounts of language processing and acquisition. 64 Within linguistics, it has been standard to view probabilistic aspects of language as of marginal importance, although mainly the study of syntax. Language is often viewed as a set of welformed strings, which are generated by a symbolic grammar, and associated, through systems of symbolic rules, with phonological and semantic representations. The mappings between phonology, syntax, and semantics can be fully described, according to this point of view, without reference to probabilities. Probability is, nonetheless, fundamentally involved in language processing and acquisition in a number of ways. Notice, for example, that the problem of analog-to-digital conversion, that is, turning an extremely rich and complex acoustic waveform into a discrete phonological representation is an enormously challenging problem of uncertain inference. The speech wave is typically highly locally ambiguous, and can only be disambiguated by piecing together large numbers of locally ambiguous cues, together with background knowledge concerning the speaker, the topic being discussed, and so on. Unsurprisingly, speech technology draws on a rich repertoire of probabilistic methods including hidden Markov models, and neural networks. 65 Probability plays a similar role in helping to construct a globally coherent parse (and associated semantic representation), in the light of the notorious local ambiguity of natural language, whether such ambiguity is lexical (e.g., bank as financial institution or geographical feature), syntactic [e.g., I saw the man (with the telescope) vs. I saw (the man with the telescope) ], or semantic (e.g., all the witnesses saw a burglar running from the scene , which might or might not be interpreted as implying that each witness all the same burglar)",
    "chunk_id": "Adv_cognitive_modelling_bayesian_models_of_cognition.json_chunk_15"
  },
  {
    "document_type": "research_paper",
    "title": "Bayesian models of cognition",
    "author": "Nick Chater, Mike Oaksford, Ulrike Hahn and Evan Heit",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Chater-2010-Bayesian-models-of-cognition.pdf",
    "date_published": "2010-09-16",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Again, a globally coherent parse and interpretation of a sentence can only be achieved by integrating these locally ambiguous cues, together with relevant background knowledge; and, just as in the problem of perception, the natural framework in which to consider such integration is probabilistic inference. Traditional theories of parsing have not, however, taken a probabilistic standpoint; indeed, such accounts have often, instead, focus purely on structural features of the competing parses. 66 Research over the last decade and a half has, however, increasingly suggested that a probabilistic integration of multiple cues is used by the language processing system in order to determine the most probable parse and interpretation of the input. 67–69 As with other aspects of learning, it is also natural to view the problem of acquiring a language as an example of uncertain inference. Any finite set of linguistic data available to the child will be compatible with an infinite number of languages; and the child must learn to generalize from the observed input to be able to successfully produce and understand linguistic material that has never previously been encountered. From a non probabilistic point of view, the problem of learning a language appears almost insuperably difficult; it will, for example, be extremely hard for the learner to distinguish between, say, normal English and a version of English with one additional constraint, for example, that it is not grammatically acceptable to begin and end a sentence with the word fish , to include more than five adjectives in a noun phrase, or to use a sentence whose sequence of words forms a palindrome (disallowing dogs chase dogs ). These possible variants of English would be extremely difficult to rule out, because the structures that they disallow are extremely rare, and might not be expected to occur more than a few times, if at all, during childhood",
    "chunk_id": "Adv_cognitive_modelling_bayesian_models_of_cognition.json_chunk_16"
  },
  {
    "document_type": "research_paper",
    "title": "Bayesian models of cognition",
    "author": "Nick Chater, Mike Oaksford, Ulrike Hahn and Evan Heit",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Chater-2010-Bayesian-models-of-cognition.pdf",
    "date_published": "2010-09-16",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". From a probabilistic point of view, these variations need not be ruled out unequivocally, but rather assigned a very low prior probability (e.g., on the basis that prior probability should be inversely related to complexity); from a non probabilistic point of view, such possibilities either need to be ruled out entirely, or pose genuine problems for the learner. Note, though, that languages do exhibit numerous apparently arbitrary constraints, which learners are able to successfully learn. So, for example, the child must infer that, while it is acceptable to say I made the clock break, I broke the clock , and I made the clock disappear , it is not acceptable to say I disappeared the rabbit , even though the meaning of this string of words is entirely clear. Learning the absence of certain linguistic possibilities has often been viewed as posing ‘logical’ problems for language acquisition, however, much data the child receives. 70 From a probabilistic standpoint, it is possible to show that learning is possible in principle, given sufficient data. 71 More important, perhaps, Bayesian analysis of language acquisition provides the tools to assess the prior information that the learner must possess, in order to learn these and other regularities, given realistic estimates of the data available to the child. 72 There has, moreover, been increasing interest in building statistical computational models, although not always using a strictly Bayesian framework, WIREs Cognitive Science Bayesian models of cognition which can potentially model the acquisition of a variety of aspects of phonology, syntax and semantics, ranging from the acquisition of morphology, to syntactic categories, and broad semantic classes 73–76 ; and there has been substantial progress in developing computational models that are able to learn phrase structure and dependency relations from corpora of untagged text",
    "chunk_id": "Adv_cognitive_modelling_bayesian_models_of_cognition.json_chunk_17"
  },
  {
    "document_type": "research_paper",
    "title": "Bayesian models of cognition",
    "author": "Nick Chater, Mike Oaksford, Ulrike Hahn and Evan Heit",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Chater-2010-Bayesian-models-of-cognition.pdf",
    "date_published": "2010-09-16",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". 77 From the point of view of a Bayesian analysis, the problem of language acquisition remains formidable indeed; but significant progress has been made both in developing specific models of learning, and defining methods for determining what is learnable in principle. INDUCTIVE REASONING Inductive reasoning involves drawing conclusions that are probably true, given a set of premises. Consquently, a rational Bayesian approach seems uniquely suited to model induction. Inductive reasoning cotrasts with deductive reasoning, in which the conclsion must necessarily follow from a set of premises. In contrast, two inductive arguments can each have some degree of inductive strength (Figure 1). There is now a well-documented set of empirical regularities on inductive reasoning (see Ref 78, for a more extensive review). These demonstrations all use inference patterns like that in figure 1. Rips, 79 looked at how people project properties of one category of animals to another (Figure 2(a) and (b)). He found that the more similar the premise category is to the conclusion category the stronger the inference (Figure 2a). He also found that the more typical the premise category [bluejays (typical) vs. geese (atypical)] the stronger the inference (Figure 2b). Using multiple regression analyses, Rips found distinct contributions of premise-conclusion similarity and premise typicality (see Ref 80 for further investigations of similarity and typicality effects). Using similar materials, Nisbett et al., 81 found that participants were very sensitive to the perceived Cows have sesamoid bones All mammals have sesamoid bones All mammals have sesamoid bones Ferrets have sesamoid bones (a) (b) FIGURE 1 | Inductive arguments vary in strength. The conclusion in argument (a) may seem stronger, or more probable given the evidence, than the conclusion in (b)",
    "chunk_id": "Adv_cognitive_modelling_bayesian_models_of_cognition.json_chunk_18"
  },
  {
    "document_type": "research_paper",
    "title": "Bayesian models of cognition",
    "author": "Nick Chater, Mike Oaksford, Ulrike Hahn and Evan Heit",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Chater-2010-Bayesian-models-of-cognition.pdf",
    "date_published": "2010-09-16",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". The conclusion in argument (a) may seem stronger, or more probable given the evidence, than the conclusion in (b). Rabbits have sesamoid bones Dogs (Bears) have sesamoid bones Bluejays (Geese) have sesamoid bones Blue tits have sesamoid bones This Barratos islander is obese All Barratos islanders are obese This Shreeble is blue All Shreebles are blue Cows require vitamin K for the liver to function Cows require vitamin K for the liver to function Horses require vitamin K for the liver to function All mammals require vitamin K for the liver to function Ferrets require vitamin K for the liver to function All mammals require vitamin K for the liver to function (a) (b) (c) (d) (e) (f) FIGURE 2 | Empirical effects. (a) Similarity: when premise and conclusion are more similar (rabbits–dogs) inference is stronger than when they are less similar (rabbits–bears). (b) Typicality: typical categories (bluejays) lead to stronger inferences than less typical (geese). Variability: variable categories (c) lead to stronger inferences than less variable categories (d). Diversity. : diverse categories (f) lead to stronger inferences than less diverse categories (e). variability of the conclusion category. After just one case, variable categories (Figure 2(c)), for example, people on an imaginary island (Barratos) with respect to obesity, lead to weaker inferences than non-variable categories, such as imaginary birds (Shreebles) with respect to color (Figure 2(d)). Nisbett et al. 81 also systematically varied the given number of observations. For example, participants were told that 1, 3, or 20 shreebles had been observed. Inferences were stronger with increased sample size (see also Ref 80). Osherson et al. 80 showed that diversity of cases also affects inductive strength, that is, Figure 2(f) is considered stronger than Figure 2(e)",
    "chunk_id": "Adv_cognitive_modelling_bayesian_models_of_cognition.json_chunk_19"
  },
  {
    "document_type": "research_paper",
    "title": "Bayesian models of cognition",
    "author": "Nick Chater, Mike Oaksford, Ulrike Hahn and Evan Heit",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Chater-2010-Bayesian-models-of-cognition.pdf",
    "date_published": "2010-09-16",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Osherson et al. 80 showed that diversity of cases also affects inductive strength, that is, Figure 2(f) is considered stronger than Figure 2(e). This diversity effect runs in the opposite direction to the typicality effect: Whereas a typical premise category leads to a fairly strong inductive argument (Figure 2(b)), an argument with two typical premise categories (Figure 2(e)) is weaker than an argument with a typical premise and an atypical premise (Figure 2(f)). Overview wires.wiley.com/cogsci A rational Bayesian model 82 views evaluating an inductive argument as learning for which categories a property is true or false. In Figure 1(a), the goal is to learn which animals have sesamoid bones. For this novel property, hypotheses must be derived from prior knowledge about familiar properties. People know some facts that are true of all mammals (including cows), but they also know some facts that are true of cows but not some other mammals. The question is which of these known kinds of properties does the novel property, ‘has sesamoid bones’, resemble most, an all-mammal property, or a cow-only property? Crucially it is assumed that novel properties follow the same distribution as known properties . Because many known properties of cows are also true of other mammals, argument Figure 1(a) seems fairly strong. As well as typicality, a Bayesian model also addresses the other key results in inductive reasoning. Similarity effects arise because given that rabbits have sesamoid bones, it more likely that dogs do rather than bears, because rabbits and dogs share more known properties than rabbits and bears. Diversity effects are also addressed. Figure 2(e) will access many idiosyncratic properties true just of large farm animals and so a novel property of cows and horses may seem idiosyncratic to farm animals. In contrast, Figure 2(f) could not access familiar idiosyncratic properties true of just these two animals, so prior hypotheses must be derived from known properties that are true of all mammals or all animals",
    "chunk_id": "Adv_cognitive_modelling_bayesian_models_of_cognition.json_chunk_20"
  },
  {
    "document_type": "research_paper",
    "title": "Bayesian models of cognition",
    "author": "Nick Chater, Mike Oaksford, Ulrike Hahn and Evan Heit",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Chater-2010-Bayesian-models-of-cognition.pdf",
    "date_published": "2010-09-16",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". We have focused here on a narrow class of inductive inference problems that have been especially well-studied empirically. But recent Bayesian models have analyzed a wide range of inductive problems, which can be naturally formulated and modeled in probabilistic terms. 83,84 DEDUCTIVE REASONING Work on ostensibly deductive reasoning tasks reveals many apparent errors and biases when performance is compared to classical logical standards. 85 The recent emergence of rational Bayesian models casts this peformance in a better light by comparing performance to a probabilistic standard. 86,87 Such models have been developed in all the three main areas investigated in the psychology of reasoning, conditional inference, 88 data selection, 89 and syllogistic reasoning. 90 The key idea behind them all is that the conditional proability, P ( q | p ), provides the meaning of conditional statements, if p then q (e.g., if you turn the key then the car starts ), and so P ( if p then q ) = P ( q | p ). This latter identity is called The Equation . 91,92 To illustrate the application of rational Bayesian models in this area, we concentrate on conditional inference which is currently the most researched topic in the area. Four inference patterns have mainly been stuied: two which are logically valid: modus ponens (MP) and modus tollens (MT), and two fallcies: denying the antecedent (DA) and affirming the consequent (AC) (Figure 3). Classical logic predicts endorsement of the valid inferences and rejection of the fallacies. However, all four inferences are endorsed above 50% and in the characteristic order: MP > MT > AC > DA 93 revealing a large discreancy between performance and logical expectations. The core intuition behind a rational Bayesian model of conditional inference is that it must account for the non monotonicity of everyday informal reasoning with conditionals",
    "chunk_id": "Adv_cognitive_modelling_bayesian_models_of_cognition.json_chunk_21"
  },
  {
    "document_type": "research_paper",
    "title": "Bayesian models of cognition",
    "author": "Nick Chater, Mike Oaksford, Ulrike Hahn and Evan Heit",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Chater-2010-Bayesian-models-of-cognition.pdf",
    "date_published": "2010-09-16",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". The core intuition behind a rational Bayesian model of conditional inference is that it must account for the non monotonicity of everyday informal reasoning with conditionals. 94,95 Classical logic is monotonic (Figure 4(a)) and hence is unable to account the ability of additional information to defeat previously derived conclusions (Figure 4(b)). The only recourse is to question the premises, e.g., in Figure 4(b) to suggest that birds fly is false. But surely, while defeasible , this is a very useful generalization that we would not want to reject as false. The Bayesian approach is to adopt The Equation and to treat conditional inference as Bayesian conditionalization. 87,88 That is, people are trying to determine the posterior probability of the conclusion, P 1 (flys( a )), given they now know that the categorical premise holds with certainty, P 1 (bird( a )) = 1 (Figure 4(a)). By Bayesian conditioalization, P 1 (flys( a )) = P 0 (flys( a ) | bird( a )), that is, the posterior probability of the conclusion equals the prior conditional probability of the conclusion given the caegorical premise. Note that this approach easily hadles non monotonicity, for example, P 0 (flys( a ) | bird( a )) = 0.9 and P 0 (flys( a ) | bird( a ),Ostrich( a )) = 0 are pefectly probabilistically consistent (Figure 4b). This approach cannot immediately apply to MT and the fallacies because, for example, DA requires knowledge of P 0 ( ¬ flys( a ) |¬ bird( a )) and there is insufficient information in the premises (MP) p ⇒ q , p p ⇒ q , ¬ p ∴ q ∴ ¬ q (DA) (MT) p ⇒ q , q ∴ p p ⇒ q , ¬ q ∴ ¬ p (AC) FIGURE 3 | The valid inferences, modus ponens (MP) and modus tollens (MT), and the fallacies, denying the antecedent (DA) and affirming the consequent (AC), investigated in conditional inference. These inference schema are to be read that if the list of premises above the line are true so must be the conclusion below the line",
    "chunk_id": "Adv_cognitive_modelling_bayesian_models_of_cognition.json_chunk_22"
  },
  {
    "document_type": "research_paper",
    "title": "Bayesian models of cognition",
    "author": "Nick Chater, Mike Oaksford, Ulrike Hahn and Evan Heit",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Chater-2010-Bayesian-models-of-cognition.pdf",
    "date_published": "2010-09-16",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". These inference schema are to be read that if the list of premises above the line are true so must be the conclusion below the line. WIREs Cognitive Science Bayesian models of cognition triangle( x ) ⇒ 3 – sides( x ), triangle( a ) triangle( x ) ⇒ 3 – sides( x ), triangle( a ), red( a ) bird ( x ) ⇒ flys ( x ), bird ( a ), Ostrich ( a ) ∴ 3 – sides( a ) ∴ flys ( a ) ∴ ¬ flys ( a ) ∴ 3 – sides( a ) (a) (b) bird ( x ) ⇒ flys ( x ), bird ( a ) FIGURE 4 | Monotonic (a) and non-monotonic (b) conditional inference by MP. In (a), the additional information, that the particular triangle a is red, cannot override the original conclusion that qua triangle, a has three sides. In contrast, in (b), the additional information, that the particular bird a is an Ostrich does override the original conclusion that qua bird, a can fly. FIGURE 5 | Bayesian conditionalization. P 0 = prior probability, for example, prior to learning that a is a bird; P 1 = posterior probability, for example, after learning that a is a bird. By Bayesian conditionalization P 1 (flys( a )) = P 0 (flys( a ) | bird( a )) . Note that (a) and (b) are perfectly probabilistically compatible, that is, Bayesian conditionalization is non-monotonic. bird ( x ) ⇒ flys ( x ), bird ( a ) ∴ flys ( a ) ∴ P 1 ( flys ( a )) = 0.9 ∴ P 1 ( flys ( a )) = 0 (a) (b) P 0 ( flys ( x ) | bird ( x )) = 0.9, P 1 ( bird ( a )) = 1 P 0 ( flys ( x ) | bird ( x )) = 0.9, P 1 ( bird ( a )) = 1, P 1 (Ostrich(a)) = 1 to determine this probability. This is actually also true of P 0 (flys( a ) | bird( a )) for MP, which on the subjective view of probability (see Introductory text) must be determined by reference to global world knowledge via the Ramsey Test , that is, add the antecedent, bird( a ), to one’s stock of beliefs, make minimal adjustments to incorporate it, and then read off the probability of the consequent, flys( a ), this is P 0 (flys( a ) | bird( a )) (Figure 5)",
    "chunk_id": "Adv_cognitive_modelling_bayesian_models_of_cognition.json_chunk_23"
  },
  {
    "document_type": "research_paper",
    "title": "Bayesian models of cognition",
    "author": "Nick Chater, Mike Oaksford, Ulrike Hahn and Evan Heit",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Chater-2010-Bayesian-models-of-cognition.pdf",
    "date_published": "2010-09-16",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". To determine the conditional probabilities for DA, AC, and MT requires the assumption that the priors P 0 (flys( x )) and P 0 (bird( x )) are also available from global world knowledge. Figure 6 show shows how well the Bayesian conditionalization model accounts for the principle data on conditional inference. ARGUMENTATION Reasoning and decision making often takes place in the service of argumentation, that is, the attempt to persuade yourself or others of a particular, perhaps controversial, position. 97 The rational Baesian approach has been extended to at least some aspects of argumentation. 98 On this view concern centers on how the premises, P , of an argument affect the probability of the conclusion, C . If P ( C | P ) is high then the argument has high inductive strength . This account has been applied most directly to reasoning fallacies in the attempt to understand how some instances seem to be good arguments while others do not. 99 For example, the classical so-called argument from ignorance, or argumentum ad ignorantiam , has many seemingly very weak exemplars: Ghosts exist, because nobody has proven that they don’t (1) FIGURE 6 | Fit of the Bayesian conditionalization model to the empirical data. (a) the fit of the standard account presented in the text; (b) the fit provided by classical logic (modified to incorporate error); (c) the fit of a modified Bayesian conditionalization model. 96 1 0.8 0.6 0.4 P (Endorse) Data Model (a) (b) (c) Error bars = 95% CIs MP DA AC MT MP DA AC MT MP DA AC MT Inference Overview wires.wiley.com/cogsci However, other exemplars of this argument form seem quite strong in scientific and everyday discourse: This drug is safe, because no-one has found any toxic effects (2) The classic tool brought to the analysis of fallacies, formal logic, is widely acknowledged to be completely unable to explain the difference between (1) and (2)",
    "chunk_id": "Adv_cognitive_modelling_bayesian_models_of_cognition.json_chunk_24"
  },
  {
    "document_type": "research_paper",
    "title": "Bayesian models of cognition",
    "author": "Nick Chater, Mike Oaksford, Ulrike Hahn and Evan Heit",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Chater-2010-Bayesian-models-of-cognition.pdf",
    "date_published": "2010-09-16",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". 99 More recent pragma-dialectical approaches, 97 which argue that fallacies arise due to the appliction of rules of argumentation outside the discourse context in which they apply, similarly cannot ditinguish (1) from (2). This is simply because (1) and (2) could appear in exactly the same discourse cotext but (2) would still be regarded as stronger than (1). 98 The rational Bayesian approach distinguishes (1) and (2) in terms of their inductive strength. Essetially, adequate tests of toxicity exist to establish with a high probability that a drug is safe. However, there are no adequate tests of the non existence or existence of Ghosts that could establish with high probability that Ghosts exist. The Bayesian approach assumes that P ( C | P ) is calculated by Bayes’ theorem which dictates the factors which should influence people’s assessments of argument strength. According to this approach, the argument in (2) corresponds to negative test validity , P ( ¬ T |¬ e ), that is, the probability that a drug is not toxic (safe) given there is no evidence of toxicity. This negtive argument contrast with positive test validity , P ( T | e ) (Figure 7). By Bayes’s theorem, these quatities depend on the sensitivity and selectivity of the test and the prior belief that the drug is toxic (Figure 7). If selectivity is higher than sensitivity—a frequent occurrence in real world clinical and pschometric tests—then positive arguments based on P ( T | e ) are stronger than negative arguments based on P ( ¬ T |¬ e ). 96,98 P ( T / e ) = P ( ¬ T / ¬ e ) = nh nh + (1 − l )(1 − h ) l (1 − h ) l (1 − h ) + (1 − n ) h FIGURE 7 | Positive ( P ( T | e )) and negative ( P ( ¬ T |¬ e )) test validity. These probabilities can be calculated from the sensitivity ( P (e | T)) and the selectivity ( P ( ¬ e |¬ T)) of the test and the prior belief that T is true ( P ( T )) using Bayes’ theorem",
    "chunk_id": "Adv_cognitive_modelling_bayesian_models_of_cognition.json_chunk_25"
  },
  {
    "document_type": "research_paper",
    "title": "Bayesian models of cognition",
    "author": "Nick Chater, Mike Oaksford, Ulrike Hahn and Evan Heit",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Chater-2010-Bayesian-models-of-cognition.pdf",
    "date_published": "2010-09-16",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". These probabilities can be calculated from the sensitivity ( P (e | T)) and the selectivity ( P ( ¬ e |¬ T)) of the test and the prior belief that T is true ( P ( T )) using Bayes’ theorem. Let n denote sensitivity, that is, n = P(e | T), l denote selectivity, that is, l = P( ¬ e |¬ T), and h denote the prior probability of drug A being toxic, that is, h = P ( T ) . One Fifty Error bars = 95% Cls R 2 = .98 1 0.9 0.8 0.7 0.6 Prob ( Conclusion ) Strong Weak Strong Weak Prior belief Positive Negative Model FIGURE 8 | The mean acceptance ratings for Ref 100 by evidence (1 vs. 50 experiments), prior belief (strong vs. weak), and argument type (positive vs. negative). CI = confidence interval, ( N = 84 ). Figure 8 shows the effect of manipulating these factors on peoples’ assessments of arguments strength, using an amount of evidence manipulation which should affect sensitivity and selectivity. Fitting the Bayesian model to the data revealed this to be the case: sensitivity and specificity were higher in the high than in the low amount of evidence condition, with P ( ¬ P |¬ C ) = 0 . 83 and P ( P | C ) = 0 . 66 (high), and P ( ¬ P |¬ C ) = . 77 and P ( P | C ) = 0 . 46 (low), respetively. Moreover, sensitivity was higher than seletivity. Similar Bayesian models have also been used to analyze circular reasoning and the slippery slope argument. 98 CONCLUSION The brain faces pervasive uncertainty. Bayesian moels of cognition aim to understand a wide range of cognitive problems involving uncertainty, ranging from perception to high-level reasoning and argument. Bayesian methods thus may provide a potential link between high-level and low-level cognition that may bridge across each of Marr’s levels of explanation",
    "chunk_id": "Adv_cognitive_modelling_bayesian_models_of_cognition.json_chunk_26"
  },
  {
    "document_type": "research_paper",
    "title": "Bayesian models of cognition",
    "author": "Nick Chater, Mike Oaksford, Ulrike Hahn and Evan Heit",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Chater-2010-Bayesian-models-of-cognition.pdf",
    "date_published": "2010-09-16",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Bayesian methods thus may provide a potential link between high-level and low-level cognition that may bridge across each of Marr’s levels of explanation. Currently, it would be true to say that the degree of acceptance enjoyed by Bayesian models is roughly inversely related to the level of the cognitive phenoena being modeled, that is, acceptance is greatest at the low neural/perceptual level and decreases as one moves toward higher level phenomena such as reasoing. This seems due in part to availability at the lower level of some quite exquisitely detailed experimental evidence relating the phenomenon to the models. Over the coming years it will be important to see whether similarly detailed and convincing evidence will emerge for Bayesian models of higher level cognition. WIREs Cognitive Science Bayesian models of cognition",
    "chunk_id": "Adv_cognitive_modelling_bayesian_models_of_cognition.json_chunk_27"
  },
  {
    "document_type": "research_paper",
    "title": "Ten simple reules for the computational modeling of behavioral data",
    "author": "Robert C Wilson, Anne GE Collins",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Wilson-2019-Ten-simple-rules-for-the-computatio.pdf",
    "date_published": "2019-11-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": "*For correspondence: bob@email.arizona.edu (RCW); annecollins@berkeley.edu (AGEC) † These authors contributed equally to this work Competing interests: The authors declare that no competing interests exist. Funding: See page 24 Received: 26 June 2019 Accepted: 09 October 2019 Published: 26 November 2019 Reviewing editor: Timothy E Behrens, University of Oxford, United Kingdom Copyright Wilson and Collins. This article is distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use and redistribution provided that the original author and source are credited. Ten simple rules for the computational modeling of behavioral data Robert C Wilson 1,2† *, Anne GE Collins 3,4† * 1 Department of Psychology, University of Arizona, Tucson, United States; 2 Cognitive Science Program, University of Arizona, Tucson, United States; 3 Department of Psychology, University of California, Berkeley, Berkeley, United States; 4 Helen Wills Neuroscience Institute, University of California, Berkeley, Berkeley, United States Abstract Computational modeling of behavior has revolutionized psychology and neuroscience. By fitting models to experimental data we can probe the algorithms underlying behavior, find neural correlates of computational variables and better understand the effects of drugs, illness and interventions. But with great power comes great responsibility. Here, we offer ten simple rules to ensure that computational modeling is used with care and yields meaningful insights. In particular, we present a beginner-friendly, pragmatic and details-oriented introduction on how to relate models to data. What, exactly, can a model tell us about the mind? To answer this, we apply our rules to the simplest modeling techniques most accessible to beginning modelers and illustrate them with examples and code available online. However, most rules apply to more advanced techniques",
    "chunk_id": "Adv_cognitive_modelling_15747544008463_1..33.json_chunk_1"
  },
  {
    "document_type": "research_paper",
    "title": "Ten simple reules for the computational modeling of behavioral data",
    "author": "Robert C Wilson, Anne GE Collins",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Wilson-2019-Ten-simple-rules-for-the-computatio.pdf",
    "date_published": "2019-11-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". However, most rules apply to more advanced techniques. Our hope is that by following our guidelines, researchers will avoid many pitfalls and unleash the power of computational modeling on their own data. What is computational modeling of behavioral data? The goal of computational modeling in behavioral science is to use precise mathematical models to make better sense of behavioral data. The behavioral data most often come in the form of choices, but can also be reaction times, eye movements, or other easily observable behaviors, and even neral data. The models come in the form of mathematical equations that link the experimentally observable variables (e.g. stimuli, outcomes, past experiences) to behavior in the immediate future. In this sense, computational models instantiate different ‘algorithmic hypotheses’ about how behaior is generated. Exactly what it means to ‘make sense’ of behavioral data is, to some extent, a matter of taste that will vary according to the researcher’s goals ( Kording et al., 2018 ). In some cases, a simple model that can explain broad qualitative features of the data is enough. In other cases, more detailed moels that make quantitative predictions are required ( Breiman, 2001 ). The exact form of the models, and exactly what we do with them, is limited only by our imaginations, but four uses dominate the literature: simulation, parameter estimation, model comparison, and latent variable inference. Simulation involves running the model with particular parameter settings to generate ‘fake’ behavioral data. These simulated data can then be analyzed in much the same way as one would analyze real data, to make precise, falsifiable predictions about qualitative and quantitative paterns in the data. Simulation is a way to make theoretical predictions more precise and testable. (Some examples include Cohen et al., 1990 ; Collins and Frank, 2014 ; Rescorla and Wagner, 1972 ; Farashahi et al., 2017 ; Montague et al., 1996 ; Abbott et al., 2015 ; Lee and Webb, 2005 )",
    "chunk_id": "Adv_cognitive_modelling_15747544008463_1..33.json_chunk_2"
  },
  {
    "document_type": "research_paper",
    "title": "Ten simple reules for the computational modeling of behavioral data",
    "author": "Robert C Wilson, Anne GE Collins",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Wilson-2019-Ten-simple-rules-for-the-computatio.pdf",
    "date_published": "2019-11-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". (Some examples include Cohen et al., 1990 ; Collins and Frank, 2014 ; Rescorla and Wagner, 1972 ; Farashahi et al., 2017 ; Montague et al., 1996 ; Abbott et al., 2015 ; Lee and Webb, 2005 ). Parameter estimation involves finding the set of parameter values that best account for real behavioral data for a given model. These parameters can be used as a succinct summary of a Wilson and Collins. eLife 2019;8:e49547. DOI: https://doi.org/10.7554/eLife.49547 1 of 33 REVIEW ARTICLE given data set ( Ratcliff, 1978 ; Wilson et al., 2013 ; Daw et al., 2011 ; Donkin et al., 2016 ), for investigating individual differences ( Frank et al., 2007 ; Starns and Ratcliff, 2010 ; Collins and Frank, 2012 ; Gillan et al., 2016 ; Somerville et al., 2017 ; Nilsson et al., 2011 ) and for quantifying the effects of interventions such as drugs, lesions, illness, or experimental condtions ( Frank et al., 2004 ; Lorains et al., 2014 ; Dowd et al., 2016 ; Zajkowski et al., 2017 ; Warren et al., 2017 ; Wimmer et al., 2018 ; van Ravenzwaaij et al., 2011 ). Model comparison involves trying to compute which of a set of possible models best describes the behavioral data, as a way to understand which mechanisms are more likely to underlie behaior. This is especially useful when the different models make similar qualitative predictions but difer quantitatively ( Wilson and Niv, 2011 ; Daw et al., 2011 ; Collins and Frank, 2012 ; Collins and Frank, 2012 ; Fischer and Ullsperger, 2013 ; Steyvers et al., 2009 ; Haaf and Rouder, 2017 ; Donkin et al., 2014 ). Latent variable inference involves using the model to compute the values of hidden variables (for example values of different choices) that are not immediately observable in the behavioral data, but which the theory assumes are important for the computations occurring in the brain",
    "chunk_id": "Adv_cognitive_modelling_15747544008463_1..33.json_chunk_3"
  },
  {
    "document_type": "research_paper",
    "title": "Ten simple reules for the computational modeling of behavioral data",
    "author": "Robert C Wilson, Anne GE Collins",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Wilson-2019-Ten-simple-rules-for-the-computatio.pdf",
    "date_published": "2019-11-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Latent variable inference is especially useful in neuroimaging where it is used to help search for the neural correlates of the model ( O’Doherty et al., 2007 ; Wilson and Niv, 2015 ; Donoso et al., 2014 ; Cohen et al., 2017 ), but also for electroencephalogram (EEG), electrocorticography (ECOG), electrophysiology and pupillometry among many other data sources ( O’Reilly et al., 2013 ; Collins and Frank, 2018 ; Samejima et al., 2005 ; Cavanagh et al., 2014 ; Nassar et al., 2012 ). Each of these uses has its strengths and weaknesses, and each of them can be mishandled in a number of ways, causing us to draw wrong and misleading conclusions ( Nassar and Frank, 2016 ; Palminteri et al., 2017 ). Here we present a beginner-friendly, pragmatic, practical and details-orented introduction (complete with example code available at [code]) on how to relate models to data and how to avoid many potential modeling mistakes. Our goal for this paper is to go beyond the mere mechanics of implementing models — as important as those mechanics are — and instead focus on the harder question of how to figure out what, exactly, a model is telling us about the mind. For this reason, we focus primarily on the simplest modeling techniques most accessible to beginning modelers, but almost all of our points apply more generally and readers interested in more advanced modeling techniques should consult the many excellent tutorials, didactic examples, and books on the topic ( Busemeyer and Diederich, 2010 ; Daw, 2011 ; Daw and Tobler, 2014 ; Heathcote et al., 2015 ; Huys, 2017 ; Turner et al., 2013 ; Vandekerckhove et al., 2015 ; Wagenmakers and Farrell, 2004 ; Rigoux et al., 2014 ; Nilsson et al., 2011 ; Farrell and Lewadowsky, 2018 ; Lee et al., 2019 ). For clarity of exposure, we chose to make all of the examples in this paper reflect a single narrow domain - reinforcement learning models applied to choice data ( Sutton and Barto, 2018 ). We chose this domain for a few reasons",
    "chunk_id": "Adv_cognitive_modelling_15747544008463_1..33.json_chunk_4"
  },
  {
    "document_type": "research_paper",
    "title": "Ten simple reules for the computational modeling of behavioral data",
    "author": "Robert C Wilson, Anne GE Collins",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Wilson-2019-Ten-simple-rules-for-the-computatio.pdf",
    "date_published": "2019-11-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". We chose this domain for a few reasons. (1) Modeling is particularly popular in the field of learning. Indeed, this field benefits from modeling particularly because of the nature of the behavioral data: trials are dependent on all past history and thus unique, making classic data analysis with aggregation across conditions less successful. (2) The sequential dependency of trials in learning contexts can lead to technical challenges when fitting models that are absent in non-learning contexts. However, the same techniques are widely and successfully applied to other observable behavior, such as reaction times ( Ratcliff and Rouder, 1998 ; Viejo et al., 2015 ; Ballard and McClure, 2019 ; Wiecki et al., 2013 ), and to other domains, including but not limited to perception ( Sims, 2018 ), perceptual decsion-making ( Ratcliff and Rouder, 1998 ; Drugowitsch et al., 2016 ; Findling et al., 2018 ), economic decision-making ( van Ravenzwaaij et al., 2011 ; Nilsson et al., 2011 ), visual short-term memory ( Donkin et al., 2016 ; Donkin et al., 2014 ; Nassar et al., 2018 ), long-term memory ( Batchelder and Riefer, 1990 ), category learning ( Lee and Webb, 2005 ), executive functions ( Haaf and Rouder, 2017 ; Jahfari et al., 2019 ), and so on. Thus, our hope is that, regardless of the techniques you use or the domain you model, by following these 10 simple steps ( Figure 1 ), you will be able to minimize your modeling mishaps and unleash the power of computational modeling on your own behavioral data! Wilson and Collins. eLife 2019;8:e49547",
    "chunk_id": "Adv_cognitive_modelling_15747544008463_1..33.json_chunk_5"
  },
  {
    "document_type": "research_paper",
    "title": "Ten simple reules for the computational modeling of behavioral data",
    "author": "Robert C Wilson, Anne GE Collins",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Wilson-2019-Ten-simple-rules-for-the-computatio.pdf",
    "date_published": "2019-11-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". eLife 2019;8:e49547. DOI: https://doi.org/10.7554/eLife.49547 2 of 33 Review Article Neuroscience Design experiment Section 1 Build models Section 2 Simulate model and experiment Section 3 Parameter recovery? Sections 4 & 5 Model recovery? Section 6 Fit real data Section 7 Validate the model Section 8 Parameter fits Section 7 Model comparison Section 7 Latent variable analysis Section 9 Report results Section 10 no yes yes no Can model and experiment answer question in theory? Can model account for the data? Figure 1. Schematic of the 10 rules and how they translate into a process for using computational modeling to better understand behavior. Wilson and Collins. eLife 2019;8:e49547. DOI: https://doi.org/10.7554/eLife.49547 3 of 33 Review Article Neuroscience Design a good experiment! Computational modeling is a powerful technique, but it can never replace good experimental design. Modeling attempts to capture how information is manipulated behind the scenes to produce the behavior; thus it is fundamentally limited by the behavioral data, which is itself fundamentally liited by the experimental protocol. A researcher studying face perception would not attempt to fit Prospect Theory to a face perception task; and a researcher studying the differential effects of gain and loss would not do it in a gambling task with only gains. Although obvious in these simple cases, the question becomes more difficult as the complexity of the model increases: is a given learning protocol rich enough to allow the identification of dynamic changes in learning rate, of working memory or episodic memory contributions to learning, or of reward range adaptation? Often, the answer to these questions will be ‘no’ unless the protocol has been deliberately designed to provide this power",
    "chunk_id": "Adv_cognitive_modelling_15747544008463_1..33.json_chunk_6"
  },
  {
    "document_type": "research_paper",
    "title": "Ten simple reules for the computational modeling of behavioral data",
    "author": "Robert C Wilson, Anne GE Collins",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Wilson-2019-Ten-simple-rules-for-the-computatio.pdf",
    "date_published": "2019-11-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". So, how should you go about designing a good experiment with computational modeling in mind? While this process will always be something of an art form, we suggest that you ask yourself the following questions in order to optimize your experimental design: What scientific question are you asking? Although this sounds obvious, it is easy to get sucked into an experimental design without ever asing the most basic questions about your goals. What cognitive process are you targeting? What aspect of behavior are you trying to capture? What hypotheses are you trying to pick apart? For example, you may be trying to identify how working memory contributes to learning or how behaioral variability can be used to explore. Keeping your scientific goals in mind when you design the task can save much time later on. Does your experiment engage the targeted processes? This may be a difficult question to answer, and it may require expert knowledge or piloting. Hoever, you need to know that the experimental design actually engages the processes that you are trying to model. Will signatures of the targeted processes be evident from the simple statistics of the data? In addition to engaging the processes of interest, the best experiments make these processes identfiable in classical analyses of the behavioral data ( Palminteri et al., 2017 ). For example, if you are investigating working memory contributions to learning, you may look for a signature of load on behavior by constructing an experimental design that varies load, to increase chances of probing working memory’s role in learning. Seeing signs of the computations of interest in simple analyses of behavior builds confidence that the modeling process will actually work. In our experience, computtional modeling is rarely informative when there is no evidence of an effect in model-independent analyses of behavior. To answer these questions, it is important to have a clear theoretical hypothesis of what phenoenon is to be modeled",
    "chunk_id": "Adv_cognitive_modelling_15747544008463_1..33.json_chunk_7"
  },
  {
    "document_type": "research_paper",
    "title": "Ten simple reules for the computational modeling of behavioral data",
    "author": "Robert C Wilson, Anne GE Collins",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Wilson-2019-Ten-simple-rules-for-the-computatio.pdf",
    "date_published": "2019-11-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". To answer these questions, it is important to have a clear theoretical hypothesis of what phenoenon is to be modeled. In fact, although designing a good experiment is the first step, it goes hanin-hand with designing a good model, and the two steps should ideally be done in parallel. But what if I’m not an experimentalist? Computational modeling is hard and many of the best modelers are specialists who never run experiments of their own. Instead these researchers test their models against published findings, publicly available datasets, or even, if they are lucky, unpublished data from their experimental coleagues. Such specialist modelers might feel that they can safely ignore this first point about expermental design and instead focus on explaining the data they can get. We strongly urge them not to. Instead we urge these specialist modelers to always be considering better ways in which their moels could be tested. Such experimental thinking helps you to be more concrete in your ideas and to think about how your model might apply outside of the context for which it was designed. In addtion, thinking experimentally — and even better talking with experimentalists — forces you to engage with behavior as it actually is rather than as you would like it to be, which in turn can lead to new insights. Finally, by proposing concrete experimental designs, it is easier to convince your Wilson and Collins. eLife 2019;8:e49547. DOI: https://doi.org/10.7554/eLife.49547 4 of 33 Review Article Neuroscience experimental colleagues to actually test your ideas, which is surely the goal if we are to move the field forward. An illustrative example: the multi-armed bandit task The ten rules in this paper are quite general, but we will illustrate many of our points using simple examples from our own field of reinforcement learning",
    "chunk_id": "Adv_cognitive_modelling_15747544008463_1..33.json_chunk_8"
  },
  {
    "document_type": "research_paper",
    "title": "Ten simple reules for the computational modeling of behavioral data",
    "author": "Robert C Wilson, Anne GE Collins",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Wilson-2019-Ten-simple-rules-for-the-computatio.pdf",
    "date_published": "2019-11-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Code for implementing all of these examples is available on GitHub ( https://github.com/AnneCollins/TenSimpleRulesModeling) ( Collins and Wison, 2019 ; copy archived at https://github.com/elifesciences-publications/TenSimpleRulesModeing ). The goal of these example studies is to understand how people learn to maximize their rewards in a case where the most rewarding choice is initially unknown. More specifically, we consider the case in which a participant makes a series of T choices between K slot machines, or ‘one-armed bandits’, to try to maximize their earnings. If played on trial t , each slot machine, k , pays out a reward, r t , which is one with reward probability, k t , and otherwise 0. The reward probabilities are different for each slot machine and are initially unknown to the subject. In the simplest version of the task, the reward probabilities are fixed over time. The three experimental parameters of this task are: the number of trials, T , the number of slot machines, K , and the reward probabilities of the different options, k t , which may or may not change over time. The settings of these parameters will be important for determining exactly what informtion we can extract from the experiment. In this example, we will assume that T 1⁄4 1000 , K 1⁄4 2 , and that the reward probabilities are 1 t 1⁄4 0 : 2 for slot machine 1 and 2 t 1⁄4 0 : 8 for slot machine 2. Design good models Just as bad experiments can limit our ability to test different hypotheses, bad models – quite literally the mathematical embodiment of our hypotheses – can further limit the conclusions we can draw ( Donkin et al., 2014 ). This point is especially important if we are designing new models, but even well-established computational models can be problematic in some cases ( Broomell and Bhatia, 2014 ; Nilsson et al., 2011 ). Critical to the design of the model is a clear understanding of your reason for modeling",
    "chunk_id": "Adv_cognitive_modelling_15747544008463_1..33.json_chunk_9"
  },
  {
    "document_type": "research_paper",
    "title": "Ten simple reules for the computational modeling of behavioral data",
    "author": "Robert C Wilson, Anne GE Collins",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Wilson-2019-Ten-simple-rules-for-the-computatio.pdf",
    "date_published": "2019-11-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Critical to the design of the model is a clear understanding of your reason for modeling. Are you interested in a descriptive model that succinctly summarizes, but perhaps does not explain, behaioral data? A mechanistic model to tie behavior to the brain? Or an elegant mathematical model to illustrate a concept? As shown in an excellent article by Kording and colleagues ( Kording et al., 2018 ), computational modelers have a wide variety of goals for their models, and understanding your own motivations is a great place to start. More pragmatically, there are a number of different approaches for designing models that have been successfully used in the literature. Perhaps the simplest approach is to use heuristics to find a ‘reasonable’ way to handle information to produce the target behavior. This approach was how the delta rule (see Model three below) was first invented ( Rescorla and Wagner, 1972 ). Another approach is to scour the artificial intelligence, computer science, and applied mathematics literature for algorithms that have been used to solve similar problems for artificial agents. This approach has been fruitfully applied in the field of reinforcement learning ( Sutton and Barto, 2018 ), where algrithms such as Q-learning and temporal difference learning have been related to human and animal behavior and brain function ( Watkins and Dayan, 1992 ; Montague et al., 1996 ). Another approach is to take a Bayes-optimal perspective, to design algorithms that perform optimally given a model of the environment and the task. Ideal observer models in vision are one example in which this approach has been applied successfully ( Geisler, 2011 ). More generally, Bayes-optimal models can be further pursued by investigating simpler algorithms that approximate the ideal strategy, or by imposing bounded rationality constraints, such as limited computational resources, on ideal observer agents ( Courville and Daw, 2008 ; Nassar et al., 2010 ; Collins and Frank, 2012 ; Daw and Couville, 2007 ; Lieder et al., 2018 )",
    "chunk_id": "Adv_cognitive_modelling_15747544008463_1..33.json_chunk_10"
  },
  {
    "document_type": "research_paper",
    "title": "Ten simple reules for the computational modeling of behavioral data",
    "author": "Robert C Wilson, Anne GE Collins",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Wilson-2019-Ten-simple-rules-for-the-computatio.pdf",
    "date_published": "2019-11-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Regardless of the approach (or, better yet, approaches) that you take to design your models, it is important to keep the following points in mind: Wilson and Collins. eLife 2019;8:e49547. DOI: https://doi.org/10.7554/eLife.49547 5 of 33 Review Article Neuroscience A computational model should be as simple as possible, but no simpler Einstein’s old edict applies equally to models of the mind as it does to models of physical systems. Simpler, more parsimonious models are easier to fit and easier to interpret and should always be included in the set of models under consideration. Indeed, formal model comparison techniques (described in detail in Appendix 2) include a penalty for overly complex models, which are more likely to overfit the data and generalize poorly, and favor simpler models so long as they can account for the data. A computational model should be interpretable (as much as possible) In the process of developing models that can account for the behavioral data, researchers run the risk of adding components to a model that are not interpretable as a sensible manipulation of infomation. For example, a negative learning rate is difficult to interpret in the framework of reinforcment learning. Although such uninterpretable models may sometimes improve fits, nonsensical parameter values may indicate that something important is missing from your model, or that a diffeent cognitive process altogether is at play. The models should capture all the hypotheses that you plan to test While it is obviously important to design models that can capture your main hypothesis, it is even more important to design models that capture competing hypotheses. Crucially, competing models should not be strawmen — they should have a genuine chance of relating to behavior in the task environment, and they should embody a number of reasonable, graded hypotheses. You should of course put equal effort into fitting these models as you do your favored hypothesis",
    "chunk_id": "Adv_cognitive_modelling_15747544008463_1..33.json_chunk_11"
  },
  {
    "document_type": "research_paper",
    "title": "Ten simple reules for the computational modeling of behavioral data",
    "author": "Robert C Wilson, Anne GE Collins",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Wilson-2019-Ten-simple-rules-for-the-computatio.pdf",
    "date_published": "2019-11-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". You should of course put equal effort into fitting these models as you do your favored hypothesis. Better yet, you shouldn’t have a favored hypothesis at all — let the data determine which model is the best fit, not your a priori commitment to one model or another. Box 1. Example: Modeling behavior in the multi-armed bandit task. We consider five different models of how participants could behave in the multi-armed bandit task. Model 1: Random responding In the first model, we assume that participants do not engage with the task at all and simply press buttons at random, perhaps with a bias for one option over the other. Such random behavior is not uncommon in behavioral experiments, especially when participants have no external incentives for performing well. Modeling such behavior can be important if we wish to identify such ‘checked out’ individuals in a quantitative and reproducible manner, either for exclusion or to study the checked-out behavior itself. To model this behavior, we assume that participants choose between the two options randomly, perhaps with some overall bias for one option over the other. This bias is captured with a parameter b (which is between 0 and 1), such that the probability of choosing the two options is p 1 t 1⁄4 b and p 2 t 1⁄4 1 b (1) Thus, for two bandits, the random responding model has just one free parameter, controlling the overall bias for option 1 over option 2, 1 1⁄4 b . Model 2: Noisy win-stay-lose-shift The win-stay-lose-shift model is one of the simplest models that adapts its behavior according to feedback. Consistent with the name, the model repeats rewarded actions and switches away from unrewarded actions. In the noisy version of the model, the win-stay-lose-shift rule is applied probabilistically, such that the model applies the win-stay-lose-shift rule with probability 1 , and chooses randomly with probability . In the two-bandit case, the probability of chooing option k is Wilson and Collins. eLife 2019;8:e49547",
    "chunk_id": "Adv_cognitive_modelling_15747544008463_1..33.json_chunk_12"
  },
  {
    "document_type": "research_paper",
    "title": "Ten simple reules for the computational modeling of behavioral data",
    "author": "Robert C Wilson, Anne GE Collins",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Wilson-2019-Ten-simple-rules-for-the-computatio.pdf",
    "date_published": "2019-11-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". In the two-bandit case, the probability of chooing option k is Wilson and Collins. eLife 2019;8:e49547. DOI: https://doi.org/10.7554/eLife.49547 6 of 33 Review Article Neuroscience p k t 1⁄4 1 = 2 if ð c t 1 1⁄4 k and r t 1 1⁄4 1 Þ OR ð c t 1 61⁄4 k and r t 1 1⁄4 0 Þ = 2 if ð c t 1 61⁄4 k and r t 1 1⁄4 1 Þ OR ð c t 1 1⁄4 k and r t 1 1⁄4 0 Þ (2) where c t 1⁄4 1 ; 2 is the choice at trial t , and r t 1⁄4 0 ; 1 the reward at trial t . Although more complex to implement, this model still only has one free parameter, the overall level of randomness, 2 1⁄4 . Model 3: Rescorla Wagner In this model, participants first learn the expected value of each slot machine based on the hitory of previous outcomes and then use these values to make a decision about what to do next. A simple model of learning is the Rescorla-Wagner learning rule ( Rescorla and Wagner, 1972 ), whereby the value of option k , Q k t is updated in response to reward r t according to: Q k t þ 1 1⁄4 Q k t þ a ð r t Q k t Þ (3) where a is the learning rate, which takes a value between 0 and 1 and captures the extent to which the prediction error, ð r t Q k t Þ , updates the value. For simplicity, we assume that the initial value, Q k 0 , is zero, although it is possible to treat the Q k 0 as a free parameter of the model. A simple model of decision making is to assume that participants use the options’ values to guide their decisions, choosing the most valuable option most frequently, but occasionally maing ‘mistakes’ (or exploring) by choosing a low-value option. One choice rule with these propeties is known as the ‘softmax’ choice rule, which chooses option k with probability p k t 1⁄4 exp ð b Q k t Þ P K i 1⁄4 1 exp ð b Q i t Þ (4) where b is the ‘inverse temperature’ parameter that controls the level of stochasticity in the choice, ranging from b 1⁄4 0 for completely random responding and b 1⁄4 ¥ for deterministically choosing the highest value option",
    "chunk_id": "Adv_cognitive_modelling_15747544008463_1..33.json_chunk_13"
  },
  {
    "document_type": "research_paper",
    "title": "Ten simple reules for the computational modeling of behavioral data",
    "author": "Robert C Wilson, Anne GE Collins",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Wilson-2019-Ten-simple-rules-for-the-computatio.pdf",
    "date_published": "2019-11-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Combining the learning ( Equation 3 ) and decision rules ( Equation 4 ) gives a simple model of decision-making in this task with two free parameters: the learning rate, a , and the inverse teperature, b . That is, in our general notation, for this model 3 1⁄4 ð a ; b Þ . Model 4: Choice kernel This model tries to capture the tendency for people to repeat their previous actions. In particlar, we assume that participants compute a ‘choice kernel,’ CK k t , for each action, which keeps track of how frequently they have chosen that option in the recent past. This choice kernel updates in much the same way as the values in the Rescorla-Wagner rule, i.e. according to CK k t þ 1 1⁄4 CK k t þ a c ð a k t CK k t Þ (5) where a k t 1⁄4 1 if option k is played on trial t , otherwise a k t 1⁄4 0 , and a c is the choice-kernel learning rate. For simplicity, we assume that the initial value of the choice kernel is always zero, although, like the initial Q -value in the Rescorla-Wagner model, this could be a parameter of the model. Note that with a c 1⁄4 1 , this model is very similar to model 2 (win-stay-lose-shift). From there, we assume that each option is chosen according to p k t 1⁄4 exp ð b c CK k t Þ P K i 1⁄4 1 exp ð b c CK i t Þ (6) where b c is the inverse temperature associated with the choice kernel. Combining the choice kernel ( Equation 5 ) with the decision rule ( Equation 6 ) gives a simple model of decision-making in this task with two free parameters: the choice-kernel learning rate, a c , and the choice-kernel inverse temperature b c . That is, in our general notation, for this model 4 1⁄4 ð a c ; b c Þ . Model 5: Rescorla Wagner + choice kernel Wilson and Collins. eLife 2019;8:e49547. DOI: https://doi.org/10.7554/eLife.49547 7 of 33 Review Article Neuroscience Finally, our most complex model mixes the reinforcement learning model with the choice kernel model. In this model, the values update according to Equation 3 , while the choice kernel updates according to Equation 5",
    "chunk_id": "Adv_cognitive_modelling_15747544008463_1..33.json_chunk_14"
  },
  {
    "document_type": "research_paper",
    "title": "Ten simple reules for the computational modeling of behavioral data",
    "author": "Robert C Wilson, Anne GE Collins",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Wilson-2019-Ten-simple-rules-for-the-computatio.pdf",
    "date_published": "2019-11-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". In this model, the values update according to Equation 3 , while the choice kernel updates according to Equation 5 . The terms are then combined to compute the choice probbilities as p k t 1⁄4 exp ð b Q k t þ b c CK k t Þ P K i 1⁄4 1 exp ð b Q i t þ b c CK i t Þ (7) This most complex model has four free parameters, i.e. 5 1⁄4 ð a ; b ; a c ; b c Þ . Simulate, simulate, simulate! Once you have an experimental design and a set of computational models, a really important step is to create fake , or surrogate data ( Palminteri et al., 2017 ). That is, you should use the models to siulate the behavior of participants in the experiment, and to observe how behavior changes with diferent models, different model parameters, and different variants of the experiment. This step will allow you to refine the first two steps: confirming that the experimental design elicits the behaviors assumed to be captured by the computational model. To do this, here are some important steps. Define model-independent measures that capture key aspects of the processes you are trying to model Finding qualitative signatures (and there will often be more than one) of the model is crucial. By studying these measures with simulated data, you will have greater intuition about what is going on when you use the same model-independent measures to analyze real behavior ( Daw et al., 2011 ; Collins and Frank, 2012 ; Collins and Frank, 2013 ; Nassar et al., 2018 ; Lee and Webb, 2005 ). Simulate the model across the range of parameter values Then, visualize behavior as a function of the parameters. Almost all models have free parameters. Understanding how changes to these parameters affect behavior will help you to better interpret your data and to understand individual differences in fit parameters",
    "chunk_id": "Adv_cognitive_modelling_15747544008463_1..33.json_chunk_15"
  },
  {
    "document_type": "research_paper",
    "title": "Ten simple reules for the computational modeling of behavioral data",
    "author": "Robert C Wilson, Anne GE Collins",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Wilson-2019-Ten-simple-rules-for-the-computatio.pdf",
    "date_published": "2019-11-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Understanding how changes to these parameters affect behavior will help you to better interpret your data and to understand individual differences in fit parameters. For example, in probabilistic reinforcement learning tasks modeled with a simple delta-rule model (Model 3; Equation 3 ), the learning rate parameter, a , can relate to both the speed of learning and noisiness in asymptotic behavior, as can the inverse temperature parameter, b (in Equation 4 ), as seen in Box 2—figure 1B . Visualize the simulated behavior of different models This will allow you to verify that behavior is qualitatively different for different models, making their predictions in the experimental setup different ( Box 2—figure 1A ). If the behavior of different moels is not qualitatively different, this is a sign that you should try to design a better experiment. Although not always possible, distinguishing between models on the basis of qualitative patterns in the data is always preferable to quantitative model comparison ( Navarro, 2019 ; Palminteri et al., 2017 ). More generally, the goal of the simulation process is to clarify how the models and experimental design satisfy your goal of identifying a cognitive process in behavior. If the answer is positive — i.e. the experiment is rich enough to capture the expected behavior, the model’s parameters are intepretable, and competing models make dissociable predictions — you can move on to the next step. Otherwise, you should loop back through these first three sections to make sure that your expermental design and models work well together, and that the model parameters have identifiable effects on the behavior, which is a prerequisite for the fourth step, fitting the parameters (c.f. Figure 1 ). Box 2. Example: simulating behavior in the bandit task. To simulate behavior, we first need to define the parameters of the task",
    "chunk_id": "Adv_cognitive_modelling_15747544008463_1..33.json_chunk_16"
  },
  {
    "document_type": "research_paper",
    "title": "Ten simple reules for the computational modeling of behavioral data",
    "author": "Robert C Wilson, Anne GE Collins",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Wilson-2019-Ten-simple-rules-for-the-computatio.pdf",
    "date_published": "2019-11-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Figure 1 ). Box 2. Example: simulating behavior in the bandit task. To simulate behavior, we first need to define the parameters of the task. These include the total number of trials, T (=1000 in the example), as well as the number of bandits, K ð1⁄4 2 Þ , and the reward probability for each bandit, k (0.2 and 0.8 for bandits 1 and 2, respectively). The Wilson and Collins. eLife 2019;8:e49547. DOI: https://doi.org/10.7554/eLife.49547 8 of 33 Review Article Neuroscience experiment parameters, as used in the simulation, should match the actual parameters used in the experiment. Next we define the parameters of the model. One way to do this is to sample these parameters randomly from prior distributions over each parameter, the exact form of which will vary from model to model. These prior distributions should generally be as broad as possible, but if something is known about the distribution of possible parameter values for a particular model, this is one place to include it. With the free parameters set, we then proceed with the simulation. First, we simulate the choice on the first trial, a 1 , by assuming that the model chooses option k with probability, p k 1 . Next we simulate the outcome, r 1 , of this choice. In Models 2–5, we use the action and/or outcome to update the choice probabilities for the next trial. Repeating this process for all trials up to t 1⁄4 T completes one simulation. The simulations can then be analyzed in the same way as participants’ data is, ideally with the same code taking different inputs. This process should be repeated several times, with different parameter settings, to get a handle on how the model behaves as a function of its parameters",
    "chunk_id": "Adv_cognitive_modelling_15747544008463_1..33.json_chunk_17"
  },
  {
    "document_type": "research_paper",
    "title": "Ten simple reules for the computational modeling of behavioral data",
    "author": "Robert C Wilson, Anne GE Collins",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Wilson-2019-Ten-simple-rules-for-the-computatio.pdf",
    "date_published": "2019-11-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". This process should be repeated several times, with different parameter settings, to get a handle on how the model behaves as a function of its parameters. To illustrate how one might visualize the simulated results, we look at two model-independent measures that should capture fundamental aspects of learning: the probability of repeating an action, p ð stay Þ (should I change my behavior in response to feedback?), and the probability of choosing the correct option, p ð correct Þ (have I learned?). In Box 2—figure 1A below, we plot p ð stay Þ as a function of the reward on the last trial for each of the models with a particular set of parameters (M1: b 1⁄4 0 : 5 , M2: 1⁄4 0 : 05 , M3: a 1⁄4 0 : 1 , b 1⁄4 5 , M4: a c 1⁄4 0 : 1 , b c 1⁄4 3 , M5: a 1⁄4 0 : 1 , b 1⁄4 5 , a c 1⁄4 0 : 1 , b c 1⁄4 1 ). For some models (in particular the win-stay-lose-shift model (Model 2), we expect a strong dependence on past reward, but for others, such as the random responder (Model 1), we expect no dependence. Of course, the exact behavior of each model depends crucially on the parameters used in the simulations and care should be taken to ensure that these simulation parameters are reasonable, perhaps by matching to typical parameter vaues used in the literature or by constraining to human-like overall performance. Better yet is to simulate behavior across a range of parameter settings to determine how the model-indepedent measures change with different parameters. A more thorough exploration of the parameter space for Model 3 is shown in Box 2—figure 1B , where we plot the p ð correct Þ in the first and last 10 trials as a function of the learning rate, a , and softmax parameter, b . Note that the ‘optimal’ learning rate, i.e. the value of a that maxmizes p ð correct Þ , varies between early and late trials and as a function of the softmax parameter b , where for early trials higher b implies a lower optimal a ( Daw et al., 2011 )",
    "chunk_id": "Adv_cognitive_modelling_15747544008463_1..33.json_chunk_18"
  },
  {
    "document_type": "research_paper",
    "title": "Ten simple reules for the computational modeling of behavioral data",
    "author": "Robert C Wilson, Anne GE Collins",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Wilson-2019-Ten-simple-rules-for-the-computatio.pdf",
    "date_published": "2019-11-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". The question of how to choose the model-independent measures of behavior has no easy answer and calls to the domain knowledge of the specific scientific question that the modeler is attempting to answer. As a rule of thumb, the measures should capture global characteristics (e.g. overall performance) and diagnostic measures that relate to the question of interest, and may visualize different qualitative predictions of different models. 0 1 previous reward 0 0.5 1 p(stay) stay behavior M1: random M2: WSLS M3: RW M4: CK M5: RW+CK 0 0.5 1 learning rate, a 0.5 0.6 0.7 0.8 0.9 1 p(correct) early trials b b b b b = 20 = 10 = 5 = 2 = 1 0 0.5 1 learning rate, a late trials A B Box 2—figure 1. Simulating behavior in the two-armed bandit task. ( A ) Win-stay-lose-shift behavior varies widely between models. ( B ) Model 3 simulations (100 per parameter setting) show how the learning rate and softmax parameters influence two aspects of behavior: early performance (first 10 trials), and late perfomance (last 10 trials). The left graph shows that learning rate is positively correlated with early performance Wilson and Collins. eLife 2019;8:e49547. DOI: https://doi.org/10.7554/eLife.49547 9 of 33 Review Article Neuroscience improvement only for low b values or for very low a values. For high b values, there is a U-shape relationship between learning rate and early speed of learning. The right graph shows that with high b values, high learing rates negatively influence asymptotic behavior. Thus, both parameters interact to influence both the speed of learning and asymptotic performance. Fit the parameters A key component of computational modeling is estimating the values of the parameters that best describe your behavioral data. There are a number of different ways of estimating parameters, but here we focus on the maximum-likelihood approach, although almost all of our points apply to other methods such as Markov Chain Monte Carlo approaches ( Lee and Wagenmakers, 2014 )",
    "chunk_id": "Adv_cognitive_modelling_15747544008463_1..33.json_chunk_19"
  },
  {
    "document_type": "research_paper",
    "title": "Ten simple reules for the computational modeling of behavioral data",
    "author": "Robert C Wilson, Anne GE Collins",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Wilson-2019-Ten-simple-rules-for-the-computatio.pdf",
    "date_published": "2019-11-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Mathmatical details, as well as additional discussion of other approaches to model fitting can be found in Appendix 1. In the maximum likelihood approach to model fitting, our goal is to find the parameter values of model m , ^ MLE m , that maximize the likelihood of the data, d 1 : T , given the parameters, p ð d 1 : T j m ; m Þ . Maximizing the likelihood is equivalent to maximizing the log of the likelihood, LL 1⁄4 log p ð d 1 : T j m ; m Þ , which is numerically more tractable. (The likelihood is a product of many numbers smaller than 1, which can be rounded to 0 with limited precision computing. By contrast, the log-likelihood is a sum of negative numbers, which is usually tractable and will not be rounded to 0.) A simple mathematical derivation shows that this log-likelihood can be written in terms of the choice probabilities of the individual model as LL 1⁄4 log p ð d 1 : T j m ; m Þ 1⁄4 X T t 1⁄4 1 log p ð c t j d 1 : t 1 ; s t ; m ; m Þ (8) where p ð c t j d 1 : t 1 ; s t ; m ; m Þ is the probability of each individual choice given the parameters of the model and the information available up to that choice, which is at the heart of the definition of each model (for example in Equations 1-7) . In principle, finding the maximum likelihood parameters is as ‘simple’ as maximizing LL . In pratice, of course, finding the maximum of a function is not a trivial process. The simplest approach, a brute force search of the entire parameter space, is occasionally useful, and may help you to undestand how different parameters interact (see Box 3—figure 1 ). However, this approach is unfeasible outside of the simplest cases (e.g. one or two parameters with tight bounds) because of the high computational costs of evaluating the likelihood function at a large number of points. Fortunately, a number of tools exist for finding local maxima (and minima) of functions quickly using variations on gradient ascent (or descent)",
    "chunk_id": "Adv_cognitive_modelling_15747544008463_1..33.json_chunk_20"
  },
  {
    "document_type": "research_paper",
    "title": "Ten simple reules for the computational modeling of behavioral data",
    "author": "Robert C Wilson, Anne GE Collins",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Wilson-2019-Ten-simple-rules-for-the-computatio.pdf",
    "date_published": "2019-11-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Fortunately, a number of tools exist for finding local maxima (and minima) of functions quickly using variations on gradient ascent (or descent). For example, Matlab’s fmincon function can use a variety of sophisticated optimization algorithms (e.g. More ́ and Sorensen, 1983 ; Byrd et al., 2000 ) to find the minimum of a function (and other factors such as the Hessian that can be useful in some situations [ Daw, 2011 ]). So long as one remembers to feed fmincon the negative log-likelihood (whose minimum is at the same parameter values as the maximum of the positive log-likelihood), using tools such as fmincon can greatly speed up model fitting. Even here, though, a number of problems can arise when trying to maximize LL that can be reduced by using the tips and tricks described below. Most of the tips come from understanding that optimization algorithms are not foolproof and in particular are subject to numerical constraints. They generalize to other black box optimization functions in other languages, for example the Python scipy.optimize package or the optim function in R. Be sure that your initial conditions give finite log-likelihoods Optimizers such as fmincon require you to specify initial parameter values from which to start the search. Perhaps the simplest way in which the search process can fail is if these initial parameters give log-likelihoods that are not finite numbers (e.g. infinities or NaNs, not a number in Matlab speak). If your fitting procedure fails, this can often be the cause. Wilson and Collins. eLife 2019;8:e49547. DOI: https://doi.org/10.7554/eLife.49547 10 of 33 Review Article Neuroscience Beware rounding errors, zeros and infinities More generally, the fitting procedure can go wrong if it encounters infinities or NaNs during the parameter search. This can occur if a choice probability is rounded down to zero, thus making the log of the choice probability ¥ . Likewise, if your model involves exponentials (e.g",
    "chunk_id": "Adv_cognitive_modelling_15747544008463_1..33.json_chunk_21"
  },
  {
    "document_type": "research_paper",
    "title": "Ten simple reules for the computational modeling of behavioral data",
    "author": "Robert C Wilson, Anne GE Collins",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Wilson-2019-Ten-simple-rules-for-the-computatio.pdf",
    "date_published": "2019-11-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". This can occur if a choice probability is rounded down to zero, thus making the log of the choice probability ¥ . Likewise, if your model involves exponentials (e.g. the softmax choice rule in Equation 4 ), this can lead to errors whereby the exponential of a very large number is ‘rounded up’ to infinity. One way to avoid these issues is by constraining parameter values to always give finite choice probabilities and log-likelihoods at the boundaries. One way to diagnose these issues is to include checks in the code for valid log-likelihoods. Be careful with constraints on parameters If the constraints are ill chosen, it is possible that the solution will be at the bounds, which is often, but not always, a red flag. Only include parameters that have an influence on the likelihood. If only two parameters impact the likelihood, but the optimizer attempts to fit three, it will usually find the optimum for the two reevant parameters and a random value for the third; however, it will lead to slower and less efficient fitting. Beware local minima! Finally, a key limitation of optimization algorithms is that they are only guaranteed to find local miima, which are not guaranteed to be the global minima corresponding to the best fitting paramters. One way to mitigate this issue is to run the fitting procedure multiple times with random initial conditions, recording the best fitting log-likelihood for each run. The best fitting parameters are then the parameters corresponding to the run with the highest log-likelihood. There is no hard-anfast rule for knowing how many starting points to use in a given situation, besides the fact that more complex models will require more starting points. Thus, this number must be determined empirically in each case. One way to validate the number of starting points is by plotting the best likelihood score as a function of the number of starting points",
    "chunk_id": "Adv_cognitive_modelling_15747544008463_1..33.json_chunk_22"
  },
  {
    "document_type": "research_paper",
    "title": "Ten simple reules for the computational modeling of behavioral data",
    "author": "Robert C Wilson, Anne GE Collins",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Wilson-2019-Ten-simple-rules-for-the-computatio.pdf",
    "date_published": "2019-11-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". One way to validate the number of starting points is by plotting the best likelihood score as a function of the number of starting points. As the number of initial conditions increases, the best-fitting likelihood (and corresponding the parameters) will improve up to an asymptote close to the true maximum of the function (e.g. Box 3—figure 1 ). Box 3. Example: contending with multiple local maxima. As a real example with local maxima, we consider the case of a simplified version of the mixed reinforcement learning and working memory model from Collins and Frank, 2012 . For simpliity, we relegate the details of this model to Appendix 4. To appreciate the example, all one really needs to know is that in its simplest version, this model has two parameters: , which catures the effect of working memory, and a , which captures the learning rate of reinforcement learning. As is seen in Box 3—figure 1 below, this model (combined with an appropriate expeiment) gives rise to a log-likelihood surface with multiple local maxima. Depending on the staring point, the optimization procedure can converge to any one of these local maxima, meaning that the ‘maximum’ likelihood fits may not reflect the global maximum likelihood. To mitigate this concern, a simple and effective approach is to repeat the optimization procdure many times, keeping track of the best fitting log-likelihood and parameters in each case. An approximation to the global maximum is to take the best log-likelihood from this list of fits. The results of this multiple iteration procedure can be summarized by plotting the best log-liklihood as a function of the number of starting points, or similarly, by plotting the distance from the so-far best parameters to the final best parameters as a function of the number of starting points ( Box 3—figure 1B ). As the number of starting points increases, the best-fitting log-likelhood and parameters will converge to the global maximum. This plot also allows us to judge when we have used enough starting points",
    "chunk_id": "Adv_cognitive_modelling_15747544008463_1..33.json_chunk_23"
  },
  {
    "document_type": "research_paper",
    "title": "Ten simple reules for the computational modeling of behavioral data",
    "author": "Robert C Wilson, Anne GE Collins",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Wilson-2019-Ten-simple-rules-for-the-computatio.pdf",
    "date_published": "2019-11-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". This plot also allows us to judge when we have used enough starting points. Specifically, if the best fitting parameters appear to have reached asymptote, that gives us a good indication that the fit is the best we can do. Wilson and Collins. eLife 2019;8:e49547. DOI: https://doi.org/10.7554/eLife.49547 11 of 33 Review Article Neuroscience Box 3—figure 1. An example with multiple local minima. ( Left ) Log-likelihood surface for a working memory reinforcement learning model with two parameters. In this case, there are several local minima, all of which can be found by the optimization procedure depending on the starting point. Red x, generative parameters; black circle, optimum with brute search method; black *, optimum with fmincon and multiple starting points. ( Right ) Plotting the distance from the best fitting parameters after n iterations to the best fitting parameters after all iterations as a function of the number of starting points n gives a good sense of when the procedure has found the global optimum. The inset shows the same plot on a logarithmic scale for distance, illustrating that there are still very small improvements to be made after the third iteration. Check that you can recover your parameters Before reading too much into the best-fitting parameter values, MLE m , it is important to check whether the fitting procedure gives meaningful parameter values in the best case scenario, -that is, when fitting fake data where the ‘true’ parameter values are known ( Nilsson et al., 2011 ). Such a procedure is known as ‘Parameter Recovery’, and is a crucial part of any model-based analysis. In principle, the recipe for parameter recovery is quite simple. First, simulate fake data with known parameter values. Next, fit the model to these fake data to try to ‘recover’ the parameters. Finally, compare the recovered parameters to their true values. In a perfect world, the simulated and recovered parameters will be tightly correlated, with no bias",
    "chunk_id": "Adv_cognitive_modelling_15747544008463_1..33.json_chunk_24"
  },
  {
    "document_type": "research_paper",
    "title": "Ten simple reules for the computational modeling of behavioral data",
    "author": "Robert C Wilson, Anne GE Collins",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Wilson-2019-Ten-simple-rules-for-the-computatio.pdf",
    "date_published": "2019-11-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Finally, compare the recovered parameters to their true values. In a perfect world, the simulated and recovered parameters will be tightly correlated, with no bias. If there is only a weak correlation between the simulated and recovered parameters and/or a significant bias, then this is an indication that there is either a bug in your code (which from our own experience is fairly likely) or the experment is underpowered to assess this model. To make the most of your parameter recovery analysis, we suggest the following tips: Make sure your simulation parameters are in the right range An important choice for parameter recovery is the range of simulation parameters that you wish to recover. Some models/experiments only give good parameter recovery for parameters in a particlar range — if the simulation parameters are too big or too small, they can be hard to recover. An illustration of this is the softmax parameter, b , where very large b values lead to almost identical behavior in most experiments. Thus parameter recovery may fail for large b values but work well for small b values. Of course, selecting only the range of parameters that can be recovered by your model is not necessarily the right choice, especially if the parameter values you obtain when fitting real data are outside of this range! For this reason, we have the following recommendations for choosing simulation parameter values: 1. If you have already fit your data, we recommend matching the range of your simulation paraeters to the range of values obtained by your fit. 2. If you have not fit your data but you are using a model that has already been published, match the range of parameters to the range seen in previous studies. 3. Finally, if the model is completely new and the ‘true’ parameter values are unknown, we reommend simulating over as wide a range as possible to get a sense of whether and where parameters can be recovered",
    "chunk_id": "Adv_cognitive_modelling_15747544008463_1..33.json_chunk_25"
  },
  {
    "document_type": "research_paper",
    "title": "Ten simple reules for the computational modeling of behavioral data",
    "author": "Robert C Wilson, Anne GE Collins",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Wilson-2019-Ten-simple-rules-for-the-computatio.pdf",
    "date_published": "2019-11-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". You can rely on your exploration of how model parameters affect simulated behavior to predict a range beyond which parameters will not affect behavior much. Note that it is not necessarily problematic if a model’s parameters are not recoverable in a full parameter space, as long as they are recoverable in the range that matters for real data. Wilson and Collins. eLife 2019;8:e49547. DOI: https://doi.org/10.7554/eLife.49547 12 of 33 Review Article Neuroscience Plot the correlations between simulated and recovered parameters While the correlation coefficient between simulated and recovered parameters is a useful number for summarizing parameter recovery, we also strongly recommend that you actually plot the simlated vs recovered parameters. This makes the correlation clear, and also reveals whether the corrlation holds in some parameter regimes but not others. It also reveals any existing bias (for example, a tendency to recover higher or lower values in average). Make sure the recovery process does not introduce correlations between parameters In addition to looking at the correlations between simulated and recovered parameters, we also reommend looking at the correlation between the recovered parameters themselves. If the simulation parameters are uncorrelated with one another, correlation between the recovered parameters is an indication that the parameters in the model are trading off against one another ( Daw, 2011 ). Such trade-offs can sometimes be avoided by reparameterizing the model (e.g. Otto et al., 2013 ) or redesigning the experiment. Sometimes, however, such trade-offs are unavoidable. In these cases, it is crucial to report the trade-off in parameters so that a ‘correlation’ between fit parameter values is not over-interpreted in real data. A note about parameter differences between different populations or conditions: a growing use of model fitting is to compare parameter values between populations (e.g",
    "chunk_id": "Adv_cognitive_modelling_15747544008463_1..33.json_chunk_26"
  },
  {
    "document_type": "research_paper",
    "title": "Ten simple reules for the computational modeling of behavioral data",
    "author": "Robert C Wilson, Anne GE Collins",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Wilson-2019-Ten-simple-rules-for-the-computatio.pdf",
    "date_published": "2019-11-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". A note about parameter differences between different populations or conditions: a growing use of model fitting is to compare parameter values between populations (e.g. schizophrenia patients vs healthy controls [ Collins et al., 2014 ]) or conditions (e.g., transcranial magnetic stimulation to one area or another [ Zajkowski et al., 2017 ]). If your primary interest is a difference like this, then paraeter recovery can be used to give an estimate of statistical power. In particular, for a proposed effect size (e.g., on the average difference in one parameter between groups or conditions) you can simlate and recover parameters for the groups or conditions and then perform statistical tests to detect group differences in this simulated data set. The power for this effect size is then the frequency with which the statistical tests detect no effect given that the effect is there. Remember that even successful parameter recovery represents a bescase scenario! What does successful parameter recovery tell you? That data generated by a known model with given parameters can be fit to recover those parameters. This is the best case you could possibly hope for in the model-based analysis and it is unlikely to ever occur as the ‘true’ generative process for behavior — that is, the inner workings of the mind and brain — is likely much more complex than any model you could conceive. There’s no easy answer to this problem. We only advise that you remember to be humble when you present your results! Box 4. Example: parameter recovery in the reinforcement learning model. We performed parameter recovery with Model 3, the Rescorla Wagner model, on the twarmed bandit task. As before, we set the means of each bandit at 1 1⁄4 0 : 2 and 2 1⁄4 0 : 8 and the number of trials at T 1⁄4 1000",
    "chunk_id": "Adv_cognitive_modelling_15747544008463_1..33.json_chunk_27"
  },
  {
    "document_type": "research_paper",
    "title": "Ten simple reules for the computational modeling of behavioral data",
    "author": "Robert C Wilson, Anne GE Collins",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Wilson-2019-Ten-simple-rules-for-the-computatio.pdf",
    "date_published": "2019-11-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". As before, we set the means of each bandit at 1 1⁄4 0 : 2 and 2 1⁄4 0 : 8 and the number of trials at T 1⁄4 1000 . We then simulated the actions of the model according to Equtions 3 and 4 , with learning rate, a , and softmax temperature, b , set according to a ~ U ð 0 ; 1 Þ and b ~ Exp ð 10 Þ (9) After simulating the model, we fit the parameters using a maximum likelihood approach to get fit values of learning rate, a , and softmax parameter, b . We then repeated this process 1000 times using new values of a and b each time. The results are plotted in Box 4—figure 1 below. As is clear from this plot, there is fairly good agreement between the simulated and fit paramter values. In addition, we can see that the fit for b is best with a range, 1 < b < 10 , and that ouside this range, the correspondence between simulation and fit is not as good. If we further select points where parameter recovery for a is bad (i.e., when j a sim a fit j > 0 : 25 , grey dots in Box 4—figure 1 ), we find that parameter recovery for a is worse when b is outside of the range. Depending on the values of b that we obtain by fitting human behavior, this worse corrspondence at small and large b values may or may not be problematic. It may be a good idea Wilson and Collins. eLife 2019;8:e49547. DOI: https://doi.org/10.7554/eLife.49547 13 of 33 Review Article Neuroscience to use the range of parameters obtained from fitting the real data to test the quality of recovery within the range that matters. Box 4—figure 1. Parameter recovery for the Rescorla Wagner model (model 3) in the bandit task with 1000 trials. Grey dots in both panels correspond to points where parameter recovery for a is bad. Can you arbitrate between different models? In model comparison, our goal is to determine which model, out of a set of possible models, is most likely to have generated the data",
    "chunk_id": "Adv_cognitive_modelling_15747544008463_1..33.json_chunk_28"
  },
  {
    "document_type": "research_paper",
    "title": "Ten simple reules for the computational modeling of behavioral data",
    "author": "Robert C Wilson, Anne GE Collins",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Wilson-2019-Ten-simple-rules-for-the-computatio.pdf",
    "date_published": "2019-11-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Can you arbitrate between different models? In model comparison, our goal is to determine which model, out of a set of possible models, is most likely to have generated the data. There are a number of different ways to make this comparison (summarized in more detail in Appendix 2) that involve different approximations to the Bayesian evdence for each model (e.g., Daw, 2011 ; Rigoux et al., 2014 ). Here, we focus on the most common method which is related to the log-likelihood computed in ’Fit the parameters’. A simplistic approach to model comparison would be to compare the log-likelihoods of each model at the best fitting parameter settings, p ð d 1 : T j ^ m ; m Þ . However, if the data, d 1 : T , used to evaluate the log-likelihood are the same as those used to fit the parameters, then this approach will lead to overfitting, as the model with the most free parameters will almost always fit this ‘training’ data best. As an extreme example, consider the case of a model with one ‘parameter’ per choice, which is the identity of the choice the person actually made. Such a ‘model’ would fit the data perfectly, but would of course tell us nothing about how the choices were actually determined and would make no predictions about what choices would be made in a different setting. Overfitting is a problem in that it decreases the generalizability of the model: it makes it less likely that the conclsions drawn would apply to a different sample. One way to avoid overfitting is to perform cross-validation: by measuring fit on held-out data, we directly test generalizability. However, this is not always possible for practical reasons (number of samples) or more fundamental ones (dependence between data points). Thus, other methods mitgate the risk of overfitting by approximately accounting for the degrees of freedom in the model. There are several methods for doing this (including penalties for free parameters), which are dicussed in more detail in the Appendices",
    "chunk_id": "Adv_cognitive_modelling_15747544008463_1..33.json_chunk_29"
  },
  {
    "document_type": "research_paper",
    "title": "Ten simple reules for the computational modeling of behavioral data",
    "author": "Robert C Wilson, Anne GE Collins",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Wilson-2019-Ten-simple-rules-for-the-computatio.pdf",
    "date_published": "2019-11-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". There are several methods for doing this (including penalties for free parameters), which are dicussed in more detail in the Appendices. There is a rich theoretical literature debating which method is best ( Wagenmakers and Farrell, 2004 ; Vandekerckhove et al., 2015 ). Here, we do not position ourselves in this theoretical debate, and instead focus on one of the simplest methods, the Bayes Information Criterion, BIC , which has an explicit penalty for free parameters. BIC 1⁄4 2 log ^ LL þ k m log ð T Þ (10) where ^ LL is the log-likelihood value at the best fitting parameter settings, and k m is the number of parameters in model m . The model with the smallest BIC score is the model that best fits the data. Thus, the positive effect of k m in the last term corresponds to a penalty for models with large nubers of parameters. While Equation 10 is simple enough to apply in order to find the model that, apparently, best fits your data, it is important to check that your model comparison process gives sensible results for Wilson and Collins. eLife 2019;8:e49547. DOI: https://doi.org/10.7554/eLife.49547 14 of 33 Review Article Neuroscience simulated data. Just as parameter fitting should be validated by parameter recovery on simulated data, so model comparison should be validated by model recovery on simulated data. More specifically, model recovery involves simulating data from all models (with a range of parameter values carefully selected as in the case of parameter recovery) and then fitting that data with all models to determine the extent to which fake data generated from model A is best fit by model A as opposed to model B . This process can be summarized in a confusion matrix (see Box 5—figure 1 below for an example) that quantifies the probability that each model is the best fit to data generated from the other models, that is, p ð fit model 1⁄4 B j simulated model 1⁄4 A Þ . In a perfect world, the confusion matrix will be the identity matrix, but in practice, this is not always the case (e",
    "chunk_id": "Adv_cognitive_modelling_15747544008463_1..33.json_chunk_30"
  },
  {
    "document_type": "research_paper",
    "title": "Ten simple reules for the computational modeling of behavioral data",
    "author": "Robert C Wilson, Anne GE Collins",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Wilson-2019-Ten-simple-rules-for-the-computatio.pdf",
    "date_published": "2019-11-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". In a perfect world, the confusion matrix will be the identity matrix, but in practice, this is not always the case (e. g., Wilson and Niv, 2011 ). When computing and interpreting a confusion matrix it is important to keep the following points in mind: Compare different methods of model comparison If the confusion matrix has large off-diagonal components, then you have a problem with model recovery. There are a number of factors that could cause this problem, ranging from a bug in the code to an underpowered experimental design. However, one cause that is worth investigating is whether you are using the wrong method for penalizing free parameters. In particular, different measures penalize parameters in different ways that are ‘correct’ under different assumptions. If your confusion matrix is not diagonal, it may be that the assumptions underlying your measures (e.g. BIC) do not hold for your models, in which case it might be worth trying another metric for model comparison (e.g., AIC [ Wagenmakers and Farrell, 2004 ]; see Appendix 2). Be careful with the choice of parameters when computing the confusion matrix Just as parameter recovery may only be successful in certain parameter regimes, so too can model recovery depend critically on the parameters chosen to simulate the models. In some parameter regimes, two models may lead to very different behavior, but they may be indistinguishable in other parameter regimes (see Box 5—figure 1 below). As with parameter recovery, we believe that the best approach is to match the range of the parameters to the range seen in your data, or to the range that you expect from prior work. A note on interpreting the confusion matrix As described above, and in keeping with standard practice from statistics, the confusion matrix is defined as the probability that data simulated by one model is best fit by another, that is, p ð fit model j simulated model Þ",
    "chunk_id": "Adv_cognitive_modelling_15747544008463_1..33.json_chunk_31"
  },
  {
    "document_type": "research_paper",
    "title": "Ten simple reules for the computational modeling of behavioral data",
    "author": "Robert C Wilson, Anne GE Collins",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Wilson-2019-Ten-simple-rules-for-the-computatio.pdf",
    "date_published": "2019-11-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". However, when we fit a model to real data, we are usually more inteested in making the reverse inference — that is, given that model B fits our data best, which model is most likely to have generated the data? This is equivalent to computing p ð simulated model j fit model Þ . Note that this measure, which we term the ‘inversion matrix’ to distiguish it from the confusion matrix, is not the same as the confusion matrix unless model recovery is perfect. Of course, the inversion matrix can be computed from the confusion matrix using Bayes rule (see Appendix 3) and it may be useful to report it in cases where the confusion matrix is not diagonal. The elephant in the room with model comparison As wonderful as it is to find that your model ‘best’ fits the behavioral data, the elephant in the room (or perhaps more correctly not in the room) with all model comparison is that it only tells you which of the models you considered fits the data best. In and of itself, this is rather limited information as there are infinitely many other models that you did not consider. This makes it imperative to start with a good set of models that rigorously capture the competing hypotheses (that is, think hard in Step 2). In addition, it will be essential to validate (at least) your winning model (see Step 9) to show how simulating its behavior can generate the patterns seen in the data that you did not explicitly fit, and thus obtain an absolute measure of how well your model relates to your data. Wilson and Collins. eLife 2019;8:e49547. DOI: https://doi.org/10.7554/eLife.49547 15 of 33 Review Article Neuroscience Box 5. Example: confusion matrices in the bandit task. To illustrate model recovery, we simulated the behavior of the five models on the two-armed bandit task. As before, the means were set at 1 1⁄4 0 : 2 and 2 1⁄4 0 : 8 , and the number of trials was set at T 1⁄4 1000 . For each simulation, model parameters were sampled randomly for each model",
    "chunk_id": "Adv_cognitive_modelling_15747544008463_1..33.json_chunk_32"
  },
  {
    "document_type": "research_paper",
    "title": "Ten simple reules for the computational modeling of behavioral data",
    "author": "Robert C Wilson, Anne GE Collins",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Wilson-2019-Ten-simple-rules-for-the-computatio.pdf",
    "date_published": "2019-11-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". As before, the means were set at 1 1⁄4 0 : 2 and 2 1⁄4 0 : 8 , and the number of trials was set at T 1⁄4 1000 . For each simulation, model parameters were sampled randomly for each model. Each simulated data set was then fit to each of the given models to determine which model fit best (according to BIC). This process was repeated 100 times to compute the confsion matrices which are plotted below in Box 5—figure 1A and B . The difference between these two confusion matrices is in the priors from which the simulation parameters were sampled. In panel A, parameters were sampled from the following priors: Model Priors Model 1 b ~ U ð 0 ; 1 Þ Model 2 ~ U ð 0 ; 1 Þ Model 3 a ~ U ð 0 ; 1 Þ , b ~ Exp ð 1 Þ Model 4 a c ~ U ð 0 ; 1 Þ , b c ~ Exp ð 1 Þ Model 5 a ~ U ð 0 ; 1 Þ , b ~ Exp ð 1 Þ , a c ~ U ð 0 ; 1 Þ , b c ~ Exp ð 1 Þ In panel B, all of the softmax parameters b and b c were increased by 1. This has the effect of reducing the amount of noise in the behavior, which makes the models more easily identifiable and the corresponding confusion matrix more diagonal. The fact that the confusion matrix can be so dependent on the simulating parameter values means that it is crucial to match the simlation parameters to the actual fit parameters as best as possible. Models that are identifiable in one parameter regime may be impossible to distinguish in another! In addition to the confusion matrices, we also plot the inversion matrices in Box 5—figure 1C and D . These are computed from the confusion matrices using Bayes rule assuming a uniform prior on models (see Appendix 3). These matrices more directly address the question of how to interpret a model comparison result where one model fits a particular subject best",
    "chunk_id": "Adv_cognitive_modelling_15747544008463_1..33.json_chunk_33"
  },
  {
    "document_type": "research_paper",
    "title": "Ten simple reules for the computational modeling of behavioral data",
    "author": "Robert C Wilson, Anne GE Collins",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Wilson-2019-Ten-simple-rules-for-the-computatio.pdf",
    "date_published": "2019-11-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". These matrices more directly address the question of how to interpret a model comparison result where one model fits a particular subject best. 1 0 0 0 0 0.01 0.99 0 0 0 0.34 0.12 0.54 0 0 0.35 0.09 0 0.54 0.01 0.14 0.04 0.26 0.26 0.3 1 2 3 4 5 fit model 1 2 3 4 5 simulated model 0.97 0.03 0 0 0 0.04 0.96 0 0 0 0.06 0 0.94 0 0 0.06 0 0.01 0.93 0 0.03 0 0.1 0.15 0.72 1 2 3 4 5 fit model 1 2 3 4 5 simulated model 0.54 0 0 0 0 0.01 0.8 0 0 0 0.18 0.1 0.68 0 0 0.19 0.07 0 0.68 0.03 0.08 0.03 0.33 0.33 0.97 1 2 3 4 5 fit model 1 2 3 4 5 simulated model 0.84 0.03 0 0 0 0.03 0.97 0 0 0 0.05 0 0.9 0 0 0.05 0 0.01 0.86 0 0.03 0 0.1 0.14 1 1 2 3 4 5 fit model 1 2 3 4 5 simulated model confusion matrix: p(fit model | simulated model) inversion matrix: p(simulated model | fit model) A B C D Wilson and Collins. eLife 2019;8:e49547. DOI: https://doi.org/10.7554/eLife.49547 16 of 33 Review Article Neuroscience Box 5—figure 1. Confusion matrices in the bandit task showing the effect of prior parameter distributions on model recovery. Numbers denote the probability that data generated with model X are best fit by model Y, thus the confusion matrix represents p ð fit model j simulated model Þ . ( A ) When there are relatively large amounts of noise in the models (possibility of small values for b and b c ), models 3–5 are hard to distinguish from one another. ( B ) When there is less noise in the models (i.e. minimum value of b and b c is 1), the models are much easier to identify. ( C ) The inversion matrix provides easier interpretation of fitting results when the true model is unknown. For example, the confusion matrix indicates that M1 is always perfectly recovered, while M5 is only recovered 30% of the time. By contrast, the inversion matrix shows that if M1 is the best fiting model, our confidence that it generated the data is low (54%), but if M5 is the best fitting model, our confidence that it did generate the data is high (97%). ( D ) Similar results with less noise in simulations",
    "chunk_id": "Adv_cognitive_modelling_15747544008463_1..33.json_chunk_34"
  },
  {
    "document_type": "research_paper",
    "title": "Ten simple reules for the computational modeling of behavioral data",
    "author": "Robert C Wilson, Anne GE Collins",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Wilson-2019-Ten-simple-rules-for-the-computatio.pdf",
    "date_published": "2019-11-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". ( D ) Similar results with less noise in simulations. Run the experiment and analyze the actual data Once all the previous steps have been completed, you can finally move on to modeling your empircal data. The first step to complete is of course to analyze the data without the model, in the same way that we recommended for model simulations in section ’Simulate, simulate, simulate!’ This model-independent analysis is extremely important: you designed the experiment to test specific hypotheses, and constructed models to reflect them. Simulations showed expected patterns of behaviors given those hypotheses. If the model-independent analyses do not show evidence of the expected results, there is almost no point in fitting the model. Instead, you should go back to the beginning, either re-thinking the computational models if the analyses show interesting patterns of behavior, or re-thinking the experimental design or even the scientific question you are trying to answer. In our experience, if there is no model-independent evidence that the processes of interest are engaged, then a model-based analysis is unlikely to uncover evidence for the processes either. If, however, the behavioral results are promising, the next step is to fit the models developed prviously and to perform model comparison. After this step, you should check that the parameter range obtained with the fitting is within a range where parameter and model recovery were good. If the range is outside what you explored with simulations, you should go back over the parameter and model recovery steps to match the empirical parameter range, and thus ensure that the model fitting and model comparison procedures lead to interpretable results. An important point to remember is that human behavior is always messier than the model, and it is unlikely that the class of models you explored actually contains the ‘real’ model thatgenerated human behavior",
    "chunk_id": "Adv_cognitive_modelling_15747544008463_1..33.json_chunk_35"
  },
  {
    "document_type": "research_paper",
    "title": "Ten simple reules for the computational modeling of behavioral data",
    "author": "Robert C Wilson, Anne GE Collins",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Wilson-2019-Ten-simple-rules-for-the-computatio.pdf",
    "date_published": "2019-11-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". At this point, you should consider looping back to Steps 2–5 to improve the models, guided by in depth model-independent analysis of the data. For example, you may consider modeling ‘unimportant parameters’, representing mechanisms that are of no interest to your scientific question but that might still affect your measures. Modeling these unimportant parameters usually captures variance in the behavior that would otherwise be attributed to noise, and as such, makes for a better estimation of ‘important’ parameters. For exaple, capturing pre-existing biases (e.g. a preference for left/right choices) in a decision or learning task provides better estimation of the inverse temperature, by avoiding attributing systematic biases to noise, which then affords better estimation of other parameters like the learning rate (this is evdent in Box 6—figure 1 ). Box 6. Example: improving parameter recovery by modeling unimportant parameters. To illustrate the effect that ‘unimportant’ parameters (i.e., parameters that represent mechnisms that are of no interest to your scientific question, but may still affect your measures) can have on fitting results, we model the effect of a side bias on parameter recovery in Model 3. In particular, we assume that, in addition to choosing based on learned value, the model also had a side bias, B , that effectively changes the value of the left bandit. That is, in the two-bandit case, the choice probabilities are given by Wilson and Collins. eLife 2019;8:e49547. DOI: https://doi.org/10.7554/eLife.49547 17 of 33 Review Article Neuroscience p left t 1⁄4 1 1 þ exp b ð Q right t Q left t B Þ (11) We then simulated behavior with this model for a range of parameter values and fit the model with the original version of model 3, without the bias, and the modified version of model 3, with the bias. In this simulation, agents learn for 10 independent two-armed bandits in succesive 50-trial blocks, with 1⁄4 f 0 : 2 ; 0 : 8 g or 1⁄4 f 0 : 8 ; 0 : 2 g in different blocks",
    "chunk_id": "Adv_cognitive_modelling_15747544008463_1..33.json_chunk_36"
  },
  {
    "document_type": "research_paper",
    "title": "Ten simple reules for the computational modeling of behavioral data",
    "author": "Robert C Wilson, Anne GE Collins",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Wilson-2019-Ten-simple-rules-for-the-computatio.pdf",
    "date_published": "2019-11-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". In this simulation, agents learn for 10 independent two-armed bandits in succesive 50-trial blocks, with 1⁄4 f 0 : 2 ; 0 : 8 g or 1⁄4 f 0 : 8 ; 0 : 2 g in different blocks. For simplicity, we assumed that the agent treats each block as independent, and started from the same initial vaues of Q right 1 1⁄4 Q left 1 1⁄4 0 : 5 . As can be seen below, including the ‘unimportant’ bias in the fit greatly improves the extent to which both the learning rate, a , and softmax parameter, b , can be recovered. 0 0.2 0.4 0.6 simulated α 0 0.5 1 fit α 0 5 10 simulated β 0 5 10 fit β 0 0.2 0.4 0.6 simulated α 0 0.5 1 fit α 0 5 10 simulated β 0 5 10 fit β 0 0.1 0.2 simulated bias 0 0.1 0.2 0.3 fit bias model 3 without bias model 3 including bias Box 6—figure 1. Modeling unimportant parameters provides better estimation of important parameters. The top row shows parameter recovery of the model without the bias term. The bottom row shows much more accurate parameter recovery, for all parameters, when the bias parameter is included in the model fits. Validate (at least) the winning model All the previous steps measure a relative goodness of fit. Does model A fit better than model B? However, before interpreting any results from a model, it is essential to ensure that the model actally usefully captures the data in an absolute sense. This step is called model validation, and should never be skipped: it is possible to fit a model, get high fit measures, and nevertheless completely miss the essence of the behavior. One method for model validation is computing the average trial likelihood as an absolute mesure of fit. Although this measure has some nice properties — for example, the best possible value is one when the model predicts behavior perfectly — it offers limited value when choices are actually stochastic (which may be the case in many situations; Drugowitsch et al., 2016 ) or the environment is complex",
    "chunk_id": "Adv_cognitive_modelling_15747544008463_1..33.json_chunk_37"
  },
  {
    "document_type": "research_paper",
    "title": "Ten simple reules for the computational modeling of behavioral data",
    "author": "Robert C Wilson, Anne GE Collins",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Wilson-2019-Ten-simple-rules-for-the-computatio.pdf",
    "date_published": "2019-11-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". In these cases, the best possible likelihood per trial is less than 1, but it is not known what the best possible likelihood per trial could be. For this reason, although the likelihood per trial can be a useful tool for model validation ( Leong et al., 2017 ), interpreting it as an absolute measure of model fit is of limited value. A better method to validate a model is to simulate it with the fit parameter values ( Palminteri et al., 2017 ; Nassar and Frank, 2016 ; Navarro, 2019 ), a procedure long performed by statisticians as part of the ‘posterior predictive check’ ( Roecker, 1991 ; Gelman et al., 1996 ). You should then analyze the simulated data in the same way that you analyzed the empirical data, to veify that all important behavioral effects are qualitatively and quantitatively captured by the Wilson and Collins. eLife 2019;8:e49547. DOI: https://doi.org/10.7554/eLife.49547 18 of 33 Review Article Neuroscience simulations with the fit parameters. For example, if you observe a qualitative difference between two conditions empirically, the model should reproduce it. Likewise, if a learning curve reaches a quantitative asymptote of 0.7, simulations shouldn’t reach a vastly different one. Some researchers analyze the posterior prediction of the model conditioned on the past history, instead of simulated data. In our previous notation, they evaluate the likelihood of choice c t given past data, d 1 : t 1 , where the past data includes choices made by the subject, not choices made by the model, p ð c t j d 1 : t 1 ; s t ; m ; m Þ . In some cases, this approach leads to very similar results to simulations, because simulations sample choices on the basis of a very similar probability, where the past data, d 1 : t 1 , include choices made by the model . However, it can also be dramatically different if the path of actions sampled by the participant is widely different from the paths likely to be selected by the model (leading to very different past histories)",
    "chunk_id": "Adv_cognitive_modelling_15747544008463_1..33.json_chunk_38"
  },
  {
    "document_type": "research_paper",
    "title": "Ten simple reules for the computational modeling of behavioral data",
    "author": "Robert C Wilson, Anne GE Collins",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Wilson-2019-Ten-simple-rules-for-the-computatio.pdf",
    "date_published": "2019-11-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Palminteri and colleagues ( Palminteri et al., 2017 ) offer a striking example of this effect, where Model A fits better than Model B by any quantitative measure of model comparison, but is completely unable to capture the essence of the behavior. In their example, data are generated with a reinforcement learning agent (which takes the place of the subject) on a reversal learning task (where a choice that was previously good becomes bad, and reciprocally). These data are then fit with either a win-stay lose-shift model (model B), or a simplistic choice kernel model, which assumes that previous choices tend to be repeated (model A). Because of the autocorrelation in the choices made by the reinforcement learning agent, model A, which tends to repeat previous actions, fits better than model B, whose win-stay-lose-shift choices only depend on the action and outcome from the last trial. However, model A is completely insensitive to reward, and thus is unable to generate a reversal behavior when it is simulated with the fit model parameters. Thus, in this case, model A should be discarded, despite a greater quantitative fit. Nevertheless, the fact that the best validating model B captures less variance than model A should serve as a warning that model B is missing crcial components of the data and that a better model probably exists. This should incite the researcher to go back to the drawing board to develop a better model, for example one that cobines elements of both models or a different model entirely, and perhaps a better experiment to test it. More generally, if your validation step fails, you should go back to the drawing board! This may involve looking for a better model, as well as redesigning the task. Be careful interpreting results from a model that is not well validated! Of course, exactly what it means for a model to ‘fail’ the valdation step is not well defined: no model is perfect, and there is no rule of thumb to tell us when a model is good enough",
    "chunk_id": "Adv_cognitive_modelling_15747544008463_1..33.json_chunk_39"
  },
  {
    "document_type": "research_paper",
    "title": "Ten simple reules for the computational modeling of behavioral data",
    "author": "Robert C Wilson, Anne GE Collins",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Wilson-2019-Ten-simple-rules-for-the-computatio.pdf",
    "date_published": "2019-11-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". The most important aspect of validation is for you (and your readers) to be aware of its limitations, and in which ways they may influence any downstream results. Box 7. Example: model validation where the fit model performs too well. Most examples of model validation involve a case where a model that fits well performs poorly on the task in simulation. For example, in the Palminteri et al. (2017) example, the choice kenel model cannot perform the task at all because its behavior is completely independent of reward. Here, we offer a different example of failed model validation in which the model peforms better in simulation than the predicted and observed artificial agent’s behavior. Morover, this model appears to fit data generated from a different model better than it fits data generated from itself! In this example, we imagine a deterministic stimulus-action learning task in which agents are presented with one of three stimuli ( s 1 , s 2 , and s 3 ), which instruct them which of three actions ( a 1 , a 2 , and a 3 ) will be rewarded when chosen. a 1 is the correct choice for both stimuli s 1 and s 2 , a 3 for s 3 , and a 2 is incorrect for all stimuli. The two models that we consider are both reinforcement learning agents. The first, a ‘blind’ agent does not see the stimulus at all and learns only about the value of the three different actions, that is Q ð a i Þ , regardless of the stimulus. The second, a ‘state-based’ agent, observes the stimulus and learns a value for each action that can be different for each stimulus, that is Q ð a i ; s i Þ . Parameters in the models are set such that the learning curves for the two agents are approximately equal ( Box 7—figure 1A ). See appendices for details of the models. Wilson and Collins. eLife 2019;8:e49547. DOI: https://doi.org/10.7554/eLife.49547 19 of 33 Review Article Neuroscience We then consider how both models fit behavior simulated by either of these models",
    "chunk_id": "Adv_cognitive_modelling_15747544008463_1..33.json_chunk_40"
  },
  {
    "document_type": "research_paper",
    "title": "Ten simple reules for the computational modeling of behavioral data",
    "author": "Robert C Wilson, Anne GE Collins",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Wilson-2019-Ten-simple-rules-for-the-computatio.pdf",
    "date_published": "2019-11-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". eLife 2019;8:e49547. DOI: https://doi.org/10.7554/eLife.49547 19 of 33 Review Article Neuroscience We then consider how both models fit behavior simulated by either of these models. In Box 7—figure 1B , we plot the average likelihood with which the state-based model predicts the actual choices of the blind and state-based agents, that is the average p ð c t j d 1 : t 1 ; m ; m 1⁄4 state-based Þ . As is clear from this figure, the state-based model predicts choices from the blind agent with higher likelihood than choices from the state-based agent! While counter intuitive, this result does not imply that the state-based model is unable to fit its own behavior. Instead, this result reflects the difference in noise (softmax parameters) between the two agents. The blind RL agent has a low noise parameter, allowing the state-based model to fit it quite well. Conversely, the state-based RL agent has a high noise parameter, meaning that the behavior is harder to predict even when it is fit with the correct model. That the state-based model captures state-based behavior better than it fits blind behavior is illustrated in Box 7—figure 1C . Here, we plot the simulated learning curves of the state-based model using the parameter values that were fit to either the state-based agent or the blind agent. Although the parameters of the state-based model obtained through the fit to the statbased agent generate a learning curve that is quite similar to that of the agent (compare blue lines in Box 7—figure 1A and C ), the state-based fit to the blind agent performs too well (copare yellow lines in Box 7—figure 1A and C ). Thus the model validation step provides support for the state-based model when it is the corect model of behavior, but rules out the state-based model when the generating model was different. The take-away from this example should be that measures of model-fit and model comparison cannot replace a thorough validation step, which can contradict them",
    "chunk_id": "Adv_cognitive_modelling_15747544008463_1..33.json_chunk_41"
  },
  {
    "document_type": "research_paper",
    "title": "Ten simple reules for the computational modeling of behavioral data",
    "author": "Robert C Wilson, Anne GE Collins",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Wilson-2019-Ten-simple-rules-for-the-computatio.pdf",
    "date_published": "2019-11-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". The take-away from this example should be that measures of model-fit and model comparison cannot replace a thorough validation step, which can contradict them. 1 5 10 15 time step 0.2 0.4 0.6 0.8 1 p(correct) 'subject' learning curves blind RL state-based RL 1 5 10 15 time step 0.2 0.4 0.6 0.8 1 likelihood of choice likelihood of state-based RL model 1 5 10 15 time step 0.2 0.4 0.6 0.8 1 p(correct) simulated learning curves from state-based RL A B C Box 7—figure 1. An example of successful and unsuccessful model validation. ( A ) Behavior is simulated by one of two reinforcement learning models (a blind agent and a state-based agent) performing the same learning task. Generative parameters of the two models were set so that the learning curves of the models were approximately equal. ( B ) Likelihood per trial seems to indicate a worse fit for the state-based-simulated data than the blind-simulated data. ( C ) However, validation by model simulations with fit parameters shows that the state-based model captures the data from the state-based agent (compare dark learning curves in panels A and C), but not from the the blind agent (yellow learning curves in panels A and C). Analyze the winning model To minimize risks of p-hacking, model-dependent analyses should only be performed on the winning model, after researchers are satisfied that the model captures the behavior. One particularly poweful application of model-based analysis of behavior involves estimating the latent variables in the model. Latent variables are the hidden components of the algorithms underlying the behavior that are not directly observable from the behavior itself. These latent variables shed light on the internal workings of the model and, if we are to take the model seriously, should have some representation in the subjects’ mind and brain ( Cohen et al., 2017 ; O’Doherty et al., 2007 ). Extracting latent variables from the model is as simple as simulating the model and recording how the latent variables evolve over time",
    "chunk_id": "Adv_cognitive_modelling_15747544008463_1..33.json_chunk_42"
  },
  {
    "document_type": "research_paper",
    "title": "Ten simple reules for the computational modeling of behavioral data",
    "author": "Robert C Wilson, Anne GE Collins",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Wilson-2019-Ten-simple-rules-for-the-computatio.pdf",
    "date_published": "2019-11-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Extracting latent variables from the model is as simple as simulating the model and recording how the latent variables evolve over time. The parameters of the simulation should be the fit paraeters for each subject. In most cases, it is useful to yoke the choices of the model to the choices the Wilson and Collins. eLife 2019;8:e49547. DOI: https://doi.org/10.7554/eLife.49547 20 of 33 Review Article Neuroscience participants actually made, thus the latent variables evolve according to the experience participants actually had. This is especially true if the choices can influence what participants see in the future. Once estimated, the latent variables can be used in much the same way as any other observable variable in the analysis of data. Perhaps the most powerful application comes when combined with physiological data such as pupil dilation, EEG, and fMRI. The simplest of these approaches uses liear regression to test whether physiological variables correlate with the latent variables of interest. Such an approach has led to a number of insights into the neural mechanisms underlying behavior ( Nassar et al., 2012 ; Daw et al., 2011 ; Donoso et al., 2014 ; Collins and Frank, 2018 ; Fischer and Ullsperger, 2013 ), although, as with any modeling exercise, latent variable analysis should be done with care ( Wilson and Niv, 2015 ). Other model-dependent analyzes include studying individual differences as captured by fit parameters. Fit parameters can be treated as a dependent variable in continuous analyses (e.g. corelating with age, symptom scales, and so on [ Gillan et al., 2016 ]) or group comparisons (e.g. patients vs. matched controls [ Collins et al., 2014 ]). Reporting model-based analyses Congratulations! You have developed, simulated, and fit your model (and maybe several other copeting models) to your data. You have estimated parameters, computed model comparison scores, and validated whether your model can generate realistic-looking behavior",
    "chunk_id": "Adv_cognitive_modelling_15747544008463_1..33.json_chunk_43"
  },
  {
    "document_type": "research_paper",
    "title": "Ten simple reules for the computational modeling of behavioral data",
    "author": "Robert C Wilson, Anne GE Collins",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Wilson-2019-Ten-simple-rules-for-the-computatio.pdf",
    "date_published": "2019-11-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". You have estimated parameters, computed model comparison scores, and validated whether your model can generate realistic-looking behavior. It’s time to start writing! But what exactly should you report in your paper? And how should you report it? Model selection In many modeling papers, a key conclusion from the work is that one model fits the data better than other competing models. To make this point convincingly, we recommend including the following things in your paper, either as main results or in the supplementary material. Model recovery analysis Confusion matrix Before anyone should believe your model comparison results, you need to demonstrate the ability of your analysis/experiment to distinguish between models under ideal conditions of simulated data. The best way to visualize these results is with a confusion matrix, as outlined in section ’Can you arbtrate between different models’? If the model comparison result is central to your paper, we recomend including the confusion matrix as a figure in the main text. If model comparison is less important, we recommend including it in the supplementary materials. Number of subjects best fit by each model The simplest way to visualize how well the winning model fits the data is with a histogram showing the number of subjects best fit by each model. Obviously if all subjects are best fit with one model, the story is simple. The more likely scenario is that some subjects will be best fit by other models. Such a result is important to acknowledge in the paper as it may reflect the use of different stratgies by different people or that the ‘correct’ model lies somewhere in between the models you have considered. Group level statistics Exceedance probabilities A more sophisticated and less biased ( Piray et al., 2018 ) way to report model comparison results is by computing the probability that a single model best describes all the data. This is clearly an assumption whose merits should be discussed in your paper",
    "chunk_id": "Adv_cognitive_modelling_15747544008463_1..33.json_chunk_44"
  },
  {
    "document_type": "research_paper",
    "title": "Ten simple reules for the computational modeling of behavioral data",
    "author": "Robert C Wilson, Anne GE Collins",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Wilson-2019-Ten-simple-rules-for-the-computatio.pdf",
    "date_published": "2019-11-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". This is clearly an assumption whose merits should be discussed in your paper. In cases where it is valid, the method of Rigoux et al. (2014) computes these ‘Exceedance Probabilities’, the probability that each model generated all the data. These probabilities can also be reported in histogram or table form. Model-independent measures of simulated data. The cleanest way to demonstrate the superiority of one model is if that model can account for qualitative patterns in the data that are not captured by other models (see section ’Validate (at least) the winning model’). Wilson and Collins. eLife 2019;8:e49547. DOI: https://doi.org/10.7554/eLife.49547 21 of 33 Review Article Neuroscience Parameter fits Many modeling papers involve fitting parameters to behavioral data. In some cases this is the main point of the paper, for example to show that parameter values differ between groups or treatments, in other cases parameter fitting is secondary to model comparison. In all cases, we recommend reporting the fit parameter values in as transparent a way as possible (i.e. more than just the means and standard errors). Report distributions of parameter values The simplest way to report parameter fits is to plot a distribution of all fit parameter values, for example in the form of a histogram (e.g. Figure S1 in Wilson et al., 2013 and Nassar et al., 2018 ) or a cloud of points (e.g. Figure 5 in Huys et al., 2011 ). This gives a great sense of the variability in each parameter across the population and can also illustrate problems with fitting. For example, if a large number of fit parameters are clustered around the upper and lower bounds, this may indicate a problem with the model. Plot pairwise correlations between fit parameter values A deeper understanding of the relationships between fit parameters can be obtained by making scatter plots of the pairwise correlations between parameters",
    "chunk_id": "Adv_cognitive_modelling_15747544008463_1..33.json_chunk_45"
  },
  {
    "document_type": "research_paper",
    "title": "Ten simple reules for the computational modeling of behavioral data",
    "author": "Robert C Wilson, Anne GE Collins",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Wilson-2019-Ten-simple-rules-for-the-computatio.pdf",
    "date_published": "2019-11-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". As with histograms of individual parameters, this approach gives a sense of the distribution of parameters, and can provide evidence of problems with the model; for example, if two parameters trade off against one another, it is a sign that these parameters may be unidentifiable in the experiment. Report parameter recovery Finally, all parameter fit analyses should sit on the shoulders of a comprehensive parameter recovery analysis with simulated data. If parameters cannot be recovered in the ideal case of simulated data, there is little that they can tell us about real behavior. Share your data and code! The most direct way to communicate your results is to share the data and code. This approach encourages transparency and ensures that others can see exactly what you did. Sharing data and code also allows others to extend your analyses easily, by applying it to their own data or adding new models into the mix. Ideally the data you share should be the raw data for the experiment, with minimal or no preprcessing (apart from the removal of identifying information). The code you share should reproduce all steps in your analysis, including any preprocessing/outlier exclusion you may have performed and generating all of the main and supplementary figures in the paper. In a perfect world, both data and code would be shared publicly on sites such as GitHub, DataVerse and so on. However, this is not always possible, for example, if the data come from collaborators who do not agree to data sharing, or if further analyses are planned using the same data set. In this case, we recommend having a clean set of ‘shareable’ code (and hopefully data too) that can be sent via email upon request. Should you always report all of your modeling results? Finally, if you are using an established model, it can be tempting to skip many of the steps outlined above and report only the most exciting results. This temptation can be even greater if you are using code developed by someone else that, perhaps, you do not fully understand",
    "chunk_id": "Adv_cognitive_modelling_15747544008463_1..33.json_chunk_46"
  },
  {
    "document_type": "research_paper",
    "title": "Ten simple reules for the computational modeling of behavioral data",
    "author": "Robert C Wilson, Anne GE Collins",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Wilson-2019-Ten-simple-rules-for-the-computatio.pdf",
    "date_published": "2019-11-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". This temptation can be even greater if you are using code developed by someone else that, perhaps, you do not fully understand. In our opinion, taking shortcuts like this is dangerous. For one thing, your experiment or population may be different and the model may perform differently in this regime. For another, quite often ‘established’ models (in the sense that they have been published before), have not been validated in a systematic way. More generally, as with any research technique, when using computational modeling you need to demostrate that you are applying the method correctly, and the that steps we outline here can help. In conclusion, even if developing the model is not the central point of your paper, you should report all of your modeling results. Wilson and Collins. eLife 2019;8:e49547. DOI: https://doi.org/10.7554/eLife.49547 22 of 33 Review Article Neuroscience What now? Looping back A modeler’s work is never done. To paraphrase George Box, there are no correct models, there are only useful models ( Box, 1979 ). To make your model more useful, there are a number of next steps to consider to test whether your model really does describe a process in the mind. Improve the model to account for discrepancies with your existing data set Model fits are never perfect and, even in the best cases, there are often small discrepancies with actual data. The simplest next step is to try to address these discrepancies by improving the model, either by including additional factors (such as side bias or lapse rates) or by devising new models entirely. Use your model to make predictions The best models don’t just explain data in one experiment, they predict data in completely new siuations. If your model does not easily generalize to new situations, try to understand why that is and how it could be adjusted to be more general",
    "chunk_id": "Adv_cognitive_modelling_15747544008463_1..33.json_chunk_47"
  },
  {
    "document_type": "research_paper",
    "title": "Ten simple reules for the computational modeling of behavioral data",
    "author": "Robert C Wilson, Anne GE Collins",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Wilson-2019-Ten-simple-rules-for-the-computatio.pdf",
    "date_published": "2019-11-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". If your model does not easily generalize to new situations, try to understand why that is and how it could be adjusted to be more general. If your model does generalize, test its predictions against new data — either data you collect yourself from a new experiment or data from other stuies that (hopefully) have been shared online. Using advanced techniques Another potential next step is to use more powerful modeling techniques. We focused here on the simplest techniques (maximum likelihood estimation and model comparison by BIC) because of their accessibility to beginners, and because most of the advice we give here generalizes to more advanced techniques. In particular, no matter how advanced the modeling technique used, validtion is essential ( Palminteri et al., 2017 ; Nassar and Frank, 2016 ; Huys, 2017 ). Nevertheless, the simple methods described here have known limitations. More advanced techniques attempt to reedy them, but come with their own pitfalls. A complete review of these advanced techniques is beyond the scope of this paper; instead we provide pointers to a few of the most interesting technques for the ambitious reader to pursue. Compute maximum a posteriori (MAP) parameter values Perhaps the simplest step for improving parameter estimates is to include prior information about parameter values. When combined with the likelihood, these priors allow us to compute the postrior, which we can use to find the maximum a posteriori (MAP) parameter values. Although they are still point estimates, with good priors, MAP parameters can be more accurate than parameters estmated with maximum likelihood approaches ( Gershman, 2016 ; Daw, 2011 ), although when the prors are bad, this method has problems of its own ( Katahira, 2016 ). Approximate the full posterior by sampling Point estimates of model parameters, such as those obtained with MLE or MAP, lose interesting information about uncertainty over the parameter distribution",
    "chunk_id": "Adv_cognitive_modelling_15747544008463_1..33.json_chunk_48"
  },
  {
    "document_type": "research_paper",
    "title": "Ten simple reules for the computational modeling of behavioral data",
    "author": "Robert C Wilson, Anne GE Collins",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Wilson-2019-Ten-simple-rules-for-the-computatio.pdf",
    "date_published": "2019-11-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Approximate the full posterior by sampling Point estimates of model parameters, such as those obtained with MLE or MAP, lose interesting information about uncertainty over the parameter distribution. Sampling approaches (such as Makov Chain Monte Carlo or MCMC) provide this richer information; furthermore, they allow modelers to investigate more complex assumptions. For example, hierarchical Bayesian approaches make it possible to fit all participants simultaneously, integrating assumptions about their depedence (e.g. one single group, multiple groups, effects of covariates of interest such as age and so on; Lee, 2011 ; Lee and Wagenmakers, 2014 ; Wiecki et al., 2013 ). Advanced optimizers and approximate likelihood Some models have intractable likelihoods, for example if the choice state has too many dimensions, as in continuous movements, or if the model included unobservable choices. There exist methods to approximate likelihoods to relate them quantitatively to data, such as the ABC method ( Turner and Sederberg, 2012 ; Sunna ̊ker et al., 2013 ). There are also advanced methods for finding best fit parameters in a sample-efficient manner when computing the likelihood is expensive ( Acerbi and Ji, 2017 ; Acerbi, 2018 ). Wilson and Collins. eLife 2019;8:e49547. DOI: https://doi.org/10.7554/eLife.49547 23 of 33 Review Article Neuroscience Model selection Bayesian model selection provides less biased, statistically more accurate ways of identifying which model is best at the group level ( Rigoux et al., 2014 ). This may be particularly important when coparing model selection between groups, for example between patients and controls ( Piray et al., 2018 ). Incorporating other types of data We focused on modeling a single type of observable data, choices. However, there is a rich literture on fitting models to other measurements, such as reaction times ( Ratcliff, 1978 ; Ratcliff and Rouder, 1998 ), but also to eye movements and neural data ( Turner et al., 2016 )",
    "chunk_id": "Adv_cognitive_modelling_15747544008463_1..33.json_chunk_49"
  },
  {
    "document_type": "research_paper",
    "title": "Ten simple reules for the computational modeling of behavioral data",
    "author": "Robert C Wilson, Anne GE Collins",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Wilson-2019-Ten-simple-rules-for-the-computatio.pdf",
    "date_published": "2019-11-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Furthermore, fiting more than one measurement at a time provides additional constraints to the model, and as such may provide better fit ( Ballard and McClure, 2019 ). However, fitting additional data can increase the complexity of the model-fitting process and additional care must be taken to determine exactly how different types of data should be combined ( Viejo et al., 2015 ). Epilogue Our goal for this paper was to offer practical advice, for beginners as well as seasoned researchers, on the computational modeling of behavioral data. To this end, we offered guidance on how to geerate models, simulate models, fit models, compare models, validate models, and extract latent varables from models to compare with physiological data. We have talked about how to avoid common pitfalls and misinterpretations that can arise with computational modeling, and lingered, quite delierately, on the importance of good experimental design. Many of these lessons were lessons we learned the hard way, by actually making these mistakes for ourselves over a combined 20+ years in the field. By following these steps, we hope that you will avoid some of the errors that slowed our own research, and that the overall quality of computational modeling in behavioral science will improve. Acknowledgements We are grateful to all our lab members who provided feedback on this paper, in particular Beth Barbault, Waitsang Keung, Sarah Master, Sam McDougle, and William Ryan. We are grateful for useful reviewers’ and editors’ feedback, including that from Tim Behrens, Mehdi Khamassi, Ken Norman, Valentin Wyart, and other anonymous reviewers. We also gratefully acknowledge the contribution of many others in our previous labs and collaborations, with whom we learned many of the techniques, tips and tricks presented here. This work was supported by NIA Grant R56 AG061888 to RCW and NSF Grant 1640885 and NIH Grant R01 MH118279 to AGEC",
    "chunk_id": "Adv_cognitive_modelling_15747544008463_1..33.json_chunk_50"
  },
  {
    "document_type": "research_paper",
    "title": "Ten simple reules for the computational modeling of behavioral data",
    "author": "Robert C Wilson, Anne GE Collins",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Wilson-2019-Ten-simple-rules-for-the-computatio.pdf",
    "date_published": "2019-11-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". This work was supported by NIA Grant R56 AG061888 to RCW and NSF Grant 1640885 and NIH Grant R01 MH118279 to AGEC. Additional information Funding Funder Grant reference number Author National Institute on Aging R56 AG061888 Robert C Wilson National Science Foundation 1640885 Anne GE Collins National Institute of Mental Health R01 MH118279 Anne GE Collins The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication. Author ORCIDs Robert C Wilson https://orcid.org/0000-0002-2963-2971 Anne GE Collins https://orcid.org/0000-0003-3751-3662 Wilson and Collins. eLife 2019;8:e49547. DOI: https://doi.org/10.7554/eLife.49547 24 of 33 Review Article Neuroscience References Abbott JT , Austerweil JL, Griffiths TL. 2015. Random walks on semantic networks can resemble optimal foraging. Psychological Review 122 :558–569. DOI: https://doi.org/10.1037/a0038693 , PMID: 25642588 Acerbi L . 2018. Variational bayesian monte carlo. Advances in Neural Information Processing Systems 8213– 8223. https://papers.nips.cc/paper/8043-variational-bayesian-monte-carlo . Acerbi L , Ji W. 2017. Practical bayesian optimization for model fitting with bayesian adaptive direct search. Advances in Neural Information Processing Systems 1836–1846. https://papers.nips.cc/paper/6780-practicabayesian-optimization-for-model-fitting-with-bayesian-adaptive-direct-search . Akaike H . 1974. A new look at the statistical model identification. IEEE Transactions on Automatic Control 19 : 716–723. DOI: https://doi.org/10.1109/TAC.1974.1100705 Ballard IC , McClure SM. 2019. Joint modeling of reaction times and choice improves parameter identifiability in reinforcement learning models. Journal of Neuroscience Methods 317 :37–44. DOI: https://doi.org/10.1016/j. jneumeth.2019.01.006 , PMID: 30664916 Batchelder WH , Riefer DM. 1990. Multinomial processing models of source monitoring. Psychological Review 97 :548–564. DOI: https://doi.org/10.1037/0033-295X.97.4.548 Box GE . 1979",
    "chunk_id": "Adv_cognitive_modelling_15747544008463_1..33.json_chunk_51"
  },
  {
    "document_type": "research_paper",
    "title": "Ten simple reules for the computational modeling of behavioral data",
    "author": "Robert C Wilson, Anne GE Collins",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Wilson-2019-Ten-simple-rules-for-the-computatio.pdf",
    "date_published": "2019-11-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". 1990. Multinomial processing models of source monitoring. Psychological Review 97 :548–564. DOI: https://doi.org/10.1037/0033-295X.97.4.548 Box GE . 1979. Robustness in the strategy of scientific model building. In: Robustness in Statistics . Elsevier. p. 201–236. DOI: https://doi.org/10.1016/b978-0-12-438150-6.50018-2 Breiman L . 2001. Statistical modeling: the two cultures (with comments and a rejoinder by the author). Statistical Science 16 :199–231. DOI: https://doi.org/10.1214/ss/1009213726 Broomell SB , Bhatia S. 2014. Parameter recovery for decision modeling using choice data. Decision 1 :252–274. DOI: https://doi.org/10.1037/dec0000020 Busemeyer JR , Diederich A. 2010. Cognitive Modeling . Sage. Byrd RH , Gilbert JC, Nocedal J. 2000. A trust region method based on interior point techniques for nonlinear programming. Mathematical Programming 89 :149–185. DOI: https://doi.org/10.1007/PL00011391 Cavanagh JF , Wiecki TV, Kochar A, Frank MJ. 2014. Eye tracking and pupillometry are indicators of dissociable latent decision processes. Journal of Experimental Psychology: General 143 :1476–1488. DOI: https://doi.org/ 10.1037/a0035813 Cohen JD , Dunbar K, McClelland JL. 1990. On the control of automatic processes: a parallel distributed processing account of the stroop effect. Psychological Review 97 :332–361. DOI: https://doi.org/10.1037/0033- 295X.97.3.332 , PMID: 2200075 Cohen JD , Daw N, Engelhardt B, Hasson U, Li K, Niv Y, Norman KA, Pillow J, Ramadge PJ, Turk-Browne NB, Willke TL. 2017. Computational approaches to fMRI analysis. Nature Neuroscience 20 :304–313. DOI: https:// doi.org/10.1038/nn.4499 , PMID: 28230848 Collins AG , Brown JK, Gold JM, Waltz JA, Frank MJ. 2014. Working memory contributions to reinforcement learning impairments in schizophrenia. The Journal of Neuroscience 34 :13747–13756. DOI: https://doi.org/10. 1523/JNEUROSCI.0989-14.2014 , PMID: 25297101 Collins AG , Frank MJ. 2012",
    "chunk_id": "Adv_cognitive_modelling_15747544008463_1..33.json_chunk_52"
  },
  {
    "document_type": "research_paper",
    "title": "Ten simple reules for the computational modeling of behavioral data",
    "author": "Robert C Wilson, Anne GE Collins",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Wilson-2019-Ten-simple-rules-for-the-computatio.pdf",
    "date_published": "2019-11-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". The Journal of Neuroscience 34 :13747–13756. DOI: https://doi.org/10. 1523/JNEUROSCI.0989-14.2014 , PMID: 25297101 Collins AG , Frank MJ. 2012. How much of reinforcement learning is working memory, not reinforcement learning? A behavioral, computational, and neurogenetic analysis. European Journal of Neuroscience 35 :1024– 1035. DOI: https://doi.org/10.1111/j.1460-9568.2011.07980.x , PMID: 22487033 Collins AG , Frank MJ. 2013. Cognitive control over learning: creating, clustering, and generalizing task-set structure. Psychological Review 120 :190–229. DOI: https://doi.org/10.1037/a0030852 , PMID: 23356780 Collins AG , Frank MJ. 2014. Opponent actor learning (OpAL): modeling interactive effects of striatal dopamine on reinforcement learning and choice incentive. Psychological Review 121 :337–366. DOI: https://doi.org/10. 1037/a0037015 , PMID: 25090423 Collins AG , Frank MJ. 2018. Within-and across-trial dynamics of human EEG reveal cooperative interplay between reinforcement learning and working memory. PNAS :201720963. Collins AG , Wilson RC. 2019. TenSimpleRulesModeling. 3a01850. Github. https://github.com/AnneCollins/ TenSimpleRulesModeling Courville AC , Daw ND. 2008. The rat as particle filter. Advances in Neural Information Processing Systems 369– 376. https://papers.nips.cc/paper/3205-the-rat-as-particle-filter . Daw ND . 2011. Trial-by-trial data analysis using computational models. Decision Making, Affect, and Learning: Attention and Performance XXIII 23 :3–38. DOI: https://doi.org/10.1093/acprof:oso/9780199600434.003.0001 Daw ND , Gershman SJ, Seymour B, Dayan P, Dolan RJ. 2011. Model-based influences on humans’ choices and striatal prediction errors. Neuron 69 :1204–1215. DOI: https://doi.org/10.1016/j.neuron.2011.02.027 , PMID: 21435563 Daw ND , Courville AC. 2007. The pigeon as particle filter. Advances in Neural Information Processing Systems. Daw ND , Tobler PN. 2014. Value learning through reinforcement: the basics of dopamine and reinforcement learning. In: Neuroeconomics . Second Edition",
    "chunk_id": "Adv_cognitive_modelling_15747544008463_1..33.json_chunk_53"
  },
  {
    "document_type": "research_paper",
    "title": "Ten simple reules for the computational modeling of behavioral data",
    "author": "Robert C Wilson, Anne GE Collins",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Wilson-2019-Ten-simple-rules-for-the-computatio.pdf",
    "date_published": "2019-11-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Daw ND , Tobler PN. 2014. Value learning through reinforcement: the basics of dopamine and reinforcement learning. In: Neuroeconomics . Second Edition. Elsevier. p. 283–298. DOI: https://doi.org/10.1016/b978-0-12- 416008-8.00015-2 Donkin C , Tran SC, Nosofsky R. 2014. Landscaping analyses of the ROC predictions of discrete-slots and signadetection models of visual working memory. Attention, Perception, & Psychophysics 76 :2103–2116. DOI: https://doi.org/10.3758/s13414-013-0561-7 Donkin C , Kary A, Tahir F, Taylor R. 2016. Resources masquerading as slots: Flexible allocation of visual working memory. Cognitive Psychology 85 :30–42. DOI: https://doi.org/10.1016/j.cogpsych.2016.01.002 Donoso M , Collins AGE, Koechlin E. 2014. Foundations of human reasoning in the prefrontal cortex. Science 344 :1481–1486. DOI: https://doi.org/10.1126/science.1252254 Wilson and Collins. eLife 2019;8:e49547. DOI: https://doi.org/10.7554/eLife.49547 25 of 33 Review Article Neuroscience Dowd EC , Frank MJ, Collins A, Gold JM, Barch DM. 2016. Probabilistic reinforcement learning in patients with schizophrenia: Relationships to anhedonia and avolition. Biological Psychiatry: Cognitive Neuroscience and Neuroimaging 1 :460–473. DOI: https://doi.org/10.1016/j.bpsc.2016.05.005 Drugowitsch J , Wyart V, Devauchelle AD, Koechlin E. 2016. Computational precision of mental inference as critical source of human choice suboptimality. Neuron 92 :1398–1411. DOI: https://doi.org/10.1016/j.neuron. 2016.11.005 , PMID: 27916454 Farashahi S , Rowe K, Aslami Z, Lee D, Soltani A. 2017. Feature-based learning improves adaptability without compromising precision. Nature Communications 8 :1768. DOI: https://doi.org/10.1038/s41467-017-01874-w , PMID: 29170381 Farrell S , Lewandowsky S. 2018. Computational Modeling of Cognition and Behavior . Cambridge University Press. DOI: https://doi.org/10.1017/CBO9781316272503 Findling C , Skvortsova V, Dromnelle R, Palminteri S, Wyart V. 2018",
    "chunk_id": "Adv_cognitive_modelling_15747544008463_1..33.json_chunk_54"
  },
  {
    "document_type": "research_paper",
    "title": "Ten simple reules for the computational modeling of behavioral data",
    "author": "Robert C Wilson, Anne GE Collins",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Wilson-2019-Ten-simple-rules-for-the-computatio.pdf",
    "date_published": "2019-11-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". 2018. Computational Modeling of Cognition and Behavior . Cambridge University Press. DOI: https://doi.org/10.1017/CBO9781316272503 Findling C , Skvortsova V, Dromnelle R, Palminteri S, Wyart V. 2018. Computational noise in reward-guided learning drives behavioral variability in volatile environments. bioRxiv . DOI: https://doi.org/10.1101/439885 Fischer AG , Ullsperger M. 2013. Real and fictive outcomes are processed differently but converge on a common adaptive mechanism. Neuron 79 :1243–1255. DOI: https://doi.org/10.1016/j.neuron.2013.07.006 , PMID: 24050408 Frank MJ , Seeberger LC, O’reilly RC. 2004. By carrot or by stick: cognitive reinforcement learning in parkinsonism. Science 306 :1940–1943. DOI: https://doi.org/10.1126/science.1102941 , PMID: 15528409 Frank MJ , Moustafa AA, Haughey HM, Curran T, Hutchison KE. 2007. Genetic triple dissociation reveals multiple roles for dopamine in reinforcement learning. PNAS 104 :16311–16316. DOI: https://doi.org/10.1073/pnas. 0706111104 , PMID: 17913879 Geisler WS . 2011. Contributions of ideal observer theory to vision research. Vision Research 51 :771–781. DOI: https://doi.org/10.1016/j.visres.2010.09.027 , PMID: 20920517 Gelman A , Meng XL, Stern H. 1996. Posterior predictive assessment of model fitness via realized discrepancies. Statistica Sinica 6 :733–760. Gershman SJ . 2016. Empirical priors for reinforcement learning models. Journal of Mathematical Psychology 71 : 1–6. DOI: https://doi.org/10.1016/j.jmp.2016.01.006 Gillan CM , Kosinski M, Whelan R, Phelps EA, Daw ND. 2016. Characterizing a psychiatric symptom dimension related to deficits in goal-directed control. eLife 5 :e11305. DOI: https://doi.org/10.7554/eLife.11305 , PMID: 26 928075 Haaf JM , Rouder JN. 2017. Developing constraint in bayesian mixed models. Psychological Methods 22 :779– 798. DOI: https://doi.org/10.1037/met0000156 , PMID: 29265850 Heathcote A , Brown SD, Wagenmakers EJ. 2015. An introduction to good practices in cognitive modeling",
    "chunk_id": "Adv_cognitive_modelling_15747544008463_1..33.json_chunk_55"
  },
  {
    "document_type": "research_paper",
    "title": "Ten simple reules for the computational modeling of behavioral data",
    "author": "Robert C Wilson, Anne GE Collins",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Wilson-2019-Ten-simple-rules-for-the-computatio.pdf",
    "date_published": "2019-11-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Psychological Methods 22 :779– 798. DOI: https://doi.org/10.1037/met0000156 , PMID: 29265850 Heathcote A , Brown SD, Wagenmakers EJ. 2015. An introduction to good practices in cognitive modeling. In: An Introduction to Model-Based Cognitive Neuroscience . Springer. p. 25–48. DOI: https://doi.org/10.1007/ 978-1-4939-2236-9_2 Huys QJM , Cools R, Go ̈ lzer M, Friedel E, Heinz A, Dolan RJ, Dayan P. 2011. Disentangling the roles of approach, activation and Valence in instrumental and pavlovian responding. PLOS Computational Biology 7 :e1002028. DOI: https://doi.org/10.1371/journal.pcbi.1002028 Huys QJM . 2017. Bayesian Approaches to Learning and Decision-Making. In: Computational Psychiatry: Mathematical Modeling of Mental Illness . Academic Press. p. 247–271. DOI: https://doi.org/10.1016/b978-0- 12-809825-7.00010-9 Jahfari S , Ridderinkhof KR, Collins AGE, Knapen T, Waldorp LJ, Frank MJ. 2019. Cross-Task contributions of frontobasal ganglia circuitry in response inhibition and Conflict-Induced slowing. Cerebral Cortex 29 :1969– 1983. DOI: https://doi.org/10.1093/cercor/bhy076 , PMID: 29912363 Kass RE , Raftery AE. 1995. Bayes factors. Journal of the American Statistical Association 90 :773–795. DOI: https://doi.org/10.1080/01621459.1995.10476572 Katahira K . 2016. How hierarchical models improve point estimates of model parameters at the individual level. Journal of Mathematical Psychology 73 :37–58. DOI: https://doi.org/10.1016/j.jmp.2016.03.007 Kording K , Blohm G, Schrater P, Kay K. 2018. Appreciating diversity of goals in computational neuroscience. OSF Preprints . https://osf.io/3vy69/ . Lee MD . 2011. How cognitive modeling can benefit from hierarchical bayesian models. Journal of Mathematical Psychology 55 :1–7. DOI: https://doi.org/10.1016/j.jmp.2010.08.013 Lee MD , Criss AH, Devezer B, Donkin C, Etz A, Leite FP, Matzke D, Rouder JN, Trueblood J, White C. 2019. Robust modeling in cognitive science. PsyArXiv . https://psyarxiv.com/dmfhk/ . Lee MD , Wagenmakers EJ. 2014",
    "chunk_id": "Adv_cognitive_modelling_15747544008463_1..33.json_chunk_56"
  },
  {
    "document_type": "research_paper",
    "title": "Ten simple reules for the computational modeling of behavioral data",
    "author": "Robert C Wilson, Anne GE Collins",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Wilson-2019-Ten-simple-rules-for-the-computatio.pdf",
    "date_published": "2019-11-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". 2019. Robust modeling in cognitive science. PsyArXiv . https://psyarxiv.com/dmfhk/ . Lee MD , Wagenmakers EJ. 2014. Bayesian Cognitive Modeling: A Practical Course . Cambridge university press. DOI: https://doi.org/10.1017/CBO9781139087759 Lee MD , Webb MR. 2005. Modeling individual differences in cognition. Psychonomic Bulletin & Review 12 :605– 621. DOI: https://doi.org/10.3758/BF03196751 , PMID: 16447375 Leong YC , Radulescu A, Daniel R, DeWoskin V, Niv Y. 2017. Dynamic interaction between reinforcement learning and attention in multidimensional environments. Neuron 93 :451–463. DOI: https://doi.org/10.1016/j.neuron. 2016.12.040 Lieder F , Griffiths TL, M Huys QJ, Goodman ND. 2018. Empirical evidence for resource-rational anchoring and adjustment. Psychonomic Bulletin & Review 25 :775–784. DOI: https://doi.org/10.3758/s13423-017-1288-6 , PMID: 28484951 Lorains FK , Dowling NA, Enticott PG, Bradshaw JL, Trueblood JS, Stout JC. 2014. Strategic and non-strategic problem gamblers differ on decision-making under risk and ambiguity. Addiction 109 :1128–1137. DOI: https:// doi.org/10.1111/add.12494 , PMID: 24450756 Wilson and Collins. eLife 2019;8:e49547. DOI: https://doi.org/10.7554/eLife.49547 26 of 33 Review Article Neuroscience MacKay DJ . 2003. Information Theory, Inference and Learning Algorithms . Cambridge University Press. Montague PR , Dayan P, Sejnowski TJ. 1996. A framework for mesencephalic dopamine systems based on predictive hebbian learning. The Journal of Neuroscience 16 :1936–1947. DOI: https://doi.org/10.1523/ JNEUROSCI.16-05-01936.1996 , PMID: 8774460 More ́ JJ , Sorensen DC. 1983. Computing a trust region step. SIAM Journal on Scientific and Statistical Computing 4 :553–572. DOI: https://doi.org/10.1137/0904038 Nassar MR , Wilson RC, Heasly B, Gold JI. 2010. An approximately bayesian delta-rule model explains the dynamics of belief updating in a changing environment. Journal of Neuroscience 30 :12366–12378",
    "chunk_id": "Adv_cognitive_modelling_15747544008463_1..33.json_chunk_57"
  },
  {
    "document_type": "research_paper",
    "title": "Ten simple reules for the computational modeling of behavioral data",
    "author": "Robert C Wilson, Anne GE Collins",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Wilson-2019-Ten-simple-rules-for-the-computatio.pdf",
    "date_published": "2019-11-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". 2010. An approximately bayesian delta-rule model explains the dynamics of belief updating in a changing environment. Journal of Neuroscience 30 :12366–12378. DOI: https://doi.org/10.1523/JNEUROSCI.0822-10.2010 , PMID: 20844132 Nassar MR , Rumsey KM, Wilson RC, Parikh K, Heasly B, Gold JI. 2012. Rational regulation of learning dynamics by pupil-linked arousal systems. Nature Neuroscience 15 :1040–1046. DOI: https://doi.org/10.1038/nn.3130 , PMID: 22660479 Nassar MR , Helmers JC, Frank MJ. 2018. Chunking as a rational strategy for lossy data compression in visual working memory. Psychological Review 125 :486–511. DOI: https://doi.org/10.1037/rev0000101 , PMID: 2 9952621 Nassar MR , Frank MJ. 2016. Taming the beast: extracting generalizable knowledge from computational models of cognition. Current Opinion in Behavioral Sciences 11 :49–54. DOI: https://doi.org/10.1016/j.cobeha.2016.04. 003 , PMID: 27574699 Navarro DJ . 2019. Between the Devil and the deep blue sea: tensions between scientific judgement and statistical model selection. Computational Brain & Behavior 2 :28–34. Nilsson H , Rieskamp J, Wagenmakers E-J. 2011. Hierarchical Bayesian parameter estimation for cumulative prospect theory. Journal of Mathematical Psychology 55 :84–93. DOI: https://doi.org/10.1016/j.jmp.2010.08. 006 O’Doherty JP , Hampton A, Kim H. 2007. Model-based fMRI and its application to reward learning and decision making. Annals of the New York Academy of Sciences 1104 :35–53. DOI: https://doi.org/10.1196/annals.1390. 022 , PMID: 17416921 O’Reilly JX , Schuffelgen U, Cuell SF, Behrens TEJ, Mars RB, Rushworth MFS. 2013. Dissociable effects of surprise and model update in parietal and anterior cingulate cortex. PNAS 110 :E3660–E3669. DOI: https://doi.org/10. 1073/pnas.1305373110 Otto AR , Raio CM, Chiang A, Phelps EA, Daw ND. 2013. Working-memory capacity protects model-based learning from stress. PNAS 110 :20941–20946. DOI: https://doi.org/10.1073/pnas.1312011110 , PMID: 24324166 Palminteri S , Wyart V, Koechlin E. 2017",
    "chunk_id": "Adv_cognitive_modelling_15747544008463_1..33.json_chunk_58"
  },
  {
    "document_type": "research_paper",
    "title": "Ten simple reules for the computational modeling of behavioral data",
    "author": "Robert C Wilson, Anne GE Collins",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Wilson-2019-Ten-simple-rules-for-the-computatio.pdf",
    "date_published": "2019-11-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". 2013. Working-memory capacity protects model-based learning from stress. PNAS 110 :20941–20946. DOI: https://doi.org/10.1073/pnas.1312011110 , PMID: 24324166 Palminteri S , Wyart V, Koechlin E. 2017. The importance of falsification in computational cognitive modeling. Trends in Cognitive Sciences 21 :425–433. DOI: https://doi.org/10.1016/j.tics.2017.03.011 , PMID: 28476348 Piray P , Dezfouli A, Heskes T, Frank MJ, Daw ND. 2018. Hierarchical bayesian inference for concurrent model fitting and comparison for group studies. bioRxiv . DOI: https://doi.org/10.1101/393561 Ratcliff R . 1978. A theory of memory retrieval. Psychological Review 85 :59–108. DOI: https://doi.org/10.1037/ 0033-295X.85.2.59 Ratcliff R , Rouder JN. 1998. Modeling response times for Two-Choice decisions. Psychological Science 9 :347– 356. DOI: https://doi.org/10.1111/1467-9280.00067 Rescorla RA , Wagner AR. 1972. A theory of pavlovian conditioning: variations in the effectiveness of reinforcement and nonreinforcement. Classical Conditioning II: Current Research and Theory 2 :64–99. Rigoux L , Stephan KE, Friston KJ, Daunizeau J. 2014. Bayesian model selection for group studies - revisited. NeuroImage 84 :971–985. DOI: https://doi.org/10.1016/j.neuroimage.2013.08.065 , PMID: 24018303 Roecker EB . 1991. Prediction error and its estimation for Subset-Selected models. Technometrics 33 :459–468. DOI: https://doi.org/10.1080/00401706.1991.10484873 Samejima K , Ueda Y, Doya K, Kimura M. 2005. Representation of action-specific reward values in the striatum. Science 310 :1337–1340. DOI: https://doi.org/10.1126/science.1115270 , PMID: 16311337 Schwarz G . 1978. Estimating the dimension of a model. The Annals of Statistics 6 :461–464. DOI: https://doi.org/ 10.1214/aos/1176344136 Sims CR . 2018. Efficient coding explains the universal law of generalization in human perception. Science 360 : 652–656. DOI: https://doi.org/10.1126/science.aaq1118 , PMID: 29748284 Somerville LH , Sasse SF, Garrad MC, Drysdale AT, Abi Akar N, Insel C, Wilson RC. 2017",
    "chunk_id": "Adv_cognitive_modelling_15747544008463_1..33.json_chunk_59"
  },
  {
    "document_type": "research_paper",
    "title": "Ten simple reules for the computational modeling of behavioral data",
    "author": "Robert C Wilson, Anne GE Collins",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Wilson-2019-Ten-simple-rules-for-the-computatio.pdf",
    "date_published": "2019-11-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Science 360 : 652–656. DOI: https://doi.org/10.1126/science.aaq1118 , PMID: 29748284 Somerville LH , Sasse SF, Garrad MC, Drysdale AT, Abi Akar N, Insel C, Wilson RC. 2017. Charting the expansion of strategic exploratory behavior during adolescence. Journal of Experimental Psychology: General 146 :155–164. DOI: https://doi.org/10.1037/xge0000250 Starns JJ , Ratcliff R. 2010. The effects of aging on the speed-accuracy compromise: boundary optimality in the diffusion model. Psychology and Aging 25 :377–390. DOI: https://doi.org/10.1037/a0018022 , PMID: 20545422 Steyvers M , Lee MD, Wagenmakers E-J. 2009. A bayesian analysis of human decision-making on bandit problems. Journal of Mathematical Psychology 53 :168–179. DOI: https://doi.org/10.1016/j.jmp.2008.11.002 Sunna ̊ker M , Busetto AG, Numminen E, Corander J, Foll M, Dessimoz C. 2013. Approximate bayesian computation. PLOS Computational Biology 9 :e1002803. DOI: https://doi.org/10.1371/journal.pcbi.1002803 , PMID: 23341757 Sutton RS , Barto AG. 2018. Reinforcement Learning: An Introduction . MIT press. Turner BM , Forstmann BU, Wagenmakers EJ, Brown SD, Sederberg PB, Steyvers M. 2013. A bayesian framework for simultaneously modeling neural and behavioral data. NeuroImage 72 :193–206. DOI: https://doi.org/10. 1016/j.neuroimage.2013.01.048 , PMID: 23370060 Wilson and Collins. eLife 2019;8:e49547. DOI: https://doi.org/10.7554/eLife.49547 27 of 33 Review Article Neuroscience Turner BM , Rodriguez CA, Norcia TM, McClure SM, Steyvers M. 2016. Why more is better: simultaneous modeling of EEG, fMRI, and behavioral data. NeuroImage 128 :96–115. DOI: https://doi.org/10.1016/j. neuroimage.2015.12.030 , PMID: 26723544 Turner BM , Sederberg PB. 2012. Approximate Bayesian computation with differential evolution. Journal of Mathematical Psychology 56 :375–385. DOI: https://doi.org/10.1016/j.jmp.2012.06.004 van Ravenzwaaij D , Dutilh G, Wagenmakers E-J. 2011. Cognitive model decomposition of the BART: assessment and application. Journal of Mathematical Psychology 55 :94–105",
    "chunk_id": "Adv_cognitive_modelling_15747544008463_1..33.json_chunk_60"
  },
  {
    "document_type": "research_paper",
    "title": "Ten simple reules for the computational modeling of behavioral data",
    "author": "Robert C Wilson, Anne GE Collins",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Wilson-2019-Ten-simple-rules-for-the-computatio.pdf",
    "date_published": "2019-11-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". 2011. Cognitive model decomposition of the BART: assessment and application. Journal of Mathematical Psychology 55 :94–105. DOI: https://doi.org/10.1016/j.jmp.2010.08. 010 Vandekerckhove J , Matzke D, Wagenmakers EJ. 2015. Model Comparison and the Principle of Parsimony. In: Busemeyer J. R, Wang Z, Townsend J. T, Eidels A (Eds). The Oxford Handbook of Computational and Mathematical Psychology . 300 Oxford University Press. p. 300319 DOI: https://doi.org/10.1093/oxfordhb/ 9780199957996.013.14 Viejo G , Khamassi M, Brovelli A, Girard B. 2015. Modeling choice and reaction time during arbitrary visuomotor learning through the coordination of adaptive working memory and reinforcement learning. Frontiers in Behavioral Neuroscience 9 :225. DOI: https://doi.org/10.3389/fnbeh.2015.00225 , PMID: 26379518 Wagenmakers E-J , Lodewyckx T, Kuriyal H, Grasman R. 2010. Bayesian hypothesis testing for psychologists: a tutorial on the Savage–Dickey method. Cognitive Psychology 60 :158–189. DOI: https://doi.org/10.1016/j. cogpsych.2009.12.001 Wagenmakers EJ , Farrell S. 2004. AIC model selection using akaike weights. Psychonomic Bulletin & Review 11 : 192–196. DOI: https://doi.org/10.3758/BF03206482 , PMID: 15117008 Warren CM , Wilson RC, van der Wee NJ, Giltay EJ, van Noorden MS, Cohen JD, Nieuwenhuis S. 2017. The effect of atomoxetine on random and directed exploration in humans. PLOS ONE 12 :e0176034. DOI: https:// doi.org/10.1371/journal.pone.0176034 Watkins CJCH , Dayan P. 1992. Q-learning. Machine Learning 8 :279–292. DOI: https://doi.org/10.1007/ BF00992698 Wiecki TV , Sofer I, Frank MJ. 2013. HDDM: hierarchical bayesian estimation of the Drift-Diffusion model in Python. Frontiers in Neuroinformatics 7 :14. DOI: https://doi.org/10.3389/fninf.2013.00014 , PMID: 23935581 Wilson RC , Nassar MR, Gold JI. 2013. A mixture of delta-rules approximation to bayesian inference in changpoint problems. PLOS Computational Biology 9 :e1003150. DOI: https://doi.org/10.1371/journal.pcbi.1003150 , PMID: 23935472 Wilson RC , Niv Y. 2011",
    "chunk_id": "Adv_cognitive_modelling_15747544008463_1..33.json_chunk_61"
  },
  {
    "document_type": "research_paper",
    "title": "Ten simple reules for the computational modeling of behavioral data",
    "author": "Robert C Wilson, Anne GE Collins",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Wilson-2019-Ten-simple-rules-for-the-computatio.pdf",
    "date_published": "2019-11-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". PLOS Computational Biology 9 :e1003150. DOI: https://doi.org/10.1371/journal.pcbi.1003150 , PMID: 23935472 Wilson RC , Niv Y. 2011. Inferring relevance in a changing world. Frontiers in Human Neuroscience 5 :189. DOI: https://doi.org/10.3389/fnhum.2011.00189 , PMID: 22291631 Wilson RC , Niv Y. 2015. Is model fitting necessary for Model-Based fMRI? PLOS Computational Biology 11 : e1004237. DOI: https://doi.org/10.1371/journal.pcbi.1004237 , PMID: 26086934 Wimmer GE , Li JK, Gorgolewski KJ, Poldrack RA. 2018. Reward learning over weeks versus minutes increases the neural representation of value in the human brain. The Journal of Neuroscience 38 :7649–7666. DOI: https:// doi.org/10.1523/JNEUROSCI.0075-18.2018 , PMID: 30061189 Zajkowski WK , Kossut M, Wilson RC. 2017. A causal role for right frontopolar cortex in directed, but not random, exploration. eLife 6 :e27430. DOI: https://doi.org/10.7554/eLife.27430 , PMID: 28914605 Wilson and Collins. eLife 2019;8:e49547. DOI: https://doi.org/10.7554/eLife.49547 28 of 33 Review Article Neuroscience Appendix 1 The theory of model fitting Formally, the goal of model fitting is to estimate the parameters, m , for each model, m , that best fit the behavioral data. To do this, we take a Bayesian approach and aim to compute (or at least approximate) the posterior distribution over the parameters given the data, p ð m j d 1 : T ; m Þ . By Bayes’ rule we can write this as p ð m j d 1 : T ; m Þ 1⁄4 p ð d 1 : T j m ; m Þ p ð m j m Þ p ð d 1 : T j m Þ (12) where p ð m j m Þ is the prior on the parameters, m ; p ð d 1 : T j m ; m Þ is the likelihood of the data given the parameters; and the normalization constant, p ð d 1 : T j m Þ , is the probability of the data given the model (which is also known as the marginal likelihood [ Lee and Wagenmakers, 2014 ], more on this below)",
    "chunk_id": "Adv_cognitive_modelling_15747544008463_1..33.json_chunk_62"
  },
  {
    "document_type": "research_paper",
    "title": "Ten simple reules for the computational modeling of behavioral data",
    "author": "Robert C Wilson, Anne GE Collins",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Wilson-2019-Ten-simple-rules-for-the-computatio.pdf",
    "date_published": "2019-11-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Because the probabilities tend to be small, it is often easier to work with the log of these quantities log p ð m j d 1 : T ; m Þ 1⁄4 log p ð d 1 : T j m ; m Þ |fflfflfflfflfflfflfflfflfflfflfflffl{zfflfflfflfflfflfflfflfflfflfflfflffl} log likelihood þ log p ð m j m Þ log p ð d 1 : T j m Þ (13) The log-likelihood often gets its own symbol, LL 1⁄4 log p ð d 1 : T j m ; m Þ , and can be written log p ð d 1 : T j m ; m Þ 1⁄4 log Y T t 1⁄4 1 p ð c t j d 1 : t 1 ; s t ; m ; m Þ ! 1⁄4 X T t 1⁄4 1 log p ð c t j d 1 : t 1 ; s t ; m ; m Þ (14) where p ð c t j d 1 : t 1 ; s t ; m ; m Þ is the probability of each individual choice given the parameters of the model, which is at the heart of the definition of each model (for example in Equations 1– 7 ). In a perfect world, we would evaluate the log-posterior, log p ð m j d 1 : T ; m Þ , exactly, but this can be difficult to compute and unwieldy to report. Instead, we must approximate it. This can be done using sampling approaches such as Markov Chain Monte Carlo approaches ( Lee and Wagenmakers, 2014 ), which approximate the full posterior with a set of samples. Another approach is to report a point estimate for the parameters such as the maximum of the loposterior (the maximum a posteriori [MAP] estimate), or the maximum of the log-likelihood (the maximum likelihood estimate [MLE]). (Note that the log transformation does not change the location of the maximum, so the maximum of the log-likelihood occurs at the same value of m as the maximum of the likelihood.) ^ MAP m 1⁄4 argmax m log p ð m j d 1 : T ; m Þ ^ MLE m 1⁄4 argmax m log p ð d 1 : T j m ; m Þ Note that with a uniform prior on m , these two estimates coincide. These approaches for estimating parameter values each have different strengths and weaknesses. The MCMC approach is the most principled as, with enough samples, it gives a good approximation of the posterior distribution over each parameter value",
    "chunk_id": "Adv_cognitive_modelling_15747544008463_1..33.json_chunk_63"
  },
  {
    "document_type": "research_paper",
    "title": "Ten simple reules for the computational modeling of behavioral data",
    "author": "Robert C Wilson, Anne GE Collins",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Wilson-2019-Ten-simple-rules-for-the-computatio.pdf",
    "date_published": "2019-11-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". The MCMC approach is the most principled as, with enough samples, it gives a good approximation of the posterior distribution over each parameter value. This approach also gracefully handles small data sets and allows us to combine data from different subjects in a rigorous manner. Despite these advantages, the MCMC approach is more complex (especially for beginners) and can be slow to implement. On the other hand, point estimates such as the MAP and MLE parameter values are much quicker to compute and often give similar answers to the MCMC approach when the amount of data is large (which is often the case when dealing with young and healthy populations). For this reason, we focus our discussion on the point estimate approaches, focusing in particular on maximum likelihood estimation. Wilson and Collins. eLife 2019;8:e49547. DOI: https://doi.org/10.7554/eLife.49547 29 of 33 Review Article Neuroscience Appendix 2 The theory of model comparison In model comparison, our goal is to figure out which model of a set of possible models is most likely to have generated the data. To do this, we compute (or at least try to estimate) the probability that model m generated the data, p ð m j d 1 : T Þ . Note that this is the normalization constant from Equation 12 . As with parameter recovery, this probability is difficult to compute directly and so we turn to Bayes’ rule and write p ð m j d 1 : T Þ / p ð d 1 : T j m Þ p ð m Þ 1⁄4 Z d m p ð d 1 : T j m ; m Þ p ð m j m Þ p ð m Þ where p ð m Þ is the prior probability that model m is the correct model and p ð d 1 : T j m Þ is the likelihood of the data given the model. In most cases, p ð m Þ is assumed to be constant and so we can focus entirely on the likelihood, p ð d 1 : T j m Þ . As before, it is easier to handle the log of this quantity which is known as the marginal likelihood ( Lee and Wagenmakers, 2014 ) or Bayesian evidence, E m ( Kass and Raftery, 1995 ), for model m",
    "chunk_id": "Adv_cognitive_modelling_15747544008463_1..33.json_chunk_64"
  },
  {
    "document_type": "research_paper",
    "title": "Ten simple reules for the computational modeling of behavioral data",
    "author": "Robert C Wilson, Anne GE Collins",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Wilson-2019-Ten-simple-rules-for-the-computatio.pdf",
    "date_published": "2019-11-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". As before, it is easier to handle the log of this quantity which is known as the marginal likelihood ( Lee and Wagenmakers, 2014 ) or Bayesian evidence, E m ( Kass and Raftery, 1995 ), for model m . More explicitly E m 1⁄4 log p ð d 1 : T j m Þ 1⁄4 log Z d m p ð d 1 : T j m ; m Þ p ð m j m Þ (17) If we can compute E m for each model, then the model with the largest evidence is most likely to have generated the data. Note that by integrating over the parameter space, the Bayesian evidence implicitly penalizes free parameters. This is because, the more free parameters, the larger the size of the space over which we integrate and, consequently, the smaller p ð m j m Þ is for any given parameter setting. Thus, unless the model predicts the data well for all parameter settings, it pays a price for each additional free parameter. This idea, that simpler models should be favored over more complex models if they both explain the data equally well, is known as Occam’s razor (see Chapter 28 in MacKay, 2003 ). Unfortunately, because it involves computing an integral over all possible parameter settings, computing the marginal likelihood exactly is usually impossible. There are several methods for approximating the integral based on either replacing it with a sum over a subset of points ( Wagenmakers et al., 2010 ; Lee and Wagenmakers, 2014 ) or replacing it with an approximation around either the MAP or MLE estimates of the parameters. The latter approach is the most common and three particular forms are used: the Bayes Information Criterion (BIC) ( Schwarz, 1978 ), Akaike information criterion (AIC) ( Akaike, 1974 ) and the Laplace approximation ( Kass and Raftery, 1995 ). Here, we will focus on BIC which is an estimate based around the maximum likelihood estimate of the parameters, ^ MLE m , BIC 1⁄4 2 log ^ L þ k m log ð T Þ » 2 log E m (18) where k m is the number of parameters in model m and ^ L is the value of the log-likelihood at ^ MLE m",
    "chunk_id": "Adv_cognitive_modelling_15747544008463_1..33.json_chunk_65"
  },
  {
    "document_type": "research_paper",
    "title": "Ten simple reules for the computational modeling of behavioral data",
    "author": "Robert C Wilson, Anne GE Collins",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Wilson-2019-Ten-simple-rules-for-the-computatio.pdf",
    "date_published": "2019-11-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Finally, we have found it useful to report the results of model comparison in terms of the likelihood-per-trial LPT , which can be thought of as the ‘average’ probability with which the model predicts each choice, LPT 1⁄4 exp E m T (19) Wilson and Collins. eLife 2019;8:e49547. DOI: https://doi.org/10.7554/eLife.49547 30 of 33 Review Article Neuroscience Appendix 3 Computing the inversion matrix from the confusion matrix In section ’Can you arbitrate between different models?’ we introduced the inversion matrix, p ð simulated model j fit model Þ , as the probability that data best fit by one model were actually generated from another model. As shown below, this can be readily computed from the confusion matrix, p ð fit model j simulated model Þ , by Bayes rule. Abbreviating ‘simulated model’ with ‘sim’ and ‘fit model’ with ‘fit’ we have p ð sim j fit Þ 1⁄4 p ð fit j sim Þ p ð sim Þ P sim p ð fit j sim Þ p ð sim Þ (20) For a uniform prior on models, computing the inversion matrix amounts to renormalizing the confusion matrix over the simulated models. Wilson and Collins. eLife 2019;8:e49547. DOI: https://doi.org/10.7554/eLife.49547 31 of 33 Review Article Neuroscience Appendix 4 Working memory model used for local minima example The model and experimental designs used in Box 3—figure 1 are a simplified version of those in Collins and Frank (2012) . In short, the experiment attempts to parse out working memory contributions to reinforcement learning by having participants and agents learn stimulus-action contingencies from deterministic feedback, with a different number of stimuli ns being learned in parallel in different blocks. This manipulation targets WM load and isolates WM contributions; see Collins and Frank (2012) for details. The simplified model assumes a mixture of a classic RL component (with parameters a and b ) and a working memory component with perfect one-shot learning. The mixture is controled by parameter , capturing the prior willingness to use working memory vs",
    "chunk_id": "Adv_cognitive_modelling_15747544008463_1..33.json_chunk_66"
  },
  {
    "document_type": "research_paper",
    "title": "Ten simple reules for the computational modeling of behavioral data",
    "author": "Robert C Wilson, Anne GE Collins",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Wilson-2019-Ten-simple-rules-for-the-computatio.pdf",
    "date_published": "2019-11-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". The mixture is controled by parameter , capturing the prior willingness to use working memory vs. RL, and capacity parameter K , which scales the mixture weight in proportion to the proportion of stimuli that may be held in working memory: min ð 1 ; K ns Þ . The original model assumes additional dynamics for the working memory policy and working memory vs. RL weights that render the model more identifiable ( Collins and Frank, 2012 ). Wilson and Collins. eLife 2019;8:e49547. DOI: https://doi.org/10.7554/eLife.49547 32 of 33 Review Article Neuroscience Appendix 5 Model validation example In this example, we imagine a deterministic stimulus-action learning task in which subjects are presented with one of three stimuli ( s 1 , s 2 , and s 3 ), which instruct the subject which of three actions ( a 1 , a 2 , and a 3 ) will be rewarded when chosen. The two models that we consider are both reinforcement learning agents. The first, a ‘blind’ agent, does not see the stimulus at all and learns only about the value of the three different actions, i.e. Q ð a i Þ , regardless of the stimulus. The second, a ‘state-based’ agent, observes the stimulus and learns a value for each action that can be different for each stimulus, i.e. Q ð a i ; s i Þ . Learning in both models occurs via a Rescorla-Wagner rule with different learning rates for positive and negative prediction errors. Thus for the blind agent, the values update according to Q ð a t Þ Q ð a t Þ þ a P ð r t Q ð a t ÞÞ if ð r t Q ð a t ÞÞ > 0 Q ð a t Þ þ a N ð r t Q ð a t ÞÞ if ð r t Q ð a t ÞÞ < 0 (21) while for the state-based agent, values update according to Q ð a t ; s t Þ Q ð a t ; s t Þ þ a P ð r t Q ð a t ; s t ÞÞ if ð r t Q ð a t ; s t ÞÞ > 0 Q ð a t ; s t Þ þ a N ð r t Q ð a t ; s t ÞÞ if ð r t Q ð a t ; s t ÞÞ < 0 (22) In both models, these values guide decisions via softmax decision rule with inverse temperature parameter, b . We begin by simulating two different agents: one using the blind algorithm and the other using the state-based approach",
    "chunk_id": "Adv_cognitive_modelling_15747544008463_1..33.json_chunk_67"
  },
  {
    "document_type": "research_paper",
    "title": "Ten simple reules for the computational modeling of behavioral data",
    "author": "Robert C Wilson, Anne GE Collins",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Wilson-2019-Ten-simple-rules-for-the-computatio.pdf",
    "date_published": "2019-11-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". We begin by simulating two different agents: one using the blind algorithm and the other using the state-based approach. Parameters in the models are set such that the learning curves for the two agents are approximately equal ( Box 7—figure 1A , blind model: a P 1⁄4 0 : 5 , a N 1⁄4 0 , b 1⁄4 6 : 5 state-based model: a P 1⁄4 0 : 65 , a N 1⁄4 0 , b 1⁄4 2 ). In both cases, the agents start from an accuracy of 1/3 and an asymptote at an accuracy of around 2/3 — the blind agent because this is the best it can do, the state-based agent because the softmax parameter is relatively small and hence performance is limited by noise. Next we consider how the state-based model fits behavior from these two different agents. In Box 7—figure 1B , we plot the average likelihood with which the state-based model predicts the actual choices of the blind and state-based agents, that is the average p ð c t j d 1 : t 1 ; m ; m 1⁄4 state-based Þ . As is clear from this figure, the state-based model predicts choices from the blind agent with higher likelihood than choices from the state-based agent! Although counter intuitive, this result does not imply that the state-based model is unable to fit its own behavior. Instead, this result reflects the difference in noise (softmax parameters) between the two subjects. The blind RL subject has a high b , implying less noise, allowing the state-based model to fit it quite well. Conversely, the state-based RL subject has a low b , implying more noise, meaning that the behavior is harder to predict even when it is fit with the correct model. That the state-based model fits state-based behavior better than it fits blind behavior is illustrated in Box 7—figure 1C . Here we plot the simulated learning curves of the state-based model using the parameter values that were fit to either the state-based agent or the blind agent",
    "chunk_id": "Adv_cognitive_modelling_15747544008463_1..33.json_chunk_68"
  },
  {
    "document_type": "research_paper",
    "title": "Ten simple reules for the computational modeling of behavioral data",
    "author": "Robert C Wilson, Anne GE Collins",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\Wilson-2019-Ten-simple-rules-for-the-computatio.pdf",
    "date_published": "2019-11-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Here we plot the simulated learning curves of the state-based model using the parameter values that were fit to either the state-based agent or the blind agent. While the fit to the state-based agent generates a learning curve quite similar to that of the subject (compare blue lines in Box 7—figure 1A and C ), the state-based fit to the blind agent performs too well (compare yellow lines in panels Box 7—figure 1A and C ). Thus the model validation step provides support for the state-based model when it is the correct model of behavior, but rules out the state-based model when the generating model was different. Wilson and Collins. eLife 2019;8:e49547. DOI: https://doi.org/10.7554/eLife.49547 33 of 33 Review Article Neuroscience",
    "chunk_id": "Adv_cognitive_modelling_15747544008463_1..33.json_chunk_69"
  },
  {
    "document_type": "online_article",
    "title": "Chapter 9 Mixture models",
    "author": "Riccardo Fusaroli",
    "source": "https://fusaroli.github.io/AdvancedCognitiveModeling2023/mixture-models.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": "When we model human cognition and behavior, we often find ourselves facing a puzzling reality: people don’t always follow a single, consistent strategy. Consider a person playing our matching pennies game - sometimes they might carefully track their opponent’s patterns, other times they might rely on a simple bias toward choosing “heads,” and occasionally they might respond completely randomly when their attention lapses. Traditional cognitive models that assume a single process are ill-equipped to capture this complexity. Mixture models provide an elegant solution to this challenge. Rather than assuming behavior reflects just one cognitive process, mixture models allow us to combine multiple different processes within a unified modeling framework. In the previous chapter, we explored model comparison techniques that help us select between competing cognitive models. Mixture models approach in a sense reframe that very problem - instead of asking “which model is correct?”, they allow us to ask “how much does each model contribute?” This shift acknowledges the possibility that multiple cognitive processes might coexist, either within a single individual or across a population",
    "chunk_id": "Adv_cognitive_modelling_chapter_9_mixture_models.json_chunk_1"
  },
  {
    "document_type": "online_article",
    "title": "Chapter 9 Mixture models",
    "author": "Riccardo Fusaroli",
    "source": "https://fusaroli.github.io/AdvancedCognitiveModeling2023/mixture-models.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". After completing this chapter, you will be able to: Understand how mixture models combine multiple cognitive processes Implement mixture models for different types of behavioral data using Stan Estimate mixture weights and component-specific parameters Evaluate mixture models through posterior predictive checks Compare mixture models to single-process alternatives In this chapter, we will: Examine reaction time data to visualize how mixture distributions appear in practice Develop a theoretical foundation for mixture modeling Implement a simple mixture model combining biased and random choice processes (thus going back to our matching pennies example) Evaluate and validate this model through posterior checks Extend to multilevel mixture models that capture individual differences Compare mixture models with traditional single-process approaches Before diving into the mathematics and implementation of mixture models, let’s start with a concrete example that visually demonstrates why we need them. Reaction time (RT) data provides a particularly clear window into the mixture of cognitive processes. In many cognitive tasks, participants are asked to respond as quickly as possible while still being accurate. However, attention fluctuates over time. Let’s simulate a scenario where participants sometimes engage in deliberate thinking (producing a log-normal distribution of RTs) and sometimes experience attentional lapses (producing more or less random responses with a uniform distribution of RTs). Now, let’s visualize the reaction time distribution: In this example, we can clearly see how the overall reaction time distribution (black line) is a combination of two distinct processes: Deliberate Thinking (Blue): A log-normal distribution centered around 500ms, representing focused cognitive processing of the task",
    "chunk_id": "Adv_cognitive_modelling_chapter_9_mixture_models.json_chunk_2"
  },
  {
    "document_type": "online_article",
    "title": "Chapter 9 Mixture models",
    "author": "Riccardo Fusaroli",
    "source": "https://fusaroli.github.io/AdvancedCognitiveModeling2023/mixture-models.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". Attentional Lapses (Red Line): A uniform distribution spanning from very quick to very slow responses, representing trials where attention has drifted, leading to either impulsive responses or delayed responses due to mind-wandering. The mixture of these processes creates a complex distribution with a prominent peak (from the deliberate process) and extended tails (from the attentional lapses). A standard single-process model assuming only a log-normal distribution would fail to capture these extended tails, leading to poor fit and potentially misleading conclusions about the cognitive processes involved. This is exactly the situation where mixture models excel. They allow us to represent observed data as coming from a weighted combination of different underlying processes. Next, we’ll formalize this intuition and extend it to decision-making models. At their core, mixture models represent data as coming from a weighted combination of different “component” distributions or processes. Mathematically, a mixture model can be expressed as: p(y) = π_1p_1(y) + π_2p_2(y) + + π_kp_k(y) Where: p(y) is the overall probability of observing data point y p_j(y) is the probability of y according to component model j π_j is the weight or mixing proportion of component j (with all π_j summing to 1) Each component distribution p_j(y) can have its own parameters, and the mixing proportions π_j determine how much each component contributes to the overall model. An alternative and often useful way to think about mixture models is through latent (unobserved) variables. We can introduce a latent categorical variable z that indicates which component generated each observation. For example, in a two-component mixture: We can then formulate the mixture model as: p(y_i, z_i) = p(z_i)p(y_i∣z_i) Where p(z_i=j)=π_j is the prior probability of component j, and p(y_i∣z_i = j) is the likelihood of y_i under component j. This latent variable perspective is particularly useful for implementing mixture models in Bayesian frameworks like Stan",
    "chunk_id": "Adv_cognitive_modelling_chapter_9_mixture_models.json_chunk_3"
  },
  {
    "document_type": "online_article",
    "title": "Chapter 9 Mixture models",
    "author": "Riccardo Fusaroli",
    "source": "https://fusaroli.github.io/AdvancedCognitiveModeling2023/mixture-models.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". This latent variable perspective is particularly useful for implementing mixture models in Bayesian frameworks like Stan. In cognitive modeling, mixture models can represent several important phenomena: Attentional fluctuations: As in our reaction time example, performance may reflect both focused engagement and attentional lapses Strategy switching: Individuals might switch between different strategies over time Dual-process theories: Behavior might arise from multiple cognitive systems (e.g., automatic vs. controlled) Individual differences: Different individuals might use different strategies Exploration vs. exploitation: Some decisions might reflect exploring new options while others exploit known rewards Now that we understand the theoretical foundation, let’s implement a simple mixture model for choice data. We’ll model behavior as a mixture of two processes: This could represent, for example, a person who sometimes carefully performs a task but occasionally responds randomly due to attentional lapses. In previous chapters we generated data to use for fitting models. Let’s use that same data but focus on a particular agent who might be mixing strategies: Let’s visualize this data to see if we can detect patterns suggestive of a mixture: For binary choice data, it’s harder to visually detect a mixture compared to reaction times. The overall proportion of right choices falls between what we’d expect from random choice (0.5) and fully biased choice with rate 0.8, which is consistent with a mixture of these processes",
    "chunk_id": "Adv_cognitive_modelling_chapter_9_mixture_models.json_chunk_4"
  },
  {
    "document_type": "online_article",
    "title": "Chapter 9 Mixture models",
    "author": "Riccardo Fusaroli",
    "source": "https://fusaroli.github.io/AdvancedCognitiveModeling2023/mixture-models.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". The overall proportion of right choices falls between what we’d expect from random choice (0.5) and fully biased choice with rate 0.8, which is consistent with a mixture of these processes. Now let’s implement a Stan model that represents choices as coming from a mixture of a biased process and a random process: Now let’s fit the model and evaluate its performance: Let’s check the model diagnostics to ensure our inference is reliable: To verify that our model can accurately recover parameters, let’s examine how close our inferred parameters are to the true values used in the simulation: The model has recovered the true parameters reasonably well, providing confidence in our approach. In a real project, we’d want to run this across a broad range of parameter values! Our model appears to capture both the overall proportion of right choices and the distribution of run lengths in the observed data. This suggests the mixture model is adequately representing the data-generating process. The mixture model provides valuable insights into the cognitive processes underlying the observed behavior: Bias Parameter (θ): The bias parameter (estimated as approximately r round(mean(draws$bias_p), 2)) represents the probability of choosing the right option when the participant is following the biased process. Noise Parameter (π): The noise parameter (estimated as approximately r round(mean(draws$noise_p), 2)) represents the proportion of choices that come from the random process rather than the biased process. This can be interpreted as the frequency of attentional lapses or exploratory behavior. The mixture model thus decomposes behavior into two distinct processes, providing a more nuanced understanding than a single-process model could offer. This has important cognitive implications: for instance, besides the usual focus on “deliberate” reaction times, individual variations attentional lapses might be affected by the experimental condition, or an underlying diagnosis, thus providing richer information",
    "chunk_id": "Adv_cognitive_modelling_chapter_9_mixture_models.json_chunk_5"
  },
  {
    "document_type": "online_article",
    "title": "Chapter 9 Mixture models",
    "author": "Riccardo Fusaroli",
    "source": "https://fusaroli.github.io/AdvancedCognitiveModeling2023/mixture-models.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". Now let’s extend our approach to a multilevel (hierarchical) mixture model that can accommodate individual differences across multiple participants. This allows us to estimate both population-level parameters and individual-specific variations. Now we’ll prepare data from multiple agents for the multilevel model: The multilevel mixture model allows us to examine individual differences in both bias and mixture weights: An important advantage of multilevel mixture models is their ability to reveal correlations between parameters across individuals: The correlation between bias and noise parameters can provide important insights into cognitive processes. For example, a negative correlation might suggest that individuals with stronger biases tend to have fewer random lapses, while a positive correlation could indicate that strong biases are associated with more exploratory behavior. However, in the simulation process we did not include any correlation between the bias and noise parameters, so the correlation we observe here is correctly estimated as centered at 0. Finally, let’s compare our mixture model with a single-process alternative to determine which better captures the observed behavior. First, let’s implement a simple single-process model that assumes all choices come from a biased process: Now let’s compare the single-process model with our mixture model using leave-one-out cross-validation (LOO-CV): Based on the model comparison, the single model appears to better capture the data-generating process than the single-process alternative. This might seem counterintuitive, but it highlights that predictive performance is not necessarily the best way of choosing your model. What happens here is that a combination of two binomials can be mathematically reduced to a single binomial (in this case with a lower rate that the biased component). This is why the single-process model performs better in terms of LOO-CV, even though the mixture model is more realistic and provides a richer interpretation of the data",
    "chunk_id": "Adv_cognitive_modelling_chapter_9_mixture_models.json_chunk_6"
  },
  {
    "document_type": "online_article",
    "title": "Chapter 9 Mixture models",
    "author": "Riccardo Fusaroli",
    "source": "https://fusaroli.github.io/AdvancedCognitiveModeling2023/mixture-models.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". This is why the single-process model performs better in terms of LOO-CV, even though the mixture model is more realistic and provides a richer interpretation of the data. Theory should guide you in this case. Mixture models have found numerous applications in cognitive science. Here are a few examples that highlight their versatility: Attention and Vigilance: Modeling attentional lapses during sustained attention tasks as a mixture of focused and random responses. Memory: Representing recognition memory as a mixture of more implicit familiarity and more explicit recollection processes, each with distinct characteristics. *Decision Making: Modeling economic choices as combinations of heuristic and deliberative processes, with the proportion varying based on task demands. Learning: Capturing the transition from rule-based to automatic processing during skill acquisition, with the mixture weights shifting over time. Individual Differences: Identifying subgroups of participants who employ qualitatively different strategies to solve the same task. Mixture models represent a crucial step forward in our cognitive modeling toolkit, allowing us to capture the complexity and variability inherent in human behavior. Through this chapter, we’ve seen how combining multiple cognitive strategies within a single model can provide richer and more realistic accounts of decision-making processes. Several key insights emerge from our exploration of mixture models: Beyond Single-Process Simplifications: Mixture models allow us to move beyond the false choice between oversimplified single-strategy models and intractably complex specifications. By combining a small number of interpretable components, we can capture substantial behavioral complexity while maintaining mathematical and computational tractability. Bayesian Implementation: The Bayesian implementation of mixture models in Stan provides powerful tools for inference",
    "chunk_id": "Adv_cognitive_modelling_chapter_9_mixture_models.json_chunk_7"
  },
  {
    "document_type": "online_article",
    "title": "Chapter 9 Mixture models",
    "author": "Riccardo Fusaroli",
    "source": "https://fusaroli.github.io/AdvancedCognitiveModeling2023/mixture-models.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". Bayesian Implementation: The Bayesian implementation of mixture models in Stan provides powerful tools for inference. We can estimate not only the parameters of different cognitive strategies but also their relative contributions to behavior and how they might vary across individuals. Model Validation: Mixture models require careful attention to identifiability and validation. Through parameter recovery studies and posterior predictive checks, we’ve seen how to verify that our specifications can reliably recover true parameter values and generate realistic behavioral patterns.",
    "chunk_id": "Adv_cognitive_modelling_chapter_9_mixture_models.json_chunk_8"
  },
  {
    "document_type": "online_article",
    "title": "Chapter 2 Foundations",
    "author": "Riccardo Fusaroli",
    "source": "https://fusaroli.github.io/AdvancedCognitiveModeling2023/foundations.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": "This chapter introduces core modeling concepts through an unexpected lens: the physics of pizza stone heating. While this might seem far removed from cognitive science, it provides an insightful introduction to the challenges and methodologies of modeling complex phenomena. Do I even need to answer that question? Because pizza, obviously. In any case, understanding how humans think and make decisions is arguably one of the most complex challenges in science. Rather than diving directly into this complexity, we begin with a more tractable problem: modeling how a pizza stone heats up in an oven. This seemingly simple process introduces us to key modeling concepts: Through this concrete example, we can focus on understanding modeling principles without the added complexity of cognitive theory. This first chpater is a bit odd, in that it pushes you straight into the deep waters of a complex example. I don’t expect you to understand all the technicalities. But, by completing this tutorial, you will be able to better grasp the importance of generative modeling, that is, of modeling that is focused on the underlying mechanisms producing the data. On the side you might learn something about how to * Implement physics-based thermal modeling using R and Stan * Apply Bayesian inference to real-world temperature data * Compare different statistical models using posterior predictions * Create professional visualizations of temperature evolution * Make practical predictions about heating times under various conditions Oh, and you’ll probably get hungry as well! Required Packages In this study, we collected temperature measurements from a pizza stone in a gas-fired oven using an infrared temperature gun. Three different raters (N, TR, and R) took measurements over time to track how the stone heated up. Understanding how pizza stones heat up is crucial for achieving the perfect pizza crust, as consistent and sufficient stone temperature is essential for proper baking",
    "chunk_id": "Adv_cognitive_modelling_chapter_2_foundations.json_chunk_1"
  },
  {
    "document_type": "online_article",
    "title": "Chapter 2 Foundations",
    "author": "Riccardo Fusaroli",
    "source": "https://fusaroli.github.io/AdvancedCognitiveModeling2023/foundations.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". Understanding how pizza stones heat up is crucial for achieving the perfect pizza crust, as consistent and sufficient stone temperature is essential for proper baking. The measurements were taken as follows: Let’s visualize how the temperature evolves over time for each rater: Several interesting patterns emerge from our data: Heating Patterns: The temperature generally increases over time, but not uniformly. We observe some fluctuations that might be due to: Measurement Patterns by Rater Missing Data: Some measurements are missing (NA values), particularly in the later time points for Rater TR. This is common in real-world data collection and needs to be considered in our analysis. Let’s examine the rate of temperature change: This visualization reveals that the heating rate is highest in the first few minutes and gradually decreases as the stone temperature approaches the oven temperature. This aligns with Newton’s Law of Cooling/Heating, which we will explore in the next section. Before developing our physics-based model, let’s explore how standard statistical approaches perform in modeling our temperature data. We’ll implement two types of models using the brms package: a linear mixed-effects model and a lognormal mixed-effects model. Both models will account for variations between raters. First, let’s ensure we have a directory for our models and set up our computational parameters: We begin with a linear mixed-effects model, which assumes that temperature increases linearly with time but allows for different patterns across raters. This model includes both fixed effects (overall time trend) and random effects (rater-specific variations). The lognormal model accounts for the fact that temperature changes might be proportional rather than additive, and ensures predictions cannot go below zero (I don’t bring my oven out in the freezing cold!)",
    "chunk_id": "Adv_cognitive_modelling_chapter_2_foundations.json_chunk_2"
  },
  {
    "document_type": "online_article",
    "title": "Chapter 2 Foundations",
    "author": "Riccardo Fusaroli",
    "source": "https://fusaroli.github.io/AdvancedCognitiveModeling2023/foundations.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". Let’s compare how these models fit our data: I have seen worse models in my time, but they do seem to have important issues: The linear mixed-effects model assumes a constant rate of temperature change, which we can see is not at all accurate. The actual temperature increase is fast at the beginning and appears to slow down over time, particularly at higher temperatures. While this model has the advantage of simplicity, it is not likely to produce accurate predictions as it seem to fail to capture the underlying physics of heat transfer. The lognormal mixed-effects model is completely off. Further, the models produce some divergences, which is often a sign that they are not well suited to the data. I suggest that the issue is that neither model incorporates our knowledge of heat transfer physics, which suggests an exponential approach to equilibrium temperature. This limitation motivates our next section, where we’ll develop a physics-based model. Temperature evolution in a pizza stone follows Newton’s Law of Cooling/Heating. We’ll start by exploring this physical model before applying it to real data. The temperature evolution of a pizza stone in a gas-fired oven is governed by the heat diffusion equation, which describes how heat flows through solid materials: \\[\\rho c_p \\frac{\\partial T}{\\partial t} = k\\nabla^2T + Q\\] where:\\(\\rho\\)represents the stone’s density (kg/m3)\\(c_p\\)denotes specific heat capacity (J/kg·K)\\(T\\)is temperature (K)\\(t\\)represents time (s)\\(k\\)is thermal conductivity (W/m·K)\\(\\nabla^2\\)is the Laplacian operator\\(Q\\)represents heat input from the oven (W/m3) While this equation provides a complete description of heat flow, we can significantly simplify our analysis by applying the lumped capacitance model. This simplification assumes that the temperature throughout the pizza stone remains uniform at any given time - not perfect, but a reasonable assumption given the stone’s relatively thin profile and good thermal conductivity",
    "chunk_id": "Adv_cognitive_modelling_chapter_2_foundations.json_chunk_3"
  },
  {
    "document_type": "online_article",
    "title": "Chapter 2 Foundations",
    "author": "Riccardo Fusaroli",
    "source": "https://fusaroli.github.io/AdvancedCognitiveModeling2023/foundations.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". This approach reduces our model to: \\[\\frac{dT}{dt} = \\frac{hA}{mc_p}(T_{\\infty} - T)\\] where:\\(h\\)is the heat transfer coefficient (W/m2·K)\\(A\\)is the surface area exposed to heat (m2)\\(m\\)is the stone’s mass (kg)\\(T_{\\infty}\\)is the oven temperature (K) This simplified equation relates the rate of temperature change to the difference between the current stone temperature T and the flame temperature T∞. The coefficient h represents the heat transfer coefficient between the flame and stone, A is the stone’s surface area exposed to heat, m is its mass, and cp remains the specific heat capacity. To solve this differential equation, we begin by separating variables: \\[\\frac{dT}{T_{\\infty} - T} = \\left(\\frac{hA}{mc_p}\\right)dt\\] Integration of both sides yields: \\[-\\ln|T_{\\infty} - T| = \\left(\\frac{hA}{mc_p}\\right)t + C\\] where C is an integration constant. Using the initial condition\\(T = T_i\\)at\\(t = 0\\), we can determine the integration constant: \\[C = -\\ln|T_{\\infty} - T_i|\\] Substituting this back and solving for temperature gives us: \\[T = T_{\\infty} + (T_i - T_{\\infty})\\exp\\left(-\\frac{hA}{mc_p}t\\right)\\] For practical reasons, we combine physical parameters into a single coefficient\\(\\theta\\): \\[HOT = \\frac{hA}{mc_p}\\]Giving our working equation:\\[T = T_{\\infty} + (T_i - T_{\\infty})\\exp(-HOT * t)\\] This equation retains the essential physics while providing a practical model for analyzing our experimental data. The HOT coefficient encapsulates the combined effects of heat transfer efficiency, stone geometry, and material properties into a single parameter that determines how quickly the stone approaches the flame temperature. Having established the theoretical foundation for our heat transfer model, we now move to its practical implementation. We will use Stan to create a Bayesian implementation of our physics-based model, allowing us to account for measurement uncertainty and variation between raters. First, we prepare our data for the Stan model",
    "chunk_id": "Adv_cognitive_modelling_chapter_2_foundations.json_chunk_4"
  },
  {
    "document_type": "online_article",
    "title": "Chapter 2 Foundations",
    "author": "Riccardo Fusaroli",
    "source": "https://fusaroli.github.io/AdvancedCognitiveModeling2023/foundations.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". First, we prepare our data for the Stan model. Our model requires initial temperatures, time measurements, and observed temperatures from each rater: Next, we implement our physics-based model in Stan. The model incorporates our derived equation while allowing for rater-specific heating coefficients: The Stan implementation translates our mathematical model into a computational framework. We assign informative priors to our parameters based on physical understanding: the heating coefficient (HOT) is expected to be small but positive, while measurement error (sigma) follows an exponential distribution to ensure positivity while allowing for varying levels of uncertainty between raters. To visualize our model’s predictions and assess its performance, we extract posterior samples and generate predictions across our time range: Our implementation combines the theoretical understanding developed in Part 3 with practical considerations for real-world data analysis. The model accounts for measurement uncertainty while maintaining the fundamental physics of heat transfer, providing a robust framework for understanding pizza stone temperature evolution. Having implemented our physics-based model, we can now analyze its predictions and develop practical insights for pizza stone temperature management. A key question for pizza making is how long it takes to reach optimal cooking temperatures under different conditions. We begin by creating a function that calculates the time needed to reach a target temperature: To understand heating times across different oven conditions, we examine how varying flame temperatures affect the time needed to reach pizza-making temperatures. We extract the heating coefficients from our fitted model and analyze temperature scenarios: Our analysis reveals several important insights for practical pizza making. First, the heating time decreases nonlinearly with flame temperature, showing diminishing returns at very high temperatures",
    "chunk_id": "Adv_cognitive_modelling_chapter_2_foundations.json_chunk_5"
  },
  {
    "document_type": "online_article",
    "title": "Chapter 2 Foundations",
    "author": "Riccardo Fusaroli",
    "source": "https://fusaroli.github.io/AdvancedCognitiveModeling2023/foundations.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". First, the heating time decreases nonlinearly with flame temperature, showing diminishing returns at very high temperatures. We can also observe differences between raters in their measured heating times. These variations likely stem from differences in measurement technique and location on the stone, highlighting the importance of consistent temperature monitoring practices. For practical application, we can provide specific heating guidelines based on our model. At a typical flame temperature of 800°C, the model predicts it will take approximately 20-30 minutes to reach optimal pizza-making temperature, assuming room temperature start. However, this time can vary significantly based on: Can we really wait that long? The journey from modeling a heating pizza stone to understanding cognitive processes might seem unusual, but it illustrates fundamental principles that will guide us throughout this course. Through this seemingly simple physics problem, we have encountered the core challenges that cognitive scientists face daily. Just relying on standard statistical models is not enough. We need to understand the underlying generative processes. We discovered how choosing the right level of analysis shapes our understanding - just as we simplified complex heat equations into workable models, cognitive scientists must decide which aspects of the mental processes to model explicitly and which to abstract. We learned that even well-understood physical processes require careful statistical treatment, foreshadowing the challenges we will face with more complex cognitive phenomena. The pizza stone experiment also demonstrated the importance of rigorous methodology. We saw how multiple measurements from different raters revealed variability in our data, leading us to consider measurement error and individual differences - themes that will become crucial when studying human behavior",
    "chunk_id": "Adv_cognitive_modelling_chapter_2_foundations.json_chunk_6"
  },
  {
    "document_type": "online_article",
    "title": "Chapter 2 Foundations",
    "author": "Riccardo Fusaroli",
    "source": "https://fusaroli.github.io/AdvancedCognitiveModeling2023/foundations.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". Our exploration of different statistical approaches, from simple linear models to more sophisticated Bayesian frameworks, established a foundation for the modeling techniques we will develop throughout this course. Perhaps most importantly, this chapter starts showing that successful modeling requires balancing competing demands. We must weigh theoretical complexity against practical utility, statistical sophistication against interpretability, and mathematical elegance against real-world applicability. These trade-offs will become even more prominent as we move into modeling cognitive processes. As we progress through this course, we will encounter increasingly complex cognitive phenomena. The principles we learned here - careful data collection, thoughtful model specification, rigorous validation, and balanced interpretation - will serve as our guide. While human cognition presents challenges far beyond those of heating pizza stones, the fundamental approach remains the same: start with clear observations, build theoretically motivated models, and test them systematically against data. In the next chapter, we will begin applying these principles directly to cognitive processes, starting with simple decision-making tasks. The mathematical tools and statistical frameworks introduced here will provide the foundation for understanding how humans process information and make choices. Finally, I hope you are hungry now. I know I am. Let’s go and make some pizza!",
    "chunk_id": "Adv_cognitive_modelling_chapter_2_foundations.json_chunk_7"
  },
  {
    "document_type": "book",
    "title": "The The generalized context model: an exemplar model of classification",
    "author": "Robert M. Nosofsky",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\The_generalized_context_model_an_exempla.pdf",
    "date_published": "2023-05-11",
    "keywords": "",
    "flag": "",
    "chunk_text": "18 Model description Conceptual overview According to the generalized context model (GCM) (Nosofsky, 1986 ), people represent categories by storing individual exemplars (or examples) in memory, and classify objects based on their similarity to these stored exemplars. For example, the model assumes that people represent the category of ‘birds’ by storing in memory the vast collection of different sparrows, robins, eagles, ostriches (and so forth) that they have experenced. If an object is sufficiently similar to some of these bird exemplars, then the person would tend to classify the object as a ‘bird’. This exeplar view of categorization contrasts dramatically with major alternative approaches that assume that people form abstract summary representtions of categories, such as rules or idealized prototypes. The standard version of the GCM adopts a multidimensional scaling (MDS) approach to modelling similarity relations among exemplars (Shepard, 1958 , 1987 ). In this approach, exemplars are represented as points in a multidimensional psychological space . Similarity between exemplars is a decreasing function of their distance in the space. In many applications, a first step in the modelling is to conduct similarity-scaling studies to derive MDS solutions for the exemplars and to discover their locations in the multidimensional similarity space (Nosofsky, 1992b ). A crucial assumption in the modelling, however, is that similarity is not an invariant relation, but a highly context-dependent one. To take an example from Medin and Schaffer ( 1978 ), humans and mannequins may be judged as highly similar in a context that emphasizes strutural appearance, but would be judged as highly dissimilar in a context that emphasizes vitality. In the GCM, the context-dependent nature of 2 The generalized context model: an exemplar model of classification Robert M",
    "chunk_id": "Adv_cognitive_modelling_the_generalized_context_model_an_exempla_page-1-22.json_chunk_1"
  },
  {
    "document_type": "book",
    "title": "The The generalized context model: an exemplar model of classification",
    "author": "Robert M. Nosofsky",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\The_generalized_context_model_an_exempla.pdf",
    "date_published": "2023-05-11",
    "keywords": "",
    "flag": "",
    "chunk_text": ". In the GCM, the context-dependent nature of 2 The generalized context model: an exemplar model of classification Robert M. Nosofsky The writing of this chapter was supported by grants FA9550–08–1–0486 from the Air Force Office of Scientific Research and MH48494 from the National Institute of Mental Health. GCM 19 similarity is modelled in terms of a set of selective-attention weights that systematically modify the structure of the psychological space in which the exemplars are embedded (Carroll & Wish, 1974 ). As will be illutrated below, the weights serve to ‘stretch’ the psychological space along highly attended, relevant dimensions, and to ‘shrink’ the space along unattended irrelevant dimensions. This stretching and shrinking can have profound influences on similarity relations among exemplars and on the resulting classification predictions from the model. Finally, the model assumes that the individual exemplars may be stored in memory with differing memory strengths . The memory strength of an exemplar may be influenced by factors such as frequency of presentation, recency of presentation, different forms of feedback provided during learning, and so forth. When a test item is presented so as to be classified, the exemplars that are most likely to be retrieved (and therefore to influence most strongly the classification decision) are those that are highly similar to the test item and that have high memory strengths. However, because exemplar retrieval is a probabilitic process, all exemplars stored in memory may influence classification decision making. The conceptual ideas summarized above are illustrated schematially in Figure 2.1 . Consider first the top panel. We suppose that there are two categories, A and B, with five exemplars in each category. The exemplars are composed of two dimensions. Exemplars A2 and B4 are close together in the space, so are highly similar to one another; whereas exemplars A5 and B2 are far apart, so are highly dissimilar",
    "chunk_id": "Adv_cognitive_modelling_the_generalized_context_model_an_exempla_page-1-22.json_chunk_2"
  },
  {
    "document_type": "book",
    "title": "The The generalized context model: an exemplar model of classification",
    "author": "Robert M. Nosofsky",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\The_generalized_context_model_an_exempla.pdf",
    "date_published": "2023-05-11",
    "keywords": "",
    "flag": "",
    "chunk_text": ". Exemplars A2 and B4 are close together in the space, so are highly similar to one another; whereas exemplars A5 and B2 are far apart, so are highly dissimilar. (The symbols used to illustrate the exemplars vary in their size in order to illustrate that the exemplars may be stored in memory with differing strengths.) Imagine that the observer is asked to classify test stimulus i into one of the two categories. According to the model, the observer sums the simlarity of test item i to all of the exemplars of Category A and to all of the exemplars of Category B (weighted by the memory strengths of the examplars), and the classification decision is based on the relative manitude of these summed similarities. In the top panel of Figure 2.1 , test item i is roughly equally similar to the exemplars of the two categories, so the observer would classify the test item into the two categories with roughly equal probability. Notice, however, that the horizontal dimension is far more relevant than is the vertical dimension for discriminating between the members of the two categories. (That is, all exemplars of Category B tend to have large values along the horizontal dimension, whereas all exemplars of Category A tend to have small values along the horizontal dimension.) Presumably, an experienced observer would learn this aspect of the Robert M. Nosofsky 20 category structure, so would learn to give greater attention to the more relevant horizontal dimension than to the less relevant vertical dimesion. The bottom panel of Figure 2.1 illustrates the same category struture, but now assuming the above-described selective-attention strategy. The space is ‘stretched’ along the more-attended horizontal dimension and is ‘shrunk’ along the less-attended vertical dimension. In effect, by implementing this selective-attention strategy, the observer is attempting to optimize similarity relations for the given classification task (Nosofsky, 1984 , 1986 )",
    "chunk_id": "Adv_cognitive_modelling_the_generalized_context_model_an_exempla_page-1-22.json_chunk_3"
  },
  {
    "document_type": "book",
    "title": "The The generalized context model: an exemplar model of classification",
    "author": "Robert M. Nosofsky",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\The_generalized_context_model_an_exempla.pdf",
    "date_published": "2023-05-11",
    "keywords": "",
    "flag": "",
    "chunk_text": ". In effect, by implementing this selective-attention strategy, the observer is attempting to optimize similarity relations for the given classification task (Nosofsky, 1984 , 1986 ). There is now greater separation between the exemplars of contrasting categories (lowered between-category similarity), yet less separation among the exemplars within each category (heightened witin-category similarity). Furthermore, note that this selective-attention strategy has a profound influence on the classification predictions from the model. In the top panel, item i was roughly equally similar to the exemplars of the two categories; however, following selective attention to the relevant dimension (bottom panel), the test item is now far more similar to the exemplars of Category A. Thus, in the latter situation, the exemplar model predicts that the test item would be classified into Category A with high probability. A5 A5 A3 A1 A3 A2 A4 B4 B1 B5 B2 B3 A1 A2 B5 B3 B2 B4 B1 i i A4 Figure 2.1 Schematic illustration of a category structure to explain the workings of the GCM. The top panel illustrates the category structure with equal attention to both dimensions. The bottom panel illustrates the structure following selective attention to the horizontal dimension. GCM 21 Computational assumptions In this section I present a brief description of how the GCM is formaized. The description assumes that there is an initial training phase in which observers are presented with n unique training exemplars. The training phase is followed by a test phase in which both training items and new transfer items might be presented. On each trial during the test phase, the observer classifies the test item into one of K N categories",
    "chunk_id": "Adv_cognitive_modelling_the_generalized_context_model_an_exempla_page-1-22.json_chunk_4"
  },
  {
    "document_type": "book",
    "title": "The The generalized context model: an exemplar model of classification",
    "author": "Robert M. Nosofsky",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\The_generalized_context_model_an_exempla.pdf",
    "date_published": "2023-05-11",
    "keywords": "",
    "flag": "",
    "chunk_text": ". On each trial during the test phase, the observer classifies the test item into one of K N categories. According to the model, the probability with which item i is classified into Category J during the test phase is given by: P i V b V J jJ j n ij K kK ik k n K K s s N J b | ( ) =                   = = = ∑ ∑ 1 1 1 γ γ ∑ , (1) where s ij denotes the similarity between item i and exemplar j ; V jJ denotes the memory strength of exemplar j with respect to Category J ; γ is a freely estimated response-scaling parameter (0 < γ ); and b J (0 < b J ) denotes the response-bias for Category J . Thus, according to the model, the observer sums the similarity of item i to all exemplars j belonging to Category J , weighted by their Category J memory strengths (and by any differential response bias). This summed similarity constitutes the ‘evidence’ in favour of Category J . This evidence is then divided by the summed evidence for all of the categories to predict the CategorJ clasification probability. The parameter γ in Equation 1 is a response-scaling parameter that influences the degree of determinism in classification responding (Ashby & Maddox, 1993 ; Nosofsky & Zaki, 2002 ). When γ = 1, the observer responds probabilistically by ‘probability matching’ to the reltive summed similarities of each category; whereas when γ grows greater than 1, observers respond more deterministically with the category that yields the largest summed similarity. The memory-strength values ( V jJ ) in Equation 1 are typically not free parameters but rather are given by the nature of the experimental design. Usually, they are set equal to the relative frequency with which each exemplar j is provided with Category J feedback during the classification training phase. (In the most usual classification learning paradigms, the exemplars are presented with equal frequency and each exemplar is assigned to only a single category. In that simple case, all exemplars j that are assigned to Category J receive Robert M",
    "chunk_id": "Adv_cognitive_modelling_the_generalized_context_model_an_exempla_page-1-22.json_chunk_5"
  },
  {
    "document_type": "book",
    "title": "The The generalized context model: an exemplar model of classification",
    "author": "Robert M. Nosofsky",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\The_generalized_context_model_an_exempla.pdf",
    "date_published": "2023-05-11",
    "keywords": "",
    "flag": "",
    "chunk_text": ". In that simple case, all exemplars j that are assigned to Category J receive Robert M. Nosofsky 22 memory strengths equal to 1; whereas the memory strength of an exeplar with respect to all its unassigned categories is equal to 0.) To apply Equation 1 , one needs to compute the similarity between item i and each exemplar j , s ij . In the standard version of the GCM, each exemplar j is represented as a single point in an M -dimensional psychlogical space. Let x jm denote the value of exemplar j on Dimension m . The distance between item i and exemplar j is given by the weighted Minkowski power model , ij m im jm r m M r w x x d = −           = ∑ | | , / 1 1 (2) where the value r determines the form of the distance metric. In sitations involving highly separable-dimension stimuli (Garner, 1974 ; Shepard, 1964 ), the value r is typically set equal to 1, which yields a city-block distance metric . By contrast, in situations involving integral-dimension stimuli, the value r is set equal to 2, which yields a Euclidean distance metric . The w m values in Equation 2 are freely estimated attention-weight parameters (with 0 ≤ w m ≤ 1, and ∑ w m = 1), reflecting the degree of attention that observers give to each dimension m in making their classification judgments. 1 A geometric interpreation for the operation of the attention weights is that of stretching and shrinking the psychological space along its component dimesions (see Figure 2.1 ). Finally, the similarity between item i and exemplar j is given by ij cd s ij p e = − , (3) where c is a freely estimated sensitivity parameter that reflects the rate at which similarity declines with distance. When c is large, the similaity gradient is steep; that is, similarity falls off rapidly with increasing distance in the space. In this situation, the GCM acts very much like a nearest-neighbour classifier (i.e., one in which classification decisions are based primarily on the category membership of a test item’s neaest neighbour)",
    "chunk_id": "Adv_cognitive_modelling_the_generalized_context_model_an_exempla_page-1-22.json_chunk_6"
  },
  {
    "document_type": "book",
    "title": "The The generalized context model: an exemplar model of classification",
    "author": "Robert M. Nosofsky",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\The_generalized_context_model_an_exempla.pdf",
    "date_published": "2023-05-11",
    "keywords": "",
    "flag": "",
    "chunk_text": ". When c is small, the similarity gradient is shallow, and 1 More precisely, the weights measure the span of each dimension relative to some prior, ‘neutral’ scaling or physical specification of the stimuli. To the extent that a prior scaling was obtained under conditions in which each dimension was equally relevant, then the weights estimated in a classification task can be interpreted in terms of the amount of ‘attention’ devoted to each dimension for purposes of the classification. GCM 23 numerous exemplars may make major contributions to the classification decision. The value p in Equation 3 determines the shape of the function relating similarity to distance. In most cases, p is set equal to one, which yields an exponential relation between similarity and psychological ditance (Shepard, 1987 ). In situations involving highly confusable stiuli, however, p is sometimes set equal to 2, yielding a Gaussian relation between similarity and distance (Nosofsky, 1985 ; for a theoretical intepretation, see Ennis, 1988 ). In sum, the free parameters used for fitting the GCM to classifiction data are the sensitivity parameter c in Equation 3 , the set of attetion weights w m in Equation 2 ; and the response-bias parameters and response-scaling parameter γ in Equation 1 . (Because they can be constrained to sum to one, there are only M − 1 freely varying attetion weights and K N − 1 freely varying response-bias parameters.) All other quantities, including the x im coordinate values (Equation 2 ), the V kK memory strengths (Equation 1 ), the distance metric (value of r in Equation 2 ), and the similarity gradient (value of p in Equation 3 ) are fixed by the nature of the experimental design or are derived from indpendent sources. Motivation The GCM is a generalization of the original context model proposed by Medin and Schaffer ( 1978 ). Nosofsky ( 1984 , 1986 ) integrated the Medin–Schaffer context model with classic theories developed in the areas of choice and similarity",
    "chunk_id": "Adv_cognitive_modelling_the_generalized_context_model_an_exempla_page-1-22.json_chunk_7"
  },
  {
    "document_type": "book",
    "title": "The The generalized context model: an exemplar model of classification",
    "author": "Robert M. Nosofsky",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\The_generalized_context_model_an_exempla.pdf",
    "date_published": "2023-05-11",
    "keywords": "",
    "flag": "",
    "chunk_text": ". Nosofsky ( 1984 , 1986 ) integrated the Medin–Schaffer context model with classic theories developed in the areas of choice and similarity. This integration provided a firm theoretical foundation for the context model and allowed the original version to be extended to more widely varying classification paradigms. For example, the original context model was applied in highly simplified domains involving stimuli that varied along only binary-valued, separable dimesions. By comparison, most applications of the GCM are in continuoudimension domains. In addition, the GCM is readily applied to predict classification performance involving integral-dimension stimuli as well as separable-dimension stimuli (Nosofsky, 1987 ). Moreover, when the GCM is used in combination with MDS approaches (in order to locate exemplars in psychological similarity spaces), it can be applied to prdict classification performance in rich and complex domains in which the underlying stimulus dimensions may not be known (e.g., Shin & Nosofsky, 1992 ). In the original version of the context model, Medin and Schaffer proposed what is essentially Equation 1 as a choice rule for classifiction. (Their equation did not include the memory-strength terms, bias Robert M. Nosofsky 24 parameters, or the γ response-scaling parameter.) However, they did not provide a strong justification for the use of the choice rule beyond the fact that it seemed to work. Nosofsky ( 1984 , 1986 ) provided a deeper foundation for the context-model response rule by noting a strong reltion between it and the classic similarity-choice model (SCM) for predicing confusions in identification paradigms (Luce, 1963 ; Shepard, 1957 ). I briefly review this motivating relation here. In an identification paradigm, there are n distinct stimuli, and each stimulus is assigned a unique response",
    "chunk_id": "Adv_cognitive_modelling_the_generalized_context_model_an_exempla_page-1-22.json_chunk_8"
  },
  {
    "document_type": "book",
    "title": "The The generalized context model: an exemplar model of classification",
    "author": "Robert M. Nosofsky",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\The_generalized_context_model_an_exempla.pdf",
    "date_published": "2023-05-11",
    "keywords": "",
    "flag": "",
    "chunk_text": ". I briefly review this motivating relation here. In an identification paradigm, there are n distinct stimuli, and each stimulus is assigned a unique response. The data are summarized in an n x n identification confusion matrix (see left panel of Figure 2.2 ), where each cell ( i , j ) of the matrix gives the conditional probability with which stimulus i is identified as stimulus j . The SCM is one of the leading descriptive models for predicting confusion probabilities in identification paradigms. According to the SCM, the probability with which stimulus i is identified as stimulus j is given by P i b s b s j ij k ik k n ( | ) , j = = ∑ 1 (4) where b j (0 < b j ) is the bias for response j , and where s ij (0 < s ij , s ij = s ij ) is the similarity between stimuli i and j . In a classification paradigm, the n stimuli are assigned to one of K N categories ( K N < n ). The data are summarized in an n × K N confusion matrix, where cell ( i , J ) of the matrix gives the conditional probability with which stimulus i is classified in Category J . An illustration with K N = 2 is provided in the right panel of Figure 2.2 . An intuitively compelling idea for predicting classification confusions from identification confusions was first proposed by Shepard , Hovland , and Jenkins ( 1961 ). The idea was that, in a classification paradigm, any time a stimulus is confused with another member of its own category, it would result in a correct classification response. Only between-class stimulus confusions would result in classification errors. Coined the mapping hypothesis 2 by Nosofsky ( 1986 ), the idea is illustrated schemaically in Figure 2.2 . In the figure, we imagine that stimuli 1–4 belong to Category A, whereas stimuli 5–8 belong to Category B. As illustrated in Figure 2.2 , according to the mapping hypothesis, stimulus 3 would 2 Identification paradigms involve a one-to-one mapping of stimuli onto responses. Classification paradigms involve a many-to-one mapping of stimuli onto responses",
    "chunk_id": "Adv_cognitive_modelling_the_generalized_context_model_an_exempla_page-1-22.json_chunk_9"
  },
  {
    "document_type": "book",
    "title": "The The generalized context model: an exemplar model of classification",
    "author": "Robert M. Nosofsky",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\The_generalized_context_model_an_exempla.pdf",
    "date_published": "2023-05-11",
    "keywords": "",
    "flag": "",
    "chunk_text": ". Classification paradigms involve a many-to-one mapping of stimuli onto responses. The mapping hypothesis allows one to use data from one-to-one mapping paradigms to predict performance in many-to-one mapping paradigms. GCM 25 receive the correct response in the classification paradigm whenever it is confused with stimuli 1–4 in the identification paradigm. More generally, if the mapping hypothesis is correct, then the proability that stimulus i is classified into Category J would be found by summing over the probabilities that it is confused with any member of Category J in the identification paradigm. It is straightforward to show that, if the SCM (Equation 4 ) describes these identification confusion probabilities, then the predicted classification probabilities are given by what is essentially Equation 1 , i.e., the context-model response rule. The main difference is that because the response set has changed, the individual-item response bias parameters are replaced with categorlevel response-bias parameters. 3 Figure 2.2 Left panel: an 8 × 8 stimulus-response (S-R) confusion matrix for an identification experiment. Right panel: an 8 × 2 S-R confusion matrix for a classification experiment (the same stimuli are used as in the identification task). Stimuli 1–4 are assigned to Category A, and stimuli 5–8 are assigned to Category B. According to the mapping hypothesis, one predicts the probability that stimulus 3 is classified in Category A by summing over the probabilities that stimulus 3 is identified as either stimulus 1, 2, 3, or 4 in the identification task. (From Nosofsky ( 1986 ), published by APA. Reprinted with permission.) 3 A further requirement for the mapping hypothesis to hold is that the γ response-scaling paameter be equal to one, which was true in the original formulation of the context model. Robert M. Nosofsky 26 Although intuitively compelling, Shepard et al",
    "chunk_id": "Adv_cognitive_modelling_the_generalized_context_model_an_exempla_page-1-22.json_chunk_10"
  },
  {
    "document_type": "book",
    "title": "The The generalized context model: an exemplar model of classification",
    "author": "Robert M. Nosofsky",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\The_generalized_context_model_an_exempla.pdf",
    "date_published": "2023-05-11",
    "keywords": "",
    "flag": "",
    "chunk_text": ". Robert M. Nosofsky 26 Although intuitively compelling, Shepard et al . ( 1961 ) observed sytematic failures in using the mapping hypothesis to predict classification confusions on the basis of identification confusions. Although a full dicussion goes beyond the scope of this chapter, Nosofsky ( 1984 , 1986 ) proposed that the mapping hypothesis not be abandoned completely. The key idea was that the similarity parameters that operate in Equations 1 and 4 may change systematically across the identification and classfication paradigms, because of the operation of the selective-attention processes depicted in Figure 2.1 . Thus, Nosofsky ( 1986 ) proposed that rather than there being a direct mapping relation, a more abstract indiect mapping relation may connect identification and classification peformance. According to this proposal, performance in both paradigms is governed by similarity relations among distinct exemplars, as formalized in Equations 1 and 4 . However, these inter-exemplar similarity relations change systematically across the paradigms because of the operation of selective attention. Nosofsky ( 1984 , 1986 , 1987 ) provided strong suport for this idea in theoretical and empirical work that investigated reltions between identification and classification performance. The motivation for the similarity equations used in the GCM (Equations 2 and 3 ) grows directly from decades of research and theoretical development in the area of similarity. MDS approaches to modelling similarity have long been among the most general and sucessful approaches in the field. Indeed, so successful have been those approaches that some of the discovered regularities have been proposed as candidates for universal laws of psychological generalization (Shepard, 1987 )",
    "chunk_id": "Adv_cognitive_modelling_the_generalized_context_model_an_exempla_page-1-22.json_chunk_11"
  },
  {
    "document_type": "book",
    "title": "The The generalized context model: an exemplar model of classification",
    "author": "Robert M. Nosofsky",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\The_generalized_context_model_an_exempla.pdf",
    "date_published": "2023-05-11",
    "keywords": "",
    "flag": "",
    "chunk_text": ". Indeed, so successful have been those approaches that some of the discovered regularities have been proposed as candidates for universal laws of psychological generalization (Shepard, 1987 ). In particular, there is a great deal of support for the idea that psychological distance relations among integral-dimension stimuli are well described by embedding the stimuli in multidimensional Euclidean spaces, whereas psychological distance relations among separabldimension stimuli are better approximated by a city-block distance metric . Furthermore, Shepard ( 1987 ) reviewed decades of research that point to an approximately exponential relation (Equation 3 with p = 1) between similarity, measured in terms of probability of stimulus genealization, and distance in these psychological spaces. In their original formulation of the context model, Medin and Schaffer ( 1978 ) proposed an inter-dimensional multiplicative rule for computing stimulus similarity. The similarity between stimuli i and j was given by ij m i j m M s s m = = ∏ δ ( , ) , 1 (5) GCM 27 where s m (0 ≤ s m ≤ 1) is a freely estimated dimensiom similarity paraeter; δ is an indicator variable set equal to 1 if stimuli i and j mismatch on dimension m , and set equal to zero if they match on dimension m . Thus, the overall similarity between stimuli i and j is simply the product of their similarities along each of their mismatching dimensions. This intedimensional multiplicative rule is a special case of the MDS approach to modelling similarity that is embodied in Equations 2 and 3 of the GCM. In particular, an inter-dimensional multiplicative rule arises whenever p = r in Equations 2 and 3 (see Nosofsky, 1986 , p. 42, for further discusion). The particular highly constrained rule used by Medin and Schaffer (Equation 5 ) arises when, in addition, the stimuli vary along a set of independent, binary-valued dimensions",
    "chunk_id": "Adv_cognitive_modelling_the_generalized_context_model_an_exempla_page-1-22.json_chunk_12"
  },
  {
    "document_type": "book",
    "title": "The The generalized context model: an exemplar model of classification",
    "author": "Robert M. Nosofsky",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\The_generalized_context_model_an_exempla.pdf",
    "date_published": "2023-05-11",
    "keywords": "",
    "flag": "",
    "chunk_text": ". The particular highly constrained rule used by Medin and Schaffer (Equation 5 ) arises when, in addition, the stimuli vary along a set of independent, binary-valued dimensions. However, as explained above, use of the MDS approach in the GCM allows for a far more general application of the model to diverse classification domains. Because of its combination of assumptions involving an exemplabased category representation and a non-linear similarity rule , the GCM is highly sensitive to effects of specific exemplars and to withiclass correlational structure in categories (for extensive discussion, see, for example, Medin and Schaffer, 1978 ; Nosofsky, 1992a ). A variety of experiments have been reported for illustrating the importance of such sensitivity. For example, in some studies, category structures have been designed in which an individual stimulus i is more similar than is stimlus j to the prototype (central tendency) of their category; yet, stimulus j has high similarity to specific exemplars of the category, whereas stimlus i does not. In such studies, it is often found that subjects classify more accurately the stimulus with high exemplar-specific similarity than the stimulus with high similarity to the prototype (for reviews and examples, see Nosofsky, 1992a , 2000 ; Nosofsky & Zaki, 2002 ), Exemplar models with non-linear similarity rules (such as the GCM) account naturally for such effects, whereas major alternative models, such as prototype models, do not. Implementation recommendations In the present section I present some practical advice on implemening the GCM. The key free parameters that are almost always estimated are the sensitivity parameter ( c ) in Equation 3 and the attention-weight parameters (the w m ) in Equation 2 . An interesting working hypothesis is that, with learning, the participant may adopt a set of ideal-observer weights, for example, a set of weights that would allow the participant to maximize his or her percentage of correct classifications",
    "chunk_id": "Adv_cognitive_modelling_the_generalized_context_model_an_exempla_page-1-22.json_chunk_13"
  },
  {
    "document_type": "book",
    "title": "The The generalized context model: an exemplar model of classification",
    "author": "Robert M. Nosofsky",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\The_generalized_context_model_an_exempla.pdf",
    "date_published": "2023-05-11",
    "keywords": "",
    "flag": "",
    "chunk_text": ". Thus, it is interesting to compare the best-fitting attention-weight parameters to Robert M. Nosofsky 28 the ideal-observer weights. In many situations, the best-fitting weights turn out to approximate the ideal-observer weights (e.g., Nosofsky, 1984 , 1986 , 1991b ). Unless there are strong experimental manipulations involving diferential category payoffs or frequencies, the response-bias parameters tend not to contribute substantially to the model fits, and can generally be set equal to one. The γ response-scaling parameter (Equation 1 ) is important when modelling performance at the individual-observer level, to allow the model to capture the deterministic response strategies that individual observers sometimes use (e.g., McKinley & Nosofsky, 1995 ; Nosofsky & Zaki, 2002 ). Practical experience suggests, however, that in fitting averaged data, γ can be held fixed at one without much loss in predictive accuracy. As discussed in the introduction, in situations involving fairly discriinable stimuli, an exponential decay function for relating similarity to distance ( p = 1 in Equation 3 ) is always assumed. For integral-dimension stimuli, a Euclidean metric ( r = 2) is assumed in Equation 2 ; whereas for highly separable-dimension stimuli, a city-block metric ( r = 1) is assumed. By contrast, in situations involving highly confusable percetual stimuli, the values p = 2 and r = 2 tend to provide much better fits. (These parameter settings are probably reflecting extensive perceptual noise in the stimulus representations that exists in high-confusability situations – see Ennis ( 1988 ) for further discussion.) The memory-strength values (Equation 1 ) are generally not treated as free parameters. Instead, they are usually set proportional to the relative frequency with which each stimulus is presented in combination with associated category feedback during the training phase of the experment",
    "chunk_id": "Adv_cognitive_modelling_the_generalized_context_model_an_exempla_page-1-22.json_chunk_14"
  },
  {
    "document_type": "book",
    "title": "The The generalized context model: an exemplar model of classification",
    "author": "Robert M. Nosofsky",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\The_generalized_context_model_an_exempla.pdf",
    "date_published": "2023-05-11",
    "keywords": "",
    "flag": "",
    "chunk_text": ". Instead, they are usually set proportional to the relative frequency with which each stimulus is presented in combination with associated category feedback during the training phase of the experment. In cases in which one models trial-by-trial performance data, a memory-strength value is often attached to each individual exemplar presented on each trial; in this case, the memory strengths are assumed to decay exponentially with lag of presentation of the exemplars (e.g., McKinley & Nosofsky, 1995 ). In general, the GCM is fitted to classification choice-probability data by using a maximum-likelihood criterion, under the assumption that the distribution of responses into categories is multinomial in form (see Nosofsky, 1989 , for examples). Hierarchically nested versions of the model, in which some parameters are held fixed at default values, can be tested against the full version of the model by using standard likelihooratio techniques (see Nosofsky, 1989 , for examples) or alternative metods such as AIC or BIC that penalize models for their number of free parameters. Because analytic solutions for the maximum-likelihood parameters are generally not available except in exceedingly simple cases, GCM 29 computer search is used for locating the best-fitting parameters. As is the case for fitting any highly nonlinear model to data, multiple starting configurations should be used in the parameter searches to guard against local minima. The GCM has been a highly successful and widely applied model. In addition, its free parameters are easily interpretable and provide measurments of psychological processes of fundamental interest. For example, researchers may be interested in the extent to which different populations of subjects adopt alternative patterns of selective attention to the dimesions that compose a set of stimuli (e.g., Viken et al ., 2002 ). The derived attention-weight parameters from the model provide such information",
    "chunk_id": "Adv_cognitive_modelling_the_generalized_context_model_an_exempla_page-1-22.json_chunk_15"
  },
  {
    "document_type": "book",
    "title": "The The generalized context model: an exemplar model of classification",
    "author": "Robert M. Nosofsky",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\The_generalized_context_model_an_exempla.pdf",
    "date_published": "2023-05-11",
    "keywords": "",
    "flag": "",
    "chunk_text": ". The derived attention-weight parameters from the model provide such information. For these reasons, an important recent development is the availability of a general-purpose computer package for conducting Bayesian analyses of the GCM (Vanpaemel, 2009 ; see also Lee, 2008 ). The package prvides estimates of the posterior distributions of the model’s parameters to allow for easy inference and interpretation of the effects of different experimental manipulations on psychological processing. Application to an example An example application of the GCM to a previously published data set (Nosofsky , 1989 ) is briefly reviewed in Figure 2.3 and Table 2.1 . Because the fits are to averaged data, they should be considered as merely illustrtive. The stimuli were a set of semicircles with an embedded radial line. The semicircles varied orthogonally in their size (four levels) and in the angle or orientation of the radial line (four levels) to create a 16-member stimulus set. Subjects were tested in four different categorization condtions, which are illustrated schematically in Figure 2.3 . In the figure, the columns of each 4 × 4 grid correspond to the different levels of angle, and the rows correspond to the different levels of size. Cells that are marked in their centre with a boldface 1 represent training exemplars of Category 1, whereas cells marked with a 2 were training exemplars of Category 2. Unmarked cells were unassigned transfer stimuli. During an initial training phase, subjects were presented with only the traiing exemplars and were provided with trial-by-trial corrective feedback. During a subsequent test phase, subjects were presented with both traiing and transfer stimuli. Feedback continued to be provided on trials in which training exemplars were presented, but was withheld on trials in which unassigned transfer stimuli were presented. As can be seen in the figure, to provide evidence of generality, a vaiety of different category structures were tested",
    "chunk_id": "Adv_cognitive_modelling_the_generalized_context_model_an_exempla_page-1-22.json_chunk_16"
  },
  {
    "document_type": "book",
    "title": "The The generalized context model: an exemplar model of classification",
    "author": "Robert M. Nosofsky",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\The_generalized_context_model_an_exempla.pdf",
    "date_published": "2023-05-11",
    "keywords": "",
    "flag": "",
    "chunk_text": ". As can be seen in the figure, to provide evidence of generality, a vaiety of different category structures were tested. The Size and Angle caegorizations provide examples of ‘unidimensional’ category structures , in Robert M. Nosofsky 30 Table 2.1 Maximum-likelihood parameters and summary fi ts for full and restricted versions of the exemplar-similarity categorization model (reprinted from Nosofsky, 1989 ) Parameters Fits Condition Model c w 1 b 1 SSE %Var –In L Size Unconstrained 1.60 0.10 0.50 0.015 99.4 40.8 Equal attention 2.38 (0.50) 0.49 0.077 97.0 72.0 Equal bias 160 0.10 (0.50) 0.015 99.4 40.8 Angle Unconstrained 3.20 0.98 0.43 0.010 99.6 44.3 Equal attention 3.57 (0.50) 0.45 0.305 86.4 164.3 Equal bias 3.09 1.00 (0.50) 0.029 98.7 56.8 Criss-cross Unconstrained 1.62 0.80 0.45 0.025 95.2 47.7 Equal attention 1.23 (0.50) 0.45 0.087 83.1 64.6 Equal bias 3.00 0.93 (0.50) 0.046 91.1 56.7 Diagonal Unconstrained 2.42 0.81 0.49 0.023 98.4 483 Equal attention 1.81 (0.50) 0.48 0.217 85.0 109.4 Equal bias 2.42 81 (0.50) 0.021 98.6 49.1 Values in parentheses were constrained a priori. The parameter w 1 gives the attention weight for Angle, and 1 – w 1 the attention weight for Size. SSE is the sum of squared deviations between predicted and observed Category 1 probabilities; %Var is the percentage of variance accounted for; ln L is the log likelihood. which one dimension is far more relevant than is the other for purposes of classification. These structures were tested to provide clear evidence of the role of selective attention in classification. Consider, for example, the Angle categorization. Note that stimulus 14 is an unassigned tranfer stimulus. In terms of ‘overall similarity’ , stimulus 14 is more similar to the exemplars of Category 2 than to the exemplars of Category 1 (it lies extremely close to exemplar 15 of Category 2)",
    "chunk_id": "Adv_cognitive_modelling_the_generalized_context_model_an_exempla_page-1-22.json_chunk_17"
  },
  {
    "document_type": "book",
    "title": "The The generalized context model: an exemplar model of classification",
    "author": "Robert M. Nosofsky",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\The_generalized_context_model_an_exempla.pdf",
    "date_published": "2023-05-11",
    "keywords": "",
    "flag": "",
    "chunk_text": ". In terms of ‘overall similarity’ , stimulus 14 is more similar to the exemplars of Category 2 than to the exemplars of Category 1 (it lies extremely close to exemplar 15 of Category 2). However, if subjects attend selectively to the relevant angle dimension, then the space will be stretched along the horizontal angle dimension, and shrunk along the vertical size dimension, rendering stimulus 14 more similar to the exemplars of Category 1. An analogous situation holds for stimulus 9 of the Size categorization. The Criss-Cross categorization provides an example of a continuous-dimension biconditional structure. Note that the structure is non-linearly separable , i.e., the members of the contrasing categories cannot be separated by drawing a straight line through the space. Whereas various categorization models are applicable only in cases involving linearly separable categories, the GCM applies generally regardless of the form of the category structure. Finally, the Diagonal GCM 31 categorization provides an example of a fairly ‘natural’ two-dimensional category structure in which the exemplars of contrasting categories can be separated by drawing a diagonal line through the space. In a preliminary similarity-scaling study involving the collection of identification confusion data (see Nosofsky, 1989 , for details), a Figure 2.3 Schematic illustration of the four category structures tested by Nosofsky ( 1989 ). Cells marked with a 1 (2) depict training exemplars of Category 1 (2). Unmarked cells depict unassigned transfer stimuli. Top-left value in each cell is the predicted Category-1 response probability from the GCM. Top-right value in each cell is the observed Category-1 response probability. (Reprinted from Nosofsky, 1989 .) Robert M. Nosofsky 32 two-dimensional scaling solution was derived for the set of 16 stimuli. Not surprisingly, the derived two-dimensional solution closely reflected the 4 × 4 grid structure of the stimulus set (see Nosofsky, 1989 , Figure 2.3 )",
    "chunk_id": "Adv_cognitive_modelling_the_generalized_context_model_an_exempla_page-1-22.json_chunk_18"
  },
  {
    "document_type": "book",
    "title": "The The generalized context model: an exemplar model of classification",
    "author": "Robert M. Nosofsky",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\The_generalized_context_model_an_exempla.pdf",
    "date_published": "2023-05-11",
    "keywords": "",
    "flag": "",
    "chunk_text": ". Not surprisingly, the derived two-dimensional solution closely reflected the 4 × 4 grid structure of the stimulus set (see Nosofsky, 1989 , Figure 2.3 ). This two-dimensional scaling solution was then used in combiation with the GCM to predict the classification data obtained in each of the four categorization conditions. The free parameters in the ‘full’ version of the model were the sensitivity parameter c , the dimension-1 attention weight w 1 (with w 2 = 1 − w 1 ), and the Category-1 responsbias parameter b 1 (with b 2 = 1 − b 1 ). All other parameters were set at the default values described previously in this chapter. (Because the stimuli were highly confusable, the Gaussian-Euclidean version of the model was used, with p = 2 and r = 2.) Parameters were estimated for each individual categorization condition that provided a maximum-likelihood fit to the data. In addition, special cases of the model were also fit to the data. In one special case, the attention weights were held fixed at w 1 = w 2 = 0.5; and in a second special case, the bias parameters were held fixed at b 1 = b 2 = 0.5. By comparing the fits of the special-case versions to the full version of the GCM, one gains evidence regarding the importance of the various free parameters. The results of the model fitting are reported in Figures 2.3 and 2.4 and in Table 2.1 . In Figure 2.3 , the top-right value in each cell gives the observed probability with which subjects classified the stimulus into Category 1, whereas the top-left value gives the predicted probability from the GCM. A summary of all of these observed-against-predicted probabilities for all four categorization conditions is provided in the scatterplot in Figure 2.4 . It can be seen from inspection that the model provides extremely accurate predictions of the data in all four condtions. The quantitative summary fits from the model are also reported in Table 2.1",
    "chunk_id": "Adv_cognitive_modelling_the_generalized_context_model_an_exempla_page-1-22.json_chunk_19"
  },
  {
    "document_type": "book",
    "title": "The The generalized context model: an exemplar model of classification",
    "author": "Robert M. Nosofsky",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\The_generalized_context_model_an_exempla.pdf",
    "date_published": "2023-05-11",
    "keywords": "",
    "flag": "",
    "chunk_text": ". It can be seen from inspection that the model provides extremely accurate predictions of the data in all four condtions. The quantitative summary fits from the model are also reported in Table 2.1 . Although the criterion of fit was to maximize likelihood (or, equivalently, to minimize the negative log-likelihood), the table also reports the sum-of-squared deviations between the predicted and observed classification probabilities, as well as the percentage of varance accounted for in each condition. Finally, the table reports the fit results for the special-case models described above. Of greatest interest are the results for the special-case version that assumes equal attention to the two stimulus dimensions. In all conditions, this special-case model fits significantly worse than does the full version (see Nosofsky, 1989 , for detailed reports of likelihooratio tests that compare the full version to the special cases). These results provide clear evidence of the need to incorporate assumptions about selective attention into the modelling. They can be understood most easily by considering the results for the critical transfer stimuli GCM 33 described above. For example, in the Angle categorization , the equaattention model predicted that transfer stimulus 14 would be classfied into Category 2 with high probability, because it has greater overall similarity to the exemplars of Category 2 than to Category 1. However, the full version of the model, which allows for selective attention to the relevant angle dimension, predicts correctly that transfer stimulus 14 is classified with somewhat higher probability into Category 1. Indeed, the maximum-likelihood estimate for the attention-weight parameter in the Angle categorization is w 1 = 0.98 (see Table 2.1 ), providing clear evdence for the operation of selective attention in this condition",
    "chunk_id": "Adv_cognitive_modelling_the_generalized_context_model_an_exempla_page-1-22.json_chunk_20"
  },
  {
    "document_type": "book",
    "title": "The The generalized context model: an exemplar model of classification",
    "author": "Robert M. Nosofsky",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\The_generalized_context_model_an_exempla.pdf",
    "date_published": "2023-05-11",
    "keywords": "",
    "flag": "",
    "chunk_text": ". Whereas the role of the selective-attention parameters in the GCM has been emphasized and studied systematically in past research, much less 1.0 .8 DIAGONAL ANGLE SIZE CRISS-CROSS .6 .4 .2 .0 .0 .2 .4 PREDICTED PROBABILITY OBSERVED PROBABILITY .6 .8 1.0 Figure 2.4 Scatterplot of observed against GCM-predicted Category-1 response probabilities for each stimulus in all four categorization conditions. (Reprinted from Nosofsky, 1989 .) Robert M. Nosofsky 34 emphasis has been placed on the role of the response-bias parameters. However, in the same way that certain patterns of selective attention may yield better classification performance than others (depending on the category structure), so may certain patterns of response bias yield better performance than others (for examples in situations involving categories with differing variabilities, see Cohen, Nosofsky, & Zaki, 2001 ). Thus, to the extent that human observers are adaptive and adjust parameter settings to achieve task goals, it would not be surprising to find evidence of systematic shifts in patterns of category response bias as a function of experimental conditions. Relations and extensions Although a detailed discussion goes beyond the scope of this chapter, it is important to remark that the GCM is closely related to a variety of rational, Bayesian , and powerful statistical/machine-learning models of categorization (e.g., Anderson, 1990 ; Ashby & Alfonso-Reese, 1995 ; Jakel, Scholkopf, & Wichman, 2008 ; Nosofsky, 1990 , 1991a ; Shepard, 1987 ). Thus, it is interesting to speculate that exemplar-based classifcation schemes evolved because they provide highly adaptive and fleible solutions to the goals of classification given the structure of natural categories and limits on the computational complexity of the mind (Anderson, 1990 )",
    "chunk_id": "Adv_cognitive_modelling_the_generalized_context_model_an_exempla_page-1-22.json_chunk_21"
  },
  {
    "document_type": "book",
    "title": "The The generalized context model: an exemplar model of classification",
    "author": "Robert M. Nosofsky",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\The_generalized_context_model_an_exempla.pdf",
    "date_published": "2023-05-11",
    "keywords": "",
    "flag": "",
    "chunk_text": ". Furthermore, perhaps because the GCM builds upon classic past models in the fields of similarity and classification, and it has itself been a highly successful and widely applied model, there have also been numerous extensions of the GCM. In this final section I briefly review some of these extensions. One extension is Kruschke ’s ( 1992 ) highly influential ALCOVE (attention-learning covering-map) model. In essence, ALCOVE adopts the GCM’s exemplar-based representational assumptions, its MDbased similarity assumptions, and its assumptions about selective attention, and embeds them within the framework of a connectionist learning network. A key potential advantage is that, whereas the seletive-attention weights are free parameters in the GCM, ALCOVE prvides a mechanism that learns the attention weights on a trial-by-trial basis. In addition, in standard applications of the GCM, the memory strengths associated with individual exemplars are assumed simply to be proportional to the frequency with which each exemplar is presented in combination with given category feedback. By contrast, in ALCOVE, learning is error driven, and association weights develop between exeplars and categories that are more intricate and potentially more adative than those allowed by the GCM. GCM 35 Whereas the GCM is limited to predicting choice-probability data in classification, other major extensions of the model enable it also to prdict classification response times (RTs). Nosofsky and Palmeri ’s ( 1997 ) exemplar-based random-walk (EBRW) model adopts the same representtional assumptions as does the GCM. However, classification decisiomaking is governed by a random-walk process. The random walk is driven by exemplars that are retrieved from memory. Importantly, in a twcategory experiment, the GCM response-rule (Equation 1 ) emerges as a special case of the EBRW model, so the EBRW provides a process-level interpretation for the GCM",
    "chunk_id": "Adv_cognitive_modelling_the_generalized_context_model_an_exempla_page-1-22.json_chunk_22"
  },
  {
    "document_type": "book",
    "title": "The The generalized context model: an exemplar model of classification",
    "author": "Robert M. Nosofsky",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\The_generalized_context_model_an_exempla.pdf",
    "date_published": "2023-05-11",
    "keywords": "",
    "flag": "",
    "chunk_text": ". Importantly, in a twcategory experiment, the GCM response-rule (Equation 1 ) emerges as a special case of the EBRW model, so the EBRW provides a process-level interpretation for the GCM. It also predicts successfully a wide variety of fundamental effects involving classification RT data, including effects of distance-from-boundary, familiarity, practice, and probabilistic feeback (Nosofsky & Palmeri, 1997 ; Nosofsky & Stanton, 2005 ). Another major extension is Lamberts ’ ( 2000 ) extended generalized context model for response times (EGCM-RT). This extension also adopts the GCM’s exemplar-based representational and similarity assumptions. However, it assumes that categorization involves the gradual construction of a peceptual representation through a process of information accumulation. In particular, the perceptual representation of a stimulus is gradually built through a process of stochastic, parallel sampling of the stimulus’s individual dimensions. Classification RTs are determined by the length of time with which the sampling process operates, which in turn is closely related to outputs from the GCM response rule. A long-standing debate in the classification literature has involved a contrast between exemplar and prototype models. Whereas exemplar models assume that categories are represented in terms of individually stored exemplars, prototype models assume instead a single summary representation that is the central tendency of the individual exemplars. In Chapter 3 of this volume, Minda and Smith consider prototype moels . They argue that prototype models provide better accounts of data than do exemplar models in a variety of experiments involving visual categories. However, this conclusion has been disputed in numerous studies (see e.g., Busemeyer, Dewey, & Medin, 1984 ; Nosofsky, 2000 ; Nosofsky & Zaki, 2002 ; Palmeri & Flanery, 2002 ; Rehder & Hoffman, 2005 ; Stanton, Nosofsky, & Zaki, 2002 ; Zaki & Nosofsky, 2004 , 2007 ; Zaki et al ., 2003 )",
    "chunk_id": "Adv_cognitive_modelling_the_generalized_context_model_an_exempla_page-1-22.json_chunk_23"
  },
  {
    "document_type": "book",
    "title": "The The generalized context model: an exemplar model of classification",
    "author": "Robert M. Nosofsky",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\The_generalized_context_model_an_exempla.pdf",
    "date_published": "2023-05-11",
    "keywords": "",
    "flag": "",
    "chunk_text": ". An intermediate view is that multiple prototypes may be formed to represent a category, where a varying number of exeplars may be averaged together to form each individual prototype. In the varying abstraction model (VAM) of Vanpaemel and Storms ( 2008 ), all possible multiple-prototype representations are considered, and the version that fits best is taken as the underlying category representation. Although the VAM is far more complex than the GCM, results from Robert M. Nosofsky 36 Vanpaemel and Storms suggest that the added complexity is justified in terms one’s ability to accurately predict human classification perforance. A closely related alternative idea is the Rex Leopold I model of De Schryver , Vandist , and Rosseel ( 2009 ). This model posits that categories are not represented in terms of the complete set of experienced exeplars, but in terms of reduced subsets of the exemplars. Analogous to the VAM, all possible reduced subsets are considered, and the best-fitting subset is taken as the category representation. Another important extension of the GCM is Stewart and Brown ’s ( 2005 ) similarity-dissimilarity exemplar model . This model posits that the evidence in favour of a category is not based solely on the similarity of a test item to the exemplars of that category, but on its dissimilarity to the exemplars of contrast categories. This extended model accounts succesfully for the use of difference information and category-contrast effects in classification. A final example is Pothos and Bailey ’s ( 2009 ) extesion of the GCM to judgments of category intuitiveness and unsupevised categorization. This unsupervised GCM operates by computing, for any given partitioning of exemplars into categories, the overall prdiction error associated with that partitioning. The category assignment that results in the smallest prediction error is considered to be the most intuitive",
    "chunk_id": "Adv_cognitive_modelling_the_generalized_context_model_an_exempla_page-1-22.json_chunk_24"
  },
  {
    "document_type": "book",
    "title": "The The generalized context model: an exemplar model of classification",
    "author": "Robert M. Nosofsky",
    "source": "raw_syllabi\\master_courses\\Adv_cognitive_modelling\\pdf_material\\The_generalized_context_model_an_exempla.pdf",
    "date_published": "2023-05-11",
    "keywords": "",
    "flag": "",
    "chunk_text": ". The category assignment that results in the smallest prediction error is considered to be the most intuitive. Finally, although I have focused on the issue of categorization in this chapter, perhaps the most important achievement of the GCM is that essentially the same model has been used to account for varieties of other fundamental cognitive processes, including individual-item identifiction, the development of automaticity, and old-new recognition perforance (e.g., Nosofsky, 1986 , 1987 , 1988 , 1991b ; Nosofsky & Zaki, 1998 ; Nosofsky & Stanton, 2006 ; Palmeri, 1997 ). The successful applications of the GCM in these domains, and the use of the model to explain reltions between categorization and performance in other fundamental tasks, suggests the possibility of developing unified, exemplar-based thories of cognitive representation and processing.",
    "chunk_id": "Adv_cognitive_modelling_the_generalized_context_model_an_exempla_page-1-22.json_chunk_25"
  },
  {
    "document_type": "online_article",
    "title": "Introduction to Bayesian Data Analysis for Cognitive Science",
    "author": "Bruno Nicenboim",
    "source": "https://bruno.nicenboim.me/bayescogsci/ch-coding2x2.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": "Chapter6provides a basic introduction into contrast coding in situations where there is one predictor variable, i.e., one factor, whose effects can be estimated using a specified contrast matrix. Here, we investigate how contrast coding generalizes to situations where there is more than one predictor variable. This could either be a situation where two factors are present or where one factor is paired with a continuous predictor variable, i.e., a covariate. We first discuss contrast coding for the case of two factors (for\\(2 \\times 2\\)designs; section7.1) and then go on to investigate situations where one predictor is a factor and the other predictor is a covariate (section7.2). One problem in the analysis of interactions occurs in situations where the model is not linear, but has some non-linear link function, for example in logistic models, or when assuming a log-normally distributed dependent variable. In these situations, the model makes predictions for each condition (i.e., design cell) at the latent level of the linear model. Sometimes it is important to translate these model predictions to the level of the observations (e.g., to probabilities in a logistic regression model). We will discuss how this can be implemented in section7.3. In section6.3of chapter6, we used a data set with one 4-level factor. Here, we assume that the same four means come from an\\(A(2) \\times B(2)\\)between-subject-factor design rather than an\\(F(4)\\)between-subject-factor design. Load the simulated data and show summary statistics in Table7.1and in Figure7.1. The means and standard deviations are exactly the same as in Figure6.2and in Table6.3. FIGURE 7.1: Means and error bars (showing standard errors) for a simulated data set with a two-by-two between-subjects factorial design. In order to carry out a\\(2\\times 2\\)ANOVA-type (main effects and interaction) analysis, one needs sum contrasts in the linear model",
    "chunk_id": "Adv_cognitive_modelling_introduction_to_bayesian_data_analysis_for_cognitive_science_4df81882.json_chunk_1"
  },
  {
    "document_type": "online_article",
    "title": "Introduction to Bayesian Data Analysis for Cognitive Science",
    "author": "Bruno Nicenboim",
    "source": "https://bruno.nicenboim.me/bayescogsci/ch-coding2x2.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". In order to carry out a\\(2\\times 2\\)ANOVA-type (main effects and interaction) analysis, one needs sum contrasts in the linear model. (This is true for factors with two levels, but does not generalize to factors with more levels.) The results of such an analysis are shown in Table7.2. (The analysis immediately below uses sum contrasts:\\(-1\\)/\\(+1\\); however, scaled sum contrasts\\(-0.5\\)/\\(+0.5\\)could also be used; in this case, the priors would need to be adapted to the respective scale.) Next, we reproduce the\\(A(2) \\times B(2)\\)ANOVA, with contrasts specified for the corresponding one-way\\(F(4)\\)ANOVA; that is, by treating the\\(2 \\times 2 = 4\\)condition means as four levels of a single factor\\(F\\). In other words, we go back to the data frame simulated for the analysis of repeated contrasts (see chapter6, section6.3). We first define weights for condition means according to our hypotheses, invert this matrix, and use it as the contrast matrix for factor\\(F\\). We define weights of\\(1/4\\)and\\(-1/4\\). We do so because (a) we want to compare the mean of two conditions to the mean of two other conditions (e.g., factor\\(A\\)compares\\(\\frac{F1 + F2}{2}\\)to\\(\\frac{F3 + F4}{2}\\)). Moreover, (b) we want coefficients to code half the difference between condition means, reflecting sum contrasts. Together\\((a+b)\\), this yields weights of\\(1/2 \\cdot 1/2 = 1/4\\). The resulting contrast matrix contains contrast coefficients of\\(+1\\)or\\(-1\\), showing that we successfully implemented sum contrasts. The results are identical to the previous models. This shows that it is possible to specify the contrasts not only for each factor (e.g., here in the\\(2 \\times 2\\)design) separately. Instead, one can also pool all experimental conditions (or design cells) into one large factor (here factor\\(F\\)with\\(4\\)levels), and specify the contrasts for the main effects and for the interactions in the resulting one large contrast matrix simultaneously",
    "chunk_id": "Adv_cognitive_modelling_introduction_to_bayesian_data_analysis_for_cognitive_science_4df81882.json_chunk_2"
  },
  {
    "document_type": "online_article",
    "title": "Introduction to Bayesian Data Analysis for Cognitive Science",
    "author": "Bruno Nicenboim",
    "source": "https://bruno.nicenboim.me/bayescogsci/ch-coding2x2.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". In this approach, it can again be very useful to apply thehyprpackage to construct contrasts for a\\(2 \\times 2\\)design. The first parameter estimates the main effect\\(A\\), i.e., it compares the average of\\(F1\\)and\\(F2\\)to the average of\\(F3\\)and\\(F4\\). The second parameter estimates the main effect\\(B\\), i.e., it compares the average of\\(F1\\)and\\(F3\\)to the average of\\(F2\\)and\\(F4\\). We code direct differences between the averages, i.e., we implement scaled sum contrasts instead of sum contrasts. This is shown below: the contrast matrix contains coefficients of\\(+1/2\\)and\\(-1/2\\)instead of\\(+1\\)and\\(-1\\). The interaction term estimates the difference between differences, i.e., the difference between\\(F1 - F2\\)and\\(F3 - F4\\). The results show that the estimates for the main effects have (approximately) double the size as compared to the\\(\\pm 1\\)sum contrasts–this is the result of the scaling that we applied. I.e., the main effects now directly estimate the difference between averages. The interaction estimates the difference between differences. Importantly, if we change the scaling of the contrasts, we also need to adapt the scaling of the priors. If appropriate priors are used, then both contrasts would lead to the same hypothesis tests if one were doing hypothesis testing using Bayes factors. Thus, thehyprpackage can be used to code hypotheses in a\\(2 \\times 2\\)design. Now the main effects and interaction can be directly interpreted as differences between averages and as differences between differences. If one wants the interaction term to be on the same scale as the main effects, it would need to be multiplied by 2; however, then its interpretation would not be straightforward any more (i.e., it is no longer “the difference between differences” but a scaled variant of this). Thus, putting the interaction on the same scale as the main effects has the advantage that it ensures that the prior has the same scaling across the different terms",
    "chunk_id": "Adv_cognitive_modelling_introduction_to_bayesian_data_analysis_for_cognitive_science_4df81882.json_chunk_3"
  },
  {
    "document_type": "online_article",
    "title": "Introduction to Bayesian Data Analysis for Cognitive Science",
    "author": "Bruno Nicenboim",
    "source": "https://bruno.nicenboim.me/bayescogsci/ch-coding2x2.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". Thus, putting the interaction on the same scale as the main effects has the advantage that it ensures that the prior has the same scaling across the different terms. However, it has the disadvantage that the interpretation of the interaction term is not straightforward. Incidentally, an alternative way to code main effects and interactions is to use theifelse()command in R. For example, if we want to use\\(\\pm 1/2\\)sum contrasts as in the above example, we can specify the contrasts for the main effects as vectors: Now, defining the interaction is simply a matter of multiplying the two vectors: This kind of vector-based contrast coding is convenient for more complex designs, such as\\(2\\times 2\\times 2\\)factorial designs. However, in such complex designs, theifelse()command can become cumbersome, so a better approach is to use themerge()function in R, as shown below. First, define a data frame that represents the main effects and interaction contrasts for the four conditions. Then, one can merge this data frame with the data frame that contains the data: One can estimate effects that do not correspond directly to main effects and interaction of the traditional ANOVA. For example, in a\\(2 \\times 2\\)experimental design, where factor\\(A\\)codes word frequency (low/high) and factor\\(B\\)is part of speech (noun/verb), one can estimate the effect of word frequency within nouns and the effect of word frequency within verbs. Formally,\\(A_{B1}\\)versus\\(A_{B2}\\)are nested within levels of\\(B\\). Said differently, simple effects of factor\\(A\\)are estimated for each of the levels of factor\\(B\\). In this version, we estimate the main effect of part of speech (\\(B\\); as in traditional ANOVA). Instead of also estimating the second main effect word frequency,\\(A\\), and the interaction, we estimate (1) the differences between the two levels of word frequency\\(A\\)in the first level of\\(B\\)(i.e., nouns), and (2) the difference between the two levels of word frequency\\(A\\)in the second level of\\(B\\)(i.e., verbs)",
    "chunk_id": "Adv_cognitive_modelling_introduction_to_bayesian_data_analysis_for_cognitive_science_4df81882.json_chunk_4"
  },
  {
    "document_type": "online_article",
    "title": "Introduction to Bayesian Data Analysis for Cognitive Science",
    "author": "Bruno Nicenboim",
    "source": "https://bruno.nicenboim.me/bayescogsci/ch-coding2x2.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". In other words, we estimate the differences between the two levels of\\(A\\)in each of the levels of\\(B\\). Often, researchers have hypotheses about these differences, and not about the interaction. The regression coefficients estimate the grand mean, the difference for the main effect of part of speech (\\(B\\)) and the two differences (for\\(A\\); i.e., simple main effects) within the two levels (noun and verb) of part of speech (\\(B\\)). These custom nested contrasts’ columns are scaled versions of the corresponding hypothesis matrix. This is the case because the columns are orthogonal. This illustrates one advantage of orthogonal contrasts for the interpretation of regression coefficients: the underlying comparisons being estimated are already clear from the contrast matrix. There is also a built-in R formula specification for nested designs. The order of factors in the formula from left to right specifies a top-down order of nesting within levels, i.e., here factor\\(A\\)(word frequency) is nested within levels of the factor\\(B\\)(part of speech). This yields the same result as our previous result based on custom nested contrasts: In cases such as these, where\\(A_{B1}\\)vs.\\(A_{B2}\\)are nested within levels of\\(B\\), it is necessary to include the effect of\\(B\\)(part of speech) in the model, even if one is only interested in the effect of\\(A\\)(word frequency) within levels of\\(B\\)(part of speech). Leaving out factor\\(B\\)in this particular case of a between-subjects deisn would increase posterior uncertainty if the data are fully balanced, and could lead to biases in parameter estimation if the data are not fully balanced",
    "chunk_id": "Adv_cognitive_modelling_introduction_to_bayesian_data_analysis_for_cognitive_science_4df81882.json_chunk_5"
  },
  {
    "document_type": "online_article",
    "title": "Introduction to Bayesian Data Analysis for Cognitive Science",
    "author": "Bruno Nicenboim",
    "source": "https://bruno.nicenboim.me/bayescogsci/ch-coding2x2.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". Again, we show how nested contrasts can be easily implemented usinghypr: Of course, we can also ask the reverse question: Are there differences for part of speech (\\(B\\)) in the levels of word frequency (\\(A\\); in addition to estimating the main effect of word frequency,\\(A\\))? That is, do nouns differ from verbs for low-frequency words (\\(B_{A1}\\)) and do nouns differ from verbs for high-frequency words (\\(B_{A2}\\))? Regression coefficients estimate the grand mean, the difference for the main effect of word frequency (\\(A\\)) and the two part of speech effects (for\\(B\\); i.e., simple main effects) within levels of word frequency (\\(A\\)). An important issue to keep in mind is that if, using nested contrasts, one finds a large effect in one nested comparison (e.g.,FA2xB) but no difference or a smaller effect in the other comparison (here,FA1xB), one cannot conclude that there is an interaction; to argue for an interaction, one would have to test for the main effects and interaction using the ANOVA contrast coding(Nieuwenhuis, Forstmann, and Wagenmakers2011). In a\\(2 \\times 2\\)experimental design, the results from sum contrasts are equivalent to typical ANOVA results that we see in frequentist analyses. This means that sum contrasts assess the main effects and the interactions. One interesting question that arises here is: what would happen in a\\(2 \\times 2\\)design if we had used treatment contrasts instead of sum contrasts? Is it still possible to meaningfully interpret the results from the treatment contrasts in a simple\\(2 \\times 2\\)design? This leads us to a very important principle in interpreting results from contrasts: When interactions between contrasts are included in a model, then the results for one contrast actually depend on the specification of the other contrast(s) in the analysis! This may be counter-intuitive at first, but it is very important and essential to keep in mind when interpreting results from contrasts",
    "chunk_id": "Adv_cognitive_modelling_introduction_to_bayesian_data_analysis_for_cognitive_science_4df81882.json_chunk_6"
  },
  {
    "document_type": "online_article",
    "title": "Introduction to Bayesian Data Analysis for Cognitive Science",
    "author": "Bruno Nicenboim",
    "source": "https://bruno.nicenboim.me/bayescogsci/ch-coding2x2.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". How does this work in detail? The general rule to remember is that the effect of one contrast measures its effect at the location\\(0\\)of the other contrast(s) in the analysis. This can be seen in the regression equation of a\\(2 \\times 2\\)design with factors\\(A\\)and\\(B\\): \\[\\begin{equation} E[Y] = \\alpha + \\beta_A A + \\beta_B B + \\beta_{A \\times B} A \\times B \\end{equation}\\] If we set the predictor\\(B\\)to zero, then the equation simplifies to: \\[\\begin{equation} E[Y] = \\alpha + \\beta_A A \\end{equation}\\] Thus, now we can see the “pure” effect of\\(A\\). What does that mean practically? Let us consider the example that we use two treatment contrasts in a\\(2 \\times 2\\)design. Here are the results from the linear model Let’s take a look at the effect of factor\\(A\\). How can we interpret what this measures? This effect actually estimates the effect of factor\\(A\\)at the “location” where factor\\(B\\)is coded as\\(0\\). Factor\\(B\\)is coded as a treatment contrast, that is, it codes a zero at its baseline condition, which is\\(B1\\). Thus, the effect of factor\\(A\\)estimates the effect of\\(A\\)nested within the baseline condition of\\(B\\), i.e., a simple effect. We take a look at the data presented in Figure7.1, what this nested effect should be. Figure7.1shows that the effect of factor\\(A\\)nested in\\(B1\\)is\\(0\\). If we now compare this to the results from the linear model, it is indeed clear that the effect of factor\\(A\\)is exactly estimated as\\(0\\). As expected, when factor\\(B\\)is coded as a treatment contrast, the effect of factor\\(A\\)estimates the effect of\\(A\\)nested within the baseline level of factor\\(B\\). Next, consider the effect of factor\\(B\\). According to the same logic, this effect estimates the effect of factor\\(B\\)at the “location” where factor\\(A\\)is\\(0\\). Factor\\(A\\)is also coded as a treatment contrast, that is, it codes its baseline condition\\(A1\\)as\\(0\\). The effect of factor\\(B\\)estimates the effect of\\(B\\)nested within the baseline condition of\\(A\\). Figure7.1shows that this effect should be\\(10\\)",
    "chunk_id": "Adv_cognitive_modelling_introduction_to_bayesian_data_analysis_for_cognitive_science_4df81882.json_chunk_7"
  },
  {
    "document_type": "online_article",
    "title": "Introduction to Bayesian Data Analysis for Cognitive Science",
    "author": "Bruno Nicenboim",
    "source": "https://bruno.nicenboim.me/bayescogsci/ch-coding2x2.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". The effect of factor\\(B\\)estimates the effect of\\(B\\)nested within the baseline condition of\\(A\\). Figure7.1shows that this effect should be\\(10\\). How do we know what the “location” is, where a contrast applies? For the treatment contrasts discussed here, it is possible to reason this through because all contrasts are coded as\\(0\\)or\\(1\\). How can one derive the “location” in general? What we can do is to look at the comparisons that are estimated when using the treatment contrasts (or in case we use Bayes factors, which hypotheses are tested) in the presence of an interaction between them by using the generalized matrix inverse. We go back to the default treatment contrasts. Then we extract the contrast matrix from the design matrix: This shows the treatment contrast for factors\\(A\\)and\\(B\\), and their interaction. We can now assign this contrast matrix to ahyprobject.hyprautomatically converts the contrast matrix into a hypothesis matrix, such that we can read from the hypothesis matrix which comparison are being estimated by the different contrasts. The same result is obtained by applying the generalized inverse to the contrast matrix (this is whathypr()does as well). An important fact is that when we apply the generalized inverse to the contrast matrix, we obtain the corresponding hypothesis matrix(for details, see Schad et al.2020). As discussed above, the effect of factor\\(A\\)estimates its effect nested within the baseline level of factor\\(B\\). Likewise, the effect of factor\\(B\\)estimates its effect nested within the baseline level of factor\\(A\\). The term\\(A:B\\)always tests the interaction between both factors, irrespective of the centering of\\(A\\)and\\(B\\). How does this work for sum contrasts? They do not have a baseline condition that is coded as\\(0\\). In sum contrasts, the average of the contrast coefficients is\\(0\\). Therefore, effects estimate the average effect across factor levels, i.e., they estimate a main effect. This is what is typically also tested in standard ANOVA",
    "chunk_id": "Adv_cognitive_modelling_introduction_to_bayesian_data_analysis_for_cognitive_science_4df81882.json_chunk_8"
  },
  {
    "document_type": "online_article",
    "title": "Introduction to Bayesian Data Analysis for Cognitive Science",
    "author": "Bruno Nicenboim",
    "source": "https://bruno.nicenboim.me/bayescogsci/ch-coding2x2.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". Therefore, effects estimate the average effect across factor levels, i.e., they estimate a main effect. This is what is typically also tested in standard ANOVA. Let’s look at the example shown in Table7.2: given that factor\\(B\\)has a sum contrast, the main effect of factor\\(A\\)is estimated as the average across levels of factor\\(B\\). Figure7.1shows that the effect of factor\\(A\\)in level B1 is\\(10 - 10 = 0\\), and in level\\(B2\\)it is\\(20 - 40 = -20\\). The average effect across both levels is\\((0 - 20)/2 = -10\\). Due to the sum contrast coding, we have to divide this by two, yielding an expected effect of\\(-10 / 2 = -5\\). This is exactly what the effect of factor\\(A\\)measures (see Table7.2,Estimatefor\\(A1\\)). Similarly, factor\\(B\\)estimates its effect at the location\\(0\\)of factor\\(A\\). Again,\\(0\\)is exactly the mean of the contrast coefficients from factor\\(A\\), which is coded as a sum contrast. Therefore, factor\\(B\\)estimates the effect of\\(B\\)averaged across factor levels of\\(A\\), i.e., the main effect of\\(B\\). For factor level\\(A1\\), factor\\(B\\)has an effect of\\(10 - 20 = -10\\). For factor level\\(A2\\), factor\\(B\\)has an effect of\\(10 - 40 = -30\\). The average effect is\\((-10 - 30)/2 = -20\\), which again needs to be divided by\\(2\\)due to the sum contrast. This yields exactly the estimate of\\(-10\\)that is also reported in Table7.2(Estimatefor B1). Again, we look at the hypothesis matrix for the main effects and the interaction: This shows that each of the effects now does not compute nested comparisons any more, but that they rather estimate their effect averaged across conditions of the other factor. The averaging involves using weights of\\(1/2\\)in the hypothesis matrix. Moreover, the regression coefficients in the sum contrast measure half the distance between conditions, leading to weights of\\(1/2 \\cdot 1/2 = 1/4\\)in the hypothesis matrix",
    "chunk_id": "Adv_cognitive_modelling_introduction_to_bayesian_data_analysis_for_cognitive_science_4df81882.json_chunk_9"
  },
  {
    "document_type": "online_article",
    "title": "Introduction to Bayesian Data Analysis for Cognitive Science",
    "author": "Bruno Nicenboim",
    "source": "https://bruno.nicenboim.me/bayescogsci/ch-coding2x2.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". Moreover, the regression coefficients in the sum contrast measure half the distance between conditions, leading to weights of\\(1/2 \\cdot 1/2 = 1/4\\)in the hypothesis matrix. The general rule to remember from these examples is that when interactions between contrasts are estimated, what an effect of a factor estimates depends on the contrast coding of the other factors in the design! The effect of a factor estimates the effect nested within the location zero of the other contrast(s) in an analysis. If another contrast is centered, and zero is the average of this other contrasts’ coefficients, then the contrast of interest estimates the average or main effect, averaged across the levels of the other factor. Importantly, this property, that the coding of the other factor determines the estimates of one factor, holds only when the interaction between two contrasts is included into a model. If the interaction is omitted and only effects are estimated, then there is no such influence. This may be a very surprising result for interactions of contrasts. However, it is also essential to interpreting contrast coefficients involved in interactions. It is particularly relevant for the analysis of the default treatment contrast, where the main effects estimate nested effects rather than average effects. In this section we treat the case where there are again two predictor variables for one dependent variable, but where one predictor variable is a discrete factor, and the other is a continuous covariate. Let’s assume we have measured some response time (RT), e.g., in a lexical decision task. We want to predict the response time based on each subject’s IQ, and we expect that higher IQ leads to shorter response times. Moreover, we have two groups of each 30 subjects. These are coded as factor\\(F\\), with factor levels\\(F1\\)and\\(F2\\). We assume that these two groups have obtained different training programs to optimize their response times on the task",
    "chunk_id": "Adv_cognitive_modelling_introduction_to_bayesian_data_analysis_for_cognitive_science_4df81882.json_chunk_10"
  },
  {
    "document_type": "online_article",
    "title": "Introduction to Bayesian Data Analysis for Cognitive Science",
    "author": "Bruno Nicenboim",
    "source": "https://bruno.nicenboim.me/bayescogsci/ch-coding2x2.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". These are coded as factor\\(F\\), with factor levels\\(F1\\)and\\(F2\\). We assume that these two groups have obtained different training programs to optimize their response times on the task. Group\\(F1\\)obtained a control training, whereas group\\(F2\\)obtained training to improve lexical decisions. We want to estimate the extent to which the training for better lexical decisions in group\\(F2\\)leads to shorter response times compared to the control group\\(F1\\). This is our main question of interest here, i.e., the extent to which the training program in\\(F2\\)leads to faster response times compared to the control group\\(F1\\). We load the data, which is a simulated data set. Our main effect of interest is the factor\\(F\\). We want to estimate its effect on response times and code it using scaled sum contrasts, such that negative parameter estimates would yield support for our hypothesis that response times are faster in the training group\\(F2\\): We run abrmsmodel to estimate the effect of factor\\(F\\), i.e., how strongly the response times in the two groups differ from each other. FIGURE 7.2: Means and error bars (showing standard errors) for a simulated data set of response times for two different groups of subjects, who have obtained a training in lexical decisions (\\(F2\\)) versus have obtained a control training (\\(F1\\)). We find (see model estimates and data shown in Figure7.2) that response times in group\\(F2\\)are roughly\\(25\\)ms faster than in group\\(F1\\)(Estimate of\\(-24\\)). This suggests that as expected, the training program that group\\(F2\\)obtained seems to be successful in speeding up response times. Recall that one cannot just look at the 95% credible interval and check whether zero is outside the interval to declare that we have found an effect. To make a discovery claim, we need to run a Bayes factor analysis on this data set to directly test this hypothesis, and this may or may not provide evidence for a difference in response times between groups",
    "chunk_id": "Adv_cognitive_modelling_introduction_to_bayesian_data_analysis_for_cognitive_science_4df81882.json_chunk_11"
  },
  {
    "document_type": "online_article",
    "title": "Introduction to Bayesian Data Analysis for Cognitive Science",
    "author": "Bruno Nicenboim",
    "source": "https://bruno.nicenboim.me/bayescogsci/ch-coding2x2.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". Let’s assume we have allocated subjects to the two groups randomly. Let’s say that we also measured the IQ of each person using an IQ test. We did so because we expected that IQ could have an influence on response times, and we wanted to control for this influence. We now can check whether the two groups had the same average IQ. Group\\(F2\\)not only obtained additional training and had faster response times, group\\(F2\\)also had a higher IQ (mean of 115) on average than group\\(F1\\)(mean IQ = 85). Thus, the random allocation of subjects to the two groups seems to have created–by chance–a difference in IQs. Now we can ask the question: why might response times in group\\(F2\\)be faster than in group\\(F1\\)? Is this because of the training program in\\(F2\\)? Or is this simply because the average IQ in group\\(F2\\)was higher than in group\\(F1\\)? To investigate this question, we add both predictor variables simultaneously in abrmsmodel. Before we enter the continuous IQ variable, we center it, by subtracting its mean. Centering covariates is generally good practice. Moreover, it is often important to\\(z\\)-transform the covariate, i.e., to not only subtract the mean, but also to divide by its standard deviation (this can be done as follows:df_contrasts5$IQ.s <- scale(df_contrasts5$IQ)). The reason why this is often important is that the sampler doesn’t work well if predictors have different scales. For the simple models we use here, the sampler works without\\(z\\)-transformation. However, for more realistic and more complex models,\\(z\\)-transformation of covariates is often very important. Importantly, when changing the scale of the predictor, then the scale of the prior has to be changed accordingly. Here, we set the same priors for the contrast and for the covariate IQ for convenience. In realistic models, these priors have to be set separately",
    "chunk_id": "Adv_cognitive_modelling_introduction_to_bayesian_data_analysis_for_cognitive_science_4df81882.json_chunk_12"
  },
  {
    "document_type": "online_article",
    "title": "Introduction to Bayesian Data Analysis for Cognitive Science",
    "author": "Bruno Nicenboim",
    "source": "https://bruno.nicenboim.me/bayescogsci/ch-coding2x2.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". Here, we set the same priors for the contrast and for the covariate IQ for convenience. In realistic models, these priors have to be set separately. The results from thebrmsmodel now show that the difference in response times between groups (i.e., factor\\(F\\)) is not estimated to be\\(-25\\)ms any more, but instead, the estimate is about\\(+7\\)ms, and the 95% credible interval spans the range\\(-20\\)to\\(33\\). Thus, there doesn’t seem to be much reason to believe any more that the groups would differ. At the same time, we see that the predictor variable IQ shows a negative effect (Estimate =\\(-1\\)with 95% credible interval:\\(-1.7\\)to\\(-0.4\\)), suggesting that–as expected–response times seem to be faster in subjects with higher IQ. FIGURE 7.3: Response times as a function of individual IQ for two groups with a lexical decision training (\\(F2\\)) versus a control training (\\(F1\\)). Points indicate individual subjects, and lines with error bands indicate linear regression lines. This result can also be seen in Figure7.3, which shows that response times decrease with increasing IQ, as suggested by thebrmsmodel. However, the heights of the two regression lines do not differ from each other, consistent with the observation in thebrmsmodel that the effect of factor\\(F\\)did not seem to differ from zero. That is, factor\\(F\\)in thebrmsmodel estimates the difference in height of the regression line between both groups. That the height does not differ and the effect of\\(F\\)is estimated to be close to zero suggests that in fact group\\(F2\\)showed faster response times not because of their additional training program. Instead, they had faster response times simply because their IQ was by chance higher on average compared to the control group\\(F1\\). This analysis is the Bayesian equivalence of the frequentist “analysis of covariance” (ANCOVA), where it’s possible to estimate a group difference after “controlling for” the influence of a covariate",
    "chunk_id": "Adv_cognitive_modelling_introduction_to_bayesian_data_analysis_for_cognitive_science_4df81882.json_chunk_13"
  },
  {
    "document_type": "online_article",
    "title": "Introduction to Bayesian Data Analysis for Cognitive Science",
    "author": "Bruno Nicenboim",
    "source": "https://bruno.nicenboim.me/bayescogsci/ch-coding2x2.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". We can also see in Figure7.3that the two regression lines for the two groups are exactly parallel to each other. That is, the influence of IQ on response times seems to be exactly the same in both groups. This is actually an assumption in the ANCOVA analysis that needs to be checked in the data. That is, if we want to estimate the difference between groups after controlling for a covariate (here IQ), we have to investigate whether the influence of the covariate is the same in both groups. We can estimate this by including an interaction term between the factor and the covariate in thebrmsmodel: The estimate for the interaction (the termF1:c_IQ) is very small here (close to\\(0\\)) and the 95% credible intervals clearly overlap with zero, showing that the two regression lines are estimated to be very similar, or parallel, to each other. If this is the case, then it is possible to correct for IQ when estimating the group difference. (From the perspective of causal inference, one might need additional requirements to draw strong conclusions here, such as measuring the covariate before the dependent variable, or reasoning based on theoretical plausibility.) We now take a look at a different data set. This again contains data from response times (RT) in two groups. Let’s assume the two groups have performed two different response time tasks, where one simple RT task doesn’t rely on much cognitive processing (group “simple”), whereas the other task is more complex and depends on complex cognitive operations (group “complex”). We therefore expect that RTs in the simple task should be independent of IQ, whereas in the complex task, individuals with a high IQ should be faster in responding compared to individuals with low IQ. Thus, our primary hypothesis of interest states that the influence of IQ on RT differs between conditions. This means that we are interested in the difference between slopes",
    "chunk_id": "Adv_cognitive_modelling_introduction_to_bayesian_data_analysis_for_cognitive_science_4df81882.json_chunk_14"
  },
  {
    "document_type": "online_article",
    "title": "Introduction to Bayesian Data Analysis for Cognitive Science",
    "author": "Bruno Nicenboim",
    "source": "https://bruno.nicenboim.me/bayescogsci/ch-coding2x2.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". Thus, our primary hypothesis of interest states that the influence of IQ on RT differs between conditions. This means that we are interested in the difference between slopes. A slope in a linear regression assesses how strongly the dependent variable (here RT) changes with an increase of one unit on the covariate (here IQ), it thus assesses how “steep” the regression line is. Our hypothesis thus states that the regression lines differ between groups. FIGURE 7.4: Response times as a function of individual IQ for two groups performing a simple versus a complex task. Points indicate individual subjects’ responses, and lines with error bands show the fitted linear regression lines. The results, displayed in Figure7.4, suggest that the data seem to support our hypothesis. For the subjects performing the complex task, response times seem to decrease with increasing IQ, whereas for subjects performing the simple task, response times seem to be independent of IQ. As stated before, our primary hypothesis relates to the difference in slopes. Statistically speaking, this is assessed in the interaction between the factor and the covariate. Thus, we run abrmsmodel where the interaction is included. Importantly, we first use scaled sum contrasts for the group effect, and again center the covariate IQ. We can see that the main effect of IQ (termc_IQ) is negative (\\(-0.8\\)) with 95% credible intervals\\(-1.5\\)to\\(-0.2\\), suggesting that overall response times decrease with increasing IQ. This is qualified by the interaction term, which is estimated to be negative (\\(-1.6\\)), with 95% credible intervals\\(-2.9\\)to\\(-0.3\\). This suggests that the slope in the complex group (which was coded as\\(+0.5\\)in the scaled sum contrast) is more negative than the slope in the simple group (which was coded as\\(-0.5\\)in the scaled sum contrast). Thus, the interaction assesses the difference between slopes",
    "chunk_id": "Adv_cognitive_modelling_introduction_to_bayesian_data_analysis_for_cognitive_science_4df81882.json_chunk_15"
  },
  {
    "document_type": "online_article",
    "title": "Introduction to Bayesian Data Analysis for Cognitive Science",
    "author": "Bruno Nicenboim",
    "source": "https://bruno.nicenboim.me/bayescogsci/ch-coding2x2.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". Thus, the interaction assesses the difference between slopes. We can also run a model, where the nested slopes are estimated, i.e., the slope of IQ in the simple group and the slope of IQ in the complex group. This can be implemented by using the nested coding that we learned about in the previous section: Now we see that the slope of IQ in the simple group (Fsimple:c_IQ) is estimated to be\\(0\\), with credible intervals clearly including zero. By contrast, the slope in the complex group (Fcomplex:c_IQ) is estimated as\\(-1.6\\)(95% CrI =\\([-2.5,-0.7]\\)). This is consistent with our hypothesis that high IQ speeds up response times for the complex but not for the simple task. (To obtain evidence for this effect, we need Bayes factors, see chapter13.) We can also see from the nested analysis that the difference in slopes between conditions is\\(-1.6 - 0.0 = -1.6\\). This is exactly the value for the interaction term that we estimated in the previous model, demonstrating that interaction terms assess the difference between slopes; i.e., they estimate in how far the regression lines in the two conditions are parallel, with an estimate of\\(0\\)indicating perfectly parallel lines. Notice that we can compute posterior samples for the nested slopes from the model with the interaction. That is, we can take the model that estimates main effects and the interaction, and compute posterior samples for the slope of IQ in the simple task and the slope of IQ in the complex task. First, we extract the posterior samples from the model. Then, we take a look at the contrast coefficients for the group factor: They show a value of\\(-0.5\\)for the simple group",
    "chunk_id": "Adv_cognitive_modelling_introduction_to_bayesian_data_analysis_for_cognitive_science_4df81882.json_chunk_16"
  },
  {
    "document_type": "online_article",
    "title": "Introduction to Bayesian Data Analysis for Cognitive Science",
    "author": "Bruno Nicenboim",
    "source": "https://bruno.nicenboim.me/bayescogsci/ch-coding2x2.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". First, we extract the posterior samples from the model. Then, we take a look at the contrast coefficients for the group factor: They show a value of\\(-0.5\\)for the simple group. Thus, to compute the slope for the simple group we have to take the overall slope forc_IQand subtract\\(-0.5\\)times the estimate for the interaction: Likewise, to estimate the slope for the complex group we have to take the overall slope forc_IQand add\\(+0.5\\)times the estimate for the interaction: The results show that the posterior means for the slope ofc_IQare\\(0\\)and\\(-1.6\\)for the simple and the complex groups, as we had found above in the nested analysis. This is the case because the data are sufficiently informative compared to the data. When the data are sparse or when working with Bayes factors, priors will have to be set carefully for each specific analysis. In most situations one should always center covariates before including them into a model. If covariates are not centered, then the effects (here the effect for the factor) cannot be interpreted as main effects any more. One can also do analyses with interactions between a covariate and a factor, but by using different contrast codings. For example, if we use treatment contrasts for the factor, then the main effect ofc_IQassesses not the average slope ofc_IQacross conditions, but instead the nested slope ofc_IQwithin the baseline group of the treatment contrast. The interaction still assesses the difference in slopes between groups. In a situation where there are more than two groups, when one estimates the interaction of contrasts with a covariate, then the contrasts define which slopes are compared with each other in the interaction terms",
    "chunk_id": "Adv_cognitive_modelling_introduction_to_bayesian_data_analysis_for_cognitive_science_4df81882.json_chunk_17"
  },
  {
    "document_type": "online_article",
    "title": "Introduction to Bayesian Data Analysis for Cognitive Science",
    "author": "Bruno Nicenboim",
    "source": "https://bruno.nicenboim.me/bayescogsci/ch-coding2x2.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". For example, when using sum contrasts in an example where the influence of IQ is measured on response times for nouns, verbs, and adjectives, then there are two interaction terms: these assess (1) whether the slope of IQ for nouns is different from the average slope across conditions, and (2) whether the slope of IQ for verbs is different from the average slope across conditions. If one uses repeated contrasts in a situation where the influence of IQ on response times is estimated for word frequency conditions “low”, “medium-low”m “medium-high”m and “high”, then there are three interaction terms (one for each contrast). The first interaction term estimates the difference in slopes between “low” and “medium-low” word frequencies, the second interaction term estimates the difference in slopes between “medium-low” and “medium-high” word frequencies, and the third interaction term estimates the difference in slopes between “medium-high” and “high” word frequency conditions. Thus, the logic of how contrasts specify certain comparisons between conditions extends directly to the situation where differences in slopes are estimated. Next, we look at generalized linear models, where a linear predictor is passed through a non-linear link function to predict the dependent variable. Examples of generalized linear models include logistic regression models and models assuming a Poisson distribution. Even though a log-normal model is a linear model on a log-transformed dependent variable, the same techniques apply to this type of model since the logarithm transform is not linear. Here, we treat an example with a logistic model in a\\(2 \\times 2\\)factorial between-subject design. The logistic model has the following non-linear link function called the logistic function:\\(P(y = 1 \\mid \\eta) = \\frac{1}{1 + \\exp(-\\eta)}\\), where\\(\\eta\\)is the latent linear predictor",
    "chunk_id": "Adv_cognitive_modelling_introduction_to_bayesian_data_analysis_for_cognitive_science_4df81882.json_chunk_18"
  },
  {
    "document_type": "online_article",
    "title": "Introduction to Bayesian Data Analysis for Cognitive Science",
    "author": "Bruno Nicenboim",
    "source": "https://bruno.nicenboim.me/bayescogsci/ch-coding2x2.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". The logistic model has the following non-linear link function called the logistic function:\\(P(y = 1 \\mid \\eta) = \\frac{1}{1 + \\exp(-\\eta)}\\), where\\(\\eta\\)is the latent linear predictor. For example, in our\\(2 \\times 2\\)factorial design with main effects A and B and their interaction,\\(\\eta\\)is computed as a linear combination of the intercept plus the main effects and their interaction:\\(\\eta = 1 + \\beta_A x_A + \\beta_B x_B + \\beta_{A \\times B} x_{A \\times B}\\). Thus, there is a latent level of linear predictions (\\(\\eta\\)), which are then passed through a non-linear link function to predict the probability that the observed data is a success (\\(P(y = 1)\\)). We will use this logistic model to analyze an example data set where the dependent variable is dichotomous, coded as either a\\(1\\)(indicating success) or a\\(0\\)(indicating failure). We load a simulated data set where the dependent variable codes whether a subject performed a task successfully (\\(pDV = 1\\)) or not (\\(pDV = 0\\)). Moreover, the data set has two between-subject factors A and B. The means for each of the four conditions are shown in Table7.3. To analyze this data, we use scaled sum contrasts, as we had done above for the\\(2 \\times 2\\)design with response times as the dependent variable; this allows us to interpret the coefficients directly as main effects. Next, we fit abrmsmodel. The model specification is the same as the model with response times–with two differences: First, thefamilyargument is now specified asfamily = bernoulli(link = \"logit\")to indicate the logistic model. We do not specify a prior forsigma, since there is no residual standard deviation in a logistic model. The results from this analysis show that the estimates for the two main effects (\\(A1\\)and\\(B1\\)) as well as the interaction (\\(A1:B1\\)) are positive and the 95% credible intervals do not include zero. If we want to make a discovery claim, we would need to perform Bayes factor analyses to investigate the evidence that there is for each of the effects",
    "chunk_id": "Adv_cognitive_modelling_introduction_to_bayesian_data_analysis_for_cognitive_science_4df81882.json_chunk_19"
  },
  {
    "document_type": "online_article",
    "title": "Introduction to Bayesian Data Analysis for Cognitive Science",
    "author": "Bruno Nicenboim",
    "source": "https://bruno.nicenboim.me/bayescogsci/ch-coding2x2.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". If we want to make a discovery claim, we would need to perform Bayes factor analyses to investigate the evidence that there is for each of the effects. Next, we discuss how we can obtain model predictions for each of the four experimental conditions for this generalized linear model. To obtain such predictions, we first take a look at the contrast matrix. We simultaneously have contrasts for two main effects and one interaction: We obtain the posterior samples for the estimates from the model: From these, we can compute the posterior samples for the linear predictions for each group. We see in the contrast matrix how we have to combine the posterior samples for the intercept, main effects, and interaction to obtain latent linear predictions for each condition. The first condition (design cell\\(A1\\),\\(B1\\)) has a weight of\\(1\\)for the intercept, and then weights of\\(-0.5\\)(for the main effect of\\(A\\)),\\(-0.5\\)(for the main effect of\\(B\\)), and\\(0.25\\)(for the interaction). The posterior samples for the other conditions are computed accordingly. Now, we have computed posterior samples for estimates of the latent linear predictor\\(\\eta\\)for each experimental condition. We can look at the posterior means: This shows that these values are not on the probability scale. Instead, they are on the (log-odds) scale of the latent linear predictor\\(\\eta\\). For presentation and interpretation of the results, it might be much more informative to look at the condition means in terms of the probabilities of success in each of the four conditions. Given that we have the linear predictions for each condition, this can be easily computed by sending all posterior samples for the linear predictions through the link function. Applying the logistic function (plogis()in R) transforms the linear predictors to the probability scale:31 Now, we have posterior samples for each condition on the probability scale",
    "chunk_id": "Adv_cognitive_modelling_introduction_to_bayesian_data_analysis_for_cognitive_science_4df81882.json_chunk_20"
  },
  {
    "document_type": "online_article",
    "title": "Introduction to Bayesian Data Analysis for Cognitive Science",
    "author": "Bruno Nicenboim",
    "source": "https://bruno.nicenboim.me/bayescogsci/ch-coding2x2.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". Applying the logistic function (plogis()in R) transforms the linear predictors to the probability scale:31 Now, we have posterior samples for each condition on the probability scale. We can take a look at the posterior means, and see that these closely correspond to the probabilities in the data that we have seen above in Table7.3. Of course, the advantage is that we now have posterior samples for these conditions available, and can compute posterior 95% credible intervals (also see Figure7.5). Rather than computing these manually, the functionconditional_effects()can do this for us. By default, all main effects and two-way interactions estimated in the model are shown (this can be changed by including, for example,effects = \"A:B\"). We plot the two-way interaction usingbrms, embedding theconditional_effects()call inplot(.)[[1]]. This allows us to select the first (and here the only)ggplot2element and to customize it. FIGURE 7.5: Means and 95 percent posterior credible intervals for a simulated data set of successful task performance in a\\(2 \\times 2\\)design. As a final remark, certain types of interactions might be present at the probability scale, but not at the logit scale (or the other way round); this can happen for any non-linear transformation(see Loftus1978; Wagenmakers et al.2012). To summarize, we showed that for contrasts in the context of\\(2 \\times 2\\)designs, depending on the contrast coding, the factors estimated nested effects or main effects and interactions. We also saw that it is possible to code contrasts for a\\(2 \\times 2\\)design by creating one factor comprising all design cells, and by specifying all effects of interest in a single contrast matrix. In designs with one factor and one covariate it is possible to “control” for group-differences for differences in the covariate (ANCOVA), or to estimate the extent to which regression slopes are parallel in different experimental conditions",
    "chunk_id": "Adv_cognitive_modelling_introduction_to_bayesian_data_analysis_for_cognitive_science_4df81882.json_chunk_21"
  },
  {
    "document_type": "online_article",
    "title": "Introduction to Bayesian Data Analysis for Cognitive Science",
    "author": "Bruno Nicenboim",
    "source": "https://bruno.nicenboim.me/bayescogsci/ch-coding2x2.html",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". Last, in generalized linear models with non-linear link functions it is possible to obtain posterior samples not only on the latent scale of linear predictors, but also on the scale of the response. Analysis of variance is discussed in detail inMaxwell, Delaney, and Kelley (2017). A practical book on ANOVA using R isFaraway (2002). Faraway, Julian James. 2002.Practical Regression and ANOVA using R. Vol. 168. Citeseer. Loftus, Geoffrey R. 1978. “On Interpretation of Interactions.”Memory & Cognition6 (3): 312–19. Maxwell, Scott E, Harold D Delaney, and Ken Kelley. 2017.Designing Experiments and Analyzing Data: A Model Comparison Perspective. New York, NY: Routledge. Nieuwenhuis, Sander, Birte U Forstmann, and Eric-Jan Wagenmakers. 2011. “Erroneous Analyses of Interactions in Neuroscience: A Problem of Significance.”Nature Neuroscience14 (9): 1105–7. Schad, Daniel J., Shravan Vasishth, Sven Hohenstein, and Reinhold Kliegl. 2020. “How to Capitalize on a Priori Contrasts in Linear (Mixed) Models: A Tutorial.”Journal of Memory and Language110 (February): 104038.https://doi.org/10/gf9tjp. Wagenmakers, Eric-Jan, Angelos-Miltiadis Krypotos, Amy H Criss, and Geoffrey Iverson. 2012. “On the Interpretation of Removable Interactions: A Survey of the Field 33 Years After Loftus.”Memory & Cognition40: 145–60. The same (with lower precision) can be achieved using1/(1+exp(-.)).↩︎",
    "chunk_id": "Adv_cognitive_modelling_introduction_to_bayesian_data_analysis_for_cognitive_science_4df81882.json_chunk_22"
  },
  {
    "document_type": "online_article",
    "title": "Bayesian power analysis: Part I. Prepare to reject `\\(H_0\\)` with simulation.",
    "author": "Unknown",
    "source": "https://solomonkurz.netlify.app/blog/bayesian-power-analysis-part-i/",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": "By A. Solomon Kurz July 18, 2019 Edited on April 21, 2021, to remove thebroom::tidy()portion of the workflow. If you’d like to learn how to do Bayesian power calculations usingbrms, stick around for this multi-part blog series. Here with part I, we’ll set the foundation. Many journals, funding agencies, and dissertation committees require power calculations for your primary analyses. Frequentists have a variety of tools available to perform these calculations (e.g.,here). Bayesians, however, have a more difficult time of it. Most of our research questions and data issues are sufficiently complicated that we cannot solve the problems by hand. We need Markov chain Monte Carlo methods to iteratively sample from the posterior to summarize the parameters from our models. Same deal for power. If you’d like to compute the power for a given combination of\\(N\\), likelihood\\(p(\\text{data} | \\theta)\\), and set of priors\\(p (\\theta)\\), you’ll need to simulate. It’s been one of my recent career goals to learn how to do this. You know how they say:The best way to learn is to teach. This series of blog posts is the evidence of me learning by teaching. It will be an exploration of what a Bayesian power simulation workflow might look like. The overall statistical framework will be withinR(R Core Team, 2022), with an emphasis on code style based on thetidyverse(Wickham et al., 2019;Wickham, 2022). We’ll be fitting our Bayesian models with Bürkner’sbrmspackage(Bürkner, 2017,2018,2022). For this series, I’m presuming you are familiar with linear regression, familiar with the basic differences between frequentist and Bayesian approaches to statistics, and have a basic sense of what we mean by statistical power. Here are some resources if you’d like to shore up. Let’s load our primary packages. Thetidyversehelps organize data and we model withbrms. Consider a case where you have some dependent variable\\(Y\\)that you’d like to compare between two groups, which we’ll call treatment and control",
    "chunk_id": "Adv_cognitive_modelling_bayesian_power_analysis_part_i._prepare_to_reject_`(h_0)`_with_simulation..json_chunk_1"
  },
  {
    "document_type": "online_article",
    "title": "Bayesian power analysis: Part I. Prepare to reject `\\(H_0\\)` with simulation.",
    "author": "Unknown",
    "source": "https://solomonkurz.netlify.app/blog/bayesian-power-analysis-part-i/",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". Consider a case where you have some dependent variable\\(Y\\)that you’d like to compare between two groups, which we’ll call treatment and control. Here we presume\\(Y\\)is continuous and, for the sake of simplicity, is in a standardized metric for the control condition. Letting\\(c\\)stand for control and\\(i\\)index the data row for a given case, we might write that as\\(y_{i, c} \\sim \\operatorname{Normal} (0, 1)\\). The mean for our treatment condition is 0.5, with the standard deviation still in the standardized metric. In the social sciences a standardized mean difference of 0.5 would typically be considered a medium effect size. Here’s what that’d look like. Sure, those distributions have a lot of overlap. But their means are clearly different and we’d like to make sure we plan on collecting enough data to do a good job showing that. A power analysis will help. Within the conventional frequentist paradigm, power is the probability of rejecting the null hypothesis\\(H_0\\)in favor of the alternative hypothesis\\(H_1\\), given the alternative hypothesis is “true.” In this case, the typical null hypothesis is $$H_0\\text{: } \\mu_c = \\mu_t,$$ or put differently, $$ H_0\\text{: } \\mu_t - \\mu_c = 0. $$ And the alternative hypothesis is often just $$H_1\\text{: } \\mu_c \\neq \\mu_t,$$ or otherwise put, $$ H_1\\text{: } \\mu_t - \\mu_c \\neq 0. $$ Within the regression framework, we’ll be comparing\\(\\mu\\)s using the formula $$\\begin{align*} y_i & \\sim \\operatorname{Normal}(\\mu_i, \\sigma) \\\\ \\mu_i & = \\beta_0 + \\beta_1 \\text{treatment}_i, \\end{align*}$$ where\\(\\text{treatment}\\)is a dummy variable coded 0 = control 1 = treatment and varies across cases indexed by\\(i\\). In this setup,\\(\\beta_0\\)is the estimate for\\(\\mu_c\\)and\\(\\beta_1\\)is the estimate of the difference between condition means,\\(\\mu_t - \\mu_c\\). Thus our focal parameter, the one we care about the most in our power analysis, will be\\(\\beta_1\\)",
    "chunk_id": "Adv_cognitive_modelling_bayesian_power_analysis_part_i._prepare_to_reject_`(h_0)`_with_simulation..json_chunk_2"
  },
  {
    "document_type": "online_article",
    "title": "Bayesian power analysis: Part I. Prepare to reject `\\(H_0\\)` with simulation.",
    "author": "Unknown",
    "source": "https://solomonkurz.netlify.app/blog/bayesian-power-analysis-part-i/",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". Thus our focal parameter, the one we care about the most in our power analysis, will be\\(\\beta_1\\). Within the frequentist paradigm, we typically compare these hypotheses using a\\(p\\)-value for\\(H_0\\)with the critical value,\\(\\alpha\\), set to .05. Thus, power is the probability we’ll have\\(p < .05\\)when it is indeed the case that\\(\\mu_c \\neq \\mu_t\\). We won’t be computing\\(p\\)-values in this project, but we will use 95% intervals. Recall that the result of a Bayesian analysis, the posterior distribution, is the probability of the parameters, given the data\\(p (\\theta | \\text{data})\\). With our 95% Bayesian credible intervals, we’ll be able to describe the parameter space over which our estimate of\\(\\mu_t - \\mu_c\\)is 95% probable. That is, for our power analysis, we’re interested in the probability our 95% credible intervals for\\(\\beta_1\\)contain zero within their bounds when we know a priori\\(\\mu_c \\neq \\mu_t\\). The reason we know\\(\\mu_c \\neq \\mu_t\\)is because we’ll be simulating the data that way. What our power analysis will help us determine is how many cases we’ll need to achieve a predetermined level of power. The conventional threshold is .8. To make this all concrete, let’s start with a simple example. We’ll simulate a single set of data, fit a Bayesian regression model, and examine the results for the critical parameter\\(\\beta_1\\). For the sake of simplicity, let’s keep our two groups, treatment and control, the same size. We’ll start with\\(n = 50\\)for each. We already decided above that $$\\begin{align*} y_{i, c} & \\sim \\operatorname{Normal}(0, 1) \\text{ and} \\\\ y_{i, t} & \\sim \\operatorname{Normal}(0.5, 1). \\end{align*}$$ Here’s how we might simulate data along those lines. In case it wasn’t clear, the two variablesgroupandtreatmentare redundant. Whereas the former is composed of names, the latter is the dummy-variable equivalent (i.e., control = 0, treatment = 1). The main event was how we used thernorm()function to simulate the normally-distributed values fory",
    "chunk_id": "Adv_cognitive_modelling_bayesian_power_analysis_part_i._prepare_to_reject_`(h_0)`_with_simulation..json_chunk_3"
  },
  {
    "document_type": "online_article",
    "title": "Bayesian power analysis: Part I. Prepare to reject `\\(H_0\\)` with simulation.",
    "author": "Unknown",
    "source": "https://solomonkurz.netlify.app/blog/bayesian-power-analysis-part-i/",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". The main event was how we used thernorm()function to simulate the normally-distributed values fory. Before we fit our model, we need to decide on priors. To give us ideas, here are thebrmsdefaults for our model and data. A few things: Notice that here we’re using the0 + Interceptsyntax. This is becausebrmshandles the priors for the default intercept under the presumption you’ve mean-centered all your predictor variables. However, since ourtreatmentvariable is a dummy, that assumption won’t fly. The0 + Interceptallows us to treat the model intercept as just another\\(\\beta\\)parameter, which makes no assumptions about centering. Along those lines, you’ll noticebrmscurrently defaults to flat priors for the\\(\\beta\\)parameters (i.e., those for whichclass = b). And finally, the default prior on\\(\\sigma\\)is moderately widestudent_t(3, 0, 2.5). By default,brmsalso sets the left bounds for\\(\\sigma\\)parameters at zero, making that a folded-$t$ distribution. If you’re confused by these details, spend some time with thebrmsreference manual(Bürkner, 2020), particularly thebrmandbrmsformulasections. In this project, we’ll be primarily using two kinds of priors: default flat priors and weakly-regularizing priors. Hopefully flat priors are self-explanatory. They let the likelihood (data) dominate the posterior and tend to produce results similar to those from frequentist estimators. As for weakly-regularizing priors, McElreath covered them in his text. They’re mentioned a bit in theStanteam’sPrior Choice Recommendationswiki, and you can learn even more from Gelman, Simpson, and Betancourt’s (2017)The prior can only be understood in the context of the likelihood. These priors aren’t strongly informative and aren’t really representative of our research hypotheses. But they’re not as absurd as flat priors, either. Rather, with just a little bit of knowledge about the data, these priors are set to keep the MCMC chains on target",
    "chunk_id": "Adv_cognitive_modelling_bayesian_power_analysis_part_i._prepare_to_reject_`(h_0)`_with_simulation..json_chunk_4"
  },
  {
    "document_type": "online_article",
    "title": "Bayesian power analysis: Part I. Prepare to reject `\\(H_0\\)` with simulation.",
    "author": "Unknown",
    "source": "https://solomonkurz.netlify.app/blog/bayesian-power-analysis-part-i/",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". But they’re not as absurd as flat priors, either. Rather, with just a little bit of knowledge about the data, these priors are set to keep the MCMC chains on target. Since ouryvariable has a mean near zero and a standard deviation near one and since our sole predictor,treatmentis a dummy, setting\\(\\operatorname{Normal}(0, 2)\\)as the prior for both\\(\\beta\\)parameters might be a good place to start. The prior is permissive enough that it will let likelihood dominate the posterior, but it also rules out ridiculous parts of the parameter space (e.g., a standardized mean difference of 20, an intercept of -93). And since we know the data are on the unit scale, we might just center our folded-Student-$t$ prior on one and add a gentle scale setting of one. Feel free to disagree and use your own priors. The great thing about priors is that they can be proposed, defended, criticized and improved. The point is to settle on the priors you can defend with written reasons. Select ones you’d feel comfortable defending to a skeptical reviewer. Here’s how we might fit the model. Before we look at the summary, we might check the chains in a trace plot. We’re looking for “stuck” chains that don’t appear to come from a normal distribution (the chains are a profile-like view rather than histogram, allowing for inspection of dependence between samples). Yep, the chains all look good. Here’s the parameter summary. The 95% credible intervals for our\\(\\beta_1\\)parameter, termedtreatmentin the output, are well above zero. Another way to look at the parameter summary is with thebrms::fixef()function. Especially with simple models like this, a lot of the time we spend waiting forbrms::brm()to return the model is wrapped up in compilation. This is becausebrmsis a collection of user-friendly functions designed to fit models withStan(Stan Development Team, 2020,2021a,2021b). With each new model,brm()translates your model intoStancode, which then gets translated to C++ and is compiled afterwards (seehereorhere)",
    "chunk_id": "Adv_cognitive_modelling_bayesian_power_analysis_part_i._prepare_to_reject_`(h_0)`_with_simulation..json_chunk_5"
  },
  {
    "document_type": "online_article",
    "title": "Bayesian power analysis: Part I. Prepare to reject `\\(H_0\\)` with simulation.",
    "author": "Unknown",
    "source": "https://solomonkurz.netlify.app/blog/bayesian-power-analysis-part-i/",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". With each new model,brm()translates your model intoStancode, which then gets translated to C++ and is compiled afterwards (seehereorhere). However, we can use theupdate()function to update a previously-compiled fit object with new data. This cuts out the compilation time and allows us to get directly to sampling. Here’s how to do it. Behold thefixef()parameter summary for our updated model. Well how about that? In this case, our 95% credible intervals for the\\(\\beta_1\\)treatmentcoefficient did include zero within their bounds. Though the posterior mean, 0.30, is still well away from zero, here we’d fail to reject\\(H_0\\)at the conventional level. This is why we simulate. To recap, we’ve We’re more than half way there! It’s time to do our first power simulation. In this post, we’ll play with three ways to do a Bayesian power simulation. They’ll all be similar, but hopefully you’ll learn a bit as we transition from one to the next. Though if you’re impatient and all this seems remedial, you could probably just skip down to the final example,Version 3. For our power analysis, we’ll need to simulate a large number of data sets, each of which we’ll fit a model to. Here we’ll make a custom function,sim_d(), that will simulate new data sets just like before. Our function will have two parameters: we’ll set our seeds withseedand determine how many cases we’d like per group withn. Here’s a quick example of how our function works. Now we’re ready to get down to business. We’re going to be saving our simulation results in a nested data frame,s. Initially,swill have one column ofseedvalues. These will serve a dual function. First, they are the values we’ll be feeding into theseedargument of our custom data-generating function,sim_d(). Second, since theseedvalues serially increase, they also stand in as iteration indexes. For our second step, we add the data simulations and save them in a nested column,d. In the first argument of thepurrr::map()function, we indicate we want to iterate over the values inseed",
    "chunk_id": "Adv_cognitive_modelling_bayesian_power_analysis_part_i._prepare_to_reject_`(h_0)`_with_simulation..json_chunk_6"
  },
  {
    "document_type": "online_article",
    "title": "Bayesian power analysis: Part I. Prepare to reject `\\(H_0\\)` with simulation.",
    "author": "Unknown",
    "source": "https://solomonkurz.netlify.app/blog/bayesian-power-analysis-part-i/",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". For our second step, we add the data simulations and save them in a nested column,d. In the first argument of thepurrr::map()function, we indicate we want to iterate over the values inseed. In the second argument, we indicate we want to serially plug thoseseedvalues into the first argument within thesim_d()function. That argument, recall, is the well-namedseedargument. With the final argument inmap(),n = 50, we hard code 50 into thenargument ofsim_d(). For the third step, we expand ourpurrr::map()skills from above topurrr::map2(), which allows us to iteratively insert two arguments into a function. Within this paradigm, the two arguments are generically termed.xand.y. Thus our approach will be.x = d, .y = seed. For our function, we specify~update(fit, newdata = .x, seed = .y). Thus we’ll be iteratively inserting our simulatedddata into thenewdataargument and will be simultaneously inserting ourseedvalues into theseedargument. Also notice that the number of iterations we’ll be working with is determined by the number of rows in theseedcolumn. We are defining that number asn_sim. Since this is just a blog post, I’m going to take it easy and use 100. But if this was a real power analysis for one of your projects, something like 1,000 would be better. Finally, you don’t have to do this, but I’m timing my simulation by savingSys.time()values at the beginning and end of the simulation. The entire simulation took just about a minute on mynew laptop. Your mileage may vary. Let’s take a look at what we’ve done. In our 100-row nested tibble, we have all our simulated data sets in thedcolumn and all of ourbrmsfit objects nested in thefitcolumn. Next we’ll usefixef()and a little wrangling to extract the parameter of interest,treatment(i.e.,\\(\\beta_1\\)), from each simulation. We’ll save the results asparameters. As an aside, I know I’m moving kinda fast with all this wackypurrr::map()/purrr::map2()stuff",
    "chunk_id": "Adv_cognitive_modelling_bayesian_power_analysis_part_i._prepare_to_reject_`(h_0)`_with_simulation..json_chunk_7"
  },
  {
    "document_type": "online_article",
    "title": "Bayesian power analysis: Part I. Prepare to reject `\\(H_0\\)` with simulation.",
    "author": "Unknown",
    "source": "https://solomonkurz.netlify.app/blog/bayesian-power-analysis-part-i/",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". We’ll save the results asparameters. As an aside, I know I’m moving kinda fast with all this wackypurrr::map()/purrr::map2()stuff. If you’re new to using thetidyversefor iterating and saving the results in nested data structures, I recommend fixing an adult beverage and cozying up with Hadley Wickham’s presentation,Managing many models. And if you really hate it, both Kruschke and McElreath texts contain many examples of how to iterate in a more baseRsort of way. Anyway, here’s what those 100\\(\\beta_1\\)summaries look like in bulk. The horizontal lines show the idealized effect size (0.5) and the null hypothesis (0). Already, it’s apparent that most of our intervals indicate there’s more than a 95% probability the null hypothesis is not credible. Several do. Here’s how to quantify that. With the secondmutate()line, we used a logical statement withinifelse()to code all instances where the lower limit of the 95% interval (Q2.5) was greater than 0 as a 1, with the rest as 0. That left us with a vector of 1’s and 0’s, which we saved ascheck. In thesummarise()line, we took the mean of that column, which returned our Bayesian power estimate. That is, in 66 of our 100 simulations, an\\(n = 50\\)per group was enough to produce a 95% Bayesian credible interval that did not straddle 0. I should probably point out that a 95% interval for whichQ97.5 < 0would have also been consistent with the alternative hypothesis of\\(\\mu_c \\neq \\mu_t\\). However, I didn’t bother to work that option into the definition of ourcheckvariable because I knew from the outset that that would be a highly unlikely result. But if you’d like to work more rigor into your checks, by all means do. And if you’ve gotten this far and have been following along with code of your own, congratulations! You did it! You’ve estimated the power of a Bayesian model with a given\\(n\\). Now let’s refine our approach. I really like it that oursobject contains all ourbrm()fits",
    "chunk_id": "Adv_cognitive_modelling_bayesian_power_analysis_part_i._prepare_to_reject_`(h_0)`_with_simulation..json_chunk_8"
  },
  {
    "document_type": "online_article",
    "title": "Bayesian power analysis: Part I. Prepare to reject `\\(H_0\\)` with simulation.",
    "author": "Unknown",
    "source": "https://solomonkurz.netlify.app/blog/bayesian-power-analysis-part-i/",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". Now let’s refine our approach. I really like it that oursobject contains all ourbrm()fits. It makes it really handy to do global diagnostics like making sure our\\(\\widehat R\\)values are all within a respectable range. Man those\\(\\widehat R\\)values look sweet. It’s great to have a workflow that lets you check them. But holding on to all those fits can take up a lot of memory. If the only thing you’re interested in are the parameter summaries, a better approach might be to do the model refitting and parameter extraction in one step. That way you only save the parameter summaries. Here’s how you might do that. Like before, this only about a minute. As a point of comparison, here are the sizes of the results from our first approach to those from the second. That’s a big difference. Hopefully you get the idea. With more complicated models and 10+ times the number of simulations, size will eventually matter. Anyway, here are the results. Same parameter summaries, lower memory burden. So far, both of our simulation attempts resulted in our saving the simulated data sets. It’s a really nice option if you ever want to go back and take a look at those simulated data. For example, you might want to inspect a random subset of the data simulations with box plots. In this case, it’s no big deal if we keep the data around or not. The data sets are fairly small and we’re only simulating 100 of them. But in cases where the data are larger and you’re doing thousands of simulations, keeping the data could become a memory drain. If you’re willing to forgo the luxury of inspecting your data simulations, it might make sense to run our power analysis in a way that avoids saving them. One way to do so would be to just wrap the data simulation and model fitting all in one function. We’ll call itsim_d_and_fit(). Now iterate 100 times once more. That was pretty quick. Here’s what it returned",
    "chunk_id": "Adv_cognitive_modelling_bayesian_power_analysis_part_i._prepare_to_reject_`(h_0)`_with_simulation..json_chunk_9"
  },
  {
    "document_type": "online_article",
    "title": "Bayesian power analysis: Part I. Prepare to reject `\\(H_0\\)` with simulation.",
    "author": "Unknown",
    "source": "https://solomonkurz.netlify.app/blog/bayesian-power-analysis-part-i/",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". We’ll call itsim_d_and_fit(). Now iterate 100 times once more. That was pretty quick. Here’s what it returned. By wrapping our data simulation, model fitting, and parameter extraction steps all in one function, we simplified the output such that we’re no longer holding on to the data simulations or thebrmsfit objects. We just have the parameter summaries and theseed, making the product even smaller. But the primary results are the same. We still get the same power estimate, too. But my goal was to figure out what\\(n\\)will get me power of .8 or more!, you say. Fair enough. Try increasingnto 65 or something. If that seems unsatisfying, welcome to the world of simulation. Since our Bayesian models are complicated, we don’t have the luxury of plugging a few values into some quick power formula. Just as simulation is an iterative process, determining on the right values to simulate over might well be an iterative process, too. Anyway, that’s the essence of thebrms/tidyverseworkflow for Bayesian power analysis. You follow these steps: In addition, we played with a few approaches based on logistical concerns like memory. In the next post,part II, we’ll see how the precision-oriented approach to sample-size planning is a viable alternative to power focused on rejecting null hypotheses. Special thanks to Christopher Peters (@statwonk) for the helpful edits and suggestions. Bürkner, P.-C. (2017).brms: An R package for Bayesian multilevel models using Stan.Journal of Statistical Software,80(1), 1–28.https://doi.org/10.18637/jss.v080.i01 Bürkner, P.-C. (2018). Advanced Bayesian multilevel modeling with the R package brms.The R Journal,10(1), 395–411.https://doi.org/10.32614/RJ-2018-017 Bürkner, P.-C. (2020).brmsreference manual, Version 2.14.4.https://CRAN.R-project.org/package=brms/brms.pdf Bürkner, P.-C. (2022).brms: Bayesian regression models using ’Stan’.https://CRAN.R-project.org/package=brms Cohen, J. (1988).Statistical power analysis for the behavioral sciences. L",
    "chunk_id": "Adv_cognitive_modelling_bayesian_power_analysis_part_i._prepare_to_reject_`(h_0)`_with_simulation..json_chunk_10"
  },
  {
    "document_type": "online_article",
    "title": "Bayesian power analysis: Part I. Prepare to reject `\\(H_0\\)` with simulation.",
    "author": "Unknown",
    "source": "https://solomonkurz.netlify.app/blog/bayesian-power-analysis-part-i/",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". (2022).brms: Bayesian regression models using ’Stan’.https://CRAN.R-project.org/package=brms Cohen, J. (1988).Statistical power analysis for the behavioral sciences. L. Erlbaum Associates.https://www.worldcat.org/title/statistical-power-analysis-for-the-behavioral-sciences/oclc/17877467 Gelman, A., Simpson, D., & Betancourt, M. (2017). The prior can often only be understood in the context of the likelihood.Entropy,19(10, 10), 555.https://doi.org/10.3390/e19100555 Grolemund, G., & Wickham, H. (2017).R for data science. O’Reilly.https://r4ds.had.co.nz Kruschke, J. K. (2015).Doing Bayesian data analysis: A tutorial with R, JAGS, and Stan. Academic Press.https://sites.google.com/site/doingbayesiandataanalysis/ Kurz, A. S. (2020).Doing Bayesian data analysis in brms and the tidyverse(version 0.3.0).https://bookdown.org/content/3686/ Kurz, A. S. (2020).Statistical rethinking with brms, Ggplot2, and the tidyverse: Second edition(version 0.1.1).https://bookdown.org/content/4857/ Kurz, A. S. (2020).Statistical rethinking with brms,ggplot2, and the tidyverse(version 1.2.0).https://doi.org/10.5281/zenodo.3693202 Maxwell, S. E., Kelley, K., & Rausch, J. R. (2008). Sample size planning for statistical power and accuracy in parameter estimation.Annual Review of Psychology,59(1), 537–563.https://doi.org/10.1146/annurev.psych.59.103006.093735 McElreath, R. (2020).Statistical rethinking: A Bayesian course with examples in R and Stan(Second Edition). CRC Press.https://xcelab.net/rm/statistical-rethinking/ McElreath, R. (2015).Statistical rethinking: A Bayesian course with examples in R and Stan. CRC press.https://xcelab.net/rm/statistical-rethinking/ Peng, R. D. (2019).R programming for data science.https://bookdown.org/rdpeng/rprogdatascience/ R Core Team. (2022).R: A language and environment for statistical computing. R Foundation for Statistical Computing.https://www.R-project.org/ Stan Development Team",
    "chunk_id": "Adv_cognitive_modelling_bayesian_power_analysis_part_i._prepare_to_reject_`(h_0)`_with_simulation..json_chunk_11"
  },
  {
    "document_type": "online_article",
    "title": "Bayesian power analysis: Part I. Prepare to reject `\\(H_0\\)` with simulation.",
    "author": "Unknown",
    "source": "https://solomonkurz.netlify.app/blog/bayesian-power-analysis-part-i/",
    "date_published": "Unknown",
    "flag": "",
    "chunk_text": ". (2022).R: A language and environment for statistical computing. R Foundation for Statistical Computing.https://www.R-project.org/ Stan Development Team. (2020, February 10).RStan: The R interface to Stan.https://cran.r-project.org/web/packages/rstan/vignettes/rstan.html Stan Development Team. (2021a).Stan reference manual, Version 2.27.https://mc-stan.org/docs/2_27/reference-manual/ Stan Development Team. (2021b).Stan user’s guide, Version 2.26.https://mc-stan.org/docs/2_26/stan-users-guide/index.html Wickham, H. (2020).The tidyverse style guide.https://style.tidyverse.org/ Wickham, H. (2022).tidyverse: Easily install and load the ’tidyverse’.https://CRAN.R-project.org/package=tidyverse Wickham, H., Averick, M., Bryan, J., Chang, W., McGowan, L. D., François, R., Grolemund, G., Hayes, A., Henry, L., Hester, J., Kuhn, M., Pedersen, T. L., Miller, E., Bache, S. M., Müller, K., Ooms, J., Robinson, D., Seidel, D. P., Spinu, V., Yutani, H. (2019). Welcome to the tidyverse.Journal of Open Source Software,4(43), 1686.https://doi.org/10.21105/joss.01686 © A. Solomon Kurz (2022)Made withHugo Apéro.Based onBlogophonicbyFormspree.",
    "chunk_id": "Adv_cognitive_modelling_bayesian_power_analysis_part_i._prepare_to_reject_`(h_0)`_with_simulation..json_chunk_12"
  }
]