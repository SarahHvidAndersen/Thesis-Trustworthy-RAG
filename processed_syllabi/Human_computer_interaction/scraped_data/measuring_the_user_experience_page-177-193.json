{
    "document_type": "book",
    "title": "Measuring the User Experience (third edition)",
    "author": "Bill ALbert, Tom Tullis",
    "source": "raw_syllabi\\master_courses\\Human_computer_interaction\\pdf_material\\Measuring the User Experience.pdf",
    "date_published": "2022-09-11",
    "keywords": "Unavailable",
    "flag": "",
    "text": "177 CHAPTER 7 Eye Tracking CONTENTS 7.1\tHOW EYE TRACKING WORKS 178 7.2\tMOBILE EYE TRACKING 180 7.2.1\tMeasuring Glanceability 181 7.2.2\tUnderstanding Mobile Users in Context 182 7.2.3\tMobile Eye Tracking Technology 183 7.2.4\tGlasses 183 7.2.5\tDevice Stand 183 7.2.6\tSoftware-Based Eye Tracking 185 7.3\tVISUALIZING EYE TRACKING DATA 186 7.4\tAREAS OF INTEREST 187 7.5\tCOMMON EYE TRACKING METRICS 189 7.5.1\tDwell Time 189 7.5.2\tNumber of Fixations 190 7.5.3\tFixation Duration 190 7.5.4\tSequence 190 7.5.5\tTime to First Fixation 190 7.5.6\tRevisits 191 7.5.7\tHit Ratio 191 7.6\tTIPS FOR ANALYZING EYE TRACKING DATA 191 7.7\tPUPILLARY RESPONSE 192 7.8\tSUMMARY 193 Eye tracking is a powerful tool in user research to gain insights into how indi- viduals visually examine different scenes, such as web pages, mobile applica- tions, grocery store shelves, or even billboards on subway platforms. As a UX researcher, eye tracking is a valuable method to better understand how someone visually interacts with any stimuli, answering fundamental questions such as: • What do they notice? • How long do they look at it? • What do they see first? • What don’t they notice (that they should)? \nEye tracking has been around since the early 1900s. Huey (1908) devised a system whereby someone would wear a contact lens with a small hole for the pupil. The contact lens was then physically attached to a pointing device which would allow researchers to observe eye movements while reading text. Thankfully, we have come a long way since then. Eye tracking is now affordable (for most budgets), highly accurate, able to measure eye movements across a wide variety of stimuli and scenes, portable (through glasses), and the analysis and visualization tools are powerful and easy to use. Plus, there is no need to inject ink into anyone's eye! Eye tracking is typically performed in one of two ways in the context of user research. In one way, eye tracking is based on a set of research questions that necessitate the need to analyze eye movements. This might involve comparing the visual attention patterns of two different web designs. In order to answer this question, the researcher must collect and analyze eye movement data. In this case, the “hit ratio” would tell them the percentage of participants who notice (or fixate) on an object in one web design compared to another web design. Another way in which eye tracking is often used in user research is simply to generate real-time qualitative insights. A stakeholder might be interested in observing the eye movements in real time or as part of a participant recording, without any intention of analyzing the data. Observing eye movements provides an additional layer of data to gain a more complete picture of the user experi- ence. Sometimes, the only associated deliverable is a heat map, with any associ- ated metrics. No matter what approach you take with eye tracking, it is critical to determine the goals and the desired output before any work begins. The information provided by an eye tracking system can be remarkably useful as part of user research. Simply enabling observers to see where the participant is looking in real time is extremely valuable. Even if you do no further analyses of the eye tracking data, just this real-time display provides insight that would not be possible otherwise. For example, assume a participant is performing a task on a website and there's a link on the homepage that would take him directly to the page required to complete the task. The participant keeps exploring the website, going down dead ends, returning to the homepage, but never reaching the required page. In a situation like this, you would like to know whether the participant ever saw the appropriate link on the homepage or whether he saw the link but dismissed it as not what he wanted (e.g., because of its wording). Although you could subsequently ask participants that question, their mem- ory may not be completely accurate. With an eye tracking system, you can tell whether the participant at least fixated on the link long enough to read it. 7.1 \u0007HOW EYE TRACKING WORKS Although a few different technologies are used, many eye tracking systems, such as the one shown in Fig. 7.1 , use some combination of an infrared video camera \nand infrared light sources to track where the participant is looking. The infrared light sources create reflections on the surface of the participant's eye (called the cor- neal reflection), and the system compares the location of that reflection to the location of the participant's pupil. The location of the corneal reflection relative to the pupil changes as the partic- ipant moves his eyes. The first activity in any eye tracking study is to calibrate the system by asking the participants to look at a series of known points; then the system can subsequently interpolate where a participant is looking based on the location of the corneal reflection. Typically, the researcher can check the quality of the calibration, usually expressed as degrees that devi- ate from the X and Y visual planes. Deviations less than one degree are gener- ally considered to be acceptable, and less than one-half of a degree is very good. Most eye tracking systems tell you something about the quality of the calibra- tion and an opportunity to attempt another calibration to improve the accuracy. It is critical that the calibration is satisfactory; otherwise, all the eye movement data should not be recorded or analyzed. Without a good calibration, there will be a disconnect between what the participant is actually looking at and what you assume he/she is looking at. Following calibration, the moderator makes sure the eye movement data are being recorded. The biggest issue tends to be partici- pants who move around in their seat. Occasionally, the moderator is required to ask the participant to move back/forward, left/right, or raise/lower their seat to recapture the participant’s eyes. Fig. 7.1  An eye tracking system from Tobii. This eye tracking hardware is easily portable and plugs into the computer’s USB port. INSTRUCTIONS FOR CALIBRATING In our experience, there are a few simple instructions that can go a long way toward making the experience easy for both participants and researchers, and provide reliable eye tracking data. 1.\tMake sure the participants are sitting at the right height and distance from the monitor or whatever device (interface) you are tracking. Chairs should ideally be on wheels, with adjustable heights. 2.\tLet the participants know that the calibration process is quick, simple, and nothing will be touching them. \n7.2 \u0007MOBILE EYE TRACKING Contributed by Andrew Schall, Modernizing Medicine. Users interact with mobile devices very differently than those in a desktop environment. Think about the kind of tasks that you perform when using your smartphone versus using a laptop. Also consider where you are performing these activities and how the environment affects your experience. Mobile experiences often occur when people are on the go and need to accomplish tasks quickly, and this can be significantly impacted by their context of use. Eye tracking pro- vides eye gaze behavior that is ideal for understanding how people view content on their mobile devices, as well as usability metrics such as glanceability. 3.\tWhen you display the dynamic calibration point (typically a small circle), tell them to visually follow or trace the circle as it moves around the screen. When the circle momentarily stops at each position, make sure they are looking at the center of the circle. 4.\tDepending on the quality of the calibration, you may have to ask the participant to go through the process a second time. Simply say something “thanks for doing that—we are going to do it once more so we can make sure we have the most accurate capture of your eye movements.” We typically don’t go through a third time, unless it is necessary for the study. 5.\tDuring the course of the study, participants may move so you no longer are tracking them. Simply ask them to readjust their position so their eyes are again being tracked. If they move around a lot, you might consider asking them to keep still as best they can. PARTICIPANTS WHO ARE DIFFICULT TO CALIBRATE It is easy to get a good calibration from most participants. However, there are a few instances that can pose particular challenges. If someone has very narrow framed glasses, the system will have difficulty distinguishing the frames of the glasses from the pupil. Also, if someone is wearing heavy eye make-up, specifically if it is reflective, this will make for a challenging calibration. Lastly, if someone is very fidgety in the chair, such as a child, this will mean that many times you will lose the eye, and you will need them to reposition themselves in a proper position. There is not a lot you can do, other than to specify your requirements during your recruit, as well as give clear instructions during the warm-up. Don’t let this discourage you, though. In our experience, we get a good calibration with well over 90% of our participants, even those with glasses. \n7.2.1 \u0007Measuring Glanceability Glanceability is defined as being able to quickly view and understand informa- tion. Mobile experiences often rely on the user noticing subtle visual cues that occur within a mobile app and then promptly acting on them. Some of the questions that can be addressed when measuring glanceability include: • How long does it take a user to notice and read a notification on their smartwatch while they are out for a run? • How quickly can a user find departure times to determine the next sub- way train to board to get to their destination? • During a meeting, how quickly can a user identify an incoming call and determine whether to answer it or not? An interface with a high degree of glanceability can be identified by rela- tively low fixation counts, short fixation durations, and short saccades. These eye tracking metrics should be paired with task performance data to determine how quickly the user was able to successfully complete a task based on the informa- tion that was observed. Fig. 7.2 shows a participant using a mobile app to compare prices in the store with those found online. This eye gaze video showed that this user quickly skimmed over the product name (indicated by the red circle) to make sure that it matched the in-store item. Fig. 7.2  An example of the use of eye tracking technology with a mobile device. \n7.2.2 \u0007Understanding Mobile Users in Context Eye tracking can provide insights into how your user’s environment and situa- tion impact their experience. Some of the questions that eye tracking can help us to answer include: • How do the distractions and disruptions on a subway train impact how users consume social media content on their phone? • How easy is it to set up and use two-factor authentication when checking your bank account balance on your smartwatch while waiting in line at a coffee shop? • While texting with a friend, what information does a user look at to determine the highest-rated pub within walking distance of their current location? Fig. 7.3 shows the variety of contexts in which eye tracking can be used in the real environment. Eye tracking glasses provided a first-person perspective as this participant attempted to set up and use the Alaska Airlines iPhone and Apple Watch apps while waiting for her flight. All of these situations require researchers to get out of the UX lab and take eye trackers into the field to see how mobile applications are used in a real-world Fig. 7.3  An example of mobile eye tracking across multiple devices and media. \nenvironment. Eye tracking can tell us how these situations affect what the user looks at while performing tasks with their mobile devices. 7.2.3 \u0007Mobile Eye Tracking Technology Conducting eye tracking research with mobile devices presents a few unique challenges. First, consider that neither the participant nor the device nor the eye tracker are stationary. This can impact the eye tracker’s ability to track participants accurately and consistently, and also potentially make it difficult to capture eye tracking data across multiple participants. In addition, mobile technology has grown to include many other devices besides a smartphone. Researchers need to evaluate the users’ experience on tablet devices, smart watches, and other wearables. There are several technologies that can be used to track mobile devices: • Glasses and wearable eye trackers : Eyewear containing eye tracking hardware worn by a participant that is paired with a portable recording device. • Device stand : A platform and arm that is used to affix a mobile device and eye tracker unit. • Software : A software app that uses the embedded camera within a mobile device. 7.2.4 \u0007Glasses Eye tracking glasses ( Fig. 7.4 ) can show us exactly what a person is looking at as they move freely in any real-world setting. The glasses provide a first-person per- spective that helps us to understand what a user is looking at in their environ- ment and to provide added context to their experience when using their mobile device. While the glasses provide a high degree of freedom for the participant, it makes it very challenging to compare eye tracking data across participants. It is recommended to use the glasses for only qualitative research insights and to rely on eye gaze recordings to tag key observational findings. 7.2.5 \u0007Device Stand A mobile device stand is best used when it is most important to standardize the testing environment where your users will be interacting with the device ( Fig. 7.5 ). The stand is used by attaching the mobile device to a platform or cradle, along with an eye tracking unit. A camera is fixed to the stand using an arm and is directed at the face of the mobile device. By restricting the movement of the device and eye tracker, it is possible to overlay eye tracking data from differ- ent participants to produce aggregated visualizations such as heatmaps and eye gaze plots. \nFig. 7.4  An example of how eye tracking glasses can be used to understand how users consume news on their phone while sipping a latte at their local coffee shop. (This image may be used for editorial purposes with credits to Tobii AB. https://www.tobiipro.com/imagevault/publishedmedia/e317fzptqw0jk3svfn4t/ TobiiPro-Glasses2-Mobile-Devseice-Usability-Cafe-150.jpg?download = 1 ) Fig. 7.5  The Tobii mobile device stand can be paired with a Tobii × 2 eye tracker and the device platform can be used with any model tablet or smartphone. \nIt is important to note that this configuration creates an artificial situation for using a mobile device. Participants interact with the device while it is sitting on the stand instead of holding it in their hands. 7.2.6 \u0007Software-Based Eye Tracking Eye movement behavior can vary widely from person to person. In order to generalize eye gaze patterns, we need tracking data from a lot of eyes. Using a software-based eye tracking solution allows any smartphone to become an eye tracking device. This allows researchers to collect eye tracking data from hun- dreds, if not thousands, of participants while they interact with a mobile web- site or app. To use this solution, participants will need to install an app on their smart- phone, or the software provider will need to embed the code within their app using an SDK. This solution relies on using the camera built into the smart- phone, and tracking accuracy can be dependent on sufficient ambient lighting conditions. Strengths and Limitations of Mobile Eye Tracking Solutions Technology Strength Limitation Glasses •\t Total freedom of movement •\t Highly portable •\t Best for qualitative insights •\t Expensive compared to other eye tracking solutions •\t Difficult to compare results across participants •\t No quantitative metrics Stand •\t Consistent configuration allows for easier comparison across participants •\t Can produce eye tracking visualizations •\t Less natural experience for the participant •\t Not very portable •\t Limited quantitative analysis capabilities Software •\t No additional hardware needed •\t Potential for large-scale data collection •\t Eye tracking visualizations that can be aggregated across participants •\t Less accurate than traditional eye tracking systems •\t Tracking accuracy can be affected by variability in ambient lighting conditions \n7.3 \u0007VISUALIZING EYE TRACKING DATA There are many ways to visualize eye tracking data. These visualizations tell the story about where people were looking and when. They might be the only thing that your stakeholders really care about. All eye tracking visualizations are either at an individual level, showing eye movements for one participant, or at an aggregate level, showing eye movements for more than one participant. Fig. 7.6 shows the series or sequence of fixations that an individual partici- pant made on the Emirates Airlines website, also known as a scan path. This is perhaps the most common way to visually represent the eye movements for a single participant. A fixation is defined by a pause in the eye's movement within a well-defined area. Eye fixations are typically around 200 ms to 250 ms (1/5th or 1/4th of a second) but are highly variable (Galley, Betz, & Biniossek, 2015). The fixations are usually numbered to indicate their sequence. The size of each circle is proportional to the length or duration of the fixation. The saccades , or movements between fixations, are shown by the lines. In Fig.7.6 it is easy to notice that the participant was focused primarily on holiday graphics at the top of the screen and the tabs directly below. However, he did not look at the logo at the top left or the content towards the bottom of the screen. Scan paths are an excellent way to show how a participant looked at the page, and what elements they saw in what order. By far the most common way to visually represent eye movement for multi- ple participants is through a heat map ( Fig. 7.7 ). In this visualization, the bright- est areas (red) represent greater density of fixations. It is an excellent way to get a sense of what areas of the page attract more (and less) visual attention. As you can see, visual attention on the REI outdoor website was concentrated on ACCURACY OF WEBCAM–BASED EYE TRACKING Burton, Albert, and Flynn (2014) conducted research comparing the accuracy of traditional infrared eye tracking systems with webcam-based eye tracking systems. Webcam-based eye tracking systems hold great promise for user researchers because of significantly lower cost, but also the ability to capture eye movement data from a large number of geographically dispersed users, without having to come into a lab. The study was very simple. Participants were presented a set of images (large and small size) on a 3 × 3 grid on the screen using both an infrared and webcam eye tracking system. Participants were instructed to look at each of the images as they were presented in different locations on the screen. The results clearly showed that both the infrared and webcam-based eye tracking systems were adequate for capturing eye movement data when looking at larger images in the center of the screen. However, the webcam-based eye tracking system was not as accurate when capturing eye movements specific to smaller images, or any size images as they moved toward the edges of the screen, regardless of their size. \nthe woman’s face and the 40% offer to the left, with very little visual attention afforded to the top navigation elements. It is important to keep in mind that the analysis software allows the researcher to define the scale of what is considered “red” versus “orange,” etc. So, beware that the researcher can easily exaggerate heat maps to show more or less color. We recommend using the default settings on most software; however, it is impor- tant to experiment with using different scales. 7.4 \u0007AREAS OF INTEREST The most common way to analyze eye tracking data is by measuring visual atten- tion on specific elements or regions. Most researchers are not just interested in how visual attention is generally distributed across an entire web page or scene, but whether participants noticed certain objects and how much time was spent looking at them. This is particularly the case in marketing, whereby the success of an ad campaign is directly tied to getting customers to notice some- thing. Also, it’s a concern when there are certain elements that are critical to task Fig. 7.6  Example of one individual’s scan path of eye movements on the Emirates Airlines website. \nsuccess or having a positive experience. When the users don’t see them, you can be sure that is a problem. Fig. 7.8 is an example of how to define specific regions on the page. These regions are typically referred to as “look zones” or “areas of interest” (AOIs). AOIs are essentially those objects (or collection of objects) that you want to measure, as defined by a set of x , y coordinates. In Fig. 7.8 there, are four AOIs, with the associated statistics for each AOI: • TTTF: This is “time to first fixation,” or the average amount of time to first notice the object. As you can see from Fig. 7.8 , the large text next to the women was noticed first, after less than 1 second, whereas the button to watch a video took nearly 5 seconds on average to first notice. • Time Spent: This is the average dwell time, or the average “time spent” looking at the AOI. As you can see, nearly 2 seconds on average were spent looking at the large image/text block in the center of the screen (AOI 1), and a ½ second looking at the four calls to action (AOI 2) on the upper right. • Ratio: The ratio is simply the number of participants who fixated, at least one time, within the AOI. All 9 participants (9/9) fixated within the large image/text block, whereas only 5 out of the 9 participants fixated on the logo in the upper left. Fig. 7.7  Example of a heat map of the REI outdoor website. \nWhen analyzing the time spent looking at different regions, keep the follow- ing in mind: • Carefully define each region. Ideally there will be a small amount of white space in between regions to make sure the eye movements don’t get caught in between two AOIs right next to each other. • Each region should be fairly homogeneous, such as navigation, content, ads, legal information, and so forth. If you prefer to subdivide your AOIs into individual elements, you can always aggregate as part of post-hoc analysis. • When presenting data by AOIs, the question about where participants actually looked within the region typically comes up. Therefore, we rec- ommend including a heat map, as in Fig. 7.8 , that shows the continuous distribution of fixations. 7.5 \u0007COMMON EYE TRACKING METRICS There are many metrics associated with eye tracking data. The following are some of the most common eye tracking metrics used by UX researchers. It’s important that all of these metrics are associated with specific AOIs. Fig. 7.8 is an example of the type of metrics derived from a single AOI. 7.5.1 \u0007Dwell Time The dwell time is the total amount of time spent looking within an AOI. This includes all fixations and saccades within the AOI, including revisits. Dwell time is an excellent metric that conveys the level of interest with a certain AOI. Fig. 7.8  Example of common eye tracking statistics for different areas of interest. \nObviously, the greater the dwell time, the greater the level of interest in the AOI. As a general rule of thumb, dwell times less than 100ms generally mean the par- ticipant processed a limited amount of information. A dwell time greater than 500 ms generally means the participant had an opportunity to process. 7.5.2 \u0007Number of Fixations The number of fixations is simply the total count of fixations with an AOI. The number of fixations, as expected, is strongly correlated with dwell time. Because of this, we typically just report dwell time. 7.5.3 \u0007Fixation Duration Fixation duration is the average time for the fixations. Fixation duration typi- cally ranges from 150 to 300 ms. Fixation duration, similar to number of fixa- tions and dwell time, represents the relative engagement with the object. The greater the average fixation duration, the greater the level of engagement. 7.5.4 \u0007Sequence The sequence represents the order in which each AOI is first fixated. The sequence tells the researcher the relative prominence of each AOI within the context of a given task. Sometimes it is very helpful to know which AOIs are jumping out to users initially and which AOIs are receiving attention later on. Typically, sequence is calculated as the average order that each AOI was visited. Keep in mind that many participants may not have experienced that exact same order. Sequence is just a best estimate. 7.5.5 \u0007Time to First Fixation In some situations, it's helpful to know how long it takes users to first notice a particular element. For example, you may know that users spend only 7 seconds on average on the page, but you want to make sure that a specific element, such as a “continue” or “sign up” button, is noticed within the first 5 seconds. It's helpful that most eye tracking systems timestamp each fixation (i.e., the exact time that each fixation occurred). One way to analyze these data is to take an average of all the times at which the particular element was first fixated. The data should be treated as elapsed time, starting from the initial exposure. The average represents the amount of time taken to first notice the element, for all of those who did notice it. Of course, it's possible that some of the participants may not have noticed it all, let alone within the first 5 seconds. Therefore, you may come up with some mis- leading data showing an artificially quick time by not taking all the participants into account. \n7.5.6 \u0007Revisits Revisits are the number of times that the eye fixates within an AOI, leaves the AOI, and returns back to fixate within the AOI. Revisits indicate the “stickiness” of the AOI. Do the users fixate and leave the AOI, never to return, or do their eyes keep coming back? 7.5.7 \u0007Hit Ratio The hit ratio is the percentage of participants who had at least one fixation within the AOI. In other words, this is the number of participants who saw the AOI. CAN YOU TRUST WHAT PEOPLE SAY THEY SAW IN A USABILITY TEST? Albert and Tedesco (2010) ran an experiment in which they used eye tracking to test whether usability test participants accurately report what they see. In this study, participants looked at a series of website home pages. After being shown each home page, the moderators pointed out a specific element. Half of the participants indicated if they had looked at specific elements based on three potential answers (did not look at the element, not sure if they looked at the element, or did look at the element). The other half of the participants used a five-point scale based on how much time was spent looking at that element (from “no time at all” up to “a lot of time”). The results showed that in general, the eye movements were consistent with what the participants reported seeing. However, in about 10% of the cases, the participant claimed to have “definitely seen” an element that the eye-movement data showed they did not fixate. In the second group of participants, about 5% of the cases, the participants said they “spent a long time looking at an element” yet did not have any eye fixations on that element. Together, these results suggest that participants self-reporting what they looked at during a usability test is reasonably reliable but certainly not perfect. 7.6 \u0007TIPS FOR ANALYZING EYE TRACKING DATA Over the years we have learned a few things about how to analyze eye track- ing data. Above all else, we strongly recommend you plan your study carefully, as well as take time to explore the data. It’s easy to draw the wrong conclusion based on a few heat maps. Here are a few other important tips to keep in mind as you dive into the data: • Control the amount of exposure time for each participant. If they did not see the same image or stimuli for the same time, pre-define the time to only include the first 10 or 15 seconds, or whatever duration makes the most sense given the context. \n• If you are not able to control for exposure time, analyze the dwell time as a percentage, not as an absolute. If someone spent 10 seconds, and the other person spent 1 minute, their eye movements will be very different, as well as the actual amount of time spent looking at each element. • Only look at time data when the participant is engaged with the task. Do not include any time data when the participant is debriefing about their experience and still being tracked. • During the study, make sure that the participant is being tracked. Monitor their eye movements in real time. As soon as they start to slouch or turn their head, gently remind them to maintain their original position. • Be careful when analyzing the eye movements on dynamic websites. Websites that change considerably due to ads, flash, frames, etc. confuse most eye tracking systems. Every new image is essentially treated as sepa- rate stimuli. We strongly recommend that you consolidate as many web pages together as possible, knowing that not every page is exactly identi- cal. Otherwise, you will end up with way too many web pages that were only viewed by a single participant. An alternative to this is to simply use static images. They are much easier to analyze but lack an interactive experience. • Consider using a trigger AOI to control where participants are initially looking at the start of the experiment. A trigger might say, “look here to start the experiment.” The text might be in the middle part of the page. After the participant has fixated on the text for a certain number of seconds, the experiment begins. This means that all participants start looking from the same location. This might be overkill for the typical usability test but should be considered for more tightly controlled eye tracking studies. 7.7 \u0007PUPILLARY RESPONSE Closely related to the use of eye tracking in user research studies is the use of information about the response of the pupil. Most eye tracking systems must detect the location of the participant's pupil and calculate its diameter to deter- mine where he or she is looking. Consequently, information about pupil diam- eter is included in most eye tracking systems. The study of pupillary response, or the contractions and dilations of the pupil, is called pupillometry. Most people know that the pupil contracts and dilates in response to the level of ambient light, but many people don't know that it also responds to cognitive processing, arousal, and increased interest. Typically, the greater the level of arousal or inter- est, the larger the pupil size. Because pupil dilation is correlated with so many different mental and emo- tional states, it's difficult to say whether pupillary changes indicate successes or failures in everyday usability testing. However, measuring pupil diameter may be useful in certain situations where the focus is on the amount of mental concentra- tion or emotional arousal. For example, if you are mainly interested in eliciting \nan emotional response to a new graphic on a website, then measuring changes in pupil diameter (from baseline) may be very useful. To do this, simply measure the percentage deviation away from a baseline for each participant and average those deviations across the participants. Alternatively, you can measure the percentage of participants who experienced dilated pupils (of a certain amount) while attend- ing to a particular graphic or performing a specific function. 7.8 \u0007SUMMARY In this chapter we covered eye tracking as a powerful tool in measuring visual attention and engagement. Eye tracking is becoming much easier to use, more accurate, more versatile and powerful, and even quite affordable. Here’s a ­summary of some of the key points to remember. 1.\t Eye tracking is the best way to measure visual attention of various aspects of a product, such as a website or mobile application. Eye track- ing is used to compare the effectiveness of different designs, as well ­calculate metrics based on areas of interest. 2.\t Eye tracking typically works with the use of infrared technology. By comparing the position of the corneal reflection to the pupil, we can calculate the gaze direction at any time. 3.\t Calibration is a key part to any eye tracking study. It is important to obtain satisfactory calibration so you can accurately measure eye movements. 4.\t Eye tracking mobile applications require the use of glasses that permit tracking eye movements, and possibly a device stand to better control the testing environment. 5.\t Visualizations in eye tracking tell the story about where people were looking and when. The most common visualizations are scan paths showing the movement of fixations, along with their duration. Another popular visualization is a heatmap, which depicts the distribution of visual attention from, typically, a group of people. 6.\t Areas of Interest, or AOIs, are one of the most common ways to ana- lyze eye tracking data. AOIs are objects on the screen, such as a particular block of text, functionality, or image. We commonly measure the amount of time spent looking at various AOIs, how long an AOI takes to receive it’s first fixation, or the order in which various AOIs are looked at. 7.\t There are many metrics associated with eye tracking; however, the most common is dwell time, or the total amount of time spent looking at an object (or AOI). Measuring the sequence tells us about the relative importance of different objects, as well as the TTFF. 8.\t Measuring changes to pupil diameter is a lesser used, but sometimes valuable, way to measure level of arousal or engagement. An increase in pupil diameter has been shown to correlate to heightened levels of interest; however, it is also influenced by external factors, such as light levels."
}