{
    "document_type": "research_paper",
    "title": "Theories of embodiment in HCI",
    "author": "Paul Marshall and Eva Hornecker",
    "source": "raw_syllabi\\master_courses\\Human_computer_interaction\\pdf_material\\embodimentChapterSage.pdf",
    "date_published": "2016-11-30",
    "keywords": "",
    "flag": "",
    "text": "Theories of embodiment in HCI Paul Marshall * and Eva Hornecker ** * UCL Interaction Centre University College London Gower Street, London, WC1E 6BT, UK ** Department of Computer and Information Science University of Strathclyde 26 Richmond St., Glasgow, G1 1XH Author bios: Paul Marshall is a lecturer in interaction design at University College London. His research interests centre on the concept of embodied interaction and how it can be applied to the design and evaluation of technologies that extend and augment individual human capabilities. This has included work on physical interaction and tangible interfaces; on technologies for face-to-face collaboration; on the design of technologies to fit specific physical contexts; and on extended cognition and perception. Eva Hornecker is a lecturer in the Dept. of Computer and Information Science at the University of Strathclyde. Her research interests focus on the design and user experience of 'beyond the desktop' interaction. This includes multitouch surfaces, tangible interaction, whole-body interaction, mobile devices, physical and physically embedded computing, support of social/collaborative interactions, and the social/societal implications of technology. 1. Introduction The concept of embodiment increasing in prominence in thinking about the design of digital technologies, particularly in the decade since the publication of Paul Dourish’s Where the Action Is (Dourish, 2001). In this chapter, we focus on how it has been applied in the area of Human Computer Interaction (HCI). Embodiment typically refers to our being living, feeling, bodily entities situated in a physical world. This contrasts with a view of human cognition as grounded in abstract information processing. Theories of embodiment focus on how our bodies and active experiences shape how we perceive, feel and think. However, rather than being a single coherent theoretical perspective, there are a number of different traditions and emphases. Here, we provide an overview of the core theoretical underpinnings of recent work on embodied interaction in HCI and show how this work has been developed in primarily two related directions through the description of work drawn from the literature. We introduce these two main branches of theory: phenomenology and embodied cognition. In the first main section, we provide a short historical overview of the cognitivist theories that were once ascendant in HCI, and follow the development of alternative views of thinking and \nacting, drawing from phenomenology through the work of Winograd and Flores, Lucy Suchman and Paul Dourish. In the next section we provide an overview of work in cognitive science described by the umbrella term embodied cognition, which has been influenced by discussions in phenomenology, but has followed a quite different trajectory. This comprises a number of theoretical perspectives, including that cognition is offloaded onto the environment (e.g., Scaife and Rogers, 1996); that the environment is part of the cognitive system (e.g., Hutchins, 1995); and that abstract thinking is grounded in bodily experience (e.g., Lakoff and Johnson, 1999). In the final section, we attempt to show by discussing (highly selective) examples from the literature, some of the diversity of work that has drawn on theories of embodiment in technology development, analysis and evaluation. In particular, we describe four perspectives. Firstly, we discuss Daniel Fällman’s use of Merleau-Ponty’s work in developing a perspective on mobility and bodily interaction that is shaped by a focus on engagement with the immediate context. Secondly, we provide an overview of Toni Robertson’s analysis of the public availability of socially situated action. Thirdly, we discuss Eva Hornecker’s framework on tangibility and social interaction. Finally we describe Hurtienne’s application of Lakoff and Johnson’s Image Schema theory to the design and evaluation of both new and traditional interfaces. 2. Background 2.1 Cognitivism Many theoretical models in early HCI adopted a perspective, drawn from the then dominant approach in the Cognitive Sciences (especially in artificial intelligence, philosophy of mind and cognitive psychology), that is now described as cognitivism (e.g., Fodor, 1975). The central claim of the cognitivist approach is that thinking is information-processing – the manipulation of physical symbols, representing facts and things in the world, according to syntactical rules in order to make inferences and to guide action. A central claim of this approach was that an information processing system is both necessary and sufficient for general intelligent action (Newell & Simon, 1976). Furthermore, it is the function of the representations and rules used to process them that are of prime importance rather than the details of their implementation. The power of this functionalist approach (cf. Putnam, 1975) is to treat cognition as a formal system that can be studied and modelled separately from the details of neuronal organisation or manifest behaviour; the implementation doesn’t matter as long as it can perform the same function of processing physical symbols. Cognition can therefore potentially occur in a human brain, a digital computer or another medium. Mental processes and physical interaction are treated as separate domains, a philosophical position known as dualism . The theorist most associated with dualism is René Descartes, and thus the cognitivist perspective is often described as Cartesian . The cognitivist programme of research has been successful in modelling cognitive processes such as planning and abstract problem solving, associated with higher-level and specifically human cognition. In HCI, it is perhaps best represented in Card, Moran and Newell’s (1983) The Psychology of Human Computer Interaction. A well-known model described by Card et al. is GOMS (Goals, Operators, Methods and Selection rules). This model represents interaction with a computer as abstracting and processing information from the environment \nthrough the perceptual system, processing it in a separate cognitive system to select an appropriate action according to a prespecified goal and then sending a message to the appropriate body parts (usually the fingers) to carry out the interface action via a motor control system. Another well-known approach in this tradition is requirements specification through a top-down hierarchical task analysis. 2.2 Critiques of cognitivism The cognitivist model of thinking and interaction has come in for sustained criticism from a variety of positions. The philosopher John Searle (1980) has argued that a model based only on the manipulation of abstract symbols doesn’t have an account of how meaning is attached to the symbols in the first place. Therefore, it is questionable whether this is a good account of human reasoning. Dreyfus (1979) critiqued cognitivism from the perspective of Heideggerian philosophy, arguing that systems which represent knowledge about the world as just a collection of symbolic facts are never going to be able to respond flexibly to changing real world contexts. The system will never be able to work out which of the changes are pertinent to the ongoing task and which to ignore. Instead, Dreyfus argues that intelligent action is grounded in a complex history of skilful bodily experiences in the world – knowing how-to do things rather than just knowing-that: “To say a hammer has the function of being for hammering leaves out the defining relation of hammers to nails and other equipment, to the point of building things, and to our skills…and so attributing functions to brute facts couldn’t capture the meaningful organization of the everyday world” (2007, pg. 248).  Dreyfus’s critique draws support from the perceived failure of classical AI to move beyond reasoning in very constrained artificial environments, with simple semantics that are specified in advance to flexible responses in complex changing environments (e.g., Brooks, 1991). 3. Introduction of embodied theories into HCI Although there are many precursors to the current focus on embodied interaction in the design and evaluation of human interface technology, two in particular have had a profound impact in Human-Computer Interaction, and the broader cognitive sciences, which they served to critique: Winograd and Flores’s Understanding Computers and Cognition and Suchman’s Plans and Situated Actions 3.1 Winograd and Flores’s Understanding Computers and Cognition Winograd and Flores (1986) presented an influential alternative to the view of cognition as a formal system, which has had significant influence in HCI, and introduced a new vocabulary to talk about thinking about and acting with technology. Drawing in particular from phenomenology (Heidegger 1927; cf. Dreyfus, 1991), they argued against the cognitivist position that separates thinking from the context in which it occurs. Instead, they propose an understanding of technology use that is inherently historical, material and social. On this view, completely detached reasoning is impossible, as it always depends on a tradition or pre- understanding that derives from a history of interactions with others who share the tradition. In this characterisation, all understanding derives from the state of being-in-the-world, which Heidegger terms Dasein . \nWinograd and Flores also adopted Heidegger’s concept of thrownness , which emphasises the experience of being fully engaged in skilfully coping within a particular context, where there is no way to predict exactly what the outcome of your actions will be and no stable objective representation of the situation. It should be clear that this kind of intrinsically online reasoning (Wheeler, 2005) is very different from the abstract thinking characteristic of cognitivism. Thrownness is closely linked to the idea of readiness-to-hand or transparency, which refers to the way that things ‘disappear’ in the course of everyday action. This doesn’t mean that they literally vanish of course, rather that they cease to be the focus of attention. The canonical example, taken from Heidegger, is of using a hammer. Here the focus is on the activity of hammering. The hammer ceases to be viewed as an object in its own right, in the same way that the tendons of the arm are used transparently during the activity, disappearing into the web of background understandings of relationships between bodies, hammers, nails, activities of making things and so on. Readiness-to-hand is seen to be the primary mode of being-in-the-world in Heidegger’s phenomenology. Again, this is in contrast to the rationalist, cognitivist approach outlined above, where knowledge is represented as a collection of objective facts, separate from the context in which they are used. Winograd and Flores adopt the perspective that nothing can be viewed separately from interpretation. Presence-at-hand refers to the case where a situation is attended to theoretically, and objects or properties are viewed as things in their own right. Heidegger argues that this has been the typical way of viewing the world in scientific analysis, disregarding readiness-to-hand which is the fundamental way of experiencing the world. Presence-at-hand occurs in the event of a breakdown: an “interrupted moment of our habitual, standard, comfortable ‘being-in-the- world’” (Winograd and Flores, 1986, pg. 77). Returning to the example of hammering, the hammer might become present-at-hand in the event of the handle becoming loose, appearing as an object of attention in its own right and available for theoretical reflection. However, again this is not the same as the rationalist cognitivist view of objective knowledge, as present-at-hand reflection will always be related to the background of ready-to-hand experience. Learning is an engaged practice of present-at-hand reflection in a context of use and application. “We do at times engage in conscious reflection and systematic thought, but these are secondary to the pre-reflective experience of being thrown in a situation in which we are already acting. We are always engaged in acting within a situation, without the opportunity to fully disengage ourselves and function as detached observers. Even what we call ‘disengagement’ occurs within thrownness: we do not escape our thrownness, but shift our domain of concern” (Winograd and Flores, 1986, pg. 71). While their work has been criticised for retaining some aspects of rationalism when applying their perspective in system development (Suchman, 1995), Winograd and Flores have had a very significant influence in introducing ideas from phenomenology into the cognitive sciences and HCI. A second significant perspective that also drew upon aspects of phenomenology was developed at around the same time by Lucy Suchman. 3.2 Suchman’s Plans and Situated Actions \nLucy Suchman (1987) presented another influential critique of the cognitivist conception of mind as applied to the design of interactive systems. She studied interactions with a photocopier that had been designed to model human cognition as following plans based upon use a planning-based model of cognition in interactions with users: one that treats cognition as the generation of a blueprint of steps to be taken based on goals, which are then used to guide behaviour. Suchman adopted an ethnomethodological orientation (Garfinkel, 1967), drawing in particular from studies of conversation (Sacks, et al. 1972). Ethnomethodology is concerned with the everyday practices by which mutual intelligibility and social order are achieved. It treats the objectivity of social facts as an ongoing achievement of the members of a social group. A central concept here is the accountability of members’ methods, i.e., the ways that they are made observable and reportable to others. Ethnomethodology also draws on ideas from phenomenology that emphasise the everyday practical engagement of social interactions (Schutz, 1970). Suchman argued that plans are a representation, but not a specification of behaviour. Thus, they can act as a projection of what will happen or retrospective account of what is or what did happen. However, behaviour itself is generated as situated action : in interaction with the contingencies of the physical and social environment. In this model, a plan is only one resource used to help to guide action. Language use is also situated, relying on its indexicality – a relationship to the changing circumstances in which it is used rather than any abstract collection of shared meaning. Ethnomethodologically-informed conversation analysis (e.g., Sacks, et al., 1972) has shown how the same utterance can have a multitude of context- dependent meanings. For example, “that’s brilliant!” could be either an enthusiastic response or a sarcastic put-down depending upon the context in which it is used. Suchman presents a case study of people struggling to use a photocopier designed with an ‘intelligent’ interface help system. Using detailed video analysis, she shows how problems emerge relating to disparities between the fixed plan implemented in the system of how to complete an action and the user’s actual situated behaviour, which is far more ad hoc and flexible. A particular problem relates to the lack of accountability of the system behaviour and it’s lack of responsiveness to the behaviour of the users. Suchman’s contribution to HCI has been very significant, introducing ideas from ethnomethodology to many in the community, providing a powerful critique of cognitivism and emphasising the importance of studying practice as it occurs in real situations, thus providing part of the intellectual foundation of Computer-Supported Co-operative Work. Paul Dourish (2001) has drawn significantly from both Winograd and Flores and Suchman in developing a view of embodied interaction as a foundational concept for HCI. We describe this approach in the next section. 4. Embodied interaction as a foundational framework Building on the research outlined in the previous section, Dourish (2001) has suggested that embodied interaction should be seen as a foundational concept for HCI. He draws upon and expands the phenomenological perspective that underpins both Winograd and Flores’s and Suchman’s work, including an overview of Husserl’s introduction of ideas in phenomenology and Heidegger’s analysis of Dasein as the inseparability of being and the world. He also draws significantly on Schutz’s (1970) development of social phenomenology. Dourish \nhighlights three elements that are common to this work. Firstly, embodiment – meaning “grounded in everyday, mundane experience” (pg. 125) – is central to all of them; secondly they focus on practice: “everyday engagement with the world directed towards the accomplishment of practical tasks” (pg. 125); and finally, this embodied practice is the source of meaning: “we find the world meaningful primarily with respect to the ways in which we act within it” (pg. 125) Dourish structures his argument by showing how recent work in the seemingly disparate fields of tangible and social computing can both be viewed as having a common concern with embodiment, in the sense of a focus on engaged activity in the world rather than abstract theorising: “Embodied interaction is the creation, manipulation and sharing of meaning through engaged interaction with artefacts” (Dourish, 2001, pg. 126). For example, Underkoffler and Ishii’s (1999) urban planning workbench (URP) enables users to flexibly explore interactions between wind, reflection and shadow effects for different configurations of buildings by manipulating tangible models. He cites Bowers, Button and Sharrock (1995), who describe how the skilled practices through which workers in a print shop manage their activities often involve stepping outside formalized procedures. Introducing a computerised system that formalised idealised procedures still further, ignoring the situated processes by which things were actually carried out, had a negative impact on the work done. A key issue in the characterisation of embodied interaction is how meaning is understood and mapped onto things in the world. Dourish focuses on three different senses of meaning: ontology, intersubjectivity and intentionality. Ontology deals with the nature of being: how it is structured into different kinds of things and the relationships between them. The phenomenological underpinning of the embodied interaction approach emphasise how ontology is derived through purposeful interactions in the world rather than being objectively defined. Therefore, it can differ significantly between individuals. Thus, if a designer embeds a particular set ontological commitments into the design of a piece of software or other technology, then this can cause problems for users who may not share them, and may have a set of quite different purposes to put the system to than the designer had in mind: “a design may reflect a particular set of ontological commitments on the part of a designer, but it cannot provide an ontology for the user” (Dourish, 2001, pg. 130). The second sense of meaning that Dourish discusses is intersubjectivity, which refers to the ways that two or more people can come to a shared understanding without having direct access to each other’s mental states. Dourish highlights two ways that intersubjectivity is relevant to the design of technology. Firstly in the ways that the designer is able to communicate to the user how they envisage that the technology will be used (Suchman’s photocopier example is a case of this going wrong). Secondly, the extent to which systems enable different users to communicate through them to develop shared ways of using software systems and appropriate them for shared patterns of practice. The third sense, intentionality , refers to the directedness of meaning; the property (of a thought, action etc) of being about something. Intentionality is a core characteristic of embodied interaction, as people act on and through computational representations to enact effects on the world – we are always already directed ‘to’ or ‘towards the world’ since it is our habitat (into which we are thrown) and primary source of meaning, as described by Merleau-Ponty. The way that intentionality is expressed in embodied interaction is through a process of coupling : “By coupling, I mean the way that we can build up and break down relationships between entities, putting them together or taking them apart for the purpose of \nincorporating them into our action” (Dourish, 2001, pg. 138). Technologies that support embodied interaction well are ones that make clear how they are coupled to the world, allowing users to orient to them in a variety of ways. Thus, a tangible interface, for example, might be attended to as an iconic representation of digital information, a controller to manipulate digital information, or as a physical object in its own right that can be picked up and shared with others, left on a desk as a reminder to complete a task the next day or moved out of the reach of others, depending upon the way it is coupled to the ongoing concerns of those who are using it. Dourish’s theoretical account of embodied interaction has been very influential, paving the way for work that has explored new forms of tangible (Hornecker and Buur, 2006), mobile (Oulasvirta, et al., 2005), ubiquitous (Chalmers, 2002) and movement-based (Hummels, et al., 2007) interaction. The primary contribution of Dourish’s work has been to analyse how meaning is fluidly negotiated in interaction with technology, the world and other people. His perspective is primarily a phenomenological one, building on the insights of Winograd and Flores and Suchman to present embodiment as a foundational concept for HCI. It has inspired a range of research that often goes back to its own reading of the original phenomenological authors. In particular, Merleau-Ponty’s work is increasingly being referred to, which has a stronger focus on the body and its felt experience. However, there has been another strand of work that has rejected aspects of the cognitivist view of thinking and interaction, but that has not drawn so explicitly from phenomenology. It is to this embodied cognition approach that we turn in the next section. 5. Embodied cognition Embodied cognition refers to a diverse group of theories and approaches that challenge different aspects of the Cartesian view of cognition (cf. Clark, 1997; Wheeler, 2005). Much of this work has drawn on the phenomenological critique of cognitivism, but it has also come about as a response to particular technical challenges or experimental findings. Thus, the influence of phenomenology should be seen as more implicit than in the work described in the previous section (cf. Wheeler, 2005). There have also been several precursors to the recent growth of embodied cognition. In particular, Gibson’s (1979) ecological approach to visual perception, which presents perception and action as inseparable has been very influential. Gibson introduced the concept of affordances as action possibilities picked up from the environment, in a relationship to the physical capacities and ongoing concerns of an organism. The concept of affordance was adapted by Donald Norman in HCI (e.g., 1999) to account for the ways in which physical and graphical artefacts suggest how they should be used (in the latter case the affordances are ‘perceived’, rather than real). There is currently little agreement on the core concepts of the embodied cognition approach, with some approaches rejecting Cartesian cognitive science completely, and others retaining some parts of it, such as symbolic representations or some aspects of functionalism. Rohrer (2007) offers a broad survey of the literature on embodiment, describing (at least) twelve different uses of the term. These include the usage in socio-cultural studies where it refers to the environment in which the body is situated, (e.g., Hutchins, 1995); the usage relating to morphology, which looks at how the physical characteristics of a cognitive agent can influence the types of cognitive processing it can carry out; and the use of the term to refer to grounding, or how abstract concepts are linked to a history of concrete, physical experience. \nLakoff and Johnson (1999) suggest that abstract concepts are related by metaphorical mappings to basic-level image schemas – mental structures that are formed through sensori- motor interaction with the world to guide our action. These metaphorical mappings preserve the inferential structure of the original domain. For example, Lakoff and Núñez (2000) suggest that Boolean Logic is an extension of a sensori-motor container schema, with the same inferential structure of IN, OUT and transitivity (e.g., a ring contained within a box that is held in a hand is also inside the hand), originally developed through experiences with real containers. Wilson (2002) focuses more narrowly on the literature identified as embodied cognition, identifying six claims: (i) cognition is situated : it takes place in a real-world environment and inherently involves perception and action; (ii) cognition is time pressured : it functions under the pressures of having to interact in real time with a dynamic environment. This and the previous claim were presented by Brooks (1991) as criticisms of robotic systems designed to first build up a model of the environment, devise a plan and then act. He argued that in reality, an organism would not have this luxury, as the world would have changed by the time it decided what it was going to do. Brooks recommends instead building systems that ‘use the world as its own best model’ and which use simpler more responsive architectures; (iii) we offload cognitive work onto the environment : cognitive workload is alleviated by holding or manipulating information in external structures (cf. Kirsh, 2010, Scaife & Rogers, 1996); (iv) the environment is part of the cognitive system : the links between internal and external representations and processing are so fundamental that they should be considered the same unit for analysis. This claim has been described as distributed cognition (Hollan, Hutchins, & Kirsh, 2000; Hutchins, 1995) and the extended mind hypothesis (Clark & Chalmers, 1998). It is also related to a number of approaches within cognitive science that resist traditional explanations in terms of internal representations (Thelen & Smith, 1994; van Gelder, 1995); (v) cognition is for action : the function of the mind is to guide action, so cognition should be understood in terms of its contribution to behaviour. Glenberg (1997) claims that cognition evolved to coordinate interaction with a three-dimensional world, enhancing survival and hence reproductive success. In this characterisation, the meaning of a situation to an organism is a coordinated set of possible actions, which are determined by physical form, learning history and goals; (vi) off-line cognition is body-based : even when decoupled from the environment, mechanisms evolved for interaction with it play a role in cognition; sensori- motor systems are involved in processing even in the absence of task-relevant perceptual input (cf. Lakoff and Johnson, 1998) Theoretical work that makes up the new approaches of embodied cognition has also been very influential in HCI. Hutchins (1995) introduced the theory of distributed cognition , arguing that what classical cognitive science took to be internal, individual acts of information processing, were in fact outcomes of a socio-cultural system. “Having failed to notice that the central metaphor of the physical-symbol-system hypothesis captured the properties of a socio-cultural system rather than those of an individual mind, AI and information-processing psychology proposed some radical conceptual surgery for the modeled human. The brain was removed and replaced with a computer. The surgery was a success. However, there was an apparently unintended side effect: the hands, the eyes, the ears, the nose, the mouth, and the emotions all fell away when the brain was replaced by a computer” (Hutchins, 1995: 363). \nThe idea of cognition as information processing is retained in distributed cognition. However, the process is analysed as propagating through a variety of representational media, including other minds, physical artefacts and technologies, and parts of the body. Distributed cognition has been used to analyse the flow of information through a variety of socio-technical systems, typically using an ethnographic approach. For example, in critiquing the idea of organisational memory through showing the details of information flow involved in a telephone hotline call (Ackerman & Halverson, 1998). A second perspective, related to Hutchin’s description of distributed cognition, is the analysis of how interaction with external representations can support cognition, change the nature of a cognitive task, or form an intrinsic part of thinking (Kirsh, 2010; Scaife & Rogers, 1996). Kirsh and Maglio (1994) for example, described how expert users of the video game Tetris solved the problem of fitting irregularly-shaped blocks together by physically rotating them on a screen and using the computationally-cheap mental processes of pattern matching and recognition. They call physical activity to reduce the burden of problem solving epistemic action . A third approach attempts to use Lakoff and Johnson’s (1999) work on image schemas and embodied conceptual metaphor in the design and evaluation of technology. Image schemas are representations, abstracted from recurrent patterns of sensori-motor experience. For example, the front-back schema is derived from movement in the world and the structure of the human body where the eyes are positioned on the front side of the body. Embodied conceptual metaphors are extensions of image schemas to think about other entities, which can be more abstract. For example, good and bad can be thought of in terms of up and down (e.g., “things are looking up”), whereas time can be thought of in terms of front and back (e.g., “your future is ahead of you”). A recent trend in HCI research has been to try to use insights from this work to design novel interface applications and to improve interface usability (e.g., Hurtienne, et al., 2008; Antle et al., 2009) A final example of embodied cognition theory that has found application in the design and evaluation of technology is work that has shown that physical changes to the body, such as adopting a different posture can in some circumstances induce changes in emotional or attitudinal states and social perceptions (e.g., Niedenthal et al., 2005). Bianchi-Berthouze et al. (2007) have experimented with trying to increase user engagement in gameplay by increasing the level of bodily involvement in interaction. 6. Case studies of work in embodied interaction In the previous sections we described some of the theoretical underpinnings of recent work in embodied interaction. Strong and consistent themes have yet to emerge, but we have shown how recent work can often be described as deriving from work on phenomenology or on embodied cognition. In this section, we describe in more detail four examples of recent projects. No attempt is made here to give a comprehensive overview of work that has attempted to apply concepts drawn from embodied interaction – indeed it is unclear if an exhaustive framework could be proposed at this stage. Rather, four quite different projects were selected to give a flavour of the diversity of work in this area. \n6.1 Fallmän: supporting skilful engagement with the world in mobile interaction Fällman used embodiment as a guiding perspective for a series of projects that formed part of his PhD research (Fällman 2003). His work is significantly influenced by Merleau-Ponty, but also by other work in phenomenology. Merleau-Ponty’s influence is evident in the emphasis that Fällman gives to the subjective experience of technology through first-person accounts. Fällman takes a phenomenological perspective to the analysis of mobile technologies, focusing on how they are experienced. His approach is design-oriented research, where research is driven by design, and designing is the means for producing new knowledge (Fällman 2003). Theories of embodiment were utilized in the conceptual design of a series of practical projects, from the design of a support tool for mobile service technicians, a slide scroller on a small screen, and a wearable ‘alternate’ reality helmet. Fällman (2003) argues that the traditional cognitivist HCI-perspective of a disembodied mind is a poor model for understanding or designing mobile interaction. This is because mobility is “strongly situated and rooted in a world (…)”. Analysing his own subjective experience of using mobile devices, he finds that these all have the common characteristic of being embedded in a relatively small physical form which relate to the human body – they are held close, felt, worn, etc. Moreover, when using mobile devices our focus is often with on the world (e.g., taking photos, checking the network connection, taking a call). As mobile device use is strongly related to context, Fällman argues that it and mobility should be seen as a mode of being-in-the-world. People “become mobile in different ways – not only corporeal – to be able to get involved in different physical and social contexts”. The design of mobile technologies should therefore not interfere with this involvement or, better still, it should support engagement with the world. This also means that desktop interface metaphors are inappropriate for mobile devices, since they tend to make it difficult to engage with the real world while interacting with the interface. Motivated by this theoretical background, one of Fällman’s projects aims to support ‘skillful coping’ with a mobile support system for service technicians. The resulting device is worn on the arm, allowing for hands-free interaction and always being there, but receding into the background of attention when not in use. It is interacted with primarily by pointing at, for example, a broken component in order to access its data sheet, thereby connecting the physical work of industrial components directly with the virtual world of data on the device. Users then interact by tilting to slide the interface, and tapping the screen. Tilting makes use of the notion of embodied interfaces (Fishkin et al 2000), exploiting the fact that humans have an embodied understanding of gravity (Lakoff and Johnson 1999). 6.2 Robertson: the mutual availability of (embodied) action Robertson (1997, 2002) also applies a phenomenological perspective to Computer-Supported Cooperative Work (CSCW) research, investigating the role of embodied action in supporting awareness and coordination. Specifically, she aims to show that Merleau-Ponty’s phenomenology of perception provides a new perspective on cooperative work, by emphasizing how the public availability of actions and artefacts provides environmental support for participants in cooperation. For designers of novel technologies such as those used in distance communication, one of the most important lessons is that perception is learned – over time we gain skill, adapt our perception and body image, and the research question thus becomes what kinds of cues and feedback mechanisms might support us in this \nprocess? A focus on lived cognition and perception furthermore highlights the agency of users, who should be supported with resources for action. Robertson (1997) analysed how embodied action supports cooperative work, based on a field study of collaborative work within an educational game design company where staff often work from home. The study highlights how much cooperative design and development of software relied on communicative interactions between staff. Sharing physical space within company premises “enabled communication by supporting the mutual perception of their embodied actions”, of talking and making or using artefacts within this space. When staff members were not on-site, workers relied on complex work practices that had evolved to support communication. Video analysis of embodied activities revealed several categories of actions. Individual actions could relate to physical objects, as in moving them (for oneself, or to make them available for somebody else), producing new representations (drawing, writing), highlighting aspects of the object, or personal use. Individual actions could also relate to other human bodies, either through communicative gesture, facial expression, talk etc., or through enacting user behaviour or the design object itself (a frequent activity in design). Further actions related to the physical workplace, such as moving around, pointing at things, or changing direction of gaze. Group activities such as conversation, shared attention on an object, creation of shared resources for conversation and shared representations (clearing the table and then sketching on it), shared use of objects, and so on, in turn are comprised of individual actions. These kinds of embodied actions were not specific to any particular phase of the software development process. Thus, distance communication technology in support of distributed design should enable and mediate the mutual perception of embodied actions and negotiation of meaning rather than supporting specific design processes or phases. This would be greatly facilitated by the reversibility of perception: the ability to anticipate how actions will be seen by others (which in turn enables the ‘actor’ to shape their action for the observer). 6.3 Hornecker: group facilitation mechanisms to influence social interaction Hornecker’s (2005) notion of ‘Embodied Facilitation’ highlights how physical, spatial, and software-determined configuration of a system affects group interaction patterns and influences the social formations and interaction patterns that emerge with and around the system. Hornecker’s argument is that both physical and software design define a structure, and that this structure may facilitate, prohibit or hinder some actions. Specific behaviours are easily feasible, and may even be invited, while other behaviours are made difficult, or even prevented. Systems can thus embody structure and thereby styles, methods and means of facilitation, very similar to how meeting facilitators, educators and professional group work facilitators steer group processes by imposing structure (with an agenda and rules of discussion), staging the setting (placing tables, chairs, flipchart or projection surfaces), and providing work materials (e.g. number of markers for writing). This perspective encourages the analysis technological systems in terms of the resources they provide for participants to engage in or join an activity and to collaborate, and the ways in which they influence how people will coordinate and collaborate. This concept is useful for understanding the effects of UbiComp technologies, which are often embedded in furniture and everyday objects, on social interaction patterns and collaboration. For example, in the design of interactive multitouch tables, the shape, size, and \nheight of the table influence how well groups tend to engage with each other, share an activity, and how many people may take part. Hornecker refers to tangible interaction systems in particular as ‘embodying facilitation’. These are comprised of physical structures embedded in space, and that users interact with through some form of bodily interaction (Hornecker and Buur 2006). The notion of ‘embodied facilitation’ draws in particular from Merleau-Ponty in that it is through bodily interaction that we use these systems, seeing and pre-reflectively interpreting the resources and constraints they provide for action. 6.4 Hurtienne: Using Image Schemas to Design Intuitive Interfaces Hurtienne, Israel and Weber (2008) conducted an empirical analysis of the utility of image schemas (Lakoff and Johnson, 1999; Johnson, 1980) in interface design. This work has shown how image schemas and embodied conceptual metaphors, can be productively utilized in interface design and provide a basic vocabulary for consistent and intuitive mapping. Hurtienne et al showed that violating embodied metaphorical extensions of image schema results in increased reaction times and error rates when interacting with simple GUI interfaces. User interfaces that were congruent with image schemas (e.g. moving a lever upward to evaluate a hotel as being ‘better quality’ or to indicate that its staff is friendly) were not only judged by participants as being better, but also resulted in faster decisions and greater accuracy (Hurtienne, 2011; Hurtienne and Blessing, 2007). This phenomenon could also be demonstrated with two buttons, where the positive (or ‘more’) rating was on top. An example for how a complex interface metaphor builds on a range of image schemas is ‘putting files into the thrashcan’, which employs the schemas of path (dragging), compulsion, containment, and full-empty. Yet, unfortunately, sometimes there can be competing image schemas, which then interfere with unconscious information-processing. Image schemas thus cannot be implemented in a mechanical way. Furthermore, as some image schemas relate and depend on each other (a container can also block content from leaking out), there may be competing image schemas, which equally could describe the users’ mental model, and thus there may be several ways of implementing this in an interface. In related work Antle and colleagues have explored the potential of embodied metaphor to support the design of less traditional interfaces, such as a whole body interaction system to encourage reasoning about social justice (Antle, et al., in press; Antle et al., 2009) and tangible and whole body interactive systems to control different properties of sound (Antle et al., 2009) 7. Discussion Embodied interaction has been taken up and developed enthusiastically in the design, analysis and evaluation of interactions with technology in recent years. However, while theoretical work on embodied interaction has been united in challenging the cognitivist model of thinking and its application in system design, this recent explosion of interest has resulted in a sometimes bewildering range of approaches, techniques and claims. In this chapter, we have summarised two broad strands of theory that are being used in HCI. The first rejects the cognitivist model completely, building instead on insights from phenomenology to emphasise the engaged, direct ways that people normally participate in activities and the flexible ways that meaning can be ascribed and negotiated in ongoing practice. Analysis of the details of \nsituated practice is well known in HCI, particularly through the influence of ethnomethodologically informed ethnography, which traces its lineage, in part, to Schutz’s (1970) analysis of the phenomenology of the social world. More recently, authors have drawn from other phenomenologists, such as Merleau-Ponty (1962) and have begun to use their insights to design novel technology interactions as well as new methods of analysis. The second strand of theory derives from cognitive science and has attempted to respond to problems with the cognitivist model by adapting, extending or replacing different aspects of it. This work is very diverse. Some, such as that arguing for a greater role for external representations in cognitive processing, have been influential in HCI and interaction design for at least 15 years (e.g., Scaife and Rogers, 1996).  Work that characterises cognition as extending beyond the boundary of the skull to include physical movements of the body, other brains, physical artefacts and technologies has also been used for some time in analysing existing socio-technical systems, as part of the distributed cognition approach. We are also beginning to see more work looking at how these insights can be used in designing novel technologies, (cf. Bird, et al., 2009; Nagel et al., 2005). More radical approaches, such as those which model cognition as a dynamical system spanning brain, body, and environment (e.g., Beer, 2000), dispensing with the idea of internal representations altogether, and the enactive approach (e.g., Thompson, 2005), which focuses on the autonomous agency and lived subjectivity of an agent (and has many links with the phenomenological approach), have so far had little influence in HCI. A focus on different aspects of embodied interaction is increasingly popular in HCI and interaction design. However, as in other areas such as cognitive science, there is still no consensus on the core concepts of embodied interaction, or the best ways to apply these concepts. In this chapter we have highlighted two strands of work – one that focuses primarily on insights from phenomenology, and one that focuses primarily on ideas from embodied cognition, which tends to be influenced only implicitly by phenomenology. There is however much work still to be done to develop this theory into the kinds of frameworks, methods and perspectives needed in the design, analysis and evaluation of interaction with technology. Further readings Dourish, P. (2001). Where the Action Is: The Foundations of Embodied Interaction. Cambridge: MIT Press. Suchman, L. (1987) Plans and Situated Actions. The Problem of Human Machine Communication. Cambridge: Cambridge University Press. Winograd, T. and Flores, F. (1986): Understanding Computers and Cognition: A New Foundation for Design . Norwood, New Jersey: Ablex Publishing Corp Glossary of terms Cartesian: relating to the work on René Descartes. In particular, this often refers to the philosophical position of dualism – treating the mind as non-physical and therefore separate from the body \nEmbodied conceptual metaphor: suggests that concepts are typically understood through metaphorical mappings to concrete sensori-motor experiences Cognitivism: an approach in cognitive science that treats cognition as information processing on discrete internal symbols Epistemic action: a physical action that changes the nature of a cognitive operation necessary to carry out a particular task. Functionalism: a philosophical approach that considers mental states in terms of the role they play in a cognitive system rather than in terms of their constitution. Image schema: a cognitive structure that abstracts across a number of sensori-motor experiences: for example, the containment schema abstracts across many concrete experiences of something being contained within something else Phenomenology: the study of the structure of conscious experience as experienced (although not necessarily studied) from a first-person perspective Presence-at-hand: the state of attending to an object, tool or representation itself as the focus of an activity. Readiness-to-hand: this concept refers to how, when working with a tool or representation we treat it almost as if it were invisible, focussing instead upon the task it is used for. References Ackerman, M. S. and Halverson, C. (1998). Considering an organization's memory. In Proceedings of the 1998 ACM conference on Computer supported cooperative work (CSCW '98). ACM, New York, NY, USA, 39-48 Antle, A.N., Corness, G., & Droumeva, M., (2009) What the Body Knows: Exploring the Benefits of Embodied Metaphors in Hybrid Physical Digital Environments. Interacting with Computers, 21 (1-1), 66-75. Antle, A. N., Corness, G., & Bevans, A. (in press) Balancing Justice: Comparing Whole Body and Controller-based Interaction for an Abstract Domain. Int J. Arts and Technology. Antle, A. N., Corness, G., Bakker, S., Droumeva, E., Hoven, E. v. d., and Bevans, A.. (2009) Designing to support reasoned imagination through embodied metaphor. In Proceedings of Creativity and cognition (C&C '09). ACM, New York, NY, USA, 275-284. \nBianchi-Berthouze, N., Kim, W.W. & Darshak, P. Does body movement engage you more in digital game play? And Why? In Proc. ACII 2007, Springer (2007), 102- 113. Bowers, J., Button, G. and Sharrock, W. (1995). Workflow from within and without: technology and cooperative work on the print industry shopfloor. In Proceedings of the fourth conference on European Conference on Computer-Supported Cooperative Work (ECSCW'95), Hans Marmolin, Yngve Sundblad, and Kjeld Schmidt (Eds.). Kluwer Academic Publishers, Norwell, MA, USA, 51-66. Brooks, R.A., Intelligence without representation, Artificial Intelligence 47 (1991), 139–159 Card, S., Moran, T., and Newell, A. (1983). The Psychology of Human-Computer Interaction. Hillsdale, NJ: Lawrence Erlbaum Associates. Chalmers, M. and Galani, A. (2004) Seamful interweaving: heterogeneity in the theory and design of interactive systems. In Proceedings of the 5th conference on Designing interactive systems: processes, practices, methods, and techniques (DIS '04). ACM, New York, NY, USA, 243-252 Clark, A. (1997). Being there: putting brain, body and world together again. Cambridge, Massachusetts: MIT Press. Clark, A. and and Chalmers, D. (1998) The Extended Mind. Analysis 58 (1998): 7–19. Dreyfus, H. L. (1979) What Computers Can’t Do: The Limits of Artificial Intelligence , Harper & Row: New York Dreyfus, H. L. (1991) Being-in-the-world: A Commentary on Heidegger's Being and Time, Division I. Cambridge, MA: MIT Press. Dreyfus, H.L. (2007), “Why Heideggerian AI failed and how fixing it would require making it more Heideggerian”, Philosophical Psychology , 20 (2), pp. 247-268 Dourish, P. (2001). Where the Action Is: The Foundations of Embodied Interaction. Cambridge: MIT Press. Fallman, D. (2003) Design-oriented Human-Computer Interaction, Proceedings of CHI2003, Conference on Human Factors in Computing Systems, New York, NY: ACM Press, pp. 225-- 232. Fallman, D. (2003) in romance with the materials of mobile interaction: a phenomenological approach to the design of mobile information technology. Doctoral thesis, Umea university, Sweden: Larsson & Co. \nFishkin, K.P., Gujar, A., Harrison, B.L., Moran, T.P., Want, R. (2000) Embodied User Interfaces for Really Direct Manipulation. Communications of the ACM, Vol 43, Issue 9, 74- 80 Fodor, J.A. (1975), The Language of Thought , Cambridge, MA: Harvard Uni. Press Garfinkel, Harold (1967) Studies in Ethnomethodology , Prentice-Hall: Englewood-Cliffs, New Jersey. Gibson, J. J. (1979) The Ecological Approach to Visual Perception , Houghton-Mifflin, Boston, Glenberg, A. M. (1997). What memory is for. Behavioral and Brain Sciences , 20(1), 1-55. Heath, C., Luff P. (2000). Technology in Action. Cambridge University Press Heidegger, M. (1927/1990). Being and Time (J. Macquarrie & E. Robinson, Trans.). Oxford: Blackwell. Hollan, J., Hutchins, E., & Kirsh, D. (2000). Distributed cognition: toward a new foundation for human-computer interaction research. ACM Transactions on Computer-Human Interaction , 7(2), 174-196. Hornecker, E. (2005) A Design Theme for Tangible Interaction: Embodied Facilitation. In Proceedings of the 9th European Conference on Computer Supported Cooperative Work (E- CSCW'05) Kluwer/Springer. pp 23-43 Hornecker, E., & Buur, J. (2006). Getting a grip on tangible interaction: a framework on physical space and social interaction. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI 2006), Montréal, Québec, Canada, 22-27 April, 437- 446. Hummels, C., Overbeeke, K. and Klooster, S. (2007) Move to get moved: a search for methods, tools and knowledge to design for expressive and rich movement-based interaction. Personal Ubiquitous Comput., 11 (8). 677-690. Hurtienne (2011). Image Schemas and Design for Intuitive Use – Exploring New Guidance for User Interface Design. PhD thesis TU Berlin. http://opus.kobv.de/tuberlin/volltexte/2011/2970/pdf/hurtienne_joern.pdf Hurtienne, J. and Blessing, L. (2007). Design for intuitive use - Testing image schema  theory for user interface design. In: Proc. International Conference on Engineering Design, Paris, Design Society. P_386, 1-12. [CD-ROM]. \nHurtienne, J., Israel, J. H. and Weber, K.  (2008) Cooking up real world buisiness applications combining physicality, digitality, and image schemas, in Proceedings of TEI’08, pp. 239–246, ACM, 2008. Hutchins, E. (1995 ). Cognition in the Wild. Cambridge, MA: MIT Press. Kirsh, D. Thinking with External Representations. AI and Society. Springer: London, (2010) 25:441–454. Kirsh, D., & Maglio, P. (1994). On distinguishing epistemic from pragmatic action. Cognitive Science , 18(4), 513-549. Lakoff, G., & Johnson, M. (1999). Philosophy in the flesh: the embodied mind and its challenge to western thought . New York: Basic Books. Lakoff, G., & Núñez, R. (2000). Where Mathematics Comes From: How the Embodied Mind Brings Mathematics into Being . New York: Basic Books. Merleau-Ponty, M. (1962). Phenomenology of Perception (C. Smith, Trans.). London: Routledge & Kegan Paul. Moran, T.P. and R.J. Anderson (1990): The Workaday World as a Paradigm for CSCW Design. In CSCW ’90, Proceedings of the Conference on Computer-Supported Cooperative Work . ACM Press, New York, pp. 381–393. Nagel, S. K., Carl, C., Kringe, T., Martin, R. and Konig, P. (2005) Beyond sensory substitution - learning the sixth sense. Journal of Neural Engineering , 2, 13–26, Newell, A., & Simon, H. (1972). Human problem solving . Englewood Cliffs, NJ: Prentice Hall. Niedenthal, P. M., Barsalou, L. W., Winkielman, P., Krauth-Gruber, S., & Ric, F. (2005). Embodiment in attitudes, social perception, and emotion. Personality and Social Psychology Review , 9(3), 184-211. Norman, D. A. (1999) Affordances, Conventions and Design. Interactions 6 (3), 38-43, May 1999, ACM Press. Oulasvirta, A. ,Tamminen, S., Roto, R. and Kuorelahti, J. (2005) Interaction in 4-Second Bursts: The Fragmented Nature of Attentional Resources in Mobile HCI. In Proceedings of CHI 2005 , Portland, Oregon, USA, 919 – 928. \nPutnam, H. (1975). Philosophy and our mental life. In H. Putnam (Ed.), Mind, language and reality (Vol. 2, pp. 291-303). Cambridge: Cambridge University Press. Robertson, T. (1997): Cooperative Work and Lived Cognition: A Taxonomy of Embodied Actions. In Proceedings of the Fifth European Conference on Computer-Supported Cooperative Work. Kluwer Academic Publishers, Dordrecht, The Netherlands,  pp. 205–220. Robertson, T. (2002) The Public Availability of Actions and Artefacts. Computer Supported Cooperative Work 11: 299–316, 2002. Robertson, T. and Loke, L. (2009) Designing Situations. Proceedings of OZCHI 2009, ACM. 1-8 Rohrer, T. (2007). The body in space: Dimensions of embodiment. In T. Ziemke, J. Zlatev & R. Frank (Eds.), Body, Language and Mind (Vol. 1: Embodiment). Berlin: Mouton de Gruyter, 339 – 378. Sacks, H., Schegeloff, E.A. and Jefferson, G. A simplest systematics for the organization of turn-taking conversation. Language, 50 (1974), 696-735. Scaife, M., & Rogers, Y. (1996). External Cognition: how do graphical representations work? International Journal of Human-Computer Studies , 45, 185-213. Schutz, A. (1970): On Phenomenology and Social Relations: Selected Writings. In H. Wagner (ed), The Heritage of Sociology collection, Chicago: University of Chicago Press. Searle, John. R. (1980) Minds, brains, and programs. Behavioral and Brain Sciences 3 (3): 417-457 Suchman, L. (1987) Plans and Situated Actions. The Problem of Human Machine Communication. Cambridge: Cambridge University Press. Thelen, E. & Smith, L. B. (1994). A dynamic systems approach to the development of cognition and action . Cambridge, MA: MIT Press. Underkoffler, J., and Ishii, H., Urp: A Luminous-Tangible Workbench for Urban Planning and Design, in Proceedings of Conference on Human Factors in Computing Systems (CHI '99), (Pittsburgh, Pennsylvania USA, May 15-20, 1999), ACM Press, pp. 386-393. van Gelder, T. (1998), The dynamical hypothesis in cognitive science, Behavioral and Brain Sciences , 21 (5), pp. 615-665 Wheeler, M. (2005). Reconstructing the cognitive world. Cambridge, MA: MIT Press. \nWilson, M. (2002). Six views of embodied cognition. Psychonomic Bulletin and Review , 9(4), 625-636. Winograd, T. and Flores, F. (1986): Understanding Computers and Cognition: A New Foundation for Design . Norwood, New Jersey: Ablex Publishing Corp"
}