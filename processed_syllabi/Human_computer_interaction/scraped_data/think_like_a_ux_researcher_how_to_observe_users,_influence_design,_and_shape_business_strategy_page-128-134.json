{
    "document_type": "book",
    "title": "Think Like a UX Researcher: How to Observe Users, Influence Design, and Shape Business Strategy",
    "author": "David Travis and Philip Hodgson",
    "source": "raw_syllabi\\master_courses\\Human_computer_interaction\\pdf_material\\Think Like a UX Researcher (David Travis, Philip Hodgson).pdf",
    "date_published": "2018-12-20",
    "keywords": "Unavailable",
    "flag": "",
    "text": "Controlling Researcher Effects We take a look at some subtle yet pervasive researcher effects, at ways they can bias the outcome of UX research, and at what we can do to control their influence. nothing is more guaranteed to shatter the illusion of reality that’s building up nicely in that best seller you’re reading, than the author suddenly appear- ing out of the blue and talking to you directly. Grandly known as “authorial intrusion,” it’s the moment the author yanks the reader’s attention out of the story, reminds us of the real world, and breaks the golden rule of fiction writ- ing and journalism: Keep yourself out of the story. It’s right up there with the film crew recording its own reflection in a passing shop window. Research has its own version of these unfortunate moments. They happen when the researcher blunders into view and ruins things by influencing the outcome of a study. We call these blunders experimenter effects . Experimenter effects contaminate the research process, but we know their origin. They are almost always the result of the experimenter having prior expectations about the hypothesis of a study. Some classic examples remind us how insidious experimenter effects can be. Recall the case of Clever Hans the counting horse. When given numbers to add, subtract, multiply, or divide, Hans would tap out the correct answer with his hoof. Psychologist oskar Pfungst showed that, rather than doing arithme- tic, Hans was simply picking up involuntary ideomotor cues from his trainer when the correct number of hoof taps was reached. When asked a math prob- lem his trainer did not know the answer to, Hans’ performance collapsed. And it’s not just horses. In 1963, psychologists Lucian Cordaro and James Ison 16 asked two groups of college students to observe and count head turns and body contractions made by planaria (flatworms). one group of students was led to believe the target behaviors would occur infrequently, while the other group was led to expect a high rate of head turns and contractions. The flatworms in each group were identical and (as is often the case with flatworms) had no expectations about anything. Sure enough, the group expecting a high rate of body movements reported a much higher count than the group expect- ing a lower rate—an outcome carried entirely by experimenter expectation. \nRobert Rosenthal’s extensive work on experimenter effects 17 (an investiga- tion spanning 30 years and including both animal and human behavioral research) reveals that 70 % of experimenter effects influence outcomes in favor of the researcher’s hypothesis. Experimenter effects are also common in UX and market research, though we’ll switch to calling them “researcher effects” as most user experience methods are not really experiments in the conventional sense. Field studies, focus groups, interviews and usability tests are all susceptible to researcher effects because researchers have expectations, and because UX and marketing research create social situations, and because being truly objective is difficult. The Double-Blind Science has a powerful antidote to researcher effects: the Double-Blind. In a double-blind study, neither the participant nor, critically, the experi- menter (nor anyone involved in moderating, observing, recording or ana- lyzing the data) knows the research hypothesis, or knows which condition participants are assigned to, or which design is the “before” and which is the “after,” which product is “ours” and which is “theirs,” etc. A double-blind eliminates the most problematic researcher effects and is effectively used in clinical trials and in debunking pseudoscientific claims. Can we apply this to UX research? Unfortunately, conducting a double- blind in UX research, while not impossible, is very challenging in prac- tice and is not something we are likely to see. A UX researcher typically works with the development team on a daily basis and has been instrumen- tal in guiding design. In any evaluative situation, there’s no way the UX researcher can suddenly have no knowledge or prior expectation of study conditions. Bringing in an external UX researcher doesn’t solve the problem either, because this person also must know the design or product at least well enough to conduct an effective study. And remember, the double-blind must extend to data recording, analyzing, interpreting, and reporting the results. In most cases, running a double-blind would turn a quick user experience study into a major covert operation. The double-blind may be the gold standard but, if we can’t use it, how else might we prevent researcher effects? The first step is to raise awareness among project teams that researcher effects exist, and that they can have serious consequences. The second step, since we can’t totally eliminate these effects, is to find ways to control them. \nHere are some ways that researchers influence the outcomes of their own research, and some thoughts on how we might control biases in these situations. Biases When Interacting with Participants These are the “Clever Hans” biases that stem from unintended communica- tions with the participant before and during a study. They result from verbal and non-verbal cues and gestures that influence the participant’s thinking or behavior during the UX research, and they become damaging when they systematically favor one particular outcome. For example, Philip observed a study during which the moderator did a good job of remaining neutral when introducing competitor designs, but she leaned forward and nodded when- ever she spoke about the sponsor’s design. In reality there are an almost infinite number of biasing behaviors that can creep into a study, from the blatantly obvious, “We hope you’ll only have good things to say about our product,” (we’re not making that one up, we actually heard a researcher say this), to the almost imperceptible smile when the participant clicks the correct button in an interface. other influ- encing behaviors can include the researcher’s mood and demeanor, tone of voice, frowning, sighing, tensing up, relaxing, shuffling on their chair, raising their eyebrows, and pulling faces. Even note-taking can introduce a bias (“oh dear, he just wrote something in his notebook, I must have done it wrong”). And this is before we even start to think about the biasing effects of leading and loaded questions, reassurances such as, “You’re not the only one to have done that wrong today,” or paraphrasing the partici- pant’s remarks with a little extra topspin, or allowing one’s own opinions to creep into the dialogue. We can’t eliminate all of these biasing factors: They are far too pervasive, and we would end up behaving like automatons if we tried to monitor our- selves down to this micro-behavioral level. So what is the solution? Since a double-blind test is not possible, here are some techniques that can help: • Standardize everything : the research protocol, the moderator script, the questions, and so on. Follow the same protocol in the same way for every participant in every condition. Present task scenarios on cards for the participant to read aloud. Stick to the script. • Have a second researcher monitor the first researcher : Monitor for “protocol drift.” \n• Stay out of the participant’s line of sight : In summative usability testing, leave the room if you can during a task. • Practice : Run mock studies that focus on controlling biasing behaviors. Video-record yourself administering a study or moderating an interview. Critically analyze your performance, and have a colleague help you note any systematic biasing behaviors and inadvertent signals you may be giving. Biases When Recording, Interpreting and Reporting Findings Researcher effects can contaminate a study in a number of ways, such as: • Systematic data recording errors. • Participant actions or responses that are given undue weight. • Jotting down what you thought the participant meant rather than what she actually said. • Trying to interpret data on the fly and too early into a test. • Making careless recording errors. • Failing to pay attention. • Struggling to keep up with the participant. • Making copying and data-entry errors. Subsequent data interpretation can also fall foul of confirmation bias . This is the tendency to prioritize evidence that fits well with what we already believe, while ignoring evidence that doesn’t. Even highly experienced researchers can fall into this cognitive trap. Biases toward a positive outcome can also influence report writing and research presentations. In the scientific community similar pressures to suc- ceed exist, such that negative results are less likely to be submitted for publi- cation and, if submitted, are less likely to be accepted than positive results. In consumer research, we’ve seen obviously negative findings given a ludicrously positive spin in a final research presentation with summary headlines such as: “Five of the 20 people really liked the new concept.” Researchers doing this risk their credibility. Business stakes are far too high to risk being misled by a researcher contriving a “feel-good” effect. This may sound unusual, but you should not care what the outcome of your research is. You should only care that your research design and data are bulletproof and will stand up to the most rigorous scrutiny. Let the chips fall where they may. It’s not your job to guarantee a happy ending. \nHere are some checks we’ve found helpful: • Decide on the data logging procedure ahead of the study. Use a man- ageable number of data codes to categorize events. Practice using them and document them in a formal test plan. • Record objective data where possible: for example, task completion rates and time on task. • Agree any pass/fail criteria ahead of the study, not afterwards. • It may not be possible to have a “blind” UX researcher, but it may be possible to have “blind” data loggers. Have at least two data loggers (or note-takers) so that you can check for inter-scorer reliability and compare notes. • Record verbatim what participants say, not what you think they mean. • Avoid trying to interpret the data during the study. • Double-check your data coding, data entry and any statistical analysis. • Ask a research colleague to read your final report, or presentation slides, and give critical feedback. Sponsorship Biases Biases toward the company sponsoring the research studies are common. In the pharmaceutical industry, for example, industry-funded trials are about four times more likely to report positive rather than negative results 18 ; and studies sponsored by pharmaceutical companies are more likely to have out- comes favoring the sponsor than are studies with other sponsors. 19 Philip recently witnessed a deliberate example of sponsorship bias, moti- vated perhaps by a misguided desire for a happy outcome, when he was invited to review a project in which a third party “independent” research company was carrying out long-term in-home trials of a new domestic appliance product. He was astonished to discover that the owner of the research company had planted herself into the study as a test participant, and that for every item on every ques- tionnaire over a three-month period, she gave the product the highest possible five-star positive rating. In her eagerness to please the client, this researcher had clearly lost sight of the purpose of the in-home research, which was to uncover problems so that they could be fixed before the product was launched. Internal company pressures, often stemming from the ever-escalating col- lective belief that the project cannot possibly fail (otherwise why are we still \ndoing it?), can create a working environment intolerant of any negative out- comes. Much of this pressure comes from testing or carrying out research too late, and it can be defused by doing research and testing early and often, and by keeping the stakeholders closely involved so that they can make course corrections and mitigate risk before things reach the point of no return. Again, if a double-blind can be employed, this can effectively put a “fire- wall” between the funding source and the research team. no one involved in conducting and reporting the study would know who the sponsoring company was. But, as we have noted, in UX research this is nearly impossible, and some- times you just have to stand by your research data, bite the bullet and break the bad news, sponsor or no sponsor. However, you might be surprised at the reaction you get. Philip once had to present negative UX research data that he knew would deliver a death blow to a $ 28 million project. To his surprise, the relief in the room was palpable. It was the final piece of evidence that gave the company the confidence to pull the plug and stop wasting more money. Why You Need to Fix Your Bias Blind Spot Bias works like a Trojan horse. It hides in our UX research toolbox, slips past our defenses, and operates from the inside. Everyone has a bias blind spot but we are less likely to detect bias in ourselves than in others. Carey Morewedge, associate professor of marketing at Boston University, says 20 : “People seem to have no idea how biased they are. Whether a good decision maker or a bad one, everyone thinks that they are less biased than their peers. This sus- ceptibility to the bias blind spot appears to be pervasive, and is unrelated to people’s intelligence, self-esteem, and actual ability to make unbiased judg- ments and decisions.” Unlike in the academic science community, where research is rigorously peer reviewed and scoured for methodological flaws, even shot down if it cannot pass muster, most UX and market research is seldom subjected to such intense scrutiny. Things are simply moving too fast. Headline findings are often all that most stakeholders see, and findings are largely taken on trust that the results are what they appear to be. Decisions are quickly made and the show moves on down the road. But false research outcomes can cost a company millions of dollars. In the absence of a double-blind methodology, your strongest weapon against researcher bias may simply be the awareness that it exists. \nTHINK LIKE A UX RESEARCHER • Think of the various stages in UX research, from planning a study through to taking action on the findings. What different biases could creep in at each stage? Are some of these stages more vulnerable to researcher bias than others? • Consider the situation where people from the development team are observing your research. If they discuss their observations with you after the session, are they biasing your recollection of events? or is this a useful way of highlighting observations you may have missed? • Do you think the way a UX researcher approaches design experi- ments meets the standards that a scientist would expect of a “con- trolled” experiment? Why, or why not? Is UX research a science? Does UX research need to adopt the scientific method to offer value? • We say that it’s nearly impossible to run a double-blind UX research study. But could we come close to a double-blind study if we used remote, unmoderated usability tools? • Whenever you work with humans, there is a tendency to empa- thize with some people more deeply than with others. Some par- ticipants in your research may be more likable, more articulate, or more needful of a good solution than others. How can you prevent this from biasing the way you interpret and report the results?"
}