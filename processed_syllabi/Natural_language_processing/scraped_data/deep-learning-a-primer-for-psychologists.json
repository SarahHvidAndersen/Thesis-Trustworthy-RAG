{
    "document_type": "research_paper",
    "title": "deep-learning-a-primer-for-psychologists",
    "author": "Unknown",
    "source": "raw_syllabi\\master_courses\\Natural_language_processing\\pdf_material\\deep-learning-a-primer-for-psychologists.pdf",
    "date_published": "2021-04-02",
    "keywords": "Unavailable",
    "flag": "",
    "text": "Psychological Methods Manuscript version of Deep Learning: A Primer for Psychologists Christopher J. Urban, Kathleen M. Gates Funded by: • National Science Foundation © 2021, American Psychological Association. This manuscript is not the copy of record and may not exactly replicate the final, authoritative version of the article. Please do not copy or cite without authors’ permission. The final version of record is available via its DOI: https://dx.doi.org/10.1037/met0000374 This article is intended solely for the personal use of the individual user and is not to be disseminated broadly. \nAbstract Deep learning has revolutionized predictive modeling in topics such as computer vision and natural language processing but is not commonly applied to psychological data. In an eﬀort to bring the beneﬁts of deep learning to psychologists, we provide an overview of deep learning for researchers who have a working knowledge of linear regression. We ﬁrst discuss several beneﬁts of the deep learning approach to predictive modeling. We then present three basic deep learning models that generalize linear regression: The feedforward neural network (FNN), the recurrent neural network (RNN), and the convolutional neural network (CNN). We include concrete toy examples with R code to demonstrate how each model may be applied to answer prediction-focused research questions using common data types collected by psychologists. Keywords: Psychology, deep learning, artiﬁcial neural networks, machine learning, predictive modeling \nTranslational Abstract Deep learning has been successfully used to solve complex problems in computer vision and in natural language processing but is rarely used in psychology. In this primer, we provide an overview of deep learning in an eﬀort to bring the beneﬁts of deep learning to psychologists. We ﬁrst discuss several beneﬁts of using deep learning algorithms to predict important outcomes. We then present three basic deep learning models: The feedforward neural network (FNN), the recurrent neural network (RNN), and the convolutional neural network (CNN). We use toy examples with R code to demonstrate how these models may be applied to predict important outcomes using the kinds of data sets typically collected by psychologists. \nDeep Learning: A Primer for Psychologists The amount of data available to psychologists in recent years has exploded. The rise of the internet has enabled researchers to recruit large, diverse, and cheap web-based samples (e.g., Buhrmester et al., 2011; Gosling et al., 2004) as well as to utilize the vast quantities of existing web-based behavioral data (e.g., Golder & Macy, 2011; Gosling et al., 2011; Landers et al., 2016; Yarkoni, 2010). Smartphones and wearable sensors give researchers unprecedented opportunities to study experiential, behavioral, and physiological processes at the individual level (e.g., Hamaker & Wichers, 2017; Miller, 2012; Trull & Ebner-Priemer, 2014). Large, publicly available data sets (e.g., Institute for Quantitative Social Science Dataverse Network, dvn.iq.harvard.edu; OpenfMRI project, www.openfmri.org) let researchers answer questions that cannot be addressed in conventional lab-based settings (Yarkoni, 2012). Statistics and artiﬁcial intelligence researchers have developed powerful, ﬂexible machine learning algorithms that can be applied to these big data sets. Oftentimes these algorithms are applied to predict some outcome, such as to classify an individual into some category based on the data or to predict a future event. In these cases, machine learning algorithms are typically used in conjunction with techniques to prevent overﬁtting , or ﬁnding spurious patterns in a data set that do not generalize to other data sets (Hastie et al., 2009). Researchers have employed machine learning algorithms to answer a variety of prediction-focused psychology research questions using the kinds of data sets described above. Social media data have been leveraged to identify important predictors of mental health issues including depression (Schwartz et al., 2014), post-traumatic stress disorder (Coppersmith et al., 2014), suicidal ideation (Coppersmith et al., 2016; De Choudhury et al., 2016), and schizophrenia (Mitchell et al., 2015). Analyses of smartphone usage and wearable sensor data have pinpointed predictors of current and future cognitive states such as moods and emotions (e.g., LiKamWa, 2012; Mehrotra et al., 2017; Rachuri et al., 2010) with a particular focus on depressive states (e.g., Canzian & Musolesi, 2015; Mehrotra \net al., 2016; Saeb et al., 2015). Large, publicly available clinical data sets have been used to make predictions associated with the diagnosis, prognosis, and treatment of mental illness in clinical psychology, psychiatry, and neuroscience (e.g., Dwyer et al., 2018). Prediction-focused studies like those just described can help inform intervention, prevention, and treatment endeavors in real-life scenarios. Focusing on prediction can also inform psychological theory by identifying important variables and relationships that can subsequently be investigated as potential causal factors underlying the phenomena being studied. However, psychologists often need to carefully select meaningful variables to include in machine learning models to get accurate predictions; this procedure is called feature engineering in machine learning (Zheng & Casari, 2018). The need for feature engineering makes it diﬃcult to build accurate predictive models without a priori expertise in the phenomena being studied, which is often unavailable in complicated data sets with many variables. Indeed, the diﬃculty of feature engineering may be a strong contributor to the fact that no single method obtained consistently high predictive accuracy across the studies described above. In this primer, we describe a potential solution to the feature engineering problem. Speciﬁcally, we introduce concepts integral for understanding deep learning , a machine learning paradigm that can be applied to the problems of prediction, forecasting, and classiﬁcation. Deep learning is the subﬁeld of machine learning concerned with extracting information from data in hierarchies of concepts where more abstract concepts are built out of less abstract concepts. We visualize this information extraction process in Figure 1 (Goodfellow et al., 2016), which contains a popular deep learning model schematic where each row of circles represents a model layer and arrows represent information ﬂow through the model. The pictured model can classify objects in images. Each individual image pixel ﬁrst enters the model’s visible layer . The model’s hidden layers extract successively more and more abstract concepts, like edges or parts of objects. Finally, the model predicts the identity of the object in the image. For those familiar with structural equation modeling \n(SEM), hidden layers in deep learning models actually extract latent variables. However, unlike in SEM, these extracted latent variables may not be directly interpretable, may be related to each other and to the observed variables via nonlinear functional forms that are not known a priori , and are not subject to many of the assumptions and constraints required for most SEM estimators. Additionally, unlike traditional SEM and many classical statistical methods, deep learning algorithms automatically extract their own hidden layer/latent variable representations of the data to use for making predictions, thereby potentially avoiding the need for extensive feature engineering. Each layer in a deep learning model is just a simpler machine learning model. The most popular foundational models used to build deep learning models are called artiﬁcial neural networks (ANNs; LeCun et al., 2015). In fact, ANNs and deep learning are so interlinked that some machine learning researchers consider ANNs to be another name for deep learning (e.g., Goodfellow et al., 2016). ANNs have produced major breakthroughs in computer vision and natural language processing (LeCun et al., 2015) as well as in accurate time series forecasting (e.g., Karlsson et al., 2014; Sezer et al., 2020). Computer scientists have even employed ANNs to accurately predict psychological constructs at unprecedented rates. For example, Suhara et al. (2017), Mikelsons et al. (2017), and Taylor et al. (2017) applied ANNs to forecast individuals’ future moods using daily diary, wearable sensor, smartphone log, and weather data. Huang et al. (2018) combined two kinds of ANNs to predict bipolar individuals’ mood disturbances using keystroke and circadian rhythm data. Aghaei et al. (2018) asked participants to wear cameras, then used ANNs on the resulting image data to classify individuals’ social interactions. In each case, ANNs outperformed the best statistical methods available for prediction, such as logistic regression and support vector machines. Despite their state-of-the-art prediction accuracy, deep learning approaches have not been widely adopted for predictive modeling in psychology. (One notable exception is in neuroscience, where ANNs are often used to identify brain-based disorders using brain \nimaging data; see Vieira et al., 2017, for a review.) The beneﬁts that deep learning approaches might confer to psychology beyond those oﬀered by simpler machine learning models are therefore undetermined. Some barriers to applying deep learning for predictive modeling in psychology might include: (1) A lack of clarity about common terms like deep learning and fundamental concepts such as artiﬁcial neural networks (i.e., a knowledge barrier); (2) the complicated nature of building deep learning models in practice (i.e., a complexity barrier); and (3) a lack of standard, easy-to-use deep learning software (i.e., an implementation barrier). Due to space concerns, we primarily address the knowledge barrier in this primer and intend to more fully address the complexity and implementation barriers in future work. The objective of this primer is to familiarize psychologists with deep learning concepts so that they can be better prepared to learn emerging methods (which are largely developed in diﬀerent disciplines) and to be critical consumers of articles in the psychological sciences that use deep learning methods. This primer aims to serve as an accessible reference for psychologists as they increasingly become exposed to studies that use deep learning methods. We accomplish this goal via a two-pronged approach. First, we introduce psychologists to some of the beneﬁts of using deep learning for predictive modeling. Second, we de-mystify deep learning by explaining common terms using both equations and words. ANN models, the most successful models under the deep learning paradigm, are presented as a generalization of the linear regression model. Specialized ANNs that work well with with sequential data (e.g., daily diary data) and with image data (e.g., fMRI data) are explained. Speciﬁcally, we describe feedforward neural network (FNN), recurrent neural network (RNN), and convolutional neural network (CNN) models. Detailed toy examples and R code are presented for each model. \nBeneﬁts of Deep Learning for Predictive Modeling Beneﬁts Shared with Other Machine Learning Algorithms Deep learning shares a number of beneﬁts with machine learning algorithms in general. First, much like machine learning algorithms such as random forests (RFs; Breiman, 2001) and support vector machines (SVMs; Boser et al., 1992), deep learning algorithms implicitly model interactions and other nonlinearities that need to be explicitly speciﬁed in classical statistical methods such as linear regression (see Appendix A for a review of linear regression). This enables deep learning algorithms to obtain high predictive accuracy when the true causal relationships underlying the data are nonlinear (e.g., Yarkoni & Westfall, 2017). Second, deep learning eﬀectively models multicollinear and high-dimensional data. Many classical statistical methods such as linear regression are unstable when the independent variables are multicollinear, often leading to inaccurate model predictions. Deep learning algorithms, on the other hand, may perform well with multicollinear and high-dimensional data sets by constructing highly predictive latent variable representations of the independent variables (De Veaux & Ungar, 1994). In this sense, deep learning algorithms are related to algorithms such as principal components regression (Hotelling, 1957; Kendall, 1957), partial least squares (Wold, 1966), and penalized partial least squares (Krämer et al., 2008), all of which aim to extract the most important information from the independent variables to make predictions. A third beneﬁt of the deep learning learning approach is that many strategies can be employed to prevent models from overﬁtting. A core objective of machine learning is to build predictive models that perform well on new, previously unseen data sets (e.g., Goodfellow et al., 2016; Hastie et al., 2009). Deep learning beneﬁts from a number of techniques speciﬁcally developed to prevent deep learning models from overﬁtting (see Goodfellow et al., 2016, for a thorough, albeit technical, review). In Appendix B, we provide an overview of fundamental, general-purpose machine learning strategies for preventing overﬁtting. In particular, we explain the important concepts of changing a \nmodel’s representational capacity, regularizing a model, and tuning a model’s hyperparameters via validation set and k-fold cross-validation approaches. Familiarity with these fundamental concepts is essential for ﬁtting deep learning models that perform well using previously unseen data sets. However, even if researchers never choose to ﬁt a deep learning model, understanding and applying machine learning techniques such as regularization and cross-validation can increase the eﬃciency and reproducibility of many analysis pipelines without necessarily altering the end results (Yarkoni & Westfall, 2017). Unique Beneﬁts of Deep Learning Algorithms Deep learning has some unique beneﬁts in addition to those shared with general machine learning techniques. First, deep learning is capable of leveraging big data sets to obtain highly accurate predictions. Although all machine learning algorithms tend to beneﬁt from increasing sample sizes, deep learning algorithms have been empirically found to leverage big data sets to increase their predictive accuracy beyond the accuracy attainable with other machine learning algorithms (e.g., RFs and SVMs; Goodfellow et al., 2016; LeCun et al., 2015). We anticipate that as society becomes increasingly digitized, psychologists will have greater access to large data sets that will be diﬃcult to eﬀectively analyze without using deep learning. Deep learning algorithms may be able to capitalize on huge data sets such as observations from internet sources (e.g., websites, blogs, and social media; Landers et al., 2016), cell phone behaviors (e.g., Hamaker & Wichers, 2017), and genomic data sets (e.g., Plomin & Davis, 2009) to predict psychological outcomes with unprecedented accuracy. We note, however, that “big data” is not required for deep learning models to obtain high predictive accuracy. Many tools exist for ﬁtting accurate deep learning models using small data sets. For example, transfer learning (Pan & Yang, 2010; Torrey & Shavlik, 2009) is a machine learning technique wherein a model ﬁtted to perform one task is re-purposed to perform another task, typically to predict a diﬀerent outcome on a new \ndata set. Transfer learning often produces models with higher predictive accuracy than models ﬁtted using only a single data set (e.g., Tan et al., 2018). Transfer learning may be useful for psychologists with small data sets, who could ﬁt a deep learning model using a large, publicly available data set (e.g., a large-scale mental health survey data set) that is related to the small data set of interest (e.g., a small clinical sample), then “ﬁne-tune” the model using the small data set. Recent work suggests that even without specialized approaches like transfer learning, deep learning models ﬁtted using small data sets are capable of obtaining high predictive accuracy on new data (Olson et al., 2018). Second, deep learning leverages small correlations for accurate predictions. Deep learning algorithms excel at discovering intricate relationships between large numbers of variables (LeCun et al., 2015). Many phenomena studied by psychologists are likely inﬂuenced by a large number of weak causal factors that interact in complicated ways – that is, “everything correlates with everything else” (Meehl, 1990). Deep learning models, which are less readily interpretable than linear regression models, may perform well in such cases (although see Montavon et al. (2017) for a tutorial overview of methods for interpreting deep learning models). Third, deep learning reduces the need for feature engineering. Psychologists usually need to think carefully about including meaningful, theoretically-relevant variables in models to obtain accurate, generalizable predictions – that is, predictive modeling in psychology often requires careful feature engineering. In some application domains, deep learning algorithms can reduce the need for feature engineering by extracting their own (though usually not directly interpretable) representations of the independent variables to make predictions (LeCun et al., 2015). For example, the psychological analysis of text data (Iliev et al., 2015), image data, and video data (Barto et al., 2017) is usually labor-intensive, requiring human coders to look through the data and manually identify important information in each observation to use for making predictions. It might not even be clear what information will lead to the most accurate predictions. In psychological text \nanalysis, for example, it is not always clear which features in a body of text will be the most useful for predicting outcomes like the author’s personality characteristics (Iliev et al., 2015). A deep learning algorithm might prove useful in this case by extracting representations of the raw text data in an automated fashion and using these representations to accurately predict personality characteristics (Mehta et al., 2020). In a similar vein, deep learning may circumvent the need for measurement models. Measurement models refer to models that relate latent psychological constructs to measures or indicators of those constructs. Building measurement models is an essential but challenging part of conducting psychological research that typically requires careful consideration of many factors including exact speciﬁcation of the relationships between constructs and indicators (e.g., Bollen, 2001). Oftentimes, psychologists construct measurement models to explain variability in some outcome variable of interest using latent predictor variables. In the case of item response theory (IRT), psychologists often build measurement models to obtain a score for an individual which can subsequently be used to make inferences pertaining to that individual (e.g., diagnostic status, performance ability). If, however, psychologists wish to accurately predict some outcome of interest rather than to make substantive inferences, deep learning may circumvent the need for measurement models by automatically extracting the latent variable representation of the input measures that is most predictive of the outcome variable 1 . Fourth, deep learning algorithms often obtain higher predictive accuracy than other machine learning algorithms when the observations are sequences or images. We note that this does not imply that deep learning algorithms are not useful for research questions 1 Those familiar with principal components regression and its variant partial least squares may note that these methods provide a similar approach to deep learning by using causal indicators where the latent variables (or components) are predicted by the indicators. This contrasts with typical measurement models in SEM and IRT where reﬂective indicators are used – that is, where the indicators are predicted by the latent variables. While deep learning does closely correspond to traditional methods based on causal indicators (for example, deep learning can be used to perform a nonlinear version of principal component analysis; Gorban et al., 2008), deep learning diverges from these methods by applying multiple nonlinear transformations to the extracted latent variables. \nbased in cross-sectional data (e.g., web-based behavioral measurements, cross-sectional survey data). Rather, deep learning algorithms outperform simpler machine learning algorithms more consistently and by a wider margin in sequence or image data sets than in cross-sectional data sets (e.g., Arik & Pﬁster, 2019; Goodfellow et al., 2016). Speciﬁcally, models called recurrent neural networks (RNNs) led to early advances in predictive modeling of text and speech data, while models called convolutional neural networks (CNNs) led to breakthroughs in processing image, video, and speech data (LeCun et al., 2015). Modern ANNs based on residual neural networks (ResNets; He et al., 2015), temporal convolutional networks (TCNs; Bai et al., 2018), and Transformers (Vaswani et al., 2017) now achieve state-of-the-art performance on a variety of sequence and image modeling problems. Fifth, deep learning can account for between- and within-group eﬀects. Hierarchical (or nested) data structures in which multiple observations are taken from each of many clusters are common in psychology (e.g., students within schools, patients within clinics). Traditionally, hierarchical data have been analyzed using multilevel modeling (Raudenbush & Bryk, 2002). In deep learning, a similar approach called multitask learning ﬁts models with parameters that are shared across groups as well as group-speciﬁc parameters (Caruana, 1997). Similar to how multilevel modeling improves on non-multilevel statistical methods by permitting unbiased estimation with hierarchical data, multitask deep learning models may improve on non-multitask machine learning and deep learning approaches by predicting psychological outcomes more accurately with hierarchical data (Zhang & Yang, 2017). For example, Taylor et al. (2017) found that a multitask deep learning approach outperformed both multitask SVMs and a hierarchical logistic regression approach at predicting mood, stress, and health status using self-reported behaviors as well as wearable sensor, smartphone log, weather, and GPS data. See Bakker and Heskes (2004) for a discussion of the similarities between multitask learning and multilevel modeling. \nDeep Learning Models, Terminology, and Notational Conventions What exactly makes a machine learning model a deep learning model ? A deﬁning feature of most deep learning models is that they map the input observations through a sequence of functions where each function in the sequence is called a layer . In more technical terms, nearly all deep learning models are compositions of functions. Function composition is the application of one function to the output of another function. Formally, function composition is written as g ¶ f ( x ) = g 1 f ( x ) 2 , (1) where g ¶ f is read as “ g composed with f ” or as “ g of f ”. Intuitively, when we compose g with f ( x ), we are feeding some input value x to the function f , which spits out a value f ( x ). In turn, f ( x ) is fed to the function g , which spits out a ﬁnal value g 1 f ( x ) 2 . In Figure 2a, we visualize this process with a schematic in which circles represent values and arrows represent functions. The functions g and f in equation 1 are univariate and scalar-valued , which means they take a single number as input and produce a single number as output, respectively. In general, functions may be multivariate and vector-valued , which means they take vectors as inputs and may produce vectors as outputs, respectively. Compositions of two multivariate vector-valued functions are written g ¶ f ( x ) = g 1 f ( x ) 2 (2) = C g 1 3Ë f 1 ( x ) , . . . , f p 1 ( x ) È € 4 , . . . , g p 2 3Ë f 1 ( x ) , . . . , f p 1 ( x ) È € 4D € , (3) where x is a p ◊ 1 vector, f ( x ) is a p 1 ◊ 1 vector, and g 1 f ( x ) 2 is a p 2 ◊ 1 vector. Equation 3 demonstrates that any vector-valued function actually consists of many scalar-valued functions. For example, the vector-valued function f actually consists of p 1 \ndiﬀerent scalar-valued functions f 1 , . . . , f p 1 that each take in the input vector x and spit out the single numbers f 1 ( x ) , . . . , f p 1 ( x ). We visualize a composition of two multivariate vector-valued functions in Figure 2b. Notice that p , p 1 , and p 2 (i.e., the number of elements in x , f ( x ), and g 1 f ( x ) 2 , respectively) are not necessarily equal: In Figure 2b, x is three-dimensional (i.e., p = 3), f ( x ) is four-dimensional (i.e., p 1 = 4), and g 1 f ( x ) 2 is two-dimensional (i.e., p 2 = 2). We omit function arguments in schematic diagrams for multivariate vector-valued functions to avoid clutter. Compositions may include more than just two functions. For example, we write a composition of three multivariate vector-valued functions as g ¶ f (2) ¶ f (1) ( x ) = g 3 f (2) 1 f (1) ( x ) 2 4 , (4) where x is a p ◊ 1 vector, f (1) ( x ) is a p 1 ◊ 1 vector, f (2) 1 f (1) ( x ) 2 is a p 2 ◊ 1 vector, and g 3 f (2) 1 f (1) ( x ) 2 4 is a p 3 ◊ 1 vector. In this primer, we use parenthesized numbers in superscripts to denote ordered sequences of objects where object i ≠ 1 comes before object i . We may in fact compose as many functions as we wish. Compositions of q + 1 multivariate vector-valued functions are written g ¶ f ( q ) ¶ · · · ¶ f (2) ¶ f (1) ( x ) = g A f ( q ) 3 . . . f (2) 1 f (1) ( x ) 2 4B , (5) where x is a p ◊ 1 vector, f ( i ) 1 . . . f (1) ( x ) 2 is a p i ◊ 1 vector for i = 1 , . . . , q , and g 1 . . . f (1) ( x ) 2 is a p q +1 ◊ 1 vector. Nearly all deep learning models are compositions of many multivariate vector-valued functions as in equation 5, where each function has parameters we can optimize to help the model accurately predict the outcome variable. Equation 5 helps us deﬁne important terminology for describing deep learning models. In deep learning models, each function composed together to build the model is called a layer . f (1) is called the ﬁrst layer , f (2) is called the second layer , and so on. x is called the input layer . Functions f (1) through f ( q ) are collectively called hidden layers . The \nﬁnal function g is called the output layer . The elements of each vector-valued layer, denoted f ( i ) 1 , . . . , f ( i ) p i for the i th layer, are called nodes , artiﬁcial neurons , or units . The total number of hidden layers q is called the model depth . Models with one hidden layer are called shallow . Models with more than one hidden layer are called deep . The number of elements in the i th layer, denoted p i , is called the width of layer i . The process in equation 5 is visualized with annotated layers in Figure 2c. The intuition behind choosing a model with many hidden layers is that the deep learning algorithm may decide how to use each hidden layer to best approximate the relationship between the input and output variables (Goodfellow et al., 2016). Overview of Artiﬁcial Neural Network Models The deﬁnition of a deep learning model as a composition of functions is quite broad. In principle, we could compose together any arbitrary functions and call the resulting composition a deep learning model. However, choosing completely arbitrary functions to build deep learning models would likely produce models that are very hard to ﬁt or models that do not perform well. Artiﬁcial neural networks (ANNs) are one popular solution to this problem. ANNs are a broad class of nonlinear statistical models that can be composed together in many layers. They were initially inspired by biological neural mechanisms (McClelland et al., 1986; McCulloch & Pitts, 1943; Rosenblatt, 1958) and aim to consolidate and transfer information much like in biological learning. Speciﬁcally, the ANN modeling framework mimics animal (and human) neural processes in which neurons transfer information via synapses in a feedforward fashion. The earliest ANNs only had one hidden layer, but deep learning implementations of ANNs have multiple hidden layers. ANNs have been extremely successful under the deep learning paradigm because they can be eﬃciently ﬁtted (using the back-propagation algorithm; Werbos, 1974) and because of their potentially high predictive accuracy. In the following sections, we present some ANNs that may be useful for predictive \nmodeling in psychology. We ﬁrst describe feedforward neural networks (FNNs). Like linear regression, FNNs are useful for predicting outcomes of interest using tabular data sets (i.e., data sets which can be formatted as the standard N ◊ p design matrix X used in linear regression; see Appendix A). Next, we discuss recurrent neural networks (RNNs), which were developed to predict outcomes of interest using sequential data (e.g., daily diary data; physiological trace data). Although RNNs are often outperformed in practice by convolutional neural networks and other modern ANNs (Bai et al., 2018; Vaswani et al., 2017), familiarity with RNN basics is an excellent starting point for exploring more recent deep learning approaches to sequence modeling. Finally, we discuss convolutional neural networks (CNNs), which are powerful tools for predicting outcomes with both image data (e.g., fMRI data) and with sequential data. In this primer, we focus on applications of CNNs to image data due to space concerns but note that applications of CNNs to sequential data are conceptually similar. We compare linear regression, FNNs, RNNs, and CNNs in Table 1. Single-Layer Feedforward Neural Networks The single-layer feedforward neural network (FNN), also called the single-layer perceptron , is the simplest ANN model. The single-layer FNN only has one hidden layer and is therefore a shallow model of the form g 1 f ( x ) 2 as in equation 2. It can be used either for regression (i.e., predicting continuous outcomes) or for classiﬁcation (i.e., predicting categorical outcomes). Just like in linear regression, the single-layer FNN starts with N observations of p predictor variables collected in an N ◊ p design matrix X as well as N observations of one outcome variable collected in an N ◊ 1 vector y . In linear regression, we typically denote the i th observed vector of predictor variables (i.e., a single row of X ) as x i and the i th observed value of the outcome variable as y i for i = 1 , . . . , N . In this primer, we simplify notation by dropping all i subscripts so that x i is written as x and y i is written as y . This \nsimpliﬁcation is justiﬁed because single-layer FNNs and other ANNs are usually ﬁtted by feeding one randomly selected observation to the model at a time. The particular observation we choose has no impact on how the model is speciﬁed. The single-layer FNN aims to to produce a p 1 ◊ 1 hidden layer representation h of each p ◊ 1 observation x that can subsequently be used to predict the corresponding outcome y . To produce this hidden layer representation, the single-layer FNN ﬁrst computes p 1 diﬀerent weighted sums of the observed predictor values x j plus an intercept: s k = b hx k, 0 + p ÿ j =1 b hx k,j x j , k = 1 , . . . , p 1 , (6) where s k are weighted sums called activations , b hx k,j are weight parameters, b hx k, 0 are intercept parameters, and p 1 is the number of hidden layer nodes. Equation 6 is simply a linear regression model (see equation A.1) repeated once for each hidden layer node (i.e., p 1 times) with diﬀerent weight parameters for each node. Note that the weight parameters have “hx” superscripts to indicate that multiplying by these weights gets us “to” the hidden layer h “from” the input layer x . We use this “to-from” notation throughout this primer to unambiguously specify the weight parameters associated with each ANN layer, which is especially helpful when describing ANNs with many layers (Lipton et al., 2015). Next, the single-layer FNN applies a nonlinear function f to each activation s k to compute the hidden layer or the derived predictor nodes: h k = f ( s k ) , k = 1 , . . . , p 1 . (7) These hidden layer nodes are elements of the p 1 ◊ 1 hidden layer representation h , which corresponds to f ( x ) from the g 1 f ( x ) 2 model described in equation 2. The nonlinear function f is called an activation function and enables the single-layer FNN to model outcomes that vary nonlinearly with the input variables. Note that the same activation function is applied to all of the hidden layer nodes. The hidden layer activation function \nfor single-layer FNNs was traditionally the sigmoid function f ( z ) = 1 1 + e ≠ z , (8) although modern single-layer FNNs mostly use the rectiﬁed linear unit or ReLU (Glorot et al., 2011; Jarrett et al., 2009; Nair & Hinton, 2010) fa ( z ) = max(0 , z ) . (9) The sigmoid activation function is visualized in Figure 3a and the ReLU activation function is visualized in Figure 3b. Activation functions are discussed further later in this section. The single-layer FNN can now use the hidden layer representation h to predict the outcome y . To do so, it computes a weighted sum of the hidden layer values plus an intercept term, then applies another nonlinear activation function g to this sum: y = g ( b yh 0 + p 1 ÿ k =1 b yh k h k ) + Á, (10) where “yh” superscripts indicate weight parameters to the output node from the hidden layer nodes and Á is a random error term. The single-layer FNN is visualized in Figure 4. ˆ y , the predicted output value in the ﬁnal node, is plugged in to an objective function (e.g., mean squared error) to evaluate the model’s predictive accuracy. Note that intercepts are included in the schematic by multiplying the intercepts by new nodes x 0 and h 0 that are both equal to one. Psychologists may be familiar with this procedure from SEM, where it is used to include intercepts in path diagrams, often as triangles (Bollen, 1989). Choosing the ﬁnal activation function g determines whether our single-layer FNN will perform regression or classiﬁcation. In regression, we wish to predict an outcome y that \nmay be any real number. In this case, we choose g to be the identity function g ( z ) = z. (11) Figure 3c shows that the identity function simply takes in any real number z and outputs the same real number z . In binary classiﬁcation, we wish to predict an outcome y that may be either zero (corresponding to the ﬁrst output category) or one (corresponding to the second output category). Here, we choose g to be the sigmoid function (equation 8). Figure 3a demonstrates that the sigmoid function takes in any real number z and outputs a number between zero and one. The number output by the sigmoid activation function represents the probability that the input observation belongs to the second output category (i.e., the category represented by y = 1). Finally, in classiﬁcation with k categories, we wish to predict a k ◊ 1 outcome vector y that is dummy coded such that the i th dummy variable is equal to 1 and all other dummy variables are equal to 0 (i.e., y = [0 , . . . , 0 , 1 , 0 , . . . , 0] € ). In this case, we choose g to be the softmax function g ( z ) i = e z i q k j =1 e z j , i = 1 , . . . , k, (12) where z is a k ◊ 1 vector. The softmax activation function takes in a k ◊ 1 vector of real values z and outputs a k ◊ 1 vector of probabilities whose i th element represents the probability that the input observation belongs to category i . Similarly to linear regression, the single-layer FNN can be expressed concisely using matrices: y = g 1 ( b yh ) € h + b yh 0 2 + Á, (13) h = f ( B hx x + b hx 0 ) , (13a) \nwhere b yh p 1 ◊ 1 = S WWWWWWWWWWU b yh 1 b yh 2 ... b yh p 1 T XXXXXXXXXXV , h p 1 ◊ 1 = S WWWWWWWWWWU h 1 h 2 ... h p 1 T XXXXXXXXXXV , (13b–c) B hx p 1 ◊ p = S WWWWWWWWWWU b hx 1 , 1 b hx 1 , 2 · · · b hx 1 ,p b hx 2 , 1 b hx 2 , 2 · · · b hx 2 ,p ... ... ... ... b hx p 1 , 1 b hx p 1 , 2 · · · b hx p 1 ,p T XXXXXXXXXXV , x p ◊ 1 = S WWWWWWWWWWU x 1 x 2 ... x p T XXXXXXXXXXV , b hx 0 p 1 ◊ 1 = S WWWWWWWWWWU b hx 1 , 0 b hx 2 , 0 ... b hx p 1 , 0 T XXXXXXXXXXV , (13d–f) and the activation functions f and g are applied to vectors element-wise. The p 1 ◊ 1 hidden layer vector h can be thought of as a representation of the original input observation x that the single-layer FNN has learned to help it predict y . As noted in the introduction, h is in fact a vector of p 1 latent variables , or unobserved variables that summarize the information contained in the original observation. Latent variables are likely familiar to psychologists from from SEM, which aims to explain the relationships between a set of observed variables in terms of a number of unobserved latent constructs. In single-layer FNNs, however, each latent variable in h depends on every observed variable in x . This may make the latent variables in single-layer FNNs more diﬃcult to interpret than those in SEM, where each latent variable is intepretable in part because it is only related to a subgroup of conceptually similar observed variables. Single-layer feedforward neural networks generalize linear regression. Previously, we mentioned that ANNs can be thought of as generalizations of linear regression. We now use basic algebra to show that the single-layer FNN can be reduced to the linear regression model. We ﬁrst choose the single-layer FNN’s activation functions g and f to be identity functions: g ( z ) = z, f ( z ) = z. (14) \nOur single-layer FNN can then be written as y = b yh 0 + p 1 ÿ k =1 b yh k h k + Á, (15) h k = b hx k, 0 + p ÿ j =1 b hx k,j x j , k = 1 , . . . , p 1 . (15a) We can substitute equation 15a into equation 15 and rearrange to obtain y = b yh 0 + p 1 ÿ k =1 b yh k h k + Á (15) = b yh 0 + p 1 ÿ k =1 b yh k ( b hx k, 0 + p ÿ j =1 b hx k,j x j ) + Á (16) = b Õ 0 + p ÿ j =1 b Õ j x j + Á, (17) where b Õ 0 = b yh 0 + p 1 ÿ k =1 b yh k b hx k, 0 , b Õ j = p 1 ÿ k =1 b yh k b hx k,j , j = 1 , . . . , p. (17a) Equation 17 clearly has the same form as the linear regression model in equation A.1. 2 We have therefore demonstrated that the single-layer FNN with identity activation functions reduces to the linear regression model. We can directly interpret the b Õ 0 , b Õ 1 , . . . , b Õ p parameters just like we can directly interpret the b 0 , b 1 , . . . , b p parameters in linear regression. However, the single-layer FNN parameters (i.e., the parameters with “yh” and “hx” superscripts) cannot be interpreted. This is because the single-layer FNN is overparameterized – that is, the model has more parameters than equations. Speciﬁcally, the single-layer FNN has ( p + 2) ◊ p 1 + 1 parameters total versus p + 1 equations total (see equations 13b, 13d, and 13f to count parameters and equations 17a to count equations). Inﬁnitely many sets of single-layer FNN parameters will satisfy equations 17a and produce a valid model, so any particular set of 2 When we use a suitable optimization procedure, our estimates for the b Õ 0 , b Õ 1 , . . . , b Õ p parameters will converge to the ˆ b 0 , ˆ b 1 , . . . , ˆ b p parameter estimates produced by the usual linear regresssion algorithm (see equation A.6; e.g., Baldi & Hornik, 1995). \nsingle-layer FNN parameters we choose will have no intrinsic meaning (Kutner et al., 2004). We showed that linear regression is a special case of the single-layer FNN to help readers better understand the relationship between these models. In practice, using a single-layer FNN to perform linear regression is overly complicated. Our toy example did, however, highlight a very real, practical issue: Overparameterization. Nearly all ANNs are overparameterized and therefore have uninterpretable parameters. The uninterpretability of ANN parameters is sometimes seen as a major shortcoming. However, ANNs often achieve much higher predictive accuracy than simpler, directly interpretable models like linear regression, especially when the true causal structure underlying the data set contains weakly correlated interactions between large numbers of variables. Additionally, recent work has explored methods for interpreting ANNs that avoid the overparameterization problem (e.g., Montavon et al., 2017). These methods aim to interpret the concepts learned by the ANN’s hidden layers and to identify the most important predictor variables. We now turn to a detailed toy example to illustrate how single-layer FNNs may be useful for psychological research despite being challenging to interpret. Single-layer FNN toy example: Predicting alcohol use disorder using cross-sectional survey data. Imagine that we have access to data from a large, nationally representative, cross-sectional survey that was designed to measure mental health and substance use. Such data are often publicly available (e.g., the National Survey on Drug Use and Health; https://nsduhweb.rti.org/respweb/homepage.cfm) and may contain a wealth of information about various psychological phenomena in the population at large. Our survey includes the demographic variables gender and age, diagnostic criteria for major depressive disorder (MDD), and diagnostic criteria for nicotine, marijuana, and alcohol use disorders (NUDs, MUDs, and AUDs, respectively). We are interested in ﬁnding out whether meeting diagnostic criteria for AUD can be predicted using the other demographic, mental health, and substance use variables available in our data set. This question may be interesting in clinical psychology, for example, where researchers and \nclinicians may wish to provide targeted interventions for individuals who are identiﬁed as being at risk for problematic outcomes such as AUD. Assume that our data set includes N = 5 , 000 individuals. Our AUD outcome is a binary variable that is equal to one when an individual meets the relevant diagnostic criteria and is equal to zero otherwise. Our gender, MDD, NUD, and MUD predictor variables are also binary. Our initial age predictor is a number greater than or equal to 18 (i.e., all individuals are adults); we normalize age by subtracting this predictor’s minimum value and dividing by its range before model ﬁtting. Our goal is to use each individual’s predictors x to predict whether they meet diagnostic criteria for AUD (i.e., their outcome value is one) or not (i.e., their outcome value is zero). Prediction problems like this are called classiﬁcation problems in machine learning because the goal is to assign each individual to the correct class (i.e., meeting diagnostic criteria for AUD or not). We will develop a predictive model using a training-test split approach (see Appendix B) wherein models are ﬁtted using a training set of 4 , 500 observations and model predictive accuracy is evaluated using a test set consisting of the remaining 500 observations. We used R (R Core Team, 2020) to simulate predictors based on the description in the previous paragraph. Speciﬁcally, predictors were sampled for each individual as follows: gender ≥ Bernoulli(0 . 5) , (18) age ≥U (18 , 85) , (19) MUD ≥ Bernoulli 1 f ( ≠ 1 ≠ age + 2 · gender) 2 , (20) NUD ≥ Bernoulli 1 f ( ≠ 1 ≠ age + 2 · gender + 0 . 5 · MUD) 2 , (21) MDD ≥ Bernoulli 1 f ( ≠ 1 ≠ age + 2 · gender + 0 . 5 · MUD + 0 . 5 · NUD) 2 , (22) where U ( a, b ) denotes a uniform distribution with lower bound a and upper bound b and f denotes the sigmoid function (equation 8). This sampling scheme was motivated as follows: (1) Approximately half of the sampled individuals should be male (gender = 1; \nequation 18); (2) individuals should all be adults (i.e., over age 18) and all age groups should be evenly represented in the sample (equation 19); (3) holding other variables constant, individuals should be at relatively low risk of MDD and substance use disorders (SUDs; intercept of ≠ 1 in equations 20-22); (4) increasing age should protect against risk of MDD and SUDs (negative coeﬃcient on age in equations 20-22); (5) being male should increase risk of MDD and SUDs (positive coeﬃcient on gender in equations 20-22); and (6) having any of MDD, MUD, or NUD should increase risk for the other variables (positive coeﬃcients on MDD, MUD, and NUD in equations 20-22). AUD outcome values were then generated nonlinearly from the predictor values where all predictors related to the outcome to varying degrees: AUD ≥ Bernoulli 3 f 1 ≠ 1 ≠ (age + age 2 + age 3 + age 4 + age 5 )+ 2 · gender + 0 . 5 · MDD + 0 . 5 · NUD + 0 . 5 · MUD ≠ 2 · (age + age 2 + age 3 + age 4 + age 5 ) · gender 2 4 , (23) where the age predictor was normalized prior to generation. Equation 23 is the same as equations 20-22 except age now enters the model nonlinearly and interacts with gender such that older males have decreased risk of AUD. Approximately 26 percent of simulated individuals met AUD criteria (i.e., 26 percent of the generated AUD outcome values were equal to one). Once the data were simulated, we used the R interface to Keras (a Python package for ﬁtting ANNs; Falbel et al., 2019) to classify individuals using the single-layer FNN given in equations 13 and 13a. We ﬁrst constructed the model as follows: fnn = keras_model_sequential () fnn %>% layer_dense (units = 5, activation = 'relu ', input_shape = c (5)) %>% layer_dense (units = 1, activation = 'sigmoid ') \nIn Keras, ANNs are constructed one layer at a time. The above code ﬁrst creates a single hidden layer (i.e., a layer_dense () ) with ﬁve nodes and a ReLU activation function, then connects these hidden nodes to the outcome node and applies a sigmoid activation function. Next, we speciﬁed some parameters for model ﬁtting: fnn %>% compile ( loss = 'binary_crossentropy ', optimizer = optimizer_adam (), metrics = c ('accuracy ') ) Here, we specify the objective function or loss function to be the log-likelihood of the Bernoulli-distributed AUD outcome summed over all individuals. This log-likelihood is called the binary cross-entropy in machine learning and is the same objective function used in logistic regression (Kutner et al., 2004). By setting optimizer = optimizer_adam () , we ﬁt our model using an optimization procedure called Adam (Kingma & Ba, 2015). Adam demonstrates good performance in practice with little to no hyperparameter tuning (Goodfellow et al., 2016). We also choose to assess model performance using predictive accuracy (i.e., the proportion of outcome values correctly predicted by the model). Finally, we ﬁtted the model as follows: fnn %>% fit ( as.matrix (train_data$X), as.matrix (train_data$y), epochs = 70, batch_size = 128 ) fnn %>% evaluate ( as.matrix (test_data$X), as.matrix (test_data$y)) The ﬁrst two inputs to the fit () function are a test set matrix of predictors and the associated vector of outcomes, respectively. ANNs are ﬁtted iteratively using small random samples of observations at each iteration. We randomly sample 128 observations at each ﬁtting iteration using batch_size = 128 . If we sample observations without replacement, \nwe will eventually have sampled all the observations in our data set and must replace all the observations before ﬁtting can proceed. A single full pass through every observation in the data set is called an epoch in deep learning. Our code continues ﬁtting until we have sampled all the observations in the data set 70 times by setting epochs = 70 . We compute the ﬁtted model’s predictive accuracy using the evaluate () function; our ﬁtted model obtained a predictive accuracy of 0.86 the test set. An important note regarding these analyses is that we did not tune our model hyperparameters. A complete R script for our simulation and analysis is available as online supplemental material. Our model is visualized in Figure 5. We now step through how our model computes a predicted value for a single observation from our simulated data set using our ﬁtted model parameters. This observation’s normalized age was 0.22, and all of the other (binary) predictors were 1. We ﬁrst compute the vector of activations s by multiplying our vector of predictors by a weight matrix B hx and adding an intecept vector b 0 hx just like in linear regression: s = B hx x + b hx 0 (24) = S WWWWWWWWWWWWWWU ≠ 0 . 03 0 . 93 0 . 47 0 . 07 0 . 50 ≠ 0 . 29 ≠ 2 . 00 1 . 59 0 . 16 ≠ 1 . 79 ≠ 0 . 01 0 . 26 0 . 81 ≠ 0 . 13 0 . 57 0 . 48 0 . 31 0 . 57 ≠ 0 . 52 0 . 44 ≠ 0 . 03 0 . 02 ≠ 0 . 07 0 . 05 0 . 42 T XXXXXXXXXXXXXXV S WWWWWWWWWWWWWWU 1 0 . 22 1 1 1 T XXXXXXXXXXXXXXV + S WWWWWWWWWWWWWWU ≠ 0 . 17 0 . 13 0 . 52 ≠ 0 . 28 0 . 43 T XXXXXXXXXXXXXXV (25) = 5 1 . 05 ≠ 0 . 65 1 . 82 0 . 76 0 . 80 6 € . (26) We then apply the ReLU activation function f (equation 9) to our vector of activations s to compute our hidden layer vector of latent variables: h = f ( s ) = 5 1 . 05 0 . 00 1 . 82 0 . 76 0 . 80 6 € , (27) \nwhich simply sets any negative values in s to zero. We then repeat the process with h : We multiply it by a weight vector ( b yh ) € , add an intercept b yh 0 , then apply the sigmoid activation function g (equation 8): y = g 1 ( b yh ) € h + b yh 0 2 (28) = g A 5 0 . 48 1 . 31 ≠ 0 . 84 0 . 62 1 . 57 6 S WWWWWWWWWWWWWWU 1 . 05 0 . 00 1 . 82 0 . 76 0 . 80 T XXXXXXXXXXXXXXV ≠ 1 B = g ( ≠ 0 . 29) = 0 . 43 . (29) The outputted value of 0 . 43 corresponds to the predicted probability that the simulated individual meets AUD criteria. Recall that our single-layer FNN’s objective function (Figure 5) is the same objective function used in logistic regression. To illustrate the diﬀerence between these methods, we compared our model’s performance to that of logistic regression with a lasso penalty ﬁtted using the R package glmnet (Friedman et al. (2010); see McNeish (2015) for an overview of lasso penalized regression). Predictive accuracy as well as sensitivity (i.e., the proportion of individuals meeting AUD criteria who were correctly predicted by the model) and speciﬁcity (i.e., i.e., the proportion of individuals not meeting AUD criteria who were correctly predicted by the model) were computed on the test set for both models. Our single-layer FNN (accuracy = 0 . 86, sensitivity = 0 . 62, speciﬁcity = 0 . 94) mostly outperformed penalized logistic regression (accuracy = 0 . 80, sensitivity = 0 . 30, speciﬁcity = 0 . 97), suggesting that the FNN better captured the underlying nonlinear relationship between the predictors and the outcomes. Additionally, the FNN obtained this superior performance with no hyperparameter tuning. Although ANNs often obtain reasonable performance with little to no hyperparameter tuning, conducting extensive hyperparameter tuning may produce astonishing performance gains. See Bengio (2012), \nHeaton (2008), or Smith (2018) for discussions of hyperparameter tuning for ANNs. We note that complex survey designs typically include sampling weights to ensure that population subgroups are adequately represented in subsequent analyses (Lavalleé & Beaumont, 2015). We chose not to simulate sampling weights to facilitate our comparison of single-layer FNNs with lasso penalized logistic regression. However, if we had simulated sampling weights, they could have been included in our single-layer FNN objective function simply by multiplying each individual’s objective function value by their sampling weight. This is easy to do using Keras – a vector of sampling weights can be included in fit () using the sample_weight argument. Deep Feedforward Neural Networks Single-layer FNNs are not deep learning models because they only have one hidden layer. Deep feedforward neural networks , also called multi-layer perceptrons , extend single-layer FNNs by including more than one hidden layer. Using many hidden layers may allow deep FNNs to model complicated, nonlinear relationships between the input and output variables more eﬃciently than single-layer FNNs, often making deep FNNs a better modeling choice than single-layer FNNs for large, complicated data sets. The deep FNN equations are very similar to the single-layer FNN equations. To produce its ﬁrst p 1 hidden layer nodes, the deep FNN computes p 1 weighted sums of the predictor values x j plus an intercept, then applies an activation function f (1) to each sum: h (1) k = f (1) ( b h 1 x k, 0 + p ÿ j =1 b h 1 x k,j x j ) , k = 1 , . . . , p 1 (30) where “ h 1 x ” superscripts indicate to weight parameters to the ﬁrst hidden layer nodes from the predictor nodes. Equation 30 is clearly the same as equation 7 substituted into equation 6 – that is, the deep FNN’s ﬁrst hidden layer is clearly computed the same way as the single-layer FNN’s single hidden layer. The deep FNN then uses the hidden layer nodes at layer ¸ ≠ 1 to produce the hidden \nlayer nodes at layer ¸ . Speciﬁcally, successive hidden layer nodes are produced by computing weighted sums over the previous hidden layer nodes plus intercept terms, then applying activation functions to these sums: h ( ¸ ) k = f ( ¸ ) ( b h ¸ h ¸ ≠ 1 k, 0 + p ¸ ≠ 1 ÿ j =1 b h ¸ h ¸ ≠ 1 k,j h ( ¸ ≠ 1) j ) , k = 1 , . . . , p ¸ , ¸ = 2 , . . . , q, (31) where q denotes the model depth, p ¸ denotes the number of nodes at hidden layer ¸ , and “h ¸ h ¸ ≠ 1 ” superscripts indicate weight parameters to hidden layer ¸ nodes from hidden layer ¸ ≠ 1 nodes. The outcome node is predicted by taking a weighted sum of the ﬁnal hidden layer nodes plus an intercept term, then applying an activation function g to this sum: y = g ( b yh q 0 + p q ÿ k =1 b yh q k h ( q ) k ) + Á, (32) where “yh q ” superscripts indicate weight parameters to the outcome node from the ﬁnal hidden layer nodes and Á is a random error term. As with the single-layer FNN, choice of the activation function g determines whether the deep FNN will perform regression or classiﬁcation. Like single-layer FNNs, deep FNNs can be represented concisely using matrices: y = g 1 ( b yh q ) € h ( q ) + b yh q 0 2 + Á, (33) h ( ¸ ) = f ( ¸ ) ( B h ¸ h ¸ ≠ 1 h ( ¸ ≠ 1) + b h ¸ h ¸ ≠ 1 0 ) , ¸ = 2 , . . . , q, (33a) h (1) = f ( B h 1 x x + b h 1 x 0 ) , (33b) where x is the p ◊ 1 vector of predictors, B h 1 x is the p 1 ◊ p weight matrix from the predictors to the ﬁrst hidden layer, b h 1 x 0 is the p 1 ◊ 1 intercept vector from the predictors to the ﬁrst hidden layer, h ( ¸ ) is the p ¸ ◊ 1 hidden layer representation at layer ¸ , B h ¸ h ¸ ≠ 1 is the p ¸ ◊ p ¸ ≠ 1 weight matrix from hidden layer ¸ ≠ 1 to hidden layer ¸ , b h ¸ h ¸ ≠ 1 0 is the p ¸ ◊ 1 \nintercept vector from hidden layer ¸ ≠ 1 to hidden layer ¸ , b yh q is the p q ◊ 1 weight vector from the ﬁnal hidden layer to the outcome, and b yh q 0 is the intercept from the ﬁnal hidden layer to the outcome. We visualize the deep FNN in Figure 6. Notice that intercept terms are omitted from the schematic and that layer-wise summation and applying an activation function are represented using a single arrow. ANNs are typically represented this way in the deep learning literature. It is also common to omit intercept terms in path diagrams for structural equation models (Bollen, 1989). It is not always clear when to use deep FNNs instead of single-layer FNNs in practice. In theory, both single-layer and deep FNNs can model very complicated relationships between the input and output variables. This is stated formally in the universal approximation theorem , which holds that both single-layer and deep FNNs are capable of approximating a wide variety of continuous functions, given some mild assumptions 3 about the hidden layer activation functions (e.g., Csáji, 2001). This capability may be useful for problems in psychology, where the true functional relationship f between the input x and the output y may be very complicated. In practice, however, single-layer FNNs may require a huge numbers of hidden layer nodes to learn the true f . Deep FNNs with many hidden layers may need fewer nodes at each layer to learn the true f and may therefore take less time to train than single-layer FNNs (Goodfellow et al., 2016). We recommend treating the number of hidden layers as a hyperparameter: Start with one hidden layer, then increase the number of hidden layers a few times and check whether predictive accuracy improves on a validation set. 3 There are a several proofs of the universal approximation theorem for both single-layer and deep FNNs. Most of these proofs assume that the hidden layer activation functions are non-constant (i.e., they are not always equal to a single, constant value), bounded (i.e., they don’t shoot oﬀto positive or negative inﬁnity), and continuous (i.e., their graphs do not have any gaps). More recent proofs (e.g., Lu et al., 2017; Sonoda & Murata, 2017) do not require the activation functions to be bounded. \nRecurrent Neural Networks Recurrent neural networks (RNNs) are specialized ANNs for processing sequential data where the order of the observations is meaningful. Like FNNs, RNNs can be used for regression or classiﬁcation. Although RNNs are outperformed by CNNs and more modern ANNs in some practical settings, this section illustrates fundamental concepts that are applicable to a broad range of ANN approaches to modeling sequential data. Before discussing RNNs, we discuss how to describe a data set where each observation is a sequence . A sequence of length T is an ordered set of T observations of p diﬀerent variables. Data sets, which we denote as X , typically contain many sequences. For example, daily diary data sets typically include N diﬀerent individuals, each of whom is asked p questions each day for T i days, i = 1 , . . . , N . Note that the lengths of the sequences in our data set may be diﬀerent for each individual, but the number of variables is the same for all individuals. We write length T i sequences as x (1) i , x (2) i , . . . , x ( T i ) i , where x ( t ) i is the p ◊ 1 vector of predictor values observed for individual i at time point t . In practical applications of RNNs, it is common to ﬁrst ensure that all sequences are the same length (e.g., by appending vectors of zeros to short sequences), say length T , then to collect each individual’s sequences into a T ◊ p matrix X i . Our data set may then be thought of as a collection of N T ◊ p matrices or, equivalently, as an N ◊ T ◊ p array called a tensor . Tensors, which are multidimensional arrays that generalize matrices to higher-dimensions, are an important concept because deep learning software typically requires data to be input in tensor form. Tensors are brieﬂy discussed and visualized in the Convolutional Neural Networks section. We can now formulate the simple RNN model. As before, we drop all i subscripts when specifying models. Consider an input sequence x (1) , x (2) , . . . , x ( T ) and a corresponding output sequence y (1) , y (2) , . . . , y ( T ) . At each time point t , the simple RNN aims to produce a p 1 ◊ 1 hidden layer representation h ( t ) of the p ◊ 1 input vector x ( t ) that can then be used to predict the outcome y ( t ) . Each hidden layer should also utilize \ninformation from the previous time step when making predictions. Intuitively, the simple RNN is just a single-layer FNN with loops carrying information forward through time. The simple RNN models the current outcome node as a function of the current predictor nodes as well as the previous hidden layer nodes: y ( t ) = g ( b yh 0 + p 1 ÿ k =1 b yh k h ( t ) k ) + Á ( t ) , t = 1 , . . . , T, (34) h ( t ) k = f ( b hx k, 0 + p ÿ j =1 b hx k,j x ( t ) j + p 1 ÿ k =1 b hh k h ( t ≠ 1) k ) , k = 1 , . . . , p 1 , t = 1 , . . . , T, (34a) where “hh” superscripts indicate recurrent weight parameters connecting hidden layer nodes at subsequent time steps, Á ( t ) is the error at time point t , and the initial hidden layer nodes h (0) k are all deﬁned to be 0. Equations 34 and 34a are called update equations because they describe how to update the hidden state h ( t ) and the predicted output y ( t ) at each time point t given the current input x ( t ) and the previous hidden state h ( t ≠ 1) . Any mathematical equation that starts with initial values and deﬁnes all future values as functions of previous values is called a recurrence relation . Recurrent neural networks are called “recurrent” because their update equations are a recurrence relation. Notice that the model re-uses the same weight parameters at each time step. Re-using weight parameters this way is called parameter sharing and allows RNNs to be trained with and applied to sequences of varying lengths. The simple RNN update equations may be written concisely with matrices: y ( t ) = g 1 ( b yh ) € h ( t ) + b yh 0 2 + Á ( t ) , t = 1 , . . . , T, (35) h ( t ) = f ( B hx x ( t ) + B hh h ( t ≠ 1) + b hx 0 ) , t = 1 , . . . , T, (35a) where h ( t ) is the p 1 ◊ 1 hidden layer vector at time point t , B hx is the p 1 ◊ p matrix of weight parameters to the hidden layer nodes from the input nodes, b hx 0 is a p 1 ◊ 1 intercept vector applied to the hidden layer nodes, B hh is an p 1 ◊ p 1 matrix of recurrent weight \nparameters, b yh is an p 1 ◊ 1 vector of weight parameters to the output node from the hidden layer nodes, b yh 0 is an intercept to the output nodes from the hidden layer nodes, and the initial hidden state nodes h (0) are deﬁned to be 0 (a p 1 ◊ 1 vector of zeros). Just like equations 34 and 34a, equations 35 and 35a are a recurrence relation – that is, all output values are functions of previous values. To better understand the simple RNN, it is helpful to write the network in equation form without using recurrence. This is called unfolding the network. The simple RNN is unfolded as y (1) = g (( b yh ) € f ( B hx x (1) + b hx 0 ) + b yh 0 ) + Á (1) , y (2) = g 3 ( b yh ) € f 1 B hx x (2) + B hh f ( B hx x (1) + b hx 0 ) + b hx 0 2 + b yh 0 4 + Á (2) , ... y ( T ) = g A ( b yh ) € f 3 B hx x ( T ) + . . . + B hh f 1 B hx x (2) + B hh f ( B hx x (1) + b hx 0 ) + b hx 0 2 . . . 4 + b yh 0 B + Á ( T ) . (36) Equations 35 are simply equation 35a substituted into equation 35 and written down explicitly for all time steps. Schematic representations of equations 35, 35a, and 36 are presented in Figure 7. The schematic on the left hand side of Figure 7 represents equations 35 and 35a as a single-layer FNN with a loop passing information from one time step to the next. The schematic on the right hand side of Figure 7 represents the unfolded simple RNN in equations 36 as T single-layer FNNs chained together. Both schematics are equivalent representations of the same simple RNN. In general, the input and output sequence need not have the same length. If our input sequence has length one (i.e., x (1) ) and our output sequence has length T (e.g., y (1) , y (2) , . . . , y ( T ) ), our RNN has a one-to-many architecture (Figure 8a). An ANN’s architecture refers to the number of nodes in the network and the ways that these nodes are connected (i.e., which nodes are connected as well as which weight structures and \nactivation functions are used; Goodfellow et al., 2016). To understand when we might use an RNN with a one-to-many architecture, consider a daily diary study in which we collect information about each individual’s moods and experiences once per day for several months. If we wish to use an individual’s mood and experiences on a given day to predict their mood each day for the next three days, we would use a one-to-many architecture. If our input sequence has length T (i.e., x (1) , x (2) , . . . , x ( T ) ) and our output sequence has length one (i.e., y (1) ), our recurrent neural network has a many-to-one architecture (Figure 8b). If we wish to predict whether or not an individual will experience a depressive episode on a particular day using their past week of moods and experiences, we would use a many-to-one architecture. Finally, if both have length greater than one, our RNN has a many-to-many architecture (Figure 8c). If we wish to predict an individual’s moods for the next three days using their past week of moods and experiences, we would use a many-to-many architecture. RNNs are appealing in theory because they use information from the past to predict future output values. In practice, however, simple RNNs struggle to use information from very far in the past (Bengio et al., 1994; Doya, 1993; Hochreiter, 1991; Pascanu et al., 2013). This may not be a problem if we only expect recent information to inﬂuence the current output value. For example, imagine collecting information about individuals’ moods and experiences twice per day. We might expect a person’s mood early in the day to strongly inﬂuence their mood later in the day, but might expect their mood yesterday or earlier to only weakly inﬂuence their nighttime mood. A simple RNN might be well-suited to to modeling this scenario. However, if an individual experienced an extremely negative life event one month ago that we expect to strongly impact their current mood, a simple RNN might struggle to use information from so far in the past to predict a current output value. To overcome this problem with simple RNNs, specialized models called gated recurrent neural networks were designed to learn long-term dependencies. Gated RNNs have been eﬀective for some sequence modeling problems including speech recognition, \nmachine translation, and image captioning (Goodfellow et al., 2016). Lipton et al. (2015) provide an accessible overview of gated RNNs that have demonstrated good performance in several practical applications. By now, some readers may have noticed that RNNs are quite similar to classical time series approaches such as dynamic factor analysis (DFA; e.g., Lütkepohl, 2005; Molenaar, 1985) that model the relationships between latent variables over time. For example, DFA models relations among latent variables at the current time as a function of the latent variables at previous, or lagged , time steps. In a conceptually similar manner, RNNs update their hidden layer values at the current time point using hidden layer values from the previous time point and may even explicitly include higher-order lagged relations between the hidden layers (e.g., relations between h ( t ≠ 2) and h ( t ) and so on). Although they are similar, RNNs and classical approaches like DFA diﬀer in several ways. In particular, RNN-based approaches improve on classical time series approaches in that they automatically account for nonlinear relationships between variables, they do not require conducting data reduction using latent variables, they do not require all individuals to have variability on each variable, and they do not require researchers to pre-screen the data for multicollinearity. We note, however, that the beneﬁts of RNNs come at the cost of model interpretability. In the previous section, we discussed how making FNNs deeper by adding more hidden layers often leads to increased predictive accuracy. Building deep RNNs is less straightforward than building deep FNNs because there are multiple ways to add more hidden layers. In particular, hidden layers can be added to RNNs in three ways: (1) Between the input nodes and the hidden layer nodes at each time point, (2) between hidden layer nodes at subsequent time points, and (3) between the hidden layer nodes and the output nodes at each time point. Each kind of deep RNN may be more or less suited for diﬀerent kinds of data sets (Pascanu et al., 2014). Determining which kind of deep RNN is best suited for a particular data set is often a matter of experimentation. \nRNN toy example: Forecasting risk of suicidal ideation using daily diary data. We now present a toy example demonstrating the possible application of RNNs to daily diary data. Imagine that we collect one week of daily diary data for a clinical sample of 1 , 000 individuals who are at risk for suicidal ideation (SI; i.e., thinking about or considering suicide; Klonsky et al., 2016). Every day, our individuals receive two cell phone notiﬁcations. The ﬁrst notiﬁcation arrives in the morning and asks each respondent to rate their current mood using a ﬁve-category scale ranging from “Extremely good” (1) to “Extremely bad” (5). The second notiﬁcation arrives at night and asks individuals to rate their mood using the same ﬁve-category scale as well as to indicate whether or not they thought about committing suicide at any time during the day (“Yes” = 1, “No” = 0). Our goal is to determine whether previous days’ moods and SI can be used to forecast whether or not respondents will engage in SI on day seven. We model this problem using a many-to-one RNN wherein respondents’ moods and SI on days one through six are the inputs (i.e., x ( t ) for t = 1 , . . . , 6) and SI on day seven is the output (i.e., ˆ y (7) ). Figure 9 steps through how computation proceeds in our RNN approach to forecasting SI. The key idea underlying these computations is that the RNN’s hidden state evolves over time based on current and lagged information. At each time step, say time step t , we start with a vector of daily diary responses x ( t ) as well as a hidden state from the previous day h ( t ≠ 1) . To compute the current hidden state h ( t ) , we ﬁrst multiply the current responses x ( t ) by the input weight matrix B hx and multiply the lagged hidden state h ( t ≠ 1) by the recurrent weight matrix B hh . After adding the resulting vectors together, we add a vector of intercepts b hx 0 and apply a ReLU activation function f to produce the current hidden state h ( t ) . At the ﬁnal time step (i.e., t = 6), we use only the ﬁnal hidden state h (6) to predict whether or not the individual will engage in SI on day seven. Notice that the hidden state is updated using the same parameters at each time step – that is, RNN parameters are time-invariant . Computing model updates this way is similar to the approach used in vector autoregression (VAR; Lütkepohl, 2005), a classical time series \napproach to modeling the relationships between observed variables over time. 4 Due to the close relationship between RNNs and classical time series approaches such as VAR, we used R to simulate data from an ordinal VAR model of lag order six, which is essentially an ordinal regression model (McCullagh, 1980) in which the observed variables at the current time step are regressed on the observed variables at the previous six time points. Creal et al. (2013) provide a full description of generalized autoregressive score (GAS) models, of which our ordinal VAR model is a special case where the observed variables at the current time point are multinomially distributed conditional on the previous time point. Our model included three ordinal variables: Morning mood , which had 5 response categories ranging from 1 to 5; nighttime mood , which had 5 categories response categories ranging from 1 to 5; and suicidal ideation (SI), which had 2 response categories of either 0 or 1. To sample sequences from this model, we needed to specify six autoregressive (AR) weight matrices describing the relationships between current and past observed variable values as well as three vectors of strictly ordered category intercepts (i.e., one intercept vector per variable; these are equivalent to the threshold parameters used in ordinal regression). We set the ﬁrst-order AR (i.e., AR(1)) weight matrix to the values given in Table 2. We chose response category 1 (i.e., “Extremely good” mood) as the reference category for morning and nighttime mood and response category 1 (engaging in SI) as the SI reference category. We therefore only needed to specify AR weights for the 9 possible non-reference categories. Choosing the values in Table 2 ensured being in a very bad mood either in the morning or at night was highly predictive of SI and that the eﬀects of previous days’ moods on individuals’ current moods tended to diminish with increasing time. More speciﬁcally, the chosen values were motivated as follows: (1) Having a good morning mood 4 Readers familiar with VAR may notice that the recurrent weight matrix B hh closely corresponds to the time-invariant weight matrix used in a VAR model of order one. The diﬀerence between these approaches is that the RNN recurrent weight matrix is used to update an unobserved hidden state, whereas the VAR weight matrix is used to predict observed variable values at each time step. \nor nighttime mood (response categories 2 or 3) on the previous day should not aﬀect the chances of having a good morning or nighttime mood or engaging in SI on the next day relative to the reference category (zero coeﬃcients on lag 1 morning and nighttime good moods); (2) having a bad morning mood or nighttime mood (response categories 4 or 5) or engaging in SI on the previous day should decrease the chances of having a good morning or nighttime mood on the next day and increase the chances of engaging in SI on the next day (positive coeﬃcients on lag 1 morning and nighttime bad moods and SI). We constructed higher-order AR weight matrices by multiplying the AR(1) weight matrix parameters by the following constants: 0 . 5 for AR(2), 0 . 4 for AR(3), 0 . 3 for AR(4), 0 . 2 for AR(5), and 0 . 1 for AR(6). Constructing AR weight matrices this way was motivated by the idea that observations from more distant time points should have less inﬂuence on the current observations than more recent observations. Intercept parameters for both morning and nighttime moods were set to ≠ 0 . 8, ≠ 0 . 2, 0 . 2, and 0 . 8, corresponding to the thresholds between response categories 1 and 2, 2 and 3, 3 and 4, and 4 and 5, respectively. The intercept parameter for SI was set to 0 . 5 so that individuals from our clinical sample would be predisposed to engaging in SI. After specifying our data generating model parameters, we sampled a data set of 1 , 000 sequences of length six, discarding the ﬁrst 100 observations from each sampling run for burn-in. Approximately 21 percent of simulated individuals engaged in SI on day seven (i.e., had y (7) = 1). We then used the R interface to Keras to ﬁt a gated RNN model called a long short-term memory neural network (LSTM; Hochreiter & Schmidhuber, 1997) using 700 simulated sequences, which we evaluated using the remaining 300 sequences. A complete explanation of LSTMs is beyond the scope of this primer but is available in Lipton et al. (2015). We constructed our LSTM as follows: rnn = keras_model_sequential () rnn %>% \nlayer_lstm(units = 32, activation = 'relu ', input_shape = c (6, 9)) %>% layer_dense (units = 32, activation = 'relu ') %>% layer_dropout (rate = 0.5) %>% layer_dense (units = 1, activation = 'sigmoid ') layer_lstm () adds an LSTM hidden layer with 32 hidden units and a ReLU activation funtion to our model. Our input consists of sequences of length six where each observation in the sequence is a nine-dimenional vector of dummy variables, so we set input_shape = c (6, 9) . We next add a single FNN layer to our LSTM, then apply a regularization technique called dropout using layer_dropout () (Srivastava et al., 2014). We complete the model speciﬁcation with a single output node with a sigmoid activation function. We used the same model ﬁtting parameters that were used for our single-layer FNN toy example: rnn %>% compile ( loss = 'binary_crossentropy ', optimizer = optimizer_adam (), metrics = c ('accuracy ') ) Speciﬁcally, we specify the binary cross-entropy objective function, the Adam optimizer, and the accuracy metric for assessing performance. Finally, we ﬁtted and evaluated the model as follows: history = rnn %>% fit ( train_data$X, as.matrix (train_data$y), epochs = 300, batch_size = 64 ) rnn %>% evaluate (test_data$X, as.matrix (test_data$y)) \nThe ﬁrst input to fit () is a 700 ◊ 6 ◊ 9 tensor of training set sequences and the second input is a vector of outcome values. We ﬁt the model for 300 epochs (i.e., passes through the full data set; see Single-layer FNN toy example: Predicting alcohol use disorder using cross-sectional survey data ) and randomly sample 64 sequences for each ﬁtting iteration. Finally, we tested our LSTM on a test set of 30 percent of observations. We also calculated sensitivity and speciﬁcity using the R package caret (Kuhn, 2008). Code for the full example is available as online supplementary material. Our ﬁtted LSTM achieved fair performance on the simulated data with relatively little hyperparameter tuning (accuracy = 0 . 80, sensitivity = 0 . 30, speciﬁcity = 0 . 87). We suspect that our LSTM struggled to model the low-order autoregressive eﬀects underlying the data as described in Gers et al. (2001). Brieﬂy, Gers et al. (2001) note that while classical time series models such as VAR explicitly specify lagged eﬀects, typical RNN implementations rarely specify lagged eﬀects and instead require lagged information to be stored in the model’s hidden layer. It may be challenging for RNNs without lagged eﬀects to “learn” when to store and when to overwrite lagged information, although we suspect this problem could be alleviated by greatly increasing the size of the RNN hidden layer or by ﬁtting the RNN for many epochs using adequate regularization. If we wished to obtain better performance on our simulated data using an alternative ANN approach, we could likely instead use a CNN because CNNs are inherently well suited to leverage eﬀects that are close together in time to obtain high predictive accuracy. We now turn to these models. Convolutional Neural Networks Just like RNNs are specialized for processing sequential data, convolutional neural networks (CNNs) are specialized for processing image data. In both cases, the ordering of the data matters. Just like FNNs and RNNs, CNNs can be used for regression or classiﬁcation. CNNs process images very eﬃciently by assuming that local information is important in each observation. With images, this assumption is almost always reasonable. \nFor example, consider the image in Figure 1. Imagine that a small, square-shaped patch of pixels is randomly selected from this image. We could look at this patch and state whether or not it contains the edge of an object without needing to look at any other parts of the image – that is, only local information is important for identifying edges of objects. This is how CNNs work: They break up images into overlapping, squared-shaped patches of pixels, then summarize the information contained in each patch. Deep CNNs perform this summarization step at each layer, building more and more abstract concepts (e.g., types of objects like faces or shirts) by summarizing less abstract concepts (e.g., edges of objects). We only discuss single-layer CNNs in this primer, although extending single-layer CNNs to deep CNNs is straightforward and is brieﬂy described at the end of this section. It is helpful to think about single-layer CNNs as specialized single-layer FNNs. Recall that single-layer FNNs aim to produce a hidden layer representation h from each input observation x that can subsequently be used to predict the corresponding output observation y . Equation 13a describes how to produce h in a single-layer FNN: Multiply x by a weight matrix B hx , add an intercept vector b hx , then apply an element-wise activation function f . Single-layer CNNs also aim to produce a hidden layer representation of each input image that can then be used to predict the corresponding output observation. However, single-layer CNNs replace multiplying the input image by a weight matrix B hx with an operation called two-dimensional discrete convolution . Intuitively, two-dimensional discrete convolution breaks up the input image into overlapping square-shaped patches, then summarizes the information contained in each patch using a single number. We describe this process with equations in the following paragraphs. Before explaining the single-layer CNN, we explain our notation for describing image data sets. In this primer, we focus on data sets containing N diﬀerent grayscale (i.e., “black-and-white”) images. Such data sets may contain fascinating psychological insights (e.g., see CNN toy example: Predicting emotions from facial expressions ). In digital form, all grayscale images are two-dimensional arrays made up of colored squares \ncalled pixels where each pixel’s color is determined by a number. We can therefore think of a grayscale image as a matrix of numbers where the ( j, k ) th number describes the color of the ( j, k ) th pixel in the image. Since each observation is a matrix, our data set is no longer a single matrix as in linear regression – rather, it is a collection of matrices. If each image in our data set is the same shape, say r x ◊ c x , we can think of our data set as an N ◊ r x ◊ c x tensor X where X i is a matrix representing the i th image in the data set and x i,j,k is a number representing the color of the ( j, k ) th pixel in this image. In Figure 10, we visualize a tensor data set containing four diﬀerent randomly generated 4 ◊ 4 grayscale images. We will also imagine that our data set includes an outcome value y i associated with image i for all i = 1 , . . . , N . As usual, we drop all i subscripts from equations – for example, we write X i as X and y i as y . The single-layer CNN aims to produce a hidden layer representation H of the input image X that can then be used to predict y . To produce H , the single-layer CNN ﬁrst applies two-dimensional discrete convolution to X to produce an intermediate representation S . This is written in equation form as s j,k = ( X ú B hx )( j, k ) = j ≠ r b ÿ m = j ≠ 1 k ≠ c b ÿ n = k ≠ 1 x m,n b hx j ≠ m,k ≠ n , j = 1 , . . . , r x + r b ≠ 1 , k = 1 , . . . , c x + c b ≠ 1 , (37) where ú is called the convolution operator , X is the r x ◊ c x input image, B hx is an r b ◊ c b weight matrix called the kernel , and s j,k are elements of the ( r x + r b ≠ 1) ◊ ( c x + c b ≠ 1) matrix S called the convolution of X and B hx . Equation 37 looks complicated but is fairly intuitive to understand. “ X ú B hx ” is read as “ X convolved with B hx ”. Convolving the input image X with the kernel (i.e., weight matrix) B hx produces a new matrix S , much like multiplying two matrices produces a new matrix. The kernel B hx is just a small weight matrix that “slides” around on the input image. As it “slides”, it performs element-wise multiplication with the patch of image it is currently on, then sums the result into a single \noutput value. This “sliding” process is how single-layer CNNs use two-dimensional discrete convolution to summarize information from small, overlapping patches on the input image. We visualize two-dimensional discrete convolution with a 4 ◊ 4 image and a 2 ◊ 2 kernel in Figure 11. Note that our ﬁgure only visualizes the output values s j,k where the kernel ﬁts completely inside the image, called the valid convolution . We previously mentioned that single-layer CNNs replace multiplying the input image X by a weight matrix B hx with convolving X and B hx . However, after performing convolution, single-layer CNNs do exactly what single-layer FNNs do to produce the hidden layer representation H : They add an intercept to each s j,k , then apply an activation function f : h j,k = f ( b hx j,k, 0 + s j,k ) , j = 1 , . . . , r x + r b ≠ 1 , k = 1 , . . . , c x + c b ≠ 1 , (38) where h j,k are elements of the resulting ( r x + r k ≠ 1) ◊ ( c x + c k ≠ 1) hidden layer representation H . As with single-layer FNNs, choosing a nonlinear activation function helps single-layer CNNs model outcomes y that vary nonlinearly with the input images X . We can now use the hidden layer H to predict the outcome y . Just like the single-layer FNN, the single-layer CNN models the outcome as a weighted sum of the hidden layer nodes, then applies a ﬁnal activation function g : y = g 1 b yh 0 + r h c h ÿ j =1 b yh j h j 2 + Á, (39) h = vec( H ) , (39a) where vec, the vectorization operation, converts the r h ◊ c h hidden layer H into an r h c h ◊ 1 vector h , 5 h j are elements of h , and Á is a random error term. As with FNNs, choosing the activation function g determines whether the single-layer CNN will perform regression or 5 The vectorization operation stacks the columns of H on top of each other. That is, vec( H ) = h = [ h 1 , 1 , . . . , h r h , 1 , h 1 , 1 , . . . , h r h , 2 , . . . , h 1 ,c h , . . . , h r h ,c h ] € . Vectorizing H just makes it easier to sum over all of its elements. \nclassiﬁcation. Deep CNNs have revolutionized predictive modeling using image data as well as video, speech, and audio data (LeCun et al., 2015). Basic deep CNNs can be constructed from single-layer CNNs just like deep FNNs can be constructed from single-layer FNNs: Simply add many hidden layers, each feeding in to the next. Additionally, modifying CNNs to process non-image data is straightforward. However, the most successful deep CNNs used in practical applications can be very complicated (e.g., Krizhevsky et al., 2012). Goodfellow et al. (2016) describe some modiﬁcations that may improve CNN predictive accuracy as well as tips for building CNNs in practice. Identifying important parts of images with two-dimensional discrete convolution. We now concretely demonstrate how the convolution operation may identify important components of images. Figure 12 presents a 3 ◊ 3 kernel B hx that is often used for identifying vertical edges in images. Directly under the kernel, we show the result of applying this kernel to a grayscale image of a face. Notice that in the convolution of the original image and the kernel, vertical edges are visible as white or light gray lines while the rest of the image is dark. At the bottom of Figure 12, we show the result of convolving the kernel with two adjacent 3 ◊ 3 patches of the original image. In the ﬁrst patch, we can tell that there is a vertical edge between the second and third columns: The ﬁrst column is dark and has small pixel values, while the second column is light and has large pixel values. When we convolve this patch with the kernel, the large pixel values in the ﬁrst column cause the result to equal to one so that the resulting pixel is essentially black. Note that since grayscale pixel values only range from zero to 255, negative values produced by computing the convolution are treated as zeros and the resulting pixels are set to black. In the adjacent patch, the vertical edge is now between the ﬁrst and second columns. The large pixel values in the second column cause the convolution to be a large positive value so the resulting pixel is set to a light gray. Placing the light resulting pixel next to \nthe dark resulting pixel in the convolution of the original image shows us that there was a vertical edge in this patch of the original image. We note that in practice, ﬁtting CNNs will likely result in diﬀerent ﬁtted kernels than the one presented in Figure 12. Other kernels can identify diﬀerent kinds of edges (e.g., horizontal or diagonal edges) or even other, less human-interpretable components of images. CNN toy example: Predicting emotions from facial expressions. We now provide a toy example to clarify the application of CNNs to psychological data. The data set used in this example is publicly available on Kaggle, an online community for data scientists and machine learning practitioners (https://www.kaggle.com/shawon10/ckplus). It is a small subset of the Extended Cohn-Kanade data set for facial expression recognition (Kanade et al., 2000; Lucey et al., 2010) and may be similar in size to data sets typically collected by psychologists. As with our FNN example, this example seeks to classify observations into discrete categories. Our data set contains 327 r x ◊ c x = 48 ◊ 48 grayscale images of faces. Each face is labeled with one of the following emotions: Anger (45 observations), contempt (18 observations), disgust (59 observations), fear (25 observations), happy (69 observations), sad (28 observations), or surprise (83 observations). Each image is duplicated three times in the data set for a total of 981 images used for ﬁtting purposes. Our goal is to use a CNN to predict which emotion a face is showing. We might build a model like this to answer any of a variety of psychological research questions. One simple use of such a classiﬁcation model might be to categorize individuals’ reactions to speciﬁc stimuli without having to ask them for self-report responses, which poses a potential cognitive burden on an emotional task. Figure 13 walks through the process of modeling a single image from our data set using a single-layer CNN. We ﬁrst select an image X from the tensor data set X . We then convolve our chosen image with a small kernel weight matrix B hx to get a new matrix S (i.e., the convolution). In the ﬁgure, we choose the kernel to be the same r b ◊ r b = 3 ◊ 3 \nkernel used in Figure 12 to detect vertical edges in images. We note that S is typically smaller than the original image X . In Figure 13, we force the kernel to stay inside of the input image (i.e., we only compute the valid convolution) so that S has size 46 ◊ 46. Once we have the convolution S , we can compute the hidden layer representation H of the input image by adding an intercept to each element of S and applying a ReLU activation function. In the ﬁgure, we set all intercepts to a large value (i.e., b hx j,k, 0 = 30 for j, k = 1 , . . . , 48) and applied the ReLU function to demonstrate the impact of this processing step. The resulting image H is a modiﬁed version of the convolution S in which only the most salient vertical edges are now visible. Identifying salient vertical edges as shown might be useful for our toy CNN, which could, for example, utilize the lines representing the individual’s teeth to predict that they are happy. Notice that H is still square-shaped. In order to predict our emotion outcome, we ﬁrst ﬂatten H into a vector h . We then multiply h by a weight vector, add an intercept, and apply a softmax activation function (equation 12). The softmax function lets our model output seven probabilities, one corresponding to each possible emotion the face could be showing. The highest predicted probability corresponds to the emotion that the CNN most strongly believes the face is showing. In practice, CNNs often require many convolutional layers composed together to obtain high predictive accuracy. Although complete descriptions of state-of-the-art CNN techniques are beyond the scope of this primer, we demonstrate the feasibility of this type of analysis by ﬁtting a deep CNN to our facial emotion data set using the R interface to Keras. Complete descriptions of the techniques used below are beyond the scope of this primer but are available in Goodfellow et al. (2016). As with our other ANN models, we constructed our deep CNN one layer at a time: cnn = keras_model_sequential () cnn %>% layer_conv_2d (filters = 6, kernel_size = c (5, 5), input_shape = c (48, 48, 1), \npadding = 'same ', activation = 'relu ') %>% layer_max_pooling_2d (pool_size = c (2, 2)) %>% layer_conv_2d (filters = 16, kernel_size = c (5, 5), padding = 'same ', activation = 'relu ') %>% layer_max_pooling_2d (pool_size = c (2, 2)) %>% layer_conv_2d (filters = 64, kernel_size = c (3, 3), padding = 'same ', activation = 'relu ') %>% layer_max_pooling_2d (pool_size = c (2, 2)) %>% layer_flatten () %>% layer_dense (units = 128, activation = 'relu ') %>% layer_dropout (rate = 0.5) %>% layer_dense (units = 7, activation = 'softmax ') layer_conv_2d () performs two-dimensional discrete convolution, adds intercepts, and applies an activation function to its input. Our input consists of 48 ◊ 48 grayscale images, so we set input_shape = c (48, 48, 1) . The ﬁnal value of 1 tells the model that we are working with grayscale images; if we had colored images, we would set this value to 3 . We choose a 5 ◊ 5 kernel by setting kernel_size = c (5, 5) and choose a ReLU activation function. Setting padding = 'same ' applies a full convolution (i.e., equation 37) instead of the valid convolution described previously. By setting filters = 6 , we choose to ﬁt six diﬀerent kernels rather than a single kernel. Each ﬁtted kernel may learn to identify diﬀerent components of the input images, such as diﬀerent kinds of edges or lines. This corresponds to including six nodes in the hidden layer of a single-layer FNN. We applied a max pooling layer after our convolutional layer using layer_max_pooling_2d () . Max pooling layers are used in CNNs to condense information as it passes through the model. Choosing pool_size = c (2, 2) decreases both the height and width of the convolved image by a factor two. Goodfellow et al. (2016) provide a full \ndescription of max pooling. After applying two more convolutional and max pooling layers in succession, we ﬂatten our convolved images into a vector using layer_flatten () . We apply a single-layer FNN to the ﬂattened vector using layer_dense () , then apply the dropout regularization technique using layer_dropout () (Srivastava et al., 2014). The ﬁnal layer_dense () outputs of vector of seven probabilities (i.e., one probability for each possible emotion) using the softmax activation function (equation 12). Next, we speciﬁed parameters for model ﬁtting: cnn %>% compile ( loss = 'categorical_crossentropy ', optimizer = optimizer_adam (), metrics = c ('accuracy ') ) This speciﬁcation is similar to the one given for our single-layer FNN and RNN toy examples. However, we now set loss = 'categorical_crossentropy ' , which extends the binary cross-entropy objective function to outcomes with more than two categories. More formally, the categorical cross-entropy is the log-likelihood of an outcome that follows a multinomial distribution with number of cells equal to the number of outcome categories, cell probabilities predicted by the ﬁtted model, and trial size one. It is the same objective function used for ﬁtting ordinal regression models (Kutner et al., 2004). We ﬁtted and tested the model: history = cnn %>% fit ( train_data$X, as.matrix (train_data$y), epochs = 50, batch_size = 7 ) cnn %>% evaluate (test_data$X, as.matrix (test_data$y)) \nThe ﬁrst input to fit () is a 683 ◊ 48 ◊ 48 ◊ 1 tensor of training set images and the second input is an outcome vector. We ﬁtted the model for 50 epochs and randomly sampled 7 images for each ﬁtting iteration. Finally, we evaluated our deep CNN on a test set of 30 percent of observations. We include a full R script for our analysis as online supplemental material. Our ﬁtted model obtained a predictive accuracy of 0 . 84 on a test set of 30 percent of observations, suggesting that our images of faces contain objective information that can be used to predict their emotional content. We could possibly increase our model’s predictive accuracy even further either by collecting more data (which could be expensive) or by ﬁtting our model to one of many publicly available large facial expression data sets (e.g., facial expression databases can be found at https://web.archive.org/web/20180325205102/http://emotion-research.net/wiki/Databases or https://www.ecse.rpi.edu/~cvrl/database/other_facial_expression.htm) then reﬁning the ﬁtted parameters on our smaller data set using a transfer learning approach. Discussion and Future Directions Deep learning is a successful machine learning paradigm that has revolutionized the psychology-related ﬁelds of computer vision and natural language processing. Psychologists will likely ﬁnd that state-of-the-art deep learning algorithms outperform other machine learning algorithms such as random forests (RFs) and support vector machines (SVMs) when used to predict outcomes of interest in very large data sets with many weakly correlated variables or with sequence (e.g., text, video) or image observations. Although such data sets are not common in mainstream psychological research, they are readily available through web-based and clinical sources. Additionally, psychologists with many other kinds of data sets may also beneﬁt from deep learning: Researchers who utilize transfer learning may reap the beneﬁts of deep learning using small data sets; survey researchers may need to spend less time developing measures when using deep learning to \npredict outcomes of interest; and researchers with hierarchically structured data (e.g., educational or clinical psychologists) may boost predictive accuracy using multitask deep learning approaches. As described in the introduction, computer scientists have already achieved promising results using deep learning to predict interesting psychological outcomes. In many cases, deep learning models outperformed other machine learning models such as RFs and SVMs, which suggests that the true causal structure underlying these data sets consisted of weakly correlated interactions between large numbers of variables. We anticipate that combining many data types including survey, computer and smartphone log, social media, image and video, biometric (e.g., wearable sensor, fMRI), genomic, and Gloabl Positioning System (GPS) data will produce large data sets that deep learning models can utilize to accurately predict important psychological outcomes. We are particularly excited by the potential of deep multitask and sequence modeling approaches, which may lead to the development of personalized models for accurately detecting risk (e.g., for suicidal ideation) at the individual level in real time. In this primer, we introduced the feedforward neural network (FNN), the recurrent neural network (RNN), and the convolutional neural network (CNN) as generalizations of linear regression. These models (or modiﬁcations of these models) are fundamental building blocks of advanced artiﬁcial neural networks used in large-scale scientiﬁc and industrial applications. We did not describe these state-of-the-art model architectures because deep learning research is progressing too quickly for such descriptions to be practically useful for long. Rather, we aimed to help psychologists gain some ﬂuency in machine learning and deep learning basics. We hope that this ﬂuency will be a ﬁrst step toward enabling psychologists to draw from the machine learning literature in the same way that they have historically drawn from the statistics literature. In future work, we will further discuss how to build deep learning models and will provide software implementations to help psychologists utilize deep learning to answer prediction-focused research questions. \nOn a ﬁnal note, we wish to emphasize that machine learning and deep learning are not panaceas. In causal modeling, the randomized controlled trial is still a powerful experimental design for understanding the causal mechanisms that give rise to psychological phenomena (e.g., Lilienfeld et al., 2018). In predictive modeling, artiﬁcial neural networks may give worse results than simpler models like linear regression in data sets with large, linear associations between a few variables. Deep learning models that “automatically” learn complicated relationships between independent and dependent variables are not a license for psychologists to feed their data into an algorithm and hope for the best. Rather, valid psychological research requires attention to the same things it always has: Identifying which research hypotheses might be interesting and useful to investigate; translating abstract theoretical constructs into meaningful observable measurements; designing studies and collecting data sets ethically; choosing appropriate classical or modern statistical modeling techniques; and many more. Machine learning and deep learning combined with excellent research practices represent a key step toward helping psychologists accurately and reliably predict human behaviors, cognitions, and emotions."
}