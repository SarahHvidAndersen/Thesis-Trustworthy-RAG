{
    "document_type": "online_article",
    "title": "Forecasting: Principles and Practice (3rd ed)",
    "author": "Rob J Hyndman, George Athanasopoulos",
    "source": "https://otexts.com/fpp3/AR.html",
    "date_published": "23 March 2025",
    "flag": "",
    "text": "In a multiple regression model, introduced in Chapter7, we forecast the variable of interest using a linear combination of predictors. In an autoregression model, we forecast the variable of interest using a linear combination ofpast values of the variable. The termautoregression indicates that it is a regression of the variable against itself. Thus, an autoregressive model of order\\(p\\)can be written as\\[\n  y_{t} = c + \\phi_{1}y_{t-1} + \\phi_{2}y_{t-2} + \\dots + \\phi_{p}y_{t-p} + \\varepsilon_{t},\n\\]where\\(\\varepsilon_t\\)is white noise. This is like a multiple regression but withlagged valuesof\\(y_t\\)as predictors. We refer to this as anAR(\\(p\\)) model, an autoregressive model of order\\(p\\). Autoregressive models are remarkably flexible at handling a wide range of different time series patterns. The two series in Figure9.5show series from an AR(1) model and an AR(2) model. Changing the parameters\\(\\phi_1,\\dots,\\phi_p\\)results in different time series patterns. The variance of the error term\\(\\varepsilon_t\\)will only change the scale of the series, not the patterns. Figure 9.5: Two examples of data from autoregressive models with different parameters. Left: AR(1) with\\(y_t = 18 -0.8y_{t-1} + \\varepsilon_t\\). Right: AR(2) with\\(y_t = 8 + 1.3y_{t-1}-0.7y_{t-2}+\\varepsilon_t\\). In both cases,\\(\\varepsilon_t\\)is normally distributed white noise with mean zero and variance one. For an AR(1) model: We normally restrict autoregressive models to stationary data, in which case some constraints on the values of the parameters are required. When\\(p\\ge3\\), the restrictions are much more complicated. Thefablepackage takes care of these restrictions when estimating a model."
}