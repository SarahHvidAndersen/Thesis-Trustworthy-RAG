[
  {
    "document_type": "research_paper",
    "title": "Ten simple rules for the computational modeling of behavioral data",
    "author": "Robert C Wilson, Anne GE Collins",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Wilson-2019-Ten-simple-rules-for-the-computatio.pdf",
    "date_published": "2019-11-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": "*For correspondence: bob@email.arizona.edu (RCW); annecollins@berkeley.edu (AGEC) † These authors contributed equally to this work Competing interests: The authors declare that no competing interests exist. Funding: See page 24 Received: 26 June 2019 Accepted: 09 October 2019 Published: 26 November 2019 Reviewing editor: Timothy E Behrens, University of Oxford, United Kingdom Copyright Wilson and Collins. This article is distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use and redistribution provided that the original author and source are credited. Ten simple rules for the computational modeling of behavioral data Robert C Wilson 1,2† *, Anne GE Collins 3,4† * 1 Department of Psychology, University of Arizona, Tucson, United States; 2 Cognitive Science Program, University of Arizona, Tucson, United States; 3 Department of Psychology, University of California, Berkeley, Berkeley, United States; 4 Helen Wills Neuroscience Institute, University of California, Berkeley, Berkeley, United States Abstract Computational modeling of behavior has revolutionized psychology and neuroscience. By fitting models to experimental data we can probe the algorithms underlying behavior, find neural correlates of computational variables and better understand the effects of drugs, illness and interventions. But with great power comes great responsibility. Here, we offer ten simple rules to ensure that computational modeling is used with care and yields meaningful insights. In particular, we present a beginner-friendly, pragmatic and details-oriented introduction on how to relate models to data. What, exactly, can a model tell us about the mind? To answer this, we apply our rules to the simplest modeling techniques most accessible to beginning modelers and illustrate them with examples and code available online. However, most rules apply to more advanced techniques",
    "chunk_id": "15747544008463_1..33.json_chunk_1"
  },
  {
    "document_type": "research_paper",
    "title": "Ten simple rules for the computational modeling of behavioral data",
    "author": "Robert C Wilson, Anne GE Collins",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Wilson-2019-Ten-simple-rules-for-the-computatio.pdf",
    "date_published": "2019-11-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". However, most rules apply to more advanced techniques. Our hope is that by following our guidelines, researchers will avoid many pitfalls and unleash the power of computational modeling on their own data. What is computational modeling of behavioral data? The goal of computational modeling in behavioral science is to use precise mathematical models to make better sense of behavioral data. The behavioral data most often come in the form of choices, but can also be reaction times, eye movements, or other easily observable behaviors, and even neral data. The models come in the form of mathematical equations that link the experimentally observable variables (e.g. stimuli, outcomes, past experiences) to behavior in the immediate future. In this sense, computational models instantiate different ‘algorithmic hypotheses’ about how behaior is generated. Exactly what it means to ‘make sense’ of behavioral data is, to some extent, a matter of taste that will vary according to the researcher’s goals ( Kording et al., 2018 ). In some cases, a simple model that can explain broad qualitative features of the data is enough. In other cases, more detailed moels that make quantitative predictions are required ( Breiman, 2001 ). The exact form of the models, and exactly what we do with them, is limited only by our imaginations, but four uses dominate the literature: simulation, parameter estimation, model comparison, and latent variable inference. Simulation involves running the model with particular parameter settings to generate ‘fake’ behavioral data. These simulated data can then be analyzed in much the same way as one would analyze real data, to make precise, falsifiable predictions about qualitative and quantitative paterns in the data. Simulation is a way to make theoretical predictions more precise and testable. (Some examples include Cohen et al., 1990 ; Collins and Frank, 2014 ; Rescorla and Wagner, 1972 ; Farashahi et al., 2017 ; Montague et al., 1996 ; Abbott et al., 2015 ; Lee and Webb, 2005 )",
    "chunk_id": "15747544008463_1..33.json_chunk_2"
  },
  {
    "document_type": "research_paper",
    "title": "Ten simple rules for the computational modeling of behavioral data",
    "author": "Robert C Wilson, Anne GE Collins",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Wilson-2019-Ten-simple-rules-for-the-computatio.pdf",
    "date_published": "2019-11-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". (Some examples include Cohen et al., 1990 ; Collins and Frank, 2014 ; Rescorla and Wagner, 1972 ; Farashahi et al., 2017 ; Montague et al., 1996 ; Abbott et al., 2015 ; Lee and Webb, 2005 ). Parameter estimation involves finding the set of parameter values that best account for real behavioral data for a given model. These parameters can be used as a succinct summary of a Wilson and Collins. eLife 2019;8:e49547. DOI: https://doi.org/10.7554/eLife.49547 1 of 33 REVIEW ARTICLE given data set ( Ratcliff, 1978 ; Wilson et al., 2013 ; Daw et al., 2011 ; Donkin et al., 2016 ), for investigating individual differences ( Frank et al., 2007 ; Starns and Ratcliff, 2010 ; Collins and Frank, 2012 ; Gillan et al., 2016 ; Somerville et al., 2017 ; Nilsson et al., 2011 ) and for quantifying the effects of interventions such as drugs, lesions, illness, or experimental condtions ( Frank et al., 2004 ; Lorains et al., 2014 ; Dowd et al., 2016 ; Zajkowski et al., 2017 ; Warren et al., 2017 ; Wimmer et al., 2018 ; van Ravenzwaaij et al., 2011 ). Model comparison involves trying to compute which of a set of possible models best describes the behavioral data, as a way to understand which mechanisms are more likely to underlie behaior. This is especially useful when the different models make similar qualitative predictions but difer quantitatively ( Wilson and Niv, 2011 ; Daw et al., 2011 ; Collins and Frank, 2012 ; Collins and Frank, 2012 ; Fischer and Ullsperger, 2013 ; Steyvers et al., 2009 ; Haaf and Rouder, 2017 ; Donkin et al., 2014 ). Latent variable inference involves using the model to compute the values of hidden variables (for example values of different choices) that are not immediately observable in the behavioral data, but which the theory assumes are important for the computations occurring in the brain",
    "chunk_id": "15747544008463_1..33.json_chunk_3"
  },
  {
    "document_type": "research_paper",
    "title": "Ten simple rules for the computational modeling of behavioral data",
    "author": "Robert C Wilson, Anne GE Collins",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Wilson-2019-Ten-simple-rules-for-the-computatio.pdf",
    "date_published": "2019-11-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Latent variable inference is especially useful in neuroimaging where it is used to help search for the neural correlates of the model ( O’Doherty et al., 2007 ; Wilson and Niv, 2015 ; Donoso et al., 2014 ; Cohen et al., 2017 ), but also for electroencephalogram (EEG), electrocorticography (ECOG), electrophysiology and pupillometry among many other data sources ( O’Reilly et al., 2013 ; Collins and Frank, 2018 ; Samejima et al., 2005 ; Cavanagh et al., 2014 ; Nassar et al., 2012 ). Each of these uses has its strengths and weaknesses, and each of them can be mishandled in a number of ways, causing us to draw wrong and misleading conclusions ( Nassar and Frank, 2016 ; Palminteri et al., 2017 ). Here we present a beginner-friendly, pragmatic, practical and details-orented introduction (complete with example code available at [code]) on how to relate models to data and how to avoid many potential modeling mistakes. Our goal for this paper is to go beyond the mere mechanics of implementing models — as important as those mechanics are — and instead focus on the harder question of how to figure out what, exactly, a model is telling us about the mind. For this reason, we focus primarily on the simplest modeling techniques most accessible to beginning modelers, but almost all of our points apply more generally and readers interested in more advanced modeling techniques should consult the many excellent tutorials, didactic examples, and books on the topic ( Busemeyer and Diederich, 2010 ; Daw, 2011 ; Daw and Tobler, 2014 ; Heathcote et al., 2015 ; Huys, 2017 ; Turner et al., 2013 ; Vandekerckhove et al., 2015 ; Wagenmakers and Farrell, 2004 ; Rigoux et al., 2014 ; Nilsson et al., 2011 ; Farrell and Lewadowsky, 2018 ; Lee et al., 2019 ). For clarity of exposure, we chose to make all of the examples in this paper reflect a single narrow domain - reinforcement learning models applied to choice data ( Sutton and Barto, 2018 ). We chose this domain for a few reasons",
    "chunk_id": "15747544008463_1..33.json_chunk_4"
  },
  {
    "document_type": "research_paper",
    "title": "Ten simple rules for the computational modeling of behavioral data",
    "author": "Robert C Wilson, Anne GE Collins",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Wilson-2019-Ten-simple-rules-for-the-computatio.pdf",
    "date_published": "2019-11-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". We chose this domain for a few reasons. (1) Modeling is particularly popular in the field of learning. Indeed, this field benefits from modeling particularly because of the nature of the behavioral data: trials are dependent on all past history and thus unique, making classic data analysis with aggregation across conditions less successful. (2) The sequential dependency of trials in learning contexts can lead to technical challenges when fitting models that are absent in non-learning contexts. However, the same techniques are widely and successfully applied to other observable behavior, such as reaction times ( Ratcliff and Rouder, 1998 ; Viejo et al., 2015 ; Ballard and McClure, 2019 ; Wiecki et al., 2013 ), and to other domains, including but not limited to perception ( Sims, 2018 ), perceptual decsion-making ( Ratcliff and Rouder, 1998 ; Drugowitsch et al., 2016 ; Findling et al., 2018 ), economic decision-making ( van Ravenzwaaij et al., 2011 ; Nilsson et al., 2011 ), visual short-term memory ( Donkin et al., 2016 ; Donkin et al., 2014 ; Nassar et al., 2018 ), long-term memory ( Batchelder and Riefer, 1990 ), category learning ( Lee and Webb, 2005 ), executive functions ( Haaf and Rouder, 2017 ; Jahfari et al., 2019 ), and so on. Thus, our hope is that, regardless of the techniques you use or the domain you model, by following these 10 simple steps ( Figure 1 ), you will be able to minimize your modeling mishaps and unleash the power of computational modeling on your own behavioral data! Wilson and Collins. eLife 2019;8:e49547",
    "chunk_id": "15747544008463_1..33.json_chunk_5"
  },
  {
    "document_type": "research_paper",
    "title": "Ten simple rules for the computational modeling of behavioral data",
    "author": "Robert C Wilson, Anne GE Collins",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Wilson-2019-Ten-simple-rules-for-the-computatio.pdf",
    "date_published": "2019-11-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". eLife 2019;8:e49547. DOI: https://doi.org/10.7554/eLife.49547 2 of 33 Review Article Neuroscience Design experiment Section 1 Build models Section 2 Simulate model and experiment Section 3 Parameter recovery? Sections 4 & 5 Model recovery? Section 6 Fit real data Section 7 Validate the model Section 8 Parameter fits Section 7 Model comparison Section 7 Latent variable analysis Section 9 Report results Section 10 no yes yes no Can model and experiment answer question in theory? Can model account for the data? Figure 1. Schematic of the 10 rules and how they translate into a process for using computational modeling to better understand behavior. Wilson and Collins. eLife 2019;8:e49547. DOI: https://doi.org/10.7554/eLife.49547 3 of 33 Review Article Neuroscience Design a good experiment! Computational modeling is a powerful technique, but it can never replace good experimental design. Modeling attempts to capture how information is manipulated behind the scenes to produce the behavior; thus it is fundamentally limited by the behavioral data, which is itself fundamentally liited by the experimental protocol. A researcher studying face perception would not attempt to fit Prospect Theory to a face perception task; and a researcher studying the differential effects of gain and loss would not do it in a gambling task with only gains. Although obvious in these simple cases, the question becomes more difficult as the complexity of the model increases: is a given learning protocol rich enough to allow the identification of dynamic changes in learning rate, of working memory or episodic memory contributions to learning, or of reward range adaptation? Often, the answer to these questions will be ‘no’ unless the protocol has been deliberately designed to provide this power",
    "chunk_id": "15747544008463_1..33.json_chunk_6"
  },
  {
    "document_type": "research_paper",
    "title": "Ten simple rules for the computational modeling of behavioral data",
    "author": "Robert C Wilson, Anne GE Collins",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Wilson-2019-Ten-simple-rules-for-the-computatio.pdf",
    "date_published": "2019-11-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". So, how should you go about designing a good experiment with computational modeling in mind? While this process will always be something of an art form, we suggest that you ask yourself the following questions in order to optimize your experimental design: What scientific question are you asking? Although this sounds obvious, it is easy to get sucked into an experimental design without ever asing the most basic questions about your goals. What cognitive process are you targeting? What aspect of behavior are you trying to capture? What hypotheses are you trying to pick apart? For example, you may be trying to identify how working memory contributes to learning or how behaioral variability can be used to explore. Keeping your scientific goals in mind when you design the task can save much time later on. Does your experiment engage the targeted processes? This may be a difficult question to answer, and it may require expert knowledge or piloting. Hoever, you need to know that the experimental design actually engages the processes that you are trying to model. Will signatures of the targeted processes be evident from the simple statistics of the data? In addition to engaging the processes of interest, the best experiments make these processes identfiable in classical analyses of the behavioral data ( Palminteri et al., 2017 ). For example, if you are investigating working memory contributions to learning, you may look for a signature of load on behavior by constructing an experimental design that varies load, to increase chances of probing working memory’s role in learning. Seeing signs of the computations of interest in simple analyses of behavior builds confidence that the modeling process will actually work. In our experience, computtional modeling is rarely informative when there is no evidence of an effect in model-independent analyses of behavior. To answer these questions, it is important to have a clear theoretical hypothesis of what phenoenon is to be modeled",
    "chunk_id": "15747544008463_1..33.json_chunk_7"
  },
  {
    "document_type": "research_paper",
    "title": "Ten simple rules for the computational modeling of behavioral data",
    "author": "Robert C Wilson, Anne GE Collins",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Wilson-2019-Ten-simple-rules-for-the-computatio.pdf",
    "date_published": "2019-11-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". To answer these questions, it is important to have a clear theoretical hypothesis of what phenoenon is to be modeled. In fact, although designing a good experiment is the first step, it goes hanin-hand with designing a good model, and the two steps should ideally be done in parallel. But what if I’m not an experimentalist? Computational modeling is hard and many of the best modelers are specialists who never run experiments of their own. Instead these researchers test their models against published findings, publicly available datasets, or even, if they are lucky, unpublished data from their experimental coleagues. Such specialist modelers might feel that they can safely ignore this first point about expermental design and instead focus on explaining the data they can get. We strongly urge them not to. Instead we urge these specialist modelers to always be considering better ways in which their moels could be tested. Such experimental thinking helps you to be more concrete in your ideas and to think about how your model might apply outside of the context for which it was designed. In addtion, thinking experimentally — and even better talking with experimentalists — forces you to engage with behavior as it actually is rather than as you would like it to be, which in turn can lead to new insights. Finally, by proposing concrete experimental designs, it is easier to convince your Wilson and Collins. eLife 2019;8:e49547. DOI: https://doi.org/10.7554/eLife.49547 4 of 33 Review Article Neuroscience experimental colleagues to actually test your ideas, which is surely the goal if we are to move the field forward. An illustrative example: the multi-armed bandit task The ten rules in this paper are quite general, but we will illustrate many of our points using simple examples from our own field of reinforcement learning",
    "chunk_id": "15747544008463_1..33.json_chunk_8"
  },
  {
    "document_type": "research_paper",
    "title": "Ten simple rules for the computational modeling of behavioral data",
    "author": "Robert C Wilson, Anne GE Collins",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Wilson-2019-Ten-simple-rules-for-the-computatio.pdf",
    "date_published": "2019-11-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Code for implementing all of these examples is available on GitHub ( https://github.com/AnneCollins/TenSimpleRulesModeling) ( Collins and Wison, 2019 ; copy archived at https://github.com/elifesciences-publications/TenSimpleRulesModeing ). The goal of these example studies is to understand how people learn to maximize their rewards in a case where the most rewarding choice is initially unknown. More specifically, we consider the case in which a participant makes a series of T choices between K slot machines, or ‘one-armed bandits’, to try to maximize their earnings. If played on trial t , each slot machine, k , pays out a reward, r t , which is one with reward probability, k t , and otherwise 0. The reward probabilities are different for each slot machine and are initially unknown to the subject. In the simplest version of the task, the reward probabilities are fixed over time. The three experimental parameters of this task are: the number of trials, T , the number of slot machines, K , and the reward probabilities of the different options, k t , which may or may not change over time. The settings of these parameters will be important for determining exactly what informtion we can extract from the experiment. In this example, we will assume that T 1⁄4 1000 , K 1⁄4 2 , and that the reward probabilities are 1 t 1⁄4 0 : 2 for slot machine 1 and 2 t 1⁄4 0 : 8 for slot machine 2. Design good models Just as bad experiments can limit our ability to test different hypotheses, bad models – quite literally the mathematical embodiment of our hypotheses – can further limit the conclusions we can draw ( Donkin et al., 2014 ). This point is especially important if we are designing new models, but even well-established computational models can be problematic in some cases ( Broomell and Bhatia, 2014 ; Nilsson et al., 2011 ). Critical to the design of the model is a clear understanding of your reason for modeling",
    "chunk_id": "15747544008463_1..33.json_chunk_9"
  },
  {
    "document_type": "research_paper",
    "title": "Ten simple rules for the computational modeling of behavioral data",
    "author": "Robert C Wilson, Anne GE Collins",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Wilson-2019-Ten-simple-rules-for-the-computatio.pdf",
    "date_published": "2019-11-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Critical to the design of the model is a clear understanding of your reason for modeling. Are you interested in a descriptive model that succinctly summarizes, but perhaps does not explain, behaioral data? A mechanistic model to tie behavior to the brain? Or an elegant mathematical model to illustrate a concept? As shown in an excellent article by Kording and colleagues ( Kording et al., 2018 ), computational modelers have a wide variety of goals for their models, and understanding your own motivations is a great place to start. More pragmatically, there are a number of different approaches for designing models that have been successfully used in the literature. Perhaps the simplest approach is to use heuristics to find a ‘reasonable’ way to handle information to produce the target behavior. This approach was how the delta rule (see Model three below) was first invented ( Rescorla and Wagner, 1972 ). Another approach is to scour the artificial intelligence, computer science, and applied mathematics literature for algorithms that have been used to solve similar problems for artificial agents. This approach has been fruitfully applied in the field of reinforcement learning ( Sutton and Barto, 2018 ), where algrithms such as Q-learning and temporal difference learning have been related to human and animal behavior and brain function ( Watkins and Dayan, 1992 ; Montague et al., 1996 ). Another approach is to take a Bayes-optimal perspective, to design algorithms that perform optimally given a model of the environment and the task. Ideal observer models in vision are one example in which this approach has been applied successfully ( Geisler, 2011 ). More generally, Bayes-optimal models can be further pursued by investigating simpler algorithms that approximate the ideal strategy, or by imposing bounded rationality constraints, such as limited computational resources, on ideal observer agents ( Courville and Daw, 2008 ; Nassar et al., 2010 ; Collins and Frank, 2012 ; Daw and Couville, 2007 ; Lieder et al., 2018 )",
    "chunk_id": "15747544008463_1..33.json_chunk_10"
  },
  {
    "document_type": "research_paper",
    "title": "Ten simple rules for the computational modeling of behavioral data",
    "author": "Robert C Wilson, Anne GE Collins",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Wilson-2019-Ten-simple-rules-for-the-computatio.pdf",
    "date_published": "2019-11-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Regardless of the approach (or, better yet, approaches) that you take to design your models, it is important to keep the following points in mind: Wilson and Collins. eLife 2019;8:e49547. DOI: https://doi.org/10.7554/eLife.49547 5 of 33 Review Article Neuroscience A computational model should be as simple as possible, but no simpler Einstein’s old edict applies equally to models of the mind as it does to models of physical systems. Simpler, more parsimonious models are easier to fit and easier to interpret and should always be included in the set of models under consideration. Indeed, formal model comparison techniques (described in detail in Appendix 2) include a penalty for overly complex models, which are more likely to overfit the data and generalize poorly, and favor simpler models so long as they can account for the data. A computational model should be interpretable (as much as possible) In the process of developing models that can account for the behavioral data, researchers run the risk of adding components to a model that are not interpretable as a sensible manipulation of infomation. For example, a negative learning rate is difficult to interpret in the framework of reinforcment learning. Although such uninterpretable models may sometimes improve fits, nonsensical parameter values may indicate that something important is missing from your model, or that a diffeent cognitive process altogether is at play. The models should capture all the hypotheses that you plan to test While it is obviously important to design models that can capture your main hypothesis, it is even more important to design models that capture competing hypotheses. Crucially, competing models should not be strawmen — they should have a genuine chance of relating to behavior in the task environment, and they should embody a number of reasonable, graded hypotheses. You should of course put equal effort into fitting these models as you do your favored hypothesis",
    "chunk_id": "15747544008463_1..33.json_chunk_11"
  },
  {
    "document_type": "research_paper",
    "title": "Ten simple rules for the computational modeling of behavioral data",
    "author": "Robert C Wilson, Anne GE Collins",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Wilson-2019-Ten-simple-rules-for-the-computatio.pdf",
    "date_published": "2019-11-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". You should of course put equal effort into fitting these models as you do your favored hypothesis. Better yet, you shouldn’t have a favored hypothesis at all — let the data determine which model is the best fit, not your a priori commitment to one model or another. Box 1. Example: Modeling behavior in the multi-armed bandit task. We consider five different models of how participants could behave in the multi-armed bandit task. Model 1: Random responding In the first model, we assume that participants do not engage with the task at all and simply press buttons at random, perhaps with a bias for one option over the other. Such random behavior is not uncommon in behavioral experiments, especially when participants have no external incentives for performing well. Modeling such behavior can be important if we wish to identify such ‘checked out’ individuals in a quantitative and reproducible manner, either for exclusion or to study the checked-out behavior itself. To model this behavior, we assume that participants choose between the two options randomly, perhaps with some overall bias for one option over the other. This bias is captured with a parameter b (which is between 0 and 1), such that the probability of choosing the two options is p 1 t 1⁄4 b and p 2 t 1⁄4 1 b (1) Thus, for two bandits, the random responding model has just one free parameter, controlling the overall bias for option 1 over option 2, 1 1⁄4 b . Model 2: Noisy win-stay-lose-shift The win-stay-lose-shift model is one of the simplest models that adapts its behavior according to feedback. Consistent with the name, the model repeats rewarded actions and switches away from unrewarded actions. In the noisy version of the model, the win-stay-lose-shift rule is applied probabilistically, such that the model applies the win-stay-lose-shift rule with probability 1 , and chooses randomly with probability . In the two-bandit case, the probability of chooing option k is Wilson and Collins. eLife 2019;8:e49547",
    "chunk_id": "15747544008463_1..33.json_chunk_12"
  },
  {
    "document_type": "research_paper",
    "title": "Ten simple rules for the computational modeling of behavioral data",
    "author": "Robert C Wilson, Anne GE Collins",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Wilson-2019-Ten-simple-rules-for-the-computatio.pdf",
    "date_published": "2019-11-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". In the two-bandit case, the probability of chooing option k is Wilson and Collins. eLife 2019;8:e49547. DOI: https://doi.org/10.7554/eLife.49547 6 of 33 Review Article Neuroscience p k t 1⁄4 1 = 2 if ð c t 1 1⁄4 k and r t 1 1⁄4 1 Þ OR ð c t 1 61⁄4 k and r t 1 1⁄4 0 Þ = 2 if ð c t 1 61⁄4 k and r t 1 1⁄4 1 Þ OR ð c t 1 1⁄4 k and r t 1 1⁄4 0 Þ (2) where c t 1⁄4 1 ; 2 is the choice at trial t , and r t 1⁄4 0 ; 1 the reward at trial t . Although more complex to implement, this model still only has one free parameter, the overall level of randomness, 2 1⁄4 . Model 3: Rescorla Wagner In this model, participants first learn the expected value of each slot machine based on the hitory of previous outcomes and then use these values to make a decision about what to do next. A simple model of learning is the Rescorla-Wagner learning rule ( Rescorla and Wagner, 1972 ), whereby the value of option k , Q k t is updated in response to reward r t according to: Q k t þ 1 1⁄4 Q k t þ a ð r t Q k t Þ (3) where a is the learning rate, which takes a value between 0 and 1 and captures the extent to which the prediction error, ð r t Q k t Þ , updates the value. For simplicity, we assume that the initial value, Q k 0 , is zero, although it is possible to treat the Q k 0 as a free parameter of the model. A simple model of decision making is to assume that participants use the options’ values to guide their decisions, choosing the most valuable option most frequently, but occasionally maing ‘mistakes’ (or exploring) by choosing a low-value option. One choice rule with these propeties is known as the ‘softmax’ choice rule, which chooses option k with probability p k t 1⁄4 exp ð b Q k t Þ P K i 1⁄4 1 exp ð b Q i t Þ (4) where b is the ‘inverse temperature’ parameter that controls the level of stochasticity in the choice, ranging from b 1⁄4 0 for completely random responding and b 1⁄4 ¥ for deterministically choosing the highest value option",
    "chunk_id": "15747544008463_1..33.json_chunk_13"
  },
  {
    "document_type": "research_paper",
    "title": "Ten simple rules for the computational modeling of behavioral data",
    "author": "Robert C Wilson, Anne GE Collins",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Wilson-2019-Ten-simple-rules-for-the-computatio.pdf",
    "date_published": "2019-11-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Combining the learning ( Equation 3 ) and decision rules ( Equation 4 ) gives a simple model of decision-making in this task with two free parameters: the learning rate, a , and the inverse teperature, b . That is, in our general notation, for this model 3 1⁄4 ð a ; b Þ . Model 4: Choice kernel This model tries to capture the tendency for people to repeat their previous actions. In particlar, we assume that participants compute a ‘choice kernel,’ CK k t , for each action, which keeps track of how frequently they have chosen that option in the recent past. This choice kernel updates in much the same way as the values in the Rescorla-Wagner rule, i.e. according to CK k t þ 1 1⁄4 CK k t þ a c ð a k t CK k t Þ (5) where a k t 1⁄4 1 if option k is played on trial t , otherwise a k t 1⁄4 0 , and a c is the choice-kernel learning rate. For simplicity, we assume that the initial value of the choice kernel is always zero, although, like the initial Q -value in the Rescorla-Wagner model, this could be a parameter of the model. Note that with a c 1⁄4 1 , this model is very similar to model 2 (win-stay-lose-shift). From there, we assume that each option is chosen according to p k t 1⁄4 exp ð b c CK k t Þ P K i 1⁄4 1 exp ð b c CK i t Þ (6) where b c is the inverse temperature associated with the choice kernel. Combining the choice kernel ( Equation 5 ) with the decision rule ( Equation 6 ) gives a simple model of decision-making in this task with two free parameters: the choice-kernel learning rate, a c , and the choice-kernel inverse temperature b c . That is, in our general notation, for this model 4 1⁄4 ð a c ; b c Þ . Model 5: Rescorla Wagner + choice kernel Wilson and Collins. eLife 2019;8:e49547. DOI: https://doi.org/10.7554/eLife.49547 7 of 33 Review Article Neuroscience Finally, our most complex model mixes the reinforcement learning model with the choice kernel model. In this model, the values update according to Equation 3 , while the choice kernel updates according to Equation 5",
    "chunk_id": "15747544008463_1..33.json_chunk_14"
  },
  {
    "document_type": "research_paper",
    "title": "Ten simple rules for the computational modeling of behavioral data",
    "author": "Robert C Wilson, Anne GE Collins",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Wilson-2019-Ten-simple-rules-for-the-computatio.pdf",
    "date_published": "2019-11-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". In this model, the values update according to Equation 3 , while the choice kernel updates according to Equation 5 . The terms are then combined to compute the choice probbilities as p k t 1⁄4 exp ð b Q k t þ b c CK k t Þ P K i 1⁄4 1 exp ð b Q i t þ b c CK i t Þ (7) This most complex model has four free parameters, i.e. 5 1⁄4 ð a ; b ; a c ; b c Þ . Simulate, simulate, simulate! Once you have an experimental design and a set of computational models, a really important step is to create fake , or surrogate data ( Palminteri et al., 2017 ). That is, you should use the models to siulate the behavior of participants in the experiment, and to observe how behavior changes with diferent models, different model parameters, and different variants of the experiment. This step will allow you to refine the first two steps: confirming that the experimental design elicits the behaviors assumed to be captured by the computational model. To do this, here are some important steps. Define model-independent measures that capture key aspects of the processes you are trying to model Finding qualitative signatures (and there will often be more than one) of the model is crucial. By studying these measures with simulated data, you will have greater intuition about what is going on when you use the same model-independent measures to analyze real behavior ( Daw et al., 2011 ; Collins and Frank, 2012 ; Collins and Frank, 2013 ; Nassar et al., 2018 ; Lee and Webb, 2005 ). Simulate the model across the range of parameter values Then, visualize behavior as a function of the parameters. Almost all models have free parameters. Understanding how changes to these parameters affect behavior will help you to better interpret your data and to understand individual differences in fit parameters",
    "chunk_id": "15747544008463_1..33.json_chunk_15"
  },
  {
    "document_type": "research_paper",
    "title": "Ten simple rules for the computational modeling of behavioral data",
    "author": "Robert C Wilson, Anne GE Collins",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Wilson-2019-Ten-simple-rules-for-the-computatio.pdf",
    "date_published": "2019-11-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Understanding how changes to these parameters affect behavior will help you to better interpret your data and to understand individual differences in fit parameters. For example, in probabilistic reinforcement learning tasks modeled with a simple delta-rule model (Model 3; Equation 3 ), the learning rate parameter, a , can relate to both the speed of learning and noisiness in asymptotic behavior, as can the inverse temperature parameter, b (in Equation 4 ), as seen in Box 2—figure 1B . Visualize the simulated behavior of different models This will allow you to verify that behavior is qualitatively different for different models, making their predictions in the experimental setup different ( Box 2—figure 1A ). If the behavior of different moels is not qualitatively different, this is a sign that you should try to design a better experiment. Although not always possible, distinguishing between models on the basis of qualitative patterns in the data is always preferable to quantitative model comparison ( Navarro, 2019 ; Palminteri et al., 2017 ). More generally, the goal of the simulation process is to clarify how the models and experimental design satisfy your goal of identifying a cognitive process in behavior. If the answer is positive — i.e. the experiment is rich enough to capture the expected behavior, the model’s parameters are intepretable, and competing models make dissociable predictions — you can move on to the next step. Otherwise, you should loop back through these first three sections to make sure that your expermental design and models work well together, and that the model parameters have identifiable effects on the behavior, which is a prerequisite for the fourth step, fitting the parameters (c.f. Figure 1 ). Box 2. Example: simulating behavior in the bandit task. To simulate behavior, we first need to define the parameters of the task",
    "chunk_id": "15747544008463_1..33.json_chunk_16"
  },
  {
    "document_type": "research_paper",
    "title": "Ten simple rules for the computational modeling of behavioral data",
    "author": "Robert C Wilson, Anne GE Collins",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Wilson-2019-Ten-simple-rules-for-the-computatio.pdf",
    "date_published": "2019-11-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Figure 1 ). Box 2. Example: simulating behavior in the bandit task. To simulate behavior, we first need to define the parameters of the task. These include the total number of trials, T (=1000 in the example), as well as the number of bandits, K ð1⁄4 2 Þ , and the reward probability for each bandit, k (0.2 and 0.8 for bandits 1 and 2, respectively). The Wilson and Collins. eLife 2019;8:e49547. DOI: https://doi.org/10.7554/eLife.49547 8 of 33 Review Article Neuroscience experiment parameters, as used in the simulation, should match the actual parameters used in the experiment. Next we define the parameters of the model. One way to do this is to sample these parameters randomly from prior distributions over each parameter, the exact form of which will vary from model to model. These prior distributions should generally be as broad as possible, but if something is known about the distribution of possible parameter values for a particular model, this is one place to include it. With the free parameters set, we then proceed with the simulation. First, we simulate the choice on the first trial, a 1 , by assuming that the model chooses option k with probability, p k 1 . Next we simulate the outcome, r 1 , of this choice. In Models 2–5, we use the action and/or outcome to update the choice probabilities for the next trial. Repeating this process for all trials up to t 1⁄4 T completes one simulation. The simulations can then be analyzed in the same way as participants’ data is, ideally with the same code taking different inputs. This process should be repeated several times, with different parameter settings, to get a handle on how the model behaves as a function of its parameters",
    "chunk_id": "15747544008463_1..33.json_chunk_17"
  },
  {
    "document_type": "research_paper",
    "title": "Ten simple rules for the computational modeling of behavioral data",
    "author": "Robert C Wilson, Anne GE Collins",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Wilson-2019-Ten-simple-rules-for-the-computatio.pdf",
    "date_published": "2019-11-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". This process should be repeated several times, with different parameter settings, to get a handle on how the model behaves as a function of its parameters. To illustrate how one might visualize the simulated results, we look at two model-independent measures that should capture fundamental aspects of learning: the probability of repeating an action, p ð stay Þ (should I change my behavior in response to feedback?), and the probability of choosing the correct option, p ð correct Þ (have I learned?). In Box 2—figure 1A below, we plot p ð stay Þ as a function of the reward on the last trial for each of the models with a particular set of parameters (M1: b 1⁄4 0 : 5 , M2: 1⁄4 0 : 05 , M3: a 1⁄4 0 : 1 , b 1⁄4 5 , M4: a c 1⁄4 0 : 1 , b c 1⁄4 3 , M5: a 1⁄4 0 : 1 , b 1⁄4 5 , a c 1⁄4 0 : 1 , b c 1⁄4 1 ). For some models (in particular the win-stay-lose-shift model (Model 2), we expect a strong dependence on past reward, but for others, such as the random responder (Model 1), we expect no dependence. Of course, the exact behavior of each model depends crucially on the parameters used in the simulations and care should be taken to ensure that these simulation parameters are reasonable, perhaps by matching to typical parameter vaues used in the literature or by constraining to human-like overall performance. Better yet is to simulate behavior across a range of parameter settings to determine how the model-indepedent measures change with different parameters. A more thorough exploration of the parameter space for Model 3 is shown in Box 2—figure 1B , where we plot the p ð correct Þ in the first and last 10 trials as a function of the learning rate, a , and softmax parameter, b . Note that the ‘optimal’ learning rate, i.e. the value of a that maxmizes p ð correct Þ , varies between early and late trials and as a function of the softmax parameter b , where for early trials higher b implies a lower optimal a ( Daw et al., 2011 )",
    "chunk_id": "15747544008463_1..33.json_chunk_18"
  },
  {
    "document_type": "research_paper",
    "title": "Ten simple rules for the computational modeling of behavioral data",
    "author": "Robert C Wilson, Anne GE Collins",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Wilson-2019-Ten-simple-rules-for-the-computatio.pdf",
    "date_published": "2019-11-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". The question of how to choose the model-independent measures of behavior has no easy answer and calls to the domain knowledge of the specific scientific question that the modeler is attempting to answer. As a rule of thumb, the measures should capture global characteristics (e.g. overall performance) and diagnostic measures that relate to the question of interest, and may visualize different qualitative predictions of different models. 0 1 previous reward 0 0.5 1 p(stay) stay behavior M1: random M2: WSLS M3: RW M4: CK M5: RW+CK 0 0.5 1 learning rate, a 0.5 0.6 0.7 0.8 0.9 1 p(correct) early trials b b b b b = 20 = 10 = 5 = 2 = 1 0 0.5 1 learning rate, a late trials A B Box 2—figure 1. Simulating behavior in the two-armed bandit task. ( A ) Win-stay-lose-shift behavior varies widely between models. ( B ) Model 3 simulations (100 per parameter setting) show how the learning rate and softmax parameters influence two aspects of behavior: early performance (first 10 trials), and late perfomance (last 10 trials). The left graph shows that learning rate is positively correlated with early performance Wilson and Collins. eLife 2019;8:e49547. DOI: https://doi.org/10.7554/eLife.49547 9 of 33 Review Article Neuroscience improvement only for low b values or for very low a values. For high b values, there is a U-shape relationship between learning rate and early speed of learning. The right graph shows that with high b values, high learing rates negatively influence asymptotic behavior. Thus, both parameters interact to influence both the speed of learning and asymptotic performance. Fit the parameters A key component of computational modeling is estimating the values of the parameters that best describe your behavioral data. There are a number of different ways of estimating parameters, but here we focus on the maximum-likelihood approach, although almost all of our points apply to other methods such as Markov Chain Monte Carlo approaches ( Lee and Wagenmakers, 2014 )",
    "chunk_id": "15747544008463_1..33.json_chunk_19"
  },
  {
    "document_type": "research_paper",
    "title": "Ten simple rules for the computational modeling of behavioral data",
    "author": "Robert C Wilson, Anne GE Collins",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Wilson-2019-Ten-simple-rules-for-the-computatio.pdf",
    "date_published": "2019-11-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Mathmatical details, as well as additional discussion of other approaches to model fitting can be found in Appendix 1. In the maximum likelihood approach to model fitting, our goal is to find the parameter values of model m , ^ MLE m , that maximize the likelihood of the data, d 1 : T , given the parameters, p ð d 1 : T j m ; m Þ . Maximizing the likelihood is equivalent to maximizing the log of the likelihood, LL 1⁄4 log p ð d 1 : T j m ; m Þ , which is numerically more tractable. (The likelihood is a product of many numbers smaller than 1, which can be rounded to 0 with limited precision computing. By contrast, the log-likelihood is a sum of negative numbers, which is usually tractable and will not be rounded to 0.) A simple mathematical derivation shows that this log-likelihood can be written in terms of the choice probabilities of the individual model as LL 1⁄4 log p ð d 1 : T j m ; m Þ 1⁄4 X T t 1⁄4 1 log p ð c t j d 1 : t 1 ; s t ; m ; m Þ (8) where p ð c t j d 1 : t 1 ; s t ; m ; m Þ is the probability of each individual choice given the parameters of the model and the information available up to that choice, which is at the heart of the definition of each model (for example in Equations 1-7) . In principle, finding the maximum likelihood parameters is as ‘simple’ as maximizing LL . In pratice, of course, finding the maximum of a function is not a trivial process. The simplest approach, a brute force search of the entire parameter space, is occasionally useful, and may help you to undestand how different parameters interact (see Box 3—figure 1 ). However, this approach is unfeasible outside of the simplest cases (e.g. one or two parameters with tight bounds) because of the high computational costs of evaluating the likelihood function at a large number of points. Fortunately, a number of tools exist for finding local maxima (and minima) of functions quickly using variations on gradient ascent (or descent)",
    "chunk_id": "15747544008463_1..33.json_chunk_20"
  },
  {
    "document_type": "research_paper",
    "title": "Ten simple rules for the computational modeling of behavioral data",
    "author": "Robert C Wilson, Anne GE Collins",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Wilson-2019-Ten-simple-rules-for-the-computatio.pdf",
    "date_published": "2019-11-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Fortunately, a number of tools exist for finding local maxima (and minima) of functions quickly using variations on gradient ascent (or descent). For example, Matlab’s fmincon function can use a variety of sophisticated optimization algorithms (e.g. More ́ and Sorensen, 1983 ; Byrd et al., 2000 ) to find the minimum of a function (and other factors such as the Hessian that can be useful in some situations [ Daw, 2011 ]). So long as one remembers to feed fmincon the negative log-likelihood (whose minimum is at the same parameter values as the maximum of the positive log-likelihood), using tools such as fmincon can greatly speed up model fitting. Even here, though, a number of problems can arise when trying to maximize LL that can be reduced by using the tips and tricks described below. Most of the tips come from understanding that optimization algorithms are not foolproof and in particular are subject to numerical constraints. They generalize to other black box optimization functions in other languages, for example the Python scipy.optimize package or the optim function in R. Be sure that your initial conditions give finite log-likelihoods Optimizers such as fmincon require you to specify initial parameter values from which to start the search. Perhaps the simplest way in which the search process can fail is if these initial parameters give log-likelihoods that are not finite numbers (e.g. infinities or NaNs, not a number in Matlab speak). If your fitting procedure fails, this can often be the cause. Wilson and Collins. eLife 2019;8:e49547. DOI: https://doi.org/10.7554/eLife.49547 10 of 33 Review Article Neuroscience Beware rounding errors, zeros and infinities More generally, the fitting procedure can go wrong if it encounters infinities or NaNs during the parameter search. This can occur if a choice probability is rounded down to zero, thus making the log of the choice probability ¥ . Likewise, if your model involves exponentials (e.g",
    "chunk_id": "15747544008463_1..33.json_chunk_21"
  },
  {
    "document_type": "research_paper",
    "title": "Ten simple rules for the computational modeling of behavioral data",
    "author": "Robert C Wilson, Anne GE Collins",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Wilson-2019-Ten-simple-rules-for-the-computatio.pdf",
    "date_published": "2019-11-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". This can occur if a choice probability is rounded down to zero, thus making the log of the choice probability ¥ . Likewise, if your model involves exponentials (e.g. the softmax choice rule in Equation 4 ), this can lead to errors whereby the exponential of a very large number is ‘rounded up’ to infinity. One way to avoid these issues is by constraining parameter values to always give finite choice probabilities and log-likelihoods at the boundaries. One way to diagnose these issues is to include checks in the code for valid log-likelihoods. Be careful with constraints on parameters If the constraints are ill chosen, it is possible that the solution will be at the bounds, which is often, but not always, a red flag. Only include parameters that have an influence on the likelihood. If only two parameters impact the likelihood, but the optimizer attempts to fit three, it will usually find the optimum for the two reevant parameters and a random value for the third; however, it will lead to slower and less efficient fitting. Beware local minima! Finally, a key limitation of optimization algorithms is that they are only guaranteed to find local miima, which are not guaranteed to be the global minima corresponding to the best fitting paramters. One way to mitigate this issue is to run the fitting procedure multiple times with random initial conditions, recording the best fitting log-likelihood for each run. The best fitting parameters are then the parameters corresponding to the run with the highest log-likelihood. There is no hard-anfast rule for knowing how many starting points to use in a given situation, besides the fact that more complex models will require more starting points. Thus, this number must be determined empirically in each case. One way to validate the number of starting points is by plotting the best likelihood score as a function of the number of starting points",
    "chunk_id": "15747544008463_1..33.json_chunk_22"
  },
  {
    "document_type": "research_paper",
    "title": "Ten simple rules for the computational modeling of behavioral data",
    "author": "Robert C Wilson, Anne GE Collins",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Wilson-2019-Ten-simple-rules-for-the-computatio.pdf",
    "date_published": "2019-11-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". One way to validate the number of starting points is by plotting the best likelihood score as a function of the number of starting points. As the number of initial conditions increases, the best-fitting likelihood (and corresponding the parameters) will improve up to an asymptote close to the true maximum of the function (e.g. Box 3—figure 1 ). Box 3. Example: contending with multiple local maxima. As a real example with local maxima, we consider the case of a simplified version of the mixed reinforcement learning and working memory model from Collins and Frank, 2012 . For simpliity, we relegate the details of this model to Appendix 4. To appreciate the example, all one really needs to know is that in its simplest version, this model has two parameters: , which catures the effect of working memory, and a , which captures the learning rate of reinforcement learning. As is seen in Box 3—figure 1 below, this model (combined with an appropriate expeiment) gives rise to a log-likelihood surface with multiple local maxima. Depending on the staring point, the optimization procedure can converge to any one of these local maxima, meaning that the ‘maximum’ likelihood fits may not reflect the global maximum likelihood. To mitigate this concern, a simple and effective approach is to repeat the optimization procdure many times, keeping track of the best fitting log-likelihood and parameters in each case. An approximation to the global maximum is to take the best log-likelihood from this list of fits. The results of this multiple iteration procedure can be summarized by plotting the best log-liklihood as a function of the number of starting points, or similarly, by plotting the distance from the so-far best parameters to the final best parameters as a function of the number of starting points ( Box 3—figure 1B ). As the number of starting points increases, the best-fitting log-likelhood and parameters will converge to the global maximum. This plot also allows us to judge when we have used enough starting points",
    "chunk_id": "15747544008463_1..33.json_chunk_23"
  },
  {
    "document_type": "research_paper",
    "title": "Ten simple rules for the computational modeling of behavioral data",
    "author": "Robert C Wilson, Anne GE Collins",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Wilson-2019-Ten-simple-rules-for-the-computatio.pdf",
    "date_published": "2019-11-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". This plot also allows us to judge when we have used enough starting points. Specifically, if the best fitting parameters appear to have reached asymptote, that gives us a good indication that the fit is the best we can do. Wilson and Collins. eLife 2019;8:e49547. DOI: https://doi.org/10.7554/eLife.49547 11 of 33 Review Article Neuroscience Box 3—figure 1. An example with multiple local minima. ( Left ) Log-likelihood surface for a working memory reinforcement learning model with two parameters. In this case, there are several local minima, all of which can be found by the optimization procedure depending on the starting point. Red x, generative parameters; black circle, optimum with brute search method; black *, optimum with fmincon and multiple starting points. ( Right ) Plotting the distance from the best fitting parameters after n iterations to the best fitting parameters after all iterations as a function of the number of starting points n gives a good sense of when the procedure has found the global optimum. The inset shows the same plot on a logarithmic scale for distance, illustrating that there are still very small improvements to be made after the third iteration. Check that you can recover your parameters Before reading too much into the best-fitting parameter values, MLE m , it is important to check whether the fitting procedure gives meaningful parameter values in the best case scenario, -that is, when fitting fake data where the ‘true’ parameter values are known ( Nilsson et al., 2011 ). Such a procedure is known as ‘Parameter Recovery’, and is a crucial part of any model-based analysis. In principle, the recipe for parameter recovery is quite simple. First, simulate fake data with known parameter values. Next, fit the model to these fake data to try to ‘recover’ the parameters. Finally, compare the recovered parameters to their true values. In a perfect world, the simulated and recovered parameters will be tightly correlated, with no bias",
    "chunk_id": "15747544008463_1..33.json_chunk_24"
  },
  {
    "document_type": "research_paper",
    "title": "Ten simple rules for the computational modeling of behavioral data",
    "author": "Robert C Wilson, Anne GE Collins",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Wilson-2019-Ten-simple-rules-for-the-computatio.pdf",
    "date_published": "2019-11-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Finally, compare the recovered parameters to their true values. In a perfect world, the simulated and recovered parameters will be tightly correlated, with no bias. If there is only a weak correlation between the simulated and recovered parameters and/or a significant bias, then this is an indication that there is either a bug in your code (which from our own experience is fairly likely) or the experment is underpowered to assess this model. To make the most of your parameter recovery analysis, we suggest the following tips: Make sure your simulation parameters are in the right range An important choice for parameter recovery is the range of simulation parameters that you wish to recover. Some models/experiments only give good parameter recovery for parameters in a particlar range — if the simulation parameters are too big or too small, they can be hard to recover. An illustration of this is the softmax parameter, b , where very large b values lead to almost identical behavior in most experiments. Thus parameter recovery may fail for large b values but work well for small b values. Of course, selecting only the range of parameters that can be recovered by your model is not necessarily the right choice, especially if the parameter values you obtain when fitting real data are outside of this range! For this reason, we have the following recommendations for choosing simulation parameter values: 1. If you have already fit your data, we recommend matching the range of your simulation paraeters to the range of values obtained by your fit. 2. If you have not fit your data but you are using a model that has already been published, match the range of parameters to the range seen in previous studies. 3. Finally, if the model is completely new and the ‘true’ parameter values are unknown, we reommend simulating over as wide a range as possible to get a sense of whether and where parameters can be recovered",
    "chunk_id": "15747544008463_1..33.json_chunk_25"
  },
  {
    "document_type": "research_paper",
    "title": "Ten simple rules for the computational modeling of behavioral data",
    "author": "Robert C Wilson, Anne GE Collins",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Wilson-2019-Ten-simple-rules-for-the-computatio.pdf",
    "date_published": "2019-11-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". You can rely on your exploration of how model parameters affect simulated behavior to predict a range beyond which parameters will not affect behavior much. Note that it is not necessarily problematic if a model’s parameters are not recoverable in a full parameter space, as long as they are recoverable in the range that matters for real data. Wilson and Collins. eLife 2019;8:e49547. DOI: https://doi.org/10.7554/eLife.49547 12 of 33 Review Article Neuroscience Plot the correlations between simulated and recovered parameters While the correlation coefficient between simulated and recovered parameters is a useful number for summarizing parameter recovery, we also strongly recommend that you actually plot the simlated vs recovered parameters. This makes the correlation clear, and also reveals whether the corrlation holds in some parameter regimes but not others. It also reveals any existing bias (for example, a tendency to recover higher or lower values in average). Make sure the recovery process does not introduce correlations between parameters In addition to looking at the correlations between simulated and recovered parameters, we also reommend looking at the correlation between the recovered parameters themselves. If the simulation parameters are uncorrelated with one another, correlation between the recovered parameters is an indication that the parameters in the model are trading off against one another ( Daw, 2011 ). Such trade-offs can sometimes be avoided by reparameterizing the model (e.g. Otto et al., 2013 ) or redesigning the experiment. Sometimes, however, such trade-offs are unavoidable. In these cases, it is crucial to report the trade-off in parameters so that a ‘correlation’ between fit parameter values is not over-interpreted in real data. A note about parameter differences between different populations or conditions: a growing use of model fitting is to compare parameter values between populations (e.g",
    "chunk_id": "15747544008463_1..33.json_chunk_26"
  },
  {
    "document_type": "research_paper",
    "title": "Ten simple rules for the computational modeling of behavioral data",
    "author": "Robert C Wilson, Anne GE Collins",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Wilson-2019-Ten-simple-rules-for-the-computatio.pdf",
    "date_published": "2019-11-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". A note about parameter differences between different populations or conditions: a growing use of model fitting is to compare parameter values between populations (e.g. schizophrenia patients vs healthy controls [ Collins et al., 2014 ]) or conditions (e.g., transcranial magnetic stimulation to one area or another [ Zajkowski et al., 2017 ]). If your primary interest is a difference like this, then paraeter recovery can be used to give an estimate of statistical power. In particular, for a proposed effect size (e.g., on the average difference in one parameter between groups or conditions) you can simlate and recover parameters for the groups or conditions and then perform statistical tests to detect group differences in this simulated data set. The power for this effect size is then the frequency with which the statistical tests detect no effect given that the effect is there. Remember that even successful parameter recovery represents a bescase scenario! What does successful parameter recovery tell you? That data generated by a known model with given parameters can be fit to recover those parameters. This is the best case you could possibly hope for in the model-based analysis and it is unlikely to ever occur as the ‘true’ generative process for behavior — that is, the inner workings of the mind and brain — is likely much more complex than any model you could conceive. There’s no easy answer to this problem. We only advise that you remember to be humble when you present your results! Box 4. Example: parameter recovery in the reinforcement learning model. We performed parameter recovery with Model 3, the Rescorla Wagner model, on the twarmed bandit task. As before, we set the means of each bandit at 1 1⁄4 0 : 2 and 2 1⁄4 0 : 8 and the number of trials at T 1⁄4 1000",
    "chunk_id": "15747544008463_1..33.json_chunk_27"
  },
  {
    "document_type": "research_paper",
    "title": "Ten simple rules for the computational modeling of behavioral data",
    "author": "Robert C Wilson, Anne GE Collins",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Wilson-2019-Ten-simple-rules-for-the-computatio.pdf",
    "date_published": "2019-11-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". As before, we set the means of each bandit at 1 1⁄4 0 : 2 and 2 1⁄4 0 : 8 and the number of trials at T 1⁄4 1000 . We then simulated the actions of the model according to Equtions 3 and 4 , with learning rate, a , and softmax temperature, b , set according to a ~ U ð 0 ; 1 Þ and b ~ Exp ð 10 Þ (9) After simulating the model, we fit the parameters using a maximum likelihood approach to get fit values of learning rate, a , and softmax parameter, b . We then repeated this process 1000 times using new values of a and b each time. The results are plotted in Box 4—figure 1 below. As is clear from this plot, there is fairly good agreement between the simulated and fit paramter values. In addition, we can see that the fit for b is best with a range, 1 < b < 10 , and that ouside this range, the correspondence between simulation and fit is not as good. If we further select points where parameter recovery for a is bad (i.e., when j a sim a fit j > 0 : 25 , grey dots in Box 4—figure 1 ), we find that parameter recovery for a is worse when b is outside of the range. Depending on the values of b that we obtain by fitting human behavior, this worse corrspondence at small and large b values may or may not be problematic. It may be a good idea Wilson and Collins. eLife 2019;8:e49547. DOI: https://doi.org/10.7554/eLife.49547 13 of 33 Review Article Neuroscience to use the range of parameters obtained from fitting the real data to test the quality of recovery within the range that matters. Box 4—figure 1. Parameter recovery for the Rescorla Wagner model (model 3) in the bandit task with 1000 trials. Grey dots in both panels correspond to points where parameter recovery for a is bad. Can you arbitrate between different models? In model comparison, our goal is to determine which model, out of a set of possible models, is most likely to have generated the data",
    "chunk_id": "15747544008463_1..33.json_chunk_28"
  },
  {
    "document_type": "research_paper",
    "title": "Ten simple rules for the computational modeling of behavioral data",
    "author": "Robert C Wilson, Anne GE Collins",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Wilson-2019-Ten-simple-rules-for-the-computatio.pdf",
    "date_published": "2019-11-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Can you arbitrate between different models? In model comparison, our goal is to determine which model, out of a set of possible models, is most likely to have generated the data. There are a number of different ways to make this comparison (summarized in more detail in Appendix 2) that involve different approximations to the Bayesian evdence for each model (e.g., Daw, 2011 ; Rigoux et al., 2014 ). Here, we focus on the most common method which is related to the log-likelihood computed in ’Fit the parameters’. A simplistic approach to model comparison would be to compare the log-likelihoods of each model at the best fitting parameter settings, p ð d 1 : T j ^ m ; m Þ . However, if the data, d 1 : T , used to evaluate the log-likelihood are the same as those used to fit the parameters, then this approach will lead to overfitting, as the model with the most free parameters will almost always fit this ‘training’ data best. As an extreme example, consider the case of a model with one ‘parameter’ per choice, which is the identity of the choice the person actually made. Such a ‘model’ would fit the data perfectly, but would of course tell us nothing about how the choices were actually determined and would make no predictions about what choices would be made in a different setting. Overfitting is a problem in that it decreases the generalizability of the model: it makes it less likely that the conclsions drawn would apply to a different sample. One way to avoid overfitting is to perform cross-validation: by measuring fit on held-out data, we directly test generalizability. However, this is not always possible for practical reasons (number of samples) or more fundamental ones (dependence between data points). Thus, other methods mitgate the risk of overfitting by approximately accounting for the degrees of freedom in the model. There are several methods for doing this (including penalties for free parameters), which are dicussed in more detail in the Appendices",
    "chunk_id": "15747544008463_1..33.json_chunk_29"
  },
  {
    "document_type": "research_paper",
    "title": "Ten simple rules for the computational modeling of behavioral data",
    "author": "Robert C Wilson, Anne GE Collins",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Wilson-2019-Ten-simple-rules-for-the-computatio.pdf",
    "date_published": "2019-11-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". There are several methods for doing this (including penalties for free parameters), which are dicussed in more detail in the Appendices. There is a rich theoretical literature debating which method is best ( Wagenmakers and Farrell, 2004 ; Vandekerckhove et al., 2015 ). Here, we do not position ourselves in this theoretical debate, and instead focus on one of the simplest methods, the Bayes Information Criterion, BIC , which has an explicit penalty for free parameters. BIC 1⁄4 2 log ^ LL þ k m log ð T Þ (10) where ^ LL is the log-likelihood value at the best fitting parameter settings, and k m is the number of parameters in model m . The model with the smallest BIC score is the model that best fits the data. Thus, the positive effect of k m in the last term corresponds to a penalty for models with large nubers of parameters. While Equation 10 is simple enough to apply in order to find the model that, apparently, best fits your data, it is important to check that your model comparison process gives sensible results for Wilson and Collins. eLife 2019;8:e49547. DOI: https://doi.org/10.7554/eLife.49547 14 of 33 Review Article Neuroscience simulated data. Just as parameter fitting should be validated by parameter recovery on simulated data, so model comparison should be validated by model recovery on simulated data. More specifically, model recovery involves simulating data from all models (with a range of parameter values carefully selected as in the case of parameter recovery) and then fitting that data with all models to determine the extent to which fake data generated from model A is best fit by model A as opposed to model B . This process can be summarized in a confusion matrix (see Box 5—figure 1 below for an example) that quantifies the probability that each model is the best fit to data generated from the other models, that is, p ð fit model 1⁄4 B j simulated model 1⁄4 A Þ . In a perfect world, the confusion matrix will be the identity matrix, but in practice, this is not always the case (e",
    "chunk_id": "15747544008463_1..33.json_chunk_30"
  },
  {
    "document_type": "research_paper",
    "title": "Ten simple rules for the computational modeling of behavioral data",
    "author": "Robert C Wilson, Anne GE Collins",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Wilson-2019-Ten-simple-rules-for-the-computatio.pdf",
    "date_published": "2019-11-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". In a perfect world, the confusion matrix will be the identity matrix, but in practice, this is not always the case (e. g., Wilson and Niv, 2011 ). When computing and interpreting a confusion matrix it is important to keep the following points in mind: Compare different methods of model comparison If the confusion matrix has large off-diagonal components, then you have a problem with model recovery. There are a number of factors that could cause this problem, ranging from a bug in the code to an underpowered experimental design. However, one cause that is worth investigating is whether you are using the wrong method for penalizing free parameters. In particular, different measures penalize parameters in different ways that are ‘correct’ under different assumptions. If your confusion matrix is not diagonal, it may be that the assumptions underlying your measures (e.g. BIC) do not hold for your models, in which case it might be worth trying another metric for model comparison (e.g., AIC [ Wagenmakers and Farrell, 2004 ]; see Appendix 2). Be careful with the choice of parameters when computing the confusion matrix Just as parameter recovery may only be successful in certain parameter regimes, so too can model recovery depend critically on the parameters chosen to simulate the models. In some parameter regimes, two models may lead to very different behavior, but they may be indistinguishable in other parameter regimes (see Box 5—figure 1 below). As with parameter recovery, we believe that the best approach is to match the range of the parameters to the range seen in your data, or to the range that you expect from prior work. A note on interpreting the confusion matrix As described above, and in keeping with standard practice from statistics, the confusion matrix is defined as the probability that data simulated by one model is best fit by another, that is, p ð fit model j simulated model Þ",
    "chunk_id": "15747544008463_1..33.json_chunk_31"
  },
  {
    "document_type": "research_paper",
    "title": "Ten simple rules for the computational modeling of behavioral data",
    "author": "Robert C Wilson, Anne GE Collins",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Wilson-2019-Ten-simple-rules-for-the-computatio.pdf",
    "date_published": "2019-11-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". However, when we fit a model to real data, we are usually more inteested in making the reverse inference — that is, given that model B fits our data best, which model is most likely to have generated the data? This is equivalent to computing p ð simulated model j fit model Þ . Note that this measure, which we term the ‘inversion matrix’ to distiguish it from the confusion matrix, is not the same as the confusion matrix unless model recovery is perfect. Of course, the inversion matrix can be computed from the confusion matrix using Bayes rule (see Appendix 3) and it may be useful to report it in cases where the confusion matrix is not diagonal. The elephant in the room with model comparison As wonderful as it is to find that your model ‘best’ fits the behavioral data, the elephant in the room (or perhaps more correctly not in the room) with all model comparison is that it only tells you which of the models you considered fits the data best. In and of itself, this is rather limited information as there are infinitely many other models that you did not consider. This makes it imperative to start with a good set of models that rigorously capture the competing hypotheses (that is, think hard in Step 2). In addition, it will be essential to validate (at least) your winning model (see Step 9) to show how simulating its behavior can generate the patterns seen in the data that you did not explicitly fit, and thus obtain an absolute measure of how well your model relates to your data. Wilson and Collins. eLife 2019;8:e49547. DOI: https://doi.org/10.7554/eLife.49547 15 of 33 Review Article Neuroscience Box 5. Example: confusion matrices in the bandit task. To illustrate model recovery, we simulated the behavior of the five models on the two-armed bandit task. As before, the means were set at 1 1⁄4 0 : 2 and 2 1⁄4 0 : 8 , and the number of trials was set at T 1⁄4 1000 . For each simulation, model parameters were sampled randomly for each model",
    "chunk_id": "15747544008463_1..33.json_chunk_32"
  },
  {
    "document_type": "research_paper",
    "title": "Ten simple rules for the computational modeling of behavioral data",
    "author": "Robert C Wilson, Anne GE Collins",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Wilson-2019-Ten-simple-rules-for-the-computatio.pdf",
    "date_published": "2019-11-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". As before, the means were set at 1 1⁄4 0 : 2 and 2 1⁄4 0 : 8 , and the number of trials was set at T 1⁄4 1000 . For each simulation, model parameters were sampled randomly for each model. Each simulated data set was then fit to each of the given models to determine which model fit best (according to BIC). This process was repeated 100 times to compute the confsion matrices which are plotted below in Box 5—figure 1A and B . The difference between these two confusion matrices is in the priors from which the simulation parameters were sampled. In panel A, parameters were sampled from the following priors: Model Priors Model 1 b ~ U ð 0 ; 1 Þ Model 2 ~ U ð 0 ; 1 Þ Model 3 a ~ U ð 0 ; 1 Þ , b ~ Exp ð 1 Þ Model 4 a c ~ U ð 0 ; 1 Þ , b c ~ Exp ð 1 Þ Model 5 a ~ U ð 0 ; 1 Þ , b ~ Exp ð 1 Þ , a c ~ U ð 0 ; 1 Þ , b c ~ Exp ð 1 Þ In panel B, all of the softmax parameters b and b c were increased by 1. This has the effect of reducing the amount of noise in the behavior, which makes the models more easily identifiable and the corresponding confusion matrix more diagonal. The fact that the confusion matrix can be so dependent on the simulating parameter values means that it is crucial to match the simlation parameters to the actual fit parameters as best as possible. Models that are identifiable in one parameter regime may be impossible to distinguish in another! In addition to the confusion matrices, we also plot the inversion matrices in Box 5—figure 1C and D . These are computed from the confusion matrices using Bayes rule assuming a uniform prior on models (see Appendix 3). These matrices more directly address the question of how to interpret a model comparison result where one model fits a particular subject best",
    "chunk_id": "15747544008463_1..33.json_chunk_33"
  },
  {
    "document_type": "research_paper",
    "title": "Ten simple rules for the computational modeling of behavioral data",
    "author": "Robert C Wilson, Anne GE Collins",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Wilson-2019-Ten-simple-rules-for-the-computatio.pdf",
    "date_published": "2019-11-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". These matrices more directly address the question of how to interpret a model comparison result where one model fits a particular subject best. 1 0 0 0 0 0.01 0.99 0 0 0 0.34 0.12 0.54 0 0 0.35 0.09 0 0.54 0.01 0.14 0.04 0.26 0.26 0.3 1 2 3 4 5 fit model 1 2 3 4 5 simulated model 0.97 0.03 0 0 0 0.04 0.96 0 0 0 0.06 0 0.94 0 0 0.06 0 0.01 0.93 0 0.03 0 0.1 0.15 0.72 1 2 3 4 5 fit model 1 2 3 4 5 simulated model 0.54 0 0 0 0 0.01 0.8 0 0 0 0.18 0.1 0.68 0 0 0.19 0.07 0 0.68 0.03 0.08 0.03 0.33 0.33 0.97 1 2 3 4 5 fit model 1 2 3 4 5 simulated model 0.84 0.03 0 0 0 0.03 0.97 0 0 0 0.05 0 0.9 0 0 0.05 0 0.01 0.86 0 0.03 0 0.1 0.14 1 1 2 3 4 5 fit model 1 2 3 4 5 simulated model confusion matrix: p(fit model | simulated model) inversion matrix: p(simulated model | fit model) A B C D Wilson and Collins. eLife 2019;8:e49547. DOI: https://doi.org/10.7554/eLife.49547 16 of 33 Review Article Neuroscience Box 5—figure 1. Confusion matrices in the bandit task showing the effect of prior parameter distributions on model recovery. Numbers denote the probability that data generated with model X are best fit by model Y, thus the confusion matrix represents p ð fit model j simulated model Þ . ( A ) When there are relatively large amounts of noise in the models (possibility of small values for b and b c ), models 3–5 are hard to distinguish from one another. ( B ) When there is less noise in the models (i.e. minimum value of b and b c is 1), the models are much easier to identify. ( C ) The inversion matrix provides easier interpretation of fitting results when the true model is unknown. For example, the confusion matrix indicates that M1 is always perfectly recovered, while M5 is only recovered 30% of the time. By contrast, the inversion matrix shows that if M1 is the best fiting model, our confidence that it generated the data is low (54%), but if M5 is the best fitting model, our confidence that it did generate the data is high (97%). ( D ) Similar results with less noise in simulations",
    "chunk_id": "15747544008463_1..33.json_chunk_34"
  },
  {
    "document_type": "research_paper",
    "title": "Ten simple rules for the computational modeling of behavioral data",
    "author": "Robert C Wilson, Anne GE Collins",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Wilson-2019-Ten-simple-rules-for-the-computatio.pdf",
    "date_published": "2019-11-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". ( D ) Similar results with less noise in simulations. Run the experiment and analyze the actual data Once all the previous steps have been completed, you can finally move on to modeling your empircal data. The first step to complete is of course to analyze the data without the model, in the same way that we recommended for model simulations in section ’Simulate, simulate, simulate!’ This model-independent analysis is extremely important: you designed the experiment to test specific hypotheses, and constructed models to reflect them. Simulations showed expected patterns of behaviors given those hypotheses. If the model-independent analyses do not show evidence of the expected results, there is almost no point in fitting the model. Instead, you should go back to the beginning, either re-thinking the computational models if the analyses show interesting patterns of behavior, or re-thinking the experimental design or even the scientific question you are trying to answer. In our experience, if there is no model-independent evidence that the processes of interest are engaged, then a model-based analysis is unlikely to uncover evidence for the processes either. If, however, the behavioral results are promising, the next step is to fit the models developed prviously and to perform model comparison. After this step, you should check that the parameter range obtained with the fitting is within a range where parameter and model recovery were good. If the range is outside what you explored with simulations, you should go back over the parameter and model recovery steps to match the empirical parameter range, and thus ensure that the model fitting and model comparison procedures lead to interpretable results. An important point to remember is that human behavior is always messier than the model, and it is unlikely that the class of models you explored actually contains the ‘real’ model thatgenerated human behavior",
    "chunk_id": "15747544008463_1..33.json_chunk_35"
  },
  {
    "document_type": "research_paper",
    "title": "Ten simple rules for the computational modeling of behavioral data",
    "author": "Robert C Wilson, Anne GE Collins",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Wilson-2019-Ten-simple-rules-for-the-computatio.pdf",
    "date_published": "2019-11-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". At this point, you should consider looping back to Steps 2–5 to improve the models, guided by in depth model-independent analysis of the data. For example, you may consider modeling ‘unimportant parameters’, representing mechanisms that are of no interest to your scientific question but that might still affect your measures. Modeling these unimportant parameters usually captures variance in the behavior that would otherwise be attributed to noise, and as such, makes for a better estimation of ‘important’ parameters. For exaple, capturing pre-existing biases (e.g. a preference for left/right choices) in a decision or learning task provides better estimation of the inverse temperature, by avoiding attributing systematic biases to noise, which then affords better estimation of other parameters like the learning rate (this is evdent in Box 6—figure 1 ). Box 6. Example: improving parameter recovery by modeling unimportant parameters. To illustrate the effect that ‘unimportant’ parameters (i.e., parameters that represent mechnisms that are of no interest to your scientific question, but may still affect your measures) can have on fitting results, we model the effect of a side bias on parameter recovery in Model 3. In particular, we assume that, in addition to choosing based on learned value, the model also had a side bias, B , that effectively changes the value of the left bandit. That is, in the two-bandit case, the choice probabilities are given by Wilson and Collins. eLife 2019;8:e49547. DOI: https://doi.org/10.7554/eLife.49547 17 of 33 Review Article Neuroscience p left t 1⁄4 1 1 þ exp b ð Q right t Q left t B Þ (11) We then simulated behavior with this model for a range of parameter values and fit the model with the original version of model 3, without the bias, and the modified version of model 3, with the bias. In this simulation, agents learn for 10 independent two-armed bandits in succesive 50-trial blocks, with 1⁄4 f 0 : 2 ; 0 : 8 g or 1⁄4 f 0 : 8 ; 0 : 2 g in different blocks",
    "chunk_id": "15747544008463_1..33.json_chunk_36"
  },
  {
    "document_type": "research_paper",
    "title": "Ten simple rules for the computational modeling of behavioral data",
    "author": "Robert C Wilson, Anne GE Collins",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Wilson-2019-Ten-simple-rules-for-the-computatio.pdf",
    "date_published": "2019-11-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". In this simulation, agents learn for 10 independent two-armed bandits in succesive 50-trial blocks, with 1⁄4 f 0 : 2 ; 0 : 8 g or 1⁄4 f 0 : 8 ; 0 : 2 g in different blocks. For simplicity, we assumed that the agent treats each block as independent, and started from the same initial vaues of Q right 1 1⁄4 Q left 1 1⁄4 0 : 5 . As can be seen below, including the ‘unimportant’ bias in the fit greatly improves the extent to which both the learning rate, a , and softmax parameter, b , can be recovered. 0 0.2 0.4 0.6 simulated α 0 0.5 1 fit α 0 5 10 simulated β 0 5 10 fit β 0 0.2 0.4 0.6 simulated α 0 0.5 1 fit α 0 5 10 simulated β 0 5 10 fit β 0 0.1 0.2 simulated bias 0 0.1 0.2 0.3 fit bias model 3 without bias model 3 including bias Box 6—figure 1. Modeling unimportant parameters provides better estimation of important parameters. The top row shows parameter recovery of the model without the bias term. The bottom row shows much more accurate parameter recovery, for all parameters, when the bias parameter is included in the model fits. Validate (at least) the winning model All the previous steps measure a relative goodness of fit. Does model A fit better than model B? However, before interpreting any results from a model, it is essential to ensure that the model actally usefully captures the data in an absolute sense. This step is called model validation, and should never be skipped: it is possible to fit a model, get high fit measures, and nevertheless completely miss the essence of the behavior. One method for model validation is computing the average trial likelihood as an absolute mesure of fit. Although this measure has some nice properties — for example, the best possible value is one when the model predicts behavior perfectly — it offers limited value when choices are actually stochastic (which may be the case in many situations; Drugowitsch et al., 2016 ) or the environment is complex",
    "chunk_id": "15747544008463_1..33.json_chunk_37"
  },
  {
    "document_type": "research_paper",
    "title": "Ten simple rules for the computational modeling of behavioral data",
    "author": "Robert C Wilson, Anne GE Collins",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Wilson-2019-Ten-simple-rules-for-the-computatio.pdf",
    "date_published": "2019-11-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". In these cases, the best possible likelihood per trial is less than 1, but it is not known what the best possible likelihood per trial could be. For this reason, although the likelihood per trial can be a useful tool for model validation ( Leong et al., 2017 ), interpreting it as an absolute measure of model fit is of limited value. A better method to validate a model is to simulate it with the fit parameter values ( Palminteri et al., 2017 ; Nassar and Frank, 2016 ; Navarro, 2019 ), a procedure long performed by statisticians as part of the ‘posterior predictive check’ ( Roecker, 1991 ; Gelman et al., 1996 ). You should then analyze the simulated data in the same way that you analyzed the empirical data, to veify that all important behavioral effects are qualitatively and quantitatively captured by the Wilson and Collins. eLife 2019;8:e49547. DOI: https://doi.org/10.7554/eLife.49547 18 of 33 Review Article Neuroscience simulations with the fit parameters. For example, if you observe a qualitative difference between two conditions empirically, the model should reproduce it. Likewise, if a learning curve reaches a quantitative asymptote of 0.7, simulations shouldn’t reach a vastly different one. Some researchers analyze the posterior prediction of the model conditioned on the past history, instead of simulated data. In our previous notation, they evaluate the likelihood of choice c t given past data, d 1 : t 1 , where the past data includes choices made by the subject, not choices made by the model, p ð c t j d 1 : t 1 ; s t ; m ; m Þ . In some cases, this approach leads to very similar results to simulations, because simulations sample choices on the basis of a very similar probability, where the past data, d 1 : t 1 , include choices made by the model . However, it can also be dramatically different if the path of actions sampled by the participant is widely different from the paths likely to be selected by the model (leading to very different past histories)",
    "chunk_id": "15747544008463_1..33.json_chunk_38"
  },
  {
    "document_type": "research_paper",
    "title": "Ten simple rules for the computational modeling of behavioral data",
    "author": "Robert C Wilson, Anne GE Collins",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Wilson-2019-Ten-simple-rules-for-the-computatio.pdf",
    "date_published": "2019-11-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Palminteri and colleagues ( Palminteri et al., 2017 ) offer a striking example of this effect, where Model A fits better than Model B by any quantitative measure of model comparison, but is completely unable to capture the essence of the behavior. In their example, data are generated with a reinforcement learning agent (which takes the place of the subject) on a reversal learning task (where a choice that was previously good becomes bad, and reciprocally). These data are then fit with either a win-stay lose-shift model (model B), or a simplistic choice kernel model, which assumes that previous choices tend to be repeated (model A). Because of the autocorrelation in the choices made by the reinforcement learning agent, model A, which tends to repeat previous actions, fits better than model B, whose win-stay-lose-shift choices only depend on the action and outcome from the last trial. However, model A is completely insensitive to reward, and thus is unable to generate a reversal behavior when it is simulated with the fit model parameters. Thus, in this case, model A should be discarded, despite a greater quantitative fit. Nevertheless, the fact that the best validating model B captures less variance than model A should serve as a warning that model B is missing crcial components of the data and that a better model probably exists. This should incite the researcher to go back to the drawing board to develop a better model, for example one that cobines elements of both models or a different model entirely, and perhaps a better experiment to test it. More generally, if your validation step fails, you should go back to the drawing board! This may involve looking for a better model, as well as redesigning the task. Be careful interpreting results from a model that is not well validated! Of course, exactly what it means for a model to ‘fail’ the valdation step is not well defined: no model is perfect, and there is no rule of thumb to tell us when a model is good enough",
    "chunk_id": "15747544008463_1..33.json_chunk_39"
  },
  {
    "document_type": "research_paper",
    "title": "Ten simple rules for the computational modeling of behavioral data",
    "author": "Robert C Wilson, Anne GE Collins",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Wilson-2019-Ten-simple-rules-for-the-computatio.pdf",
    "date_published": "2019-11-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". The most important aspect of validation is for you (and your readers) to be aware of its limitations, and in which ways they may influence any downstream results. Box 7. Example: model validation where the fit model performs too well. Most examples of model validation involve a case where a model that fits well performs poorly on the task in simulation. For example, in the Palminteri et al. (2017) example, the choice kenel model cannot perform the task at all because its behavior is completely independent of reward. Here, we offer a different example of failed model validation in which the model peforms better in simulation than the predicted and observed artificial agent’s behavior. Morover, this model appears to fit data generated from a different model better than it fits data generated from itself! In this example, we imagine a deterministic stimulus-action learning task in which agents are presented with one of three stimuli ( s 1 , s 2 , and s 3 ), which instruct them which of three actions ( a 1 , a 2 , and a 3 ) will be rewarded when chosen. a 1 is the correct choice for both stimuli s 1 and s 2 , a 3 for s 3 , and a 2 is incorrect for all stimuli. The two models that we consider are both reinforcement learning agents. The first, a ‘blind’ agent does not see the stimulus at all and learns only about the value of the three different actions, that is Q ð a i Þ , regardless of the stimulus. The second, a ‘state-based’ agent, observes the stimulus and learns a value for each action that can be different for each stimulus, that is Q ð a i ; s i Þ . Parameters in the models are set such that the learning curves for the two agents are approximately equal ( Box 7—figure 1A ). See appendices for details of the models. Wilson and Collins. eLife 2019;8:e49547. DOI: https://doi.org/10.7554/eLife.49547 19 of 33 Review Article Neuroscience We then consider how both models fit behavior simulated by either of these models",
    "chunk_id": "15747544008463_1..33.json_chunk_40"
  },
  {
    "document_type": "research_paper",
    "title": "Ten simple rules for the computational modeling of behavioral data",
    "author": "Robert C Wilson, Anne GE Collins",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Wilson-2019-Ten-simple-rules-for-the-computatio.pdf",
    "date_published": "2019-11-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". eLife 2019;8:e49547. DOI: https://doi.org/10.7554/eLife.49547 19 of 33 Review Article Neuroscience We then consider how both models fit behavior simulated by either of these models. In Box 7—figure 1B , we plot the average likelihood with which the state-based model predicts the actual choices of the blind and state-based agents, that is the average p ð c t j d 1 : t 1 ; m ; m 1⁄4 state-based Þ . As is clear from this figure, the state-based model predicts choices from the blind agent with higher likelihood than choices from the state-based agent! While counter intuitive, this result does not imply that the state-based model is unable to fit its own behavior. Instead, this result reflects the difference in noise (softmax parameters) between the two agents. The blind RL agent has a low noise parameter, allowing the state-based model to fit it quite well. Conversely, the state-based RL agent has a high noise parameter, meaning that the behavior is harder to predict even when it is fit with the correct model. That the state-based model captures state-based behavior better than it fits blind behavior is illustrated in Box 7—figure 1C . Here, we plot the simulated learning curves of the state-based model using the parameter values that were fit to either the state-based agent or the blind agent. Although the parameters of the state-based model obtained through the fit to the statbased agent generate a learning curve that is quite similar to that of the agent (compare blue lines in Box 7—figure 1A and C ), the state-based fit to the blind agent performs too well (copare yellow lines in Box 7—figure 1A and C ). Thus the model validation step provides support for the state-based model when it is the corect model of behavior, but rules out the state-based model when the generating model was different. The take-away from this example should be that measures of model-fit and model comparison cannot replace a thorough validation step, which can contradict them",
    "chunk_id": "15747544008463_1..33.json_chunk_41"
  },
  {
    "document_type": "research_paper",
    "title": "Ten simple rules for the computational modeling of behavioral data",
    "author": "Robert C Wilson, Anne GE Collins",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Wilson-2019-Ten-simple-rules-for-the-computatio.pdf",
    "date_published": "2019-11-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". The take-away from this example should be that measures of model-fit and model comparison cannot replace a thorough validation step, which can contradict them. 1 5 10 15 time step 0.2 0.4 0.6 0.8 1 p(correct) 'subject' learning curves blind RL state-based RL 1 5 10 15 time step 0.2 0.4 0.6 0.8 1 likelihood of choice likelihood of state-based RL model 1 5 10 15 time step 0.2 0.4 0.6 0.8 1 p(correct) simulated learning curves from state-based RL A B C Box 7—figure 1. An example of successful and unsuccessful model validation. ( A ) Behavior is simulated by one of two reinforcement learning models (a blind agent and a state-based agent) performing the same learning task. Generative parameters of the two models were set so that the learning curves of the models were approximately equal. ( B ) Likelihood per trial seems to indicate a worse fit for the state-based-simulated data than the blind-simulated data. ( C ) However, validation by model simulations with fit parameters shows that the state-based model captures the data from the state-based agent (compare dark learning curves in panels A and C), but not from the the blind agent (yellow learning curves in panels A and C). Analyze the winning model To minimize risks of p-hacking, model-dependent analyses should only be performed on the winning model, after researchers are satisfied that the model captures the behavior. One particularly poweful application of model-based analysis of behavior involves estimating the latent variables in the model. Latent variables are the hidden components of the algorithms underlying the behavior that are not directly observable from the behavior itself. These latent variables shed light on the internal workings of the model and, if we are to take the model seriously, should have some representation in the subjects’ mind and brain ( Cohen et al., 2017 ; O’Doherty et al., 2007 ). Extracting latent variables from the model is as simple as simulating the model and recording how the latent variables evolve over time",
    "chunk_id": "15747544008463_1..33.json_chunk_42"
  },
  {
    "document_type": "research_paper",
    "title": "Ten simple rules for the computational modeling of behavioral data",
    "author": "Robert C Wilson, Anne GE Collins",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Wilson-2019-Ten-simple-rules-for-the-computatio.pdf",
    "date_published": "2019-11-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Extracting latent variables from the model is as simple as simulating the model and recording how the latent variables evolve over time. The parameters of the simulation should be the fit paraeters for each subject. In most cases, it is useful to yoke the choices of the model to the choices the Wilson and Collins. eLife 2019;8:e49547. DOI: https://doi.org/10.7554/eLife.49547 20 of 33 Review Article Neuroscience participants actually made, thus the latent variables evolve according to the experience participants actually had. This is especially true if the choices can influence what participants see in the future. Once estimated, the latent variables can be used in much the same way as any other observable variable in the analysis of data. Perhaps the most powerful application comes when combined with physiological data such as pupil dilation, EEG, and fMRI. The simplest of these approaches uses liear regression to test whether physiological variables correlate with the latent variables of interest. Such an approach has led to a number of insights into the neural mechanisms underlying behavior ( Nassar et al., 2012 ; Daw et al., 2011 ; Donoso et al., 2014 ; Collins and Frank, 2018 ; Fischer and Ullsperger, 2013 ), although, as with any modeling exercise, latent variable analysis should be done with care ( Wilson and Niv, 2015 ). Other model-dependent analyzes include studying individual differences as captured by fit parameters. Fit parameters can be treated as a dependent variable in continuous analyses (e.g. corelating with age, symptom scales, and so on [ Gillan et al., 2016 ]) or group comparisons (e.g. patients vs. matched controls [ Collins et al., 2014 ]). Reporting model-based analyses Congratulations! You have developed, simulated, and fit your model (and maybe several other copeting models) to your data. You have estimated parameters, computed model comparison scores, and validated whether your model can generate realistic-looking behavior",
    "chunk_id": "15747544008463_1..33.json_chunk_43"
  },
  {
    "document_type": "research_paper",
    "title": "Ten simple rules for the computational modeling of behavioral data",
    "author": "Robert C Wilson, Anne GE Collins",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Wilson-2019-Ten-simple-rules-for-the-computatio.pdf",
    "date_published": "2019-11-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". You have estimated parameters, computed model comparison scores, and validated whether your model can generate realistic-looking behavior. It’s time to start writing! But what exactly should you report in your paper? And how should you report it? Model selection In many modeling papers, a key conclusion from the work is that one model fits the data better than other competing models. To make this point convincingly, we recommend including the following things in your paper, either as main results or in the supplementary material. Model recovery analysis Confusion matrix Before anyone should believe your model comparison results, you need to demonstrate the ability of your analysis/experiment to distinguish between models under ideal conditions of simulated data. The best way to visualize these results is with a confusion matrix, as outlined in section ’Can you arbtrate between different models’? If the model comparison result is central to your paper, we recomend including the confusion matrix as a figure in the main text. If model comparison is less important, we recommend including it in the supplementary materials. Number of subjects best fit by each model The simplest way to visualize how well the winning model fits the data is with a histogram showing the number of subjects best fit by each model. Obviously if all subjects are best fit with one model, the story is simple. The more likely scenario is that some subjects will be best fit by other models. Such a result is important to acknowledge in the paper as it may reflect the use of different stratgies by different people or that the ‘correct’ model lies somewhere in between the models you have considered. Group level statistics Exceedance probabilities A more sophisticated and less biased ( Piray et al., 2018 ) way to report model comparison results is by computing the probability that a single model best describes all the data. This is clearly an assumption whose merits should be discussed in your paper",
    "chunk_id": "15747544008463_1..33.json_chunk_44"
  },
  {
    "document_type": "research_paper",
    "title": "Ten simple rules for the computational modeling of behavioral data",
    "author": "Robert C Wilson, Anne GE Collins",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Wilson-2019-Ten-simple-rules-for-the-computatio.pdf",
    "date_published": "2019-11-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". This is clearly an assumption whose merits should be discussed in your paper. In cases where it is valid, the method of Rigoux et al. (2014) computes these ‘Exceedance Probabilities’, the probability that each model generated all the data. These probabilities can also be reported in histogram or table form. Model-independent measures of simulated data. The cleanest way to demonstrate the superiority of one model is if that model can account for qualitative patterns in the data that are not captured by other models (see section ’Validate (at least) the winning model’). Wilson and Collins. eLife 2019;8:e49547. DOI: https://doi.org/10.7554/eLife.49547 21 of 33 Review Article Neuroscience Parameter fits Many modeling papers involve fitting parameters to behavioral data. In some cases this is the main point of the paper, for example to show that parameter values differ between groups or treatments, in other cases parameter fitting is secondary to model comparison. In all cases, we recommend reporting the fit parameter values in as transparent a way as possible (i.e. more than just the means and standard errors). Report distributions of parameter values The simplest way to report parameter fits is to plot a distribution of all fit parameter values, for example in the form of a histogram (e.g. Figure S1 in Wilson et al., 2013 and Nassar et al., 2018 ) or a cloud of points (e.g. Figure 5 in Huys et al., 2011 ). This gives a great sense of the variability in each parameter across the population and can also illustrate problems with fitting. For example, if a large number of fit parameters are clustered around the upper and lower bounds, this may indicate a problem with the model. Plot pairwise correlations between fit parameter values A deeper understanding of the relationships between fit parameters can be obtained by making scatter plots of the pairwise correlations between parameters",
    "chunk_id": "15747544008463_1..33.json_chunk_45"
  },
  {
    "document_type": "research_paper",
    "title": "Ten simple rules for the computational modeling of behavioral data",
    "author": "Robert C Wilson, Anne GE Collins",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Wilson-2019-Ten-simple-rules-for-the-computatio.pdf",
    "date_published": "2019-11-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". As with histograms of individual parameters, this approach gives a sense of the distribution of parameters, and can provide evidence of problems with the model; for example, if two parameters trade off against one another, it is a sign that these parameters may be unidentifiable in the experiment. Report parameter recovery Finally, all parameter fit analyses should sit on the shoulders of a comprehensive parameter recovery analysis with simulated data. If parameters cannot be recovered in the ideal case of simulated data, there is little that they can tell us about real behavior. Share your data and code! The most direct way to communicate your results is to share the data and code. This approach encourages transparency and ensures that others can see exactly what you did. Sharing data and code also allows others to extend your analyses easily, by applying it to their own data or adding new models into the mix. Ideally the data you share should be the raw data for the experiment, with minimal or no preprcessing (apart from the removal of identifying information). The code you share should reproduce all steps in your analysis, including any preprocessing/outlier exclusion you may have performed and generating all of the main and supplementary figures in the paper. In a perfect world, both data and code would be shared publicly on sites such as GitHub, DataVerse and so on. However, this is not always possible, for example, if the data come from collaborators who do not agree to data sharing, or if further analyses are planned using the same data set. In this case, we recommend having a clean set of ‘shareable’ code (and hopefully data too) that can be sent via email upon request. Should you always report all of your modeling results? Finally, if you are using an established model, it can be tempting to skip many of the steps outlined above and report only the most exciting results. This temptation can be even greater if you are using code developed by someone else that, perhaps, you do not fully understand",
    "chunk_id": "15747544008463_1..33.json_chunk_46"
  },
  {
    "document_type": "research_paper",
    "title": "Ten simple rules for the computational modeling of behavioral data",
    "author": "Robert C Wilson, Anne GE Collins",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Wilson-2019-Ten-simple-rules-for-the-computatio.pdf",
    "date_published": "2019-11-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". This temptation can be even greater if you are using code developed by someone else that, perhaps, you do not fully understand. In our opinion, taking shortcuts like this is dangerous. For one thing, your experiment or population may be different and the model may perform differently in this regime. For another, quite often ‘established’ models (in the sense that they have been published before), have not been validated in a systematic way. More generally, as with any research technique, when using computational modeling you need to demostrate that you are applying the method correctly, and the that steps we outline here can help. In conclusion, even if developing the model is not the central point of your paper, you should report all of your modeling results. Wilson and Collins. eLife 2019;8:e49547. DOI: https://doi.org/10.7554/eLife.49547 22 of 33 Review Article Neuroscience What now? Looping back A modeler’s work is never done. To paraphrase George Box, there are no correct models, there are only useful models ( Box, 1979 ). To make your model more useful, there are a number of next steps to consider to test whether your model really does describe a process in the mind. Improve the model to account for discrepancies with your existing data set Model fits are never perfect and, even in the best cases, there are often small discrepancies with actual data. The simplest next step is to try to address these discrepancies by improving the model, either by including additional factors (such as side bias or lapse rates) or by devising new models entirely. Use your model to make predictions The best models don’t just explain data in one experiment, they predict data in completely new siuations. If your model does not easily generalize to new situations, try to understand why that is and how it could be adjusted to be more general",
    "chunk_id": "15747544008463_1..33.json_chunk_47"
  },
  {
    "document_type": "research_paper",
    "title": "Ten simple rules for the computational modeling of behavioral data",
    "author": "Robert C Wilson, Anne GE Collins",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Wilson-2019-Ten-simple-rules-for-the-computatio.pdf",
    "date_published": "2019-11-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". If your model does not easily generalize to new situations, try to understand why that is and how it could be adjusted to be more general. If your model does generalize, test its predictions against new data — either data you collect yourself from a new experiment or data from other stuies that (hopefully) have been shared online. Using advanced techniques Another potential next step is to use more powerful modeling techniques. We focused here on the simplest techniques (maximum likelihood estimation and model comparison by BIC) because of their accessibility to beginners, and because most of the advice we give here generalizes to more advanced techniques. In particular, no matter how advanced the modeling technique used, validtion is essential ( Palminteri et al., 2017 ; Nassar and Frank, 2016 ; Huys, 2017 ). Nevertheless, the simple methods described here have known limitations. More advanced techniques attempt to reedy them, but come with their own pitfalls. A complete review of these advanced techniques is beyond the scope of this paper; instead we provide pointers to a few of the most interesting technques for the ambitious reader to pursue. Compute maximum a posteriori (MAP) parameter values Perhaps the simplest step for improving parameter estimates is to include prior information about parameter values. When combined with the likelihood, these priors allow us to compute the postrior, which we can use to find the maximum a posteriori (MAP) parameter values. Although they are still point estimates, with good priors, MAP parameters can be more accurate than parameters estmated with maximum likelihood approaches ( Gershman, 2016 ; Daw, 2011 ), although when the prors are bad, this method has problems of its own ( Katahira, 2016 ). Approximate the full posterior by sampling Point estimates of model parameters, such as those obtained with MLE or MAP, lose interesting information about uncertainty over the parameter distribution",
    "chunk_id": "15747544008463_1..33.json_chunk_48"
  },
  {
    "document_type": "research_paper",
    "title": "Ten simple rules for the computational modeling of behavioral data",
    "author": "Robert C Wilson, Anne GE Collins",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Wilson-2019-Ten-simple-rules-for-the-computatio.pdf",
    "date_published": "2019-11-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Approximate the full posterior by sampling Point estimates of model parameters, such as those obtained with MLE or MAP, lose interesting information about uncertainty over the parameter distribution. Sampling approaches (such as Makov Chain Monte Carlo or MCMC) provide this richer information; furthermore, they allow modelers to investigate more complex assumptions. For example, hierarchical Bayesian approaches make it possible to fit all participants simultaneously, integrating assumptions about their depedence (e.g. one single group, multiple groups, effects of covariates of interest such as age and so on; Lee, 2011 ; Lee and Wagenmakers, 2014 ; Wiecki et al., 2013 ). Advanced optimizers and approximate likelihood Some models have intractable likelihoods, for example if the choice state has too many dimensions, as in continuous movements, or if the model included unobservable choices. There exist methods to approximate likelihoods to relate them quantitatively to data, such as the ABC method ( Turner and Sederberg, 2012 ; Sunna ̊ker et al., 2013 ). There are also advanced methods for finding best fit parameters in a sample-efficient manner when computing the likelihood is expensive ( Acerbi and Ji, 2017 ; Acerbi, 2018 ). Wilson and Collins. eLife 2019;8:e49547. DOI: https://doi.org/10.7554/eLife.49547 23 of 33 Review Article Neuroscience Model selection Bayesian model selection provides less biased, statistically more accurate ways of identifying which model is best at the group level ( Rigoux et al., 2014 ). This may be particularly important when coparing model selection between groups, for example between patients and controls ( Piray et al., 2018 ). Incorporating other types of data We focused on modeling a single type of observable data, choices. However, there is a rich literture on fitting models to other measurements, such as reaction times ( Ratcliff, 1978 ; Ratcliff and Rouder, 1998 ), but also to eye movements and neural data ( Turner et al., 2016 )",
    "chunk_id": "15747544008463_1..33.json_chunk_49"
  },
  {
    "document_type": "research_paper",
    "title": "Ten simple rules for the computational modeling of behavioral data",
    "author": "Robert C Wilson, Anne GE Collins",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Wilson-2019-Ten-simple-rules-for-the-computatio.pdf",
    "date_published": "2019-11-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Furthermore, fiting more than one measurement at a time provides additional constraints to the model, and as such may provide better fit ( Ballard and McClure, 2019 ). However, fitting additional data can increase the complexity of the model-fitting process and additional care must be taken to determine exactly how different types of data should be combined ( Viejo et al., 2015 ). Epilogue Our goal for this paper was to offer practical advice, for beginners as well as seasoned researchers, on the computational modeling of behavioral data. To this end, we offered guidance on how to geerate models, simulate models, fit models, compare models, validate models, and extract latent varables from models to compare with physiological data. We have talked about how to avoid common pitfalls and misinterpretations that can arise with computational modeling, and lingered, quite delierately, on the importance of good experimental design. Many of these lessons were lessons we learned the hard way, by actually making these mistakes for ourselves over a combined 20+ years in the field. By following these steps, we hope that you will avoid some of the errors that slowed our own research, and that the overall quality of computational modeling in behavioral science will improve. Acknowledgements We are grateful to all our lab members who provided feedback on this paper, in particular Beth Barbault, Waitsang Keung, Sarah Master, Sam McDougle, and William Ryan. We are grateful for useful reviewers’ and editors’ feedback, including that from Tim Behrens, Mehdi Khamassi, Ken Norman, Valentin Wyart, and other anonymous reviewers. We also gratefully acknowledge the contribution of many others in our previous labs and collaborations, with whom we learned many of the techniques, tips and tricks presented here. This work was supported by NIA Grant R56 AG061888 to RCW and NSF Grant 1640885 and NIH Grant R01 MH118279 to AGEC",
    "chunk_id": "15747544008463_1..33.json_chunk_50"
  },
  {
    "document_type": "research_paper",
    "title": "Ten simple rules for the computational modeling of behavioral data",
    "author": "Robert C Wilson, Anne GE Collins",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Wilson-2019-Ten-simple-rules-for-the-computatio.pdf",
    "date_published": "2019-11-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". This work was supported by NIA Grant R56 AG061888 to RCW and NSF Grant 1640885 and NIH Grant R01 MH118279 to AGEC. Additional information Funding Funder Grant reference number Author National Institute on Aging R56 AG061888 Robert C Wilson National Science Foundation 1640885 Anne GE Collins National Institute of Mental Health R01 MH118279 Anne GE Collins The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication. Author ORCIDs Robert C Wilson https://orcid.org/0000-0002-2963-2971 Anne GE Collins https://orcid.org/0000-0003-3751-3662 Wilson and Collins. eLife 2019;8:e49547. DOI: https://doi.org/10.7554/eLife.49547 24 of 33 Review Article Neuroscience References Abbott JT , Austerweil JL, Griffiths TL. 2015. Random walks on semantic networks can resemble optimal foraging. Psychological Review 122 :558–569. DOI: https://doi.org/10.1037/a0038693 , PMID: 25642588 Acerbi L . 2018. Variational bayesian monte carlo. Advances in Neural Information Processing Systems 8213– 8223. https://papers.nips.cc/paper/8043-variational-bayesian-monte-carlo . Acerbi L , Ji W. 2017. Practical bayesian optimization for model fitting with bayesian adaptive direct search. Advances in Neural Information Processing Systems 1836–1846. https://papers.nips.cc/paper/6780-practicabayesian-optimization-for-model-fitting-with-bayesian-adaptive-direct-search . Akaike H . 1974. A new look at the statistical model identification. IEEE Transactions on Automatic Control 19 : 716–723. DOI: https://doi.org/10.1109/TAC.1974.1100705 Ballard IC , McClure SM. 2019. Joint modeling of reaction times and choice improves parameter identifiability in reinforcement learning models. Journal of Neuroscience Methods 317 :37–44. DOI: https://doi.org/10.1016/j. jneumeth.2019.01.006 , PMID: 30664916 Batchelder WH , Riefer DM. 1990. Multinomial processing models of source monitoring. Psychological Review 97 :548–564. DOI: https://doi.org/10.1037/0033-295X.97.4.548 Box GE . 1979",
    "chunk_id": "15747544008463_1..33.json_chunk_51"
  },
  {
    "document_type": "research_paper",
    "title": "Ten simple rules for the computational modeling of behavioral data",
    "author": "Robert C Wilson, Anne GE Collins",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Wilson-2019-Ten-simple-rules-for-the-computatio.pdf",
    "date_published": "2019-11-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". 1990. Multinomial processing models of source monitoring. Psychological Review 97 :548–564. DOI: https://doi.org/10.1037/0033-295X.97.4.548 Box GE . 1979. Robustness in the strategy of scientific model building. In: Robustness in Statistics . Elsevier. p. 201–236. DOI: https://doi.org/10.1016/b978-0-12-438150-6.50018-2 Breiman L . 2001. Statistical modeling: the two cultures (with comments and a rejoinder by the author). Statistical Science 16 :199–231. DOI: https://doi.org/10.1214/ss/1009213726 Broomell SB , Bhatia S. 2014. Parameter recovery for decision modeling using choice data. Decision 1 :252–274. DOI: https://doi.org/10.1037/dec0000020 Busemeyer JR , Diederich A. 2010. Cognitive Modeling . Sage. Byrd RH , Gilbert JC, Nocedal J. 2000. A trust region method based on interior point techniques for nonlinear programming. Mathematical Programming 89 :149–185. DOI: https://doi.org/10.1007/PL00011391 Cavanagh JF , Wiecki TV, Kochar A, Frank MJ. 2014. Eye tracking and pupillometry are indicators of dissociable latent decision processes. Journal of Experimental Psychology: General 143 :1476–1488. DOI: https://doi.org/ 10.1037/a0035813 Cohen JD , Dunbar K, McClelland JL. 1990. On the control of automatic processes: a parallel distributed processing account of the stroop effect. Psychological Review 97 :332–361. DOI: https://doi.org/10.1037/0033- 295X.97.3.332 , PMID: 2200075 Cohen JD , Daw N, Engelhardt B, Hasson U, Li K, Niv Y, Norman KA, Pillow J, Ramadge PJ, Turk-Browne NB, Willke TL. 2017. Computational approaches to fMRI analysis. Nature Neuroscience 20 :304–313. DOI: https:// doi.org/10.1038/nn.4499 , PMID: 28230848 Collins AG , Brown JK, Gold JM, Waltz JA, Frank MJ. 2014. Working memory contributions to reinforcement learning impairments in schizophrenia. The Journal of Neuroscience 34 :13747–13756. DOI: https://doi.org/10. 1523/JNEUROSCI.0989-14.2014 , PMID: 25297101 Collins AG , Frank MJ. 2012",
    "chunk_id": "15747544008463_1..33.json_chunk_52"
  },
  {
    "document_type": "research_paper",
    "title": "Ten simple rules for the computational modeling of behavioral data",
    "author": "Robert C Wilson, Anne GE Collins",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Wilson-2019-Ten-simple-rules-for-the-computatio.pdf",
    "date_published": "2019-11-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". The Journal of Neuroscience 34 :13747–13756. DOI: https://doi.org/10. 1523/JNEUROSCI.0989-14.2014 , PMID: 25297101 Collins AG , Frank MJ. 2012. How much of reinforcement learning is working memory, not reinforcement learning? A behavioral, computational, and neurogenetic analysis. European Journal of Neuroscience 35 :1024– 1035. DOI: https://doi.org/10.1111/j.1460-9568.2011.07980.x , PMID: 22487033 Collins AG , Frank MJ. 2013. Cognitive control over learning: creating, clustering, and generalizing task-set structure. Psychological Review 120 :190–229. DOI: https://doi.org/10.1037/a0030852 , PMID: 23356780 Collins AG , Frank MJ. 2014. Opponent actor learning (OpAL): modeling interactive effects of striatal dopamine on reinforcement learning and choice incentive. Psychological Review 121 :337–366. DOI: https://doi.org/10. 1037/a0037015 , PMID: 25090423 Collins AG , Frank MJ. 2018. Within-and across-trial dynamics of human EEG reveal cooperative interplay between reinforcement learning and working memory. PNAS :201720963. Collins AG , Wilson RC. 2019. TenSimpleRulesModeling. 3a01850. Github. https://github.com/AnneCollins/ TenSimpleRulesModeling Courville AC , Daw ND. 2008. The rat as particle filter. Advances in Neural Information Processing Systems 369– 376. https://papers.nips.cc/paper/3205-the-rat-as-particle-filter . Daw ND . 2011. Trial-by-trial data analysis using computational models. Decision Making, Affect, and Learning: Attention and Performance XXIII 23 :3–38. DOI: https://doi.org/10.1093/acprof:oso/9780199600434.003.0001 Daw ND , Gershman SJ, Seymour B, Dayan P, Dolan RJ. 2011. Model-based influences on humans’ choices and striatal prediction errors. Neuron 69 :1204–1215. DOI: https://doi.org/10.1016/j.neuron.2011.02.027 , PMID: 21435563 Daw ND , Courville AC. 2007. The pigeon as particle filter. Advances in Neural Information Processing Systems. Daw ND , Tobler PN. 2014. Value learning through reinforcement: the basics of dopamine and reinforcement learning. In: Neuroeconomics . Second Edition",
    "chunk_id": "15747544008463_1..33.json_chunk_53"
  },
  {
    "document_type": "research_paper",
    "title": "Ten simple rules for the computational modeling of behavioral data",
    "author": "Robert C Wilson, Anne GE Collins",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Wilson-2019-Ten-simple-rules-for-the-computatio.pdf",
    "date_published": "2019-11-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Daw ND , Tobler PN. 2014. Value learning through reinforcement: the basics of dopamine and reinforcement learning. In: Neuroeconomics . Second Edition. Elsevier. p. 283–298. DOI: https://doi.org/10.1016/b978-0-12- 416008-8.00015-2 Donkin C , Tran SC, Nosofsky R. 2014. Landscaping analyses of the ROC predictions of discrete-slots and signadetection models of visual working memory. Attention, Perception, & Psychophysics 76 :2103–2116. DOI: https://doi.org/10.3758/s13414-013-0561-7 Donkin C , Kary A, Tahir F, Taylor R. 2016. Resources masquerading as slots: Flexible allocation of visual working memory. Cognitive Psychology 85 :30–42. DOI: https://doi.org/10.1016/j.cogpsych.2016.01.002 Donoso M , Collins AGE, Koechlin E. 2014. Foundations of human reasoning in the prefrontal cortex. Science 344 :1481–1486. DOI: https://doi.org/10.1126/science.1252254 Wilson and Collins. eLife 2019;8:e49547. DOI: https://doi.org/10.7554/eLife.49547 25 of 33 Review Article Neuroscience Dowd EC , Frank MJ, Collins A, Gold JM, Barch DM. 2016. Probabilistic reinforcement learning in patients with schizophrenia: Relationships to anhedonia and avolition. Biological Psychiatry: Cognitive Neuroscience and Neuroimaging 1 :460–473. DOI: https://doi.org/10.1016/j.bpsc.2016.05.005 Drugowitsch J , Wyart V, Devauchelle AD, Koechlin E. 2016. Computational precision of mental inference as critical source of human choice suboptimality. Neuron 92 :1398–1411. DOI: https://doi.org/10.1016/j.neuron. 2016.11.005 , PMID: 27916454 Farashahi S , Rowe K, Aslami Z, Lee D, Soltani A. 2017. Feature-based learning improves adaptability without compromising precision. Nature Communications 8 :1768. DOI: https://doi.org/10.1038/s41467-017-01874-w , PMID: 29170381 Farrell S , Lewandowsky S. 2018. Computational Modeling of Cognition and Behavior . Cambridge University Press. DOI: https://doi.org/10.1017/CBO9781316272503 Findling C , Skvortsova V, Dromnelle R, Palminteri S, Wyart V. 2018",
    "chunk_id": "15747544008463_1..33.json_chunk_54"
  },
  {
    "document_type": "research_paper",
    "title": "Ten simple rules for the computational modeling of behavioral data",
    "author": "Robert C Wilson, Anne GE Collins",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Wilson-2019-Ten-simple-rules-for-the-computatio.pdf",
    "date_published": "2019-11-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". 2018. Computational Modeling of Cognition and Behavior . Cambridge University Press. DOI: https://doi.org/10.1017/CBO9781316272503 Findling C , Skvortsova V, Dromnelle R, Palminteri S, Wyart V. 2018. Computational noise in reward-guided learning drives behavioral variability in volatile environments. bioRxiv . DOI: https://doi.org/10.1101/439885 Fischer AG , Ullsperger M. 2013. Real and fictive outcomes are processed differently but converge on a common adaptive mechanism. Neuron 79 :1243–1255. DOI: https://doi.org/10.1016/j.neuron.2013.07.006 , PMID: 24050408 Frank MJ , Seeberger LC, O’reilly RC. 2004. By carrot or by stick: cognitive reinforcement learning in parkinsonism. Science 306 :1940–1943. DOI: https://doi.org/10.1126/science.1102941 , PMID: 15528409 Frank MJ , Moustafa AA, Haughey HM, Curran T, Hutchison KE. 2007. Genetic triple dissociation reveals multiple roles for dopamine in reinforcement learning. PNAS 104 :16311–16316. DOI: https://doi.org/10.1073/pnas. 0706111104 , PMID: 17913879 Geisler WS . 2011. Contributions of ideal observer theory to vision research. Vision Research 51 :771–781. DOI: https://doi.org/10.1016/j.visres.2010.09.027 , PMID: 20920517 Gelman A , Meng XL, Stern H. 1996. Posterior predictive assessment of model fitness via realized discrepancies. Statistica Sinica 6 :733–760. Gershman SJ . 2016. Empirical priors for reinforcement learning models. Journal of Mathematical Psychology 71 : 1–6. DOI: https://doi.org/10.1016/j.jmp.2016.01.006 Gillan CM , Kosinski M, Whelan R, Phelps EA, Daw ND. 2016. Characterizing a psychiatric symptom dimension related to deficits in goal-directed control. eLife 5 :e11305. DOI: https://doi.org/10.7554/eLife.11305 , PMID: 26 928075 Haaf JM , Rouder JN. 2017. Developing constraint in bayesian mixed models. Psychological Methods 22 :779– 798. DOI: https://doi.org/10.1037/met0000156 , PMID: 29265850 Heathcote A , Brown SD, Wagenmakers EJ. 2015. An introduction to good practices in cognitive modeling",
    "chunk_id": "15747544008463_1..33.json_chunk_55"
  },
  {
    "document_type": "research_paper",
    "title": "Ten simple rules for the computational modeling of behavioral data",
    "author": "Robert C Wilson, Anne GE Collins",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Wilson-2019-Ten-simple-rules-for-the-computatio.pdf",
    "date_published": "2019-11-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Psychological Methods 22 :779– 798. DOI: https://doi.org/10.1037/met0000156 , PMID: 29265850 Heathcote A , Brown SD, Wagenmakers EJ. 2015. An introduction to good practices in cognitive modeling. In: An Introduction to Model-Based Cognitive Neuroscience . Springer. p. 25–48. DOI: https://doi.org/10.1007/ 978-1-4939-2236-9_2 Huys QJM , Cools R, Go ̈ lzer M, Friedel E, Heinz A, Dolan RJ, Dayan P. 2011. Disentangling the roles of approach, activation and Valence in instrumental and pavlovian responding. PLOS Computational Biology 7 :e1002028. DOI: https://doi.org/10.1371/journal.pcbi.1002028 Huys QJM . 2017. Bayesian Approaches to Learning and Decision-Making. In: Computational Psychiatry: Mathematical Modeling of Mental Illness . Academic Press. p. 247–271. DOI: https://doi.org/10.1016/b978-0- 12-809825-7.00010-9 Jahfari S , Ridderinkhof KR, Collins AGE, Knapen T, Waldorp LJ, Frank MJ. 2019. Cross-Task contributions of frontobasal ganglia circuitry in response inhibition and Conflict-Induced slowing. Cerebral Cortex 29 :1969– 1983. DOI: https://doi.org/10.1093/cercor/bhy076 , PMID: 29912363 Kass RE , Raftery AE. 1995. Bayes factors. Journal of the American Statistical Association 90 :773–795. DOI: https://doi.org/10.1080/01621459.1995.10476572 Katahira K . 2016. How hierarchical models improve point estimates of model parameters at the individual level. Journal of Mathematical Psychology 73 :37–58. DOI: https://doi.org/10.1016/j.jmp.2016.03.007 Kording K , Blohm G, Schrater P, Kay K. 2018. Appreciating diversity of goals in computational neuroscience. OSF Preprints . https://osf.io/3vy69/ . Lee MD . 2011. How cognitive modeling can benefit from hierarchical bayesian models. Journal of Mathematical Psychology 55 :1–7. DOI: https://doi.org/10.1016/j.jmp.2010.08.013 Lee MD , Criss AH, Devezer B, Donkin C, Etz A, Leite FP, Matzke D, Rouder JN, Trueblood J, White C. 2019. Robust modeling in cognitive science. PsyArXiv . https://psyarxiv.com/dmfhk/ . Lee MD , Wagenmakers EJ. 2014",
    "chunk_id": "15747544008463_1..33.json_chunk_56"
  },
  {
    "document_type": "research_paper",
    "title": "Ten simple rules for the computational modeling of behavioral data",
    "author": "Robert C Wilson, Anne GE Collins",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Wilson-2019-Ten-simple-rules-for-the-computatio.pdf",
    "date_published": "2019-11-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". 2019. Robust modeling in cognitive science. PsyArXiv . https://psyarxiv.com/dmfhk/ . Lee MD , Wagenmakers EJ. 2014. Bayesian Cognitive Modeling: A Practical Course . Cambridge university press. DOI: https://doi.org/10.1017/CBO9781139087759 Lee MD , Webb MR. 2005. Modeling individual differences in cognition. Psychonomic Bulletin & Review 12 :605– 621. DOI: https://doi.org/10.3758/BF03196751 , PMID: 16447375 Leong YC , Radulescu A, Daniel R, DeWoskin V, Niv Y. 2017. Dynamic interaction between reinforcement learning and attention in multidimensional environments. Neuron 93 :451–463. DOI: https://doi.org/10.1016/j.neuron. 2016.12.040 Lieder F , Griffiths TL, M Huys QJ, Goodman ND. 2018. Empirical evidence for resource-rational anchoring and adjustment. Psychonomic Bulletin & Review 25 :775–784. DOI: https://doi.org/10.3758/s13423-017-1288-6 , PMID: 28484951 Lorains FK , Dowling NA, Enticott PG, Bradshaw JL, Trueblood JS, Stout JC. 2014. Strategic and non-strategic problem gamblers differ on decision-making under risk and ambiguity. Addiction 109 :1128–1137. DOI: https:// doi.org/10.1111/add.12494 , PMID: 24450756 Wilson and Collins. eLife 2019;8:e49547. DOI: https://doi.org/10.7554/eLife.49547 26 of 33 Review Article Neuroscience MacKay DJ . 2003. Information Theory, Inference and Learning Algorithms . Cambridge University Press. Montague PR , Dayan P, Sejnowski TJ. 1996. A framework for mesencephalic dopamine systems based on predictive hebbian learning. The Journal of Neuroscience 16 :1936–1947. DOI: https://doi.org/10.1523/ JNEUROSCI.16-05-01936.1996 , PMID: 8774460 More ́ JJ , Sorensen DC. 1983. Computing a trust region step. SIAM Journal on Scientific and Statistical Computing 4 :553–572. DOI: https://doi.org/10.1137/0904038 Nassar MR , Wilson RC, Heasly B, Gold JI. 2010. An approximately bayesian delta-rule model explains the dynamics of belief updating in a changing environment. Journal of Neuroscience 30 :12366–12378",
    "chunk_id": "15747544008463_1..33.json_chunk_57"
  },
  {
    "document_type": "research_paper",
    "title": "Ten simple rules for the computational modeling of behavioral data",
    "author": "Robert C Wilson, Anne GE Collins",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Wilson-2019-Ten-simple-rules-for-the-computatio.pdf",
    "date_published": "2019-11-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". 2010. An approximately bayesian delta-rule model explains the dynamics of belief updating in a changing environment. Journal of Neuroscience 30 :12366–12378. DOI: https://doi.org/10.1523/JNEUROSCI.0822-10.2010 , PMID: 20844132 Nassar MR , Rumsey KM, Wilson RC, Parikh K, Heasly B, Gold JI. 2012. Rational regulation of learning dynamics by pupil-linked arousal systems. Nature Neuroscience 15 :1040–1046. DOI: https://doi.org/10.1038/nn.3130 , PMID: 22660479 Nassar MR , Helmers JC, Frank MJ. 2018. Chunking as a rational strategy for lossy data compression in visual working memory. Psychological Review 125 :486–511. DOI: https://doi.org/10.1037/rev0000101 , PMID: 2 9952621 Nassar MR , Frank MJ. 2016. Taming the beast: extracting generalizable knowledge from computational models of cognition. Current Opinion in Behavioral Sciences 11 :49–54. DOI: https://doi.org/10.1016/j.cobeha.2016.04. 003 , PMID: 27574699 Navarro DJ . 2019. Between the Devil and the deep blue sea: tensions between scientific judgement and statistical model selection. Computational Brain & Behavior 2 :28–34. Nilsson H , Rieskamp J, Wagenmakers E-J. 2011. Hierarchical Bayesian parameter estimation for cumulative prospect theory. Journal of Mathematical Psychology 55 :84–93. DOI: https://doi.org/10.1016/j.jmp.2010.08. 006 O’Doherty JP , Hampton A, Kim H. 2007. Model-based fMRI and its application to reward learning and decision making. Annals of the New York Academy of Sciences 1104 :35–53. DOI: https://doi.org/10.1196/annals.1390. 022 , PMID: 17416921 O’Reilly JX , Schuffelgen U, Cuell SF, Behrens TEJ, Mars RB, Rushworth MFS. 2013. Dissociable effects of surprise and model update in parietal and anterior cingulate cortex. PNAS 110 :E3660–E3669. DOI: https://doi.org/10. 1073/pnas.1305373110 Otto AR , Raio CM, Chiang A, Phelps EA, Daw ND. 2013. Working-memory capacity protects model-based learning from stress. PNAS 110 :20941–20946. DOI: https://doi.org/10.1073/pnas.1312011110 , PMID: 24324166 Palminteri S , Wyart V, Koechlin E. 2017",
    "chunk_id": "15747544008463_1..33.json_chunk_58"
  },
  {
    "document_type": "research_paper",
    "title": "Ten simple rules for the computational modeling of behavioral data",
    "author": "Robert C Wilson, Anne GE Collins",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Wilson-2019-Ten-simple-rules-for-the-computatio.pdf",
    "date_published": "2019-11-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". 2013. Working-memory capacity protects model-based learning from stress. PNAS 110 :20941–20946. DOI: https://doi.org/10.1073/pnas.1312011110 , PMID: 24324166 Palminteri S , Wyart V, Koechlin E. 2017. The importance of falsification in computational cognitive modeling. Trends in Cognitive Sciences 21 :425–433. DOI: https://doi.org/10.1016/j.tics.2017.03.011 , PMID: 28476348 Piray P , Dezfouli A, Heskes T, Frank MJ, Daw ND. 2018. Hierarchical bayesian inference for concurrent model fitting and comparison for group studies. bioRxiv . DOI: https://doi.org/10.1101/393561 Ratcliff R . 1978. A theory of memory retrieval. Psychological Review 85 :59–108. DOI: https://doi.org/10.1037/ 0033-295X.85.2.59 Ratcliff R , Rouder JN. 1998. Modeling response times for Two-Choice decisions. Psychological Science 9 :347– 356. DOI: https://doi.org/10.1111/1467-9280.00067 Rescorla RA , Wagner AR. 1972. A theory of pavlovian conditioning: variations in the effectiveness of reinforcement and nonreinforcement. Classical Conditioning II: Current Research and Theory 2 :64–99. Rigoux L , Stephan KE, Friston KJ, Daunizeau J. 2014. Bayesian model selection for group studies - revisited. NeuroImage 84 :971–985. DOI: https://doi.org/10.1016/j.neuroimage.2013.08.065 , PMID: 24018303 Roecker EB . 1991. Prediction error and its estimation for Subset-Selected models. Technometrics 33 :459–468. DOI: https://doi.org/10.1080/00401706.1991.10484873 Samejima K , Ueda Y, Doya K, Kimura M. 2005. Representation of action-specific reward values in the striatum. Science 310 :1337–1340. DOI: https://doi.org/10.1126/science.1115270 , PMID: 16311337 Schwarz G . 1978. Estimating the dimension of a model. The Annals of Statistics 6 :461–464. DOI: https://doi.org/ 10.1214/aos/1176344136 Sims CR . 2018. Efficient coding explains the universal law of generalization in human perception. Science 360 : 652–656. DOI: https://doi.org/10.1126/science.aaq1118 , PMID: 29748284 Somerville LH , Sasse SF, Garrad MC, Drysdale AT, Abi Akar N, Insel C, Wilson RC. 2017",
    "chunk_id": "15747544008463_1..33.json_chunk_59"
  },
  {
    "document_type": "research_paper",
    "title": "Ten simple rules for the computational modeling of behavioral data",
    "author": "Robert C Wilson, Anne GE Collins",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Wilson-2019-Ten-simple-rules-for-the-computatio.pdf",
    "date_published": "2019-11-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Science 360 : 652–656. DOI: https://doi.org/10.1126/science.aaq1118 , PMID: 29748284 Somerville LH , Sasse SF, Garrad MC, Drysdale AT, Abi Akar N, Insel C, Wilson RC. 2017. Charting the expansion of strategic exploratory behavior during adolescence. Journal of Experimental Psychology: General 146 :155–164. DOI: https://doi.org/10.1037/xge0000250 Starns JJ , Ratcliff R. 2010. The effects of aging on the speed-accuracy compromise: boundary optimality in the diffusion model. Psychology and Aging 25 :377–390. DOI: https://doi.org/10.1037/a0018022 , PMID: 20545422 Steyvers M , Lee MD, Wagenmakers E-J. 2009. A bayesian analysis of human decision-making on bandit problems. Journal of Mathematical Psychology 53 :168–179. DOI: https://doi.org/10.1016/j.jmp.2008.11.002 Sunna ̊ker M , Busetto AG, Numminen E, Corander J, Foll M, Dessimoz C. 2013. Approximate bayesian computation. PLOS Computational Biology 9 :e1002803. DOI: https://doi.org/10.1371/journal.pcbi.1002803 , PMID: 23341757 Sutton RS , Barto AG. 2018. Reinforcement Learning: An Introduction . MIT press. Turner BM , Forstmann BU, Wagenmakers EJ, Brown SD, Sederberg PB, Steyvers M. 2013. A bayesian framework for simultaneously modeling neural and behavioral data. NeuroImage 72 :193–206. DOI: https://doi.org/10. 1016/j.neuroimage.2013.01.048 , PMID: 23370060 Wilson and Collins. eLife 2019;8:e49547. DOI: https://doi.org/10.7554/eLife.49547 27 of 33 Review Article Neuroscience Turner BM , Rodriguez CA, Norcia TM, McClure SM, Steyvers M. 2016. Why more is better: simultaneous modeling of EEG, fMRI, and behavioral data. NeuroImage 128 :96–115. DOI: https://doi.org/10.1016/j. neuroimage.2015.12.030 , PMID: 26723544 Turner BM , Sederberg PB. 2012. Approximate Bayesian computation with differential evolution. Journal of Mathematical Psychology 56 :375–385. DOI: https://doi.org/10.1016/j.jmp.2012.06.004 van Ravenzwaaij D , Dutilh G, Wagenmakers E-J. 2011. Cognitive model decomposition of the BART: assessment and application. Journal of Mathematical Psychology 55 :94–105",
    "chunk_id": "15747544008463_1..33.json_chunk_60"
  },
  {
    "document_type": "research_paper",
    "title": "Ten simple rules for the computational modeling of behavioral data",
    "author": "Robert C Wilson, Anne GE Collins",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Wilson-2019-Ten-simple-rules-for-the-computatio.pdf",
    "date_published": "2019-11-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". 2011. Cognitive model decomposition of the BART: assessment and application. Journal of Mathematical Psychology 55 :94–105. DOI: https://doi.org/10.1016/j.jmp.2010.08. 010 Vandekerckhove J , Matzke D, Wagenmakers EJ. 2015. Model Comparison and the Principle of Parsimony. In: Busemeyer J. R, Wang Z, Townsend J. T, Eidels A (Eds). The Oxford Handbook of Computational and Mathematical Psychology . 300 Oxford University Press. p. 300319 DOI: https://doi.org/10.1093/oxfordhb/ 9780199957996.013.14 Viejo G , Khamassi M, Brovelli A, Girard B. 2015. Modeling choice and reaction time during arbitrary visuomotor learning through the coordination of adaptive working memory and reinforcement learning. Frontiers in Behavioral Neuroscience 9 :225. DOI: https://doi.org/10.3389/fnbeh.2015.00225 , PMID: 26379518 Wagenmakers E-J , Lodewyckx T, Kuriyal H, Grasman R. 2010. Bayesian hypothesis testing for psychologists: a tutorial on the Savage–Dickey method. Cognitive Psychology 60 :158–189. DOI: https://doi.org/10.1016/j. cogpsych.2009.12.001 Wagenmakers EJ , Farrell S. 2004. AIC model selection using akaike weights. Psychonomic Bulletin & Review 11 : 192–196. DOI: https://doi.org/10.3758/BF03206482 , PMID: 15117008 Warren CM , Wilson RC, van der Wee NJ, Giltay EJ, van Noorden MS, Cohen JD, Nieuwenhuis S. 2017. The effect of atomoxetine on random and directed exploration in humans. PLOS ONE 12 :e0176034. DOI: https:// doi.org/10.1371/journal.pone.0176034 Watkins CJCH , Dayan P. 1992. Q-learning. Machine Learning 8 :279–292. DOI: https://doi.org/10.1007/ BF00992698 Wiecki TV , Sofer I, Frank MJ. 2013. HDDM: hierarchical bayesian estimation of the Drift-Diffusion model in Python. Frontiers in Neuroinformatics 7 :14. DOI: https://doi.org/10.3389/fninf.2013.00014 , PMID: 23935581 Wilson RC , Nassar MR, Gold JI. 2013. A mixture of delta-rules approximation to bayesian inference in changpoint problems. PLOS Computational Biology 9 :e1003150. DOI: https://doi.org/10.1371/journal.pcbi.1003150 , PMID: 23935472 Wilson RC , Niv Y. 2011",
    "chunk_id": "15747544008463_1..33.json_chunk_61"
  },
  {
    "document_type": "research_paper",
    "title": "Ten simple rules for the computational modeling of behavioral data",
    "author": "Robert C Wilson, Anne GE Collins",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Wilson-2019-Ten-simple-rules-for-the-computatio.pdf",
    "date_published": "2019-11-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". PLOS Computational Biology 9 :e1003150. DOI: https://doi.org/10.1371/journal.pcbi.1003150 , PMID: 23935472 Wilson RC , Niv Y. 2011. Inferring relevance in a changing world. Frontiers in Human Neuroscience 5 :189. DOI: https://doi.org/10.3389/fnhum.2011.00189 , PMID: 22291631 Wilson RC , Niv Y. 2015. Is model fitting necessary for Model-Based fMRI? PLOS Computational Biology 11 : e1004237. DOI: https://doi.org/10.1371/journal.pcbi.1004237 , PMID: 26086934 Wimmer GE , Li JK, Gorgolewski KJ, Poldrack RA. 2018. Reward learning over weeks versus minutes increases the neural representation of value in the human brain. The Journal of Neuroscience 38 :7649–7666. DOI: https:// doi.org/10.1523/JNEUROSCI.0075-18.2018 , PMID: 30061189 Zajkowski WK , Kossut M, Wilson RC. 2017. A causal role for right frontopolar cortex in directed, but not random, exploration. eLife 6 :e27430. DOI: https://doi.org/10.7554/eLife.27430 , PMID: 28914605 Wilson and Collins. eLife 2019;8:e49547. DOI: https://doi.org/10.7554/eLife.49547 28 of 33 Review Article Neuroscience Appendix 1 The theory of model fitting Formally, the goal of model fitting is to estimate the parameters, m , for each model, m , that best fit the behavioral data. To do this, we take a Bayesian approach and aim to compute (or at least approximate) the posterior distribution over the parameters given the data, p ð m j d 1 : T ; m Þ . By Bayes’ rule we can write this as p ð m j d 1 : T ; m Þ 1⁄4 p ð d 1 : T j m ; m Þ p ð m j m Þ p ð d 1 : T j m Þ (12) where p ð m j m Þ is the prior on the parameters, m ; p ð d 1 : T j m ; m Þ is the likelihood of the data given the parameters; and the normalization constant, p ð d 1 : T j m Þ , is the probability of the data given the model (which is also known as the marginal likelihood [ Lee and Wagenmakers, 2014 ], more on this below)",
    "chunk_id": "15747544008463_1..33.json_chunk_62"
  },
  {
    "document_type": "research_paper",
    "title": "Ten simple rules for the computational modeling of behavioral data",
    "author": "Robert C Wilson, Anne GE Collins",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Wilson-2019-Ten-simple-rules-for-the-computatio.pdf",
    "date_published": "2019-11-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Because the probabilities tend to be small, it is often easier to work with the log of these quantities log p ð m j d 1 : T ; m Þ 1⁄4 log p ð d 1 : T j m ; m Þ |fflfflfflfflfflfflfflfflfflfflfflffl{zfflfflfflfflfflfflfflfflfflfflfflffl} log likelihood þ log p ð m j m Þ log p ð d 1 : T j m Þ (13) The log-likelihood often gets its own symbol, LL 1⁄4 log p ð d 1 : T j m ; m Þ , and can be written log p ð d 1 : T j m ; m Þ 1⁄4 log Y T t 1⁄4 1 p ð c t j d 1 : t 1 ; s t ; m ; m Þ ! 1⁄4 X T t 1⁄4 1 log p ð c t j d 1 : t 1 ; s t ; m ; m Þ (14) where p ð c t j d 1 : t 1 ; s t ; m ; m Þ is the probability of each individual choice given the parameters of the model, which is at the heart of the definition of each model (for example in Equations 1– 7 ). In a perfect world, we would evaluate the log-posterior, log p ð m j d 1 : T ; m Þ , exactly, but this can be difficult to compute and unwieldy to report. Instead, we must approximate it. This can be done using sampling approaches such as Markov Chain Monte Carlo approaches ( Lee and Wagenmakers, 2014 ), which approximate the full posterior with a set of samples. Another approach is to report a point estimate for the parameters such as the maximum of the loposterior (the maximum a posteriori [MAP] estimate), or the maximum of the log-likelihood (the maximum likelihood estimate [MLE]). (Note that the log transformation does not change the location of the maximum, so the maximum of the log-likelihood occurs at the same value of m as the maximum of the likelihood.) ^ MAP m 1⁄4 argmax m log p ð m j d 1 : T ; m Þ ^ MLE m 1⁄4 argmax m log p ð d 1 : T j m ; m Þ Note that with a uniform prior on m , these two estimates coincide. These approaches for estimating parameter values each have different strengths and weaknesses. The MCMC approach is the most principled as, with enough samples, it gives a good approximation of the posterior distribution over each parameter value",
    "chunk_id": "15747544008463_1..33.json_chunk_63"
  },
  {
    "document_type": "research_paper",
    "title": "Ten simple rules for the computational modeling of behavioral data",
    "author": "Robert C Wilson, Anne GE Collins",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Wilson-2019-Ten-simple-rules-for-the-computatio.pdf",
    "date_published": "2019-11-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". The MCMC approach is the most principled as, with enough samples, it gives a good approximation of the posterior distribution over each parameter value. This approach also gracefully handles small data sets and allows us to combine data from different subjects in a rigorous manner. Despite these advantages, the MCMC approach is more complex (especially for beginners) and can be slow to implement. On the other hand, point estimates such as the MAP and MLE parameter values are much quicker to compute and often give similar answers to the MCMC approach when the amount of data is large (which is often the case when dealing with young and healthy populations). For this reason, we focus our discussion on the point estimate approaches, focusing in particular on maximum likelihood estimation. Wilson and Collins. eLife 2019;8:e49547. DOI: https://doi.org/10.7554/eLife.49547 29 of 33 Review Article Neuroscience Appendix 2 The theory of model comparison In model comparison, our goal is to figure out which model of a set of possible models is most likely to have generated the data. To do this, we compute (or at least try to estimate) the probability that model m generated the data, p ð m j d 1 : T Þ . Note that this is the normalization constant from Equation 12 . As with parameter recovery, this probability is difficult to compute directly and so we turn to Bayes’ rule and write p ð m j d 1 : T Þ / p ð d 1 : T j m Þ p ð m Þ 1⁄4 Z d m p ð d 1 : T j m ; m Þ p ð m j m Þ p ð m Þ where p ð m Þ is the prior probability that model m is the correct model and p ð d 1 : T j m Þ is the likelihood of the data given the model. In most cases, p ð m Þ is assumed to be constant and so we can focus entirely on the likelihood, p ð d 1 : T j m Þ . As before, it is easier to handle the log of this quantity which is known as the marginal likelihood ( Lee and Wagenmakers, 2014 ) or Bayesian evidence, E m ( Kass and Raftery, 1995 ), for model m",
    "chunk_id": "15747544008463_1..33.json_chunk_64"
  },
  {
    "document_type": "research_paper",
    "title": "Ten simple rules for the computational modeling of behavioral data",
    "author": "Robert C Wilson, Anne GE Collins",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Wilson-2019-Ten-simple-rules-for-the-computatio.pdf",
    "date_published": "2019-11-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". As before, it is easier to handle the log of this quantity which is known as the marginal likelihood ( Lee and Wagenmakers, 2014 ) or Bayesian evidence, E m ( Kass and Raftery, 1995 ), for model m . More explicitly E m 1⁄4 log p ð d 1 : T j m Þ 1⁄4 log Z d m p ð d 1 : T j m ; m Þ p ð m j m Þ (17) If we can compute E m for each model, then the model with the largest evidence is most likely to have generated the data. Note that by integrating over the parameter space, the Bayesian evidence implicitly penalizes free parameters. This is because, the more free parameters, the larger the size of the space over which we integrate and, consequently, the smaller p ð m j m Þ is for any given parameter setting. Thus, unless the model predicts the data well for all parameter settings, it pays a price for each additional free parameter. This idea, that simpler models should be favored over more complex models if they both explain the data equally well, is known as Occam’s razor (see Chapter 28 in MacKay, 2003 ). Unfortunately, because it involves computing an integral over all possible parameter settings, computing the marginal likelihood exactly is usually impossible. There are several methods for approximating the integral based on either replacing it with a sum over a subset of points ( Wagenmakers et al., 2010 ; Lee and Wagenmakers, 2014 ) or replacing it with an approximation around either the MAP or MLE estimates of the parameters. The latter approach is the most common and three particular forms are used: the Bayes Information Criterion (BIC) ( Schwarz, 1978 ), Akaike information criterion (AIC) ( Akaike, 1974 ) and the Laplace approximation ( Kass and Raftery, 1995 ). Here, we will focus on BIC which is an estimate based around the maximum likelihood estimate of the parameters, ^ MLE m , BIC 1⁄4 2 log ^ L þ k m log ð T Þ » 2 log E m (18) where k m is the number of parameters in model m and ^ L is the value of the log-likelihood at ^ MLE m",
    "chunk_id": "15747544008463_1..33.json_chunk_65"
  },
  {
    "document_type": "research_paper",
    "title": "Ten simple rules for the computational modeling of behavioral data",
    "author": "Robert C Wilson, Anne GE Collins",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Wilson-2019-Ten-simple-rules-for-the-computatio.pdf",
    "date_published": "2019-11-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Finally, we have found it useful to report the results of model comparison in terms of the likelihood-per-trial LPT , which can be thought of as the ‘average’ probability with which the model predicts each choice, LPT 1⁄4 exp E m T (19) Wilson and Collins. eLife 2019;8:e49547. DOI: https://doi.org/10.7554/eLife.49547 30 of 33 Review Article Neuroscience Appendix 3 Computing the inversion matrix from the confusion matrix In section ’Can you arbitrate between different models?’ we introduced the inversion matrix, p ð simulated model j fit model Þ , as the probability that data best fit by one model were actually generated from another model. As shown below, this can be readily computed from the confusion matrix, p ð fit model j simulated model Þ , by Bayes rule. Abbreviating ‘simulated model’ with ‘sim’ and ‘fit model’ with ‘fit’ we have p ð sim j fit Þ 1⁄4 p ð fit j sim Þ p ð sim Þ P sim p ð fit j sim Þ p ð sim Þ (20) For a uniform prior on models, computing the inversion matrix amounts to renormalizing the confusion matrix over the simulated models. Wilson and Collins. eLife 2019;8:e49547. DOI: https://doi.org/10.7554/eLife.49547 31 of 33 Review Article Neuroscience Appendix 4 Working memory model used for local minima example The model and experimental designs used in Box 3—figure 1 are a simplified version of those in Collins and Frank (2012) . In short, the experiment attempts to parse out working memory contributions to reinforcement learning by having participants and agents learn stimulus-action contingencies from deterministic feedback, with a different number of stimuli ns being learned in parallel in different blocks. This manipulation targets WM load and isolates WM contributions; see Collins and Frank (2012) for details. The simplified model assumes a mixture of a classic RL component (with parameters a and b ) and a working memory component with perfect one-shot learning. The mixture is controled by parameter , capturing the prior willingness to use working memory vs",
    "chunk_id": "15747544008463_1..33.json_chunk_66"
  },
  {
    "document_type": "research_paper",
    "title": "Ten simple rules for the computational modeling of behavioral data",
    "author": "Robert C Wilson, Anne GE Collins",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Wilson-2019-Ten-simple-rules-for-the-computatio.pdf",
    "date_published": "2019-11-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". The mixture is controled by parameter , capturing the prior willingness to use working memory vs. RL, and capacity parameter K , which scales the mixture weight in proportion to the proportion of stimuli that may be held in working memory: min ð 1 ; K ns Þ . The original model assumes additional dynamics for the working memory policy and working memory vs. RL weights that render the model more identifiable ( Collins and Frank, 2012 ). Wilson and Collins. eLife 2019;8:e49547. DOI: https://doi.org/10.7554/eLife.49547 32 of 33 Review Article Neuroscience Appendix 5 Model validation example In this example, we imagine a deterministic stimulus-action learning task in which subjects are presented with one of three stimuli ( s 1 , s 2 , and s 3 ), which instruct the subject which of three actions ( a 1 , a 2 , and a 3 ) will be rewarded when chosen. The two models that we consider are both reinforcement learning agents. The first, a ‘blind’ agent, does not see the stimulus at all and learns only about the value of the three different actions, i.e. Q ð a i Þ , regardless of the stimulus. The second, a ‘state-based’ agent, observes the stimulus and learns a value for each action that can be different for each stimulus, i.e. Q ð a i ; s i Þ . Learning in both models occurs via a Rescorla-Wagner rule with different learning rates for positive and negative prediction errors. Thus for the blind agent, the values update according to Q ð a t Þ Q ð a t Þ þ a P ð r t Q ð a t ÞÞ if ð r t Q ð a t ÞÞ > 0 Q ð a t Þ þ a N ð r t Q ð a t ÞÞ if ð r t Q ð a t ÞÞ < 0 (21) while for the state-based agent, values update according to Q ð a t ; s t Þ Q ð a t ; s t Þ þ a P ð r t Q ð a t ; s t ÞÞ if ð r t Q ð a t ; s t ÞÞ > 0 Q ð a t ; s t Þ þ a N ð r t Q ð a t ; s t ÞÞ if ð r t Q ð a t ; s t ÞÞ < 0 (22) In both models, these values guide decisions via softmax decision rule with inverse temperature parameter, b . We begin by simulating two different agents: one using the blind algorithm and the other using the state-based approach",
    "chunk_id": "15747544008463_1..33.json_chunk_67"
  },
  {
    "document_type": "research_paper",
    "title": "Ten simple rules for the computational modeling of behavioral data",
    "author": "Robert C Wilson, Anne GE Collins",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Wilson-2019-Ten-simple-rules-for-the-computatio.pdf",
    "date_published": "2019-11-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". We begin by simulating two different agents: one using the blind algorithm and the other using the state-based approach. Parameters in the models are set such that the learning curves for the two agents are approximately equal ( Box 7—figure 1A , blind model: a P 1⁄4 0 : 5 , a N 1⁄4 0 , b 1⁄4 6 : 5 state-based model: a P 1⁄4 0 : 65 , a N 1⁄4 0 , b 1⁄4 2 ). In both cases, the agents start from an accuracy of 1/3 and an asymptote at an accuracy of around 2/3 — the blind agent because this is the best it can do, the state-based agent because the softmax parameter is relatively small and hence performance is limited by noise. Next we consider how the state-based model fits behavior from these two different agents. In Box 7—figure 1B , we plot the average likelihood with which the state-based model predicts the actual choices of the blind and state-based agents, that is the average p ð c t j d 1 : t 1 ; m ; m 1⁄4 state-based Þ . As is clear from this figure, the state-based model predicts choices from the blind agent with higher likelihood than choices from the state-based agent! Although counter intuitive, this result does not imply that the state-based model is unable to fit its own behavior. Instead, this result reflects the difference in noise (softmax parameters) between the two subjects. The blind RL subject has a high b , implying less noise, allowing the state-based model to fit it quite well. Conversely, the state-based RL subject has a low b , implying more noise, meaning that the behavior is harder to predict even when it is fit with the correct model. That the state-based model fits state-based behavior better than it fits blind behavior is illustrated in Box 7—figure 1C . Here we plot the simulated learning curves of the state-based model using the parameter values that were fit to either the state-based agent or the blind agent",
    "chunk_id": "15747544008463_1..33.json_chunk_68"
  },
  {
    "document_type": "research_paper",
    "title": "Ten simple rules for the computational modeling of behavioral data",
    "author": "Robert C Wilson, Anne GE Collins",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Wilson-2019-Ten-simple-rules-for-the-computatio.pdf",
    "date_published": "2019-11-26",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Here we plot the simulated learning curves of the state-based model using the parameter values that were fit to either the state-based agent or the blind agent. While the fit to the state-based agent generates a learning curve quite similar to that of the subject (compare blue lines in Box 7—figure 1A and C ), the state-based fit to the blind agent performs too well (compare yellow lines in panels Box 7—figure 1A and C ). Thus the model validation step provides support for the state-based model when it is the correct model of behavior, but rules out the state-based model when the generating model was different. Wilson and Collins. eLife 2019;8:e49547. DOI: https://doi.org/10.7554/eLife.49547 33 of 33 Review Article Neuroscience",
    "chunk_id": "15747544008463_1..33.json_chunk_69"
  },
  {
    "document_type": "research_paper",
    "title": "Bayesian hypothesis testing for psychologists: A tutorial on the Savage–Dickey method",
    "author": "\"Eric-Jan Wagenmakers; Tom Lodewyckx; Himanshu Kuriyal; Raoul Grasman\"",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\bayesian_hypothesis_testing_for_psychologists.pdf",
    "date_published": "2010-03-03",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": "Bayesian hypothesis testing for psychologists: A tutorial on the Savage–Dickey method Eric-Jan Wagenmakers a, * , Tom Lodewyckx b , Himanshu Kuriyal c , Raoul Grasman a a University of Amsterdam, Department of Psychology, Roetersstraat 15, 1018 WB Amsterdam, The Netherlands b Leuven University, Department of Psychology, Tiensestraat 102, B-3000 Leuven, Belgium c Indian Institute of Technology, Kharagpur, India a r t i c l e i n f o Article history: Accepted 14 December 2009 Available online 12 January 2010 Keywords: Statistical evidence Model selection Bayes factor Hierarchical modeling Random effects Order-restrictions a b s t r a c t In the field of cognitive psychology, the p -value hypothesis test has established a stranglehold on statistical reporting. This is unfortnate, as the p -value provides at best a rough estimate of the evdence that the data provide for the presence of an experimental effect. An alternative and arguably more appropriate measure of evidence is conveyed by a Bayesian hypothesis test, which prefers the model with the highest average likelihood. One of the main problems with this Bayesian hypothesis test, however, is that it often requires relatively sophisticated numerical methods for its computation. Here we draw attention to the Savage–Dickey density ratio method, a method that can be used to compute the result of a Bayesian hypothesis test for nested models and under certain plasible restrictions on the parameter priors. Practical examples deonstrate the method’s validity, generality, and flexibility. 2009 Elsevier Inc. All rights reserved. 1. Introduction Inside every Non-Bayesian, there is a Bayesian struggling to get out – Dennis Lindley, as cited in Jaynes (2003) . How do cognitive psychologists analyze their data? Gert Gigerenzer answered this question by invoking the Freudian concept of unconscious conflict between the Superego, the Ego, and the Id ( Gigerenzer, 1993, 2004; Gigerenzer, Krauss, & Vitouch, 2004 )",
    "chunk_id": "bayesian_hypothesis_testing_for_psychologists_a_tutorial_on_the_savage–dickey_method.json_chunk_1"
  },
  {
    "document_type": "research_paper",
    "title": "Bayesian hypothesis testing for psychologists: A tutorial on the Savage–Dickey method",
    "author": "\"Eric-Jan Wagenmakers; Tom Lodewyckx; Himanshu Kuriyal; Raoul Grasman\"",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\bayesian_hypothesis_testing_for_psychologists.pdf",
    "date_published": "2010-03-03",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". In Gigerenzer’s analogy, the cognitive 0010-0285/$ - see front matter 2009 Elsevier Inc. All rights reserved. doi: 10.1016/j.cogpsych.2009.12.001 * Corresponding author. Fax: +31 20 639 0279. E-mail address: EJ.Wagenmakers@gmail.com (E.-J. Wagenmakers). Cognitive Psychology 60 (2010) 158–189 Contents lists available at ScienceDirect Cognitive Psychology journal homepage: www.elsevier.com/locate/cogpsych psychologist’s Superego wants to follow the Neyman–Pearson tradition; it seeks to contrast two weldefined hypotheses (i.e., the null hypothesis and an alternative hypothesis), it operates using concepts of a -level and power, and it is generally concerned with procedures that will work well in the long run. In contrast, the cognitive psychologist’s Ego follows the Fisherian tradition; it does not posit a specific alternative hypothesis, it ignores power, and it computes a p -value that is supposed to indicate the statistical evidence against the null hypothesis. Finally, the cognitive psychologist’s Id is Bayesian , and it desperately wants to attach probabilities to hypotheses. However, this wish is suppressed by the Superego and Ego. In its continual struggle to obtain what it desires, the Id—although unable to change the statistical analysis procedures that are used—wields its influence to change and distort the interpretations that these analysis procedures afford. 1 The unconscious Freudian conflict has arguably resulted in widespread confusion. Researchers oten assume that a small p -value means that the null hypothesis is likely to be false, that a large p -value means that the null hypothesis is likely to be true, and that a 95% confidence interval for a parameter l means that there is a 95% chance that l lies in the specified interval. All of these conclusions are false ( Haller & Krauss, 2002 )—this is because the conclusions are Bayesian, but the methodology that is used is not",
    "chunk_id": "bayesian_hypothesis_testing_for_psychologists_a_tutorial_on_the_savage–dickey_method.json_chunk_2"
  },
  {
    "document_type": "research_paper",
    "title": "Bayesian hypothesis testing for psychologists: A tutorial on the Savage–Dickey method",
    "author": "\"Eric-Jan Wagenmakers; Tom Lodewyckx; Himanshu Kuriyal; Raoul Grasman\"",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\bayesian_hypothesis_testing_for_psychologists.pdf",
    "date_published": "2010-03-03",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". All of these conclusions are false ( Haller & Krauss, 2002 )—this is because the conclusions are Bayesian, but the methodology that is used is not. To resolve the unconscious Freudian conflict and bring the statistical procedures in line with their interpretation, two courses of action present themselves. First, one can try to suppress the Id even more strongly, perhaps by rigorous statistical education and repeated warnings such as ‘‘Never use the unfortunate expression ‘accept the null-hypothesis’.” ( Wilkinson & the Task Force on Statistical Inference., 1999, p. 599 ). Second, one can explore Bayesian statistical procedures that provide exactly what the Id wants—probabilities for hypotheses. Using Bayesian procedures, one can quantify support both in favor of and against the null hypothesis ( Gallistel, 2009; Rouder, Speckman, Sun, Morey, & Iverson, 2009; Wetzels, Raaijmakers, Jakab, & Wagenmakers, 2009 ), and one can state that the proability that a parameter l lies in a 95% ‘‘credible interval” is, indeed, .95. In this article, we promote the second course of action. In order to keep this article self-contained, we first provide a brief overview of the Bayesian pardigm, with special emphasis on the difference between parameter estimation and hypothesis testing. We then describe a method, known as the Savage–Dickey density ratio, to carry out a Bayesian hypothesis test with relative ease. Next we illustrate the practical value of the Savage–Dickey method by applying it to three data sets",
    "chunk_id": "bayesian_hypothesis_testing_for_psychologists_a_tutorial_on_the_savage–dickey_method.json_chunk_3"
  },
  {
    "document_type": "research_paper",
    "title": "Bayesian hypothesis testing for psychologists: A tutorial on the Savage–Dickey method",
    "author": "\"Eric-Jan Wagenmakers; Tom Lodewyckx; Himanshu Kuriyal; Raoul Grasman\"",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\bayesian_hypothesis_testing_for_psychologists.pdf",
    "date_published": "2010-03-03",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Next we illustrate the practical value of the Savage–Dickey method by applying it to three data sets. The first data set is used to test the hypothesis that the sexual behaior of so-called virginity pledgers differs from that of non-pledgers (i.e., a hypothesis test for the equaity of two rates, Brückner & Bearman, 2005 ); the second data set is used to test the hypothesis that prior study of both choice alternatives improves later performance in a two-choice perceptual identfication task (i.e., a hypothesis test in a hierarchical within-subjects design, Zeelenberg, Wagenmakers, & Raaijmakers, 2002 ); and the third data set is used to test the hypothesis that typically developing children outperform children with ADHD on the Wisconsin card sorting test (i.e., a hypothesis test in a hierarchical between-subjects design, Geurts, Verté, Oosterlaan, Roeyers, & Sergeant, 2004 ). In these examples, we show how the Bayesian hypothesis test can be adjusted to deal with random effects and order-restrictions, both for within-subjects and between-subjects designs. WinBUGS code is presented in Appendix B and R code is available online. 2 2. Bayesian background Before outlining the Savage–Dickey method, it is important to introduce some key concepts of Bayesian inference. More detailed information can be found in Bayesian articles and books that discuss philosophical foundations ( Lindley, 2000; O’Hagan & Forster, 2004 ), computational innovations ( Gamerman & Lopes, 2006 ), and practical contributions ( Congdon, 2003; Ntzoufras, 2009 ). An idepth discussion on the advantages of Bayesian inference, especially when compared to p -value 1 For more information about the difference between the three statistical paradigms, see for instance Christensen (2005), Hubbard and Bayarri (2003) and Royall (1997) . 2 All computer code is available from the first author’s website, http://users.fmg.uva.nl/ewagenmakers/papers.html . E.-J. Wagenmakers et al",
    "chunk_id": "bayesian_hypothesis_testing_for_psychologists_a_tutorial_on_the_savage–dickey_method.json_chunk_4"
  },
  {
    "document_type": "research_paper",
    "title": "Bayesian hypothesis testing for psychologists: A tutorial on the Savage–Dickey method",
    "author": "\"Eric-Jan Wagenmakers; Tom Lodewyckx; Himanshu Kuriyal; Raoul Grasman\"",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\bayesian_hypothesis_testing_for_psychologists.pdf",
    "date_published": "2010-03-03",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". 2 All computer code is available from the first author’s website, http://users.fmg.uva.nl/ewagenmakers/papers.html . E.-J. Wagenmakers et al. / Cognitive Psychology 60 (2010) 158–189 159 hypothesis testing, is beyond the scope of this article, and we instead refer the interested reader to Berger and Berry (1988b), Edwards, Lindman, and Savage (1963), Sellke, Bayarri, and Berger (2001), Wagenmakers (2007) and Wagenmakers et al. (2008) . Those familiar with Bayesian inference can safely skip to the section that introduces the Savage–Dickey method. 2.1. Bayesian parameter estimation As is customary, we introduce Bayesian parameter estimation by means of the binomial example. Assume we prepare for you a series of 10 factual true/false questions of equal difficulty. Interest ceters on your latent probability h of answering any one question correctly. In Bayesian inference, uncetainty with respect to parameters is—at any point in time—quantified by probability distributions. Thus, in order to get the Bayesian inference machine off the ground, we need to specify our uncetainty with respect to h before seeing the data. Suppose you do not know anything about the topic or about the difficulty level of the questions. Then, a reasonable ‘‘prior distribution”, denoted by p ð h Þ , is one that assigns equal probability to every value of h . This uniform distribution is shown by the dotted horizontal line in Fig. 1 . Now we proceed with the test, and find that you answered 9 out of 10 questions correctly. After having seen these data, our updated knowledge about h is described by a ‘‘posterior distribution”, dnoted p ð h j s ; n Þ , where s 1⁄4 9 and n 1⁄4 10 indicate the number of successes and the number of questions, respectively",
    "chunk_id": "bayesian_hypothesis_testing_for_psychologists_a_tutorial_on_the_savage–dickey_method.json_chunk_5"
  },
  {
    "document_type": "research_paper",
    "title": "Bayesian hypothesis testing for psychologists: A tutorial on the Savage–Dickey method",
    "author": "\"Eric-Jan Wagenmakers; Tom Lodewyckx; Himanshu Kuriyal; Raoul Grasman\"",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\bayesian_hypothesis_testing_for_psychologists.pdf",
    "date_published": "2010-03-03",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Assume that the probability of the data is given by the binomial distribution: p ð s j h ; n Þ 1⁄4 n s h s ð 1 h Þ n s : ð 1 Þ The transition from prior p ð h Þ to posterior p ð h j s ; n Þ is then given by Bayes’ rule, p ð h j s ; n Þ 1⁄4 p ð s j h ; n Þ p ð h Þ p ð s j n Þ : ð 2 Þ Density Density Fig. 1. Bayesian parameter estimation for binomial rate parameter h , after observing nine correct responses and one incorrect response. The mode of the posterior distribution for h is 0.9, equal to the maximum likelihood estimate, and the 95% confidence interval extends from 0.59 to 0.98. The two black circles positioned at h 1⁄4 0 : 5 help to illustrate the Savage–Dickey density ratio discussed later. 160 E.-J. Wagenmakers et al. / Cognitive Psychology 60 (2010) 158–189 This equation is often presented as posterior 1⁄4 likelihood prior marginal likelihood : ð 3 Þ Note that the marginal likelihood (i.e., the probability of the observed data) does not involve the parameter h , and is given by a single number that ensures that the area under the posterior distribtion equals 1. Therefore, Eq. (2) is often written as p ð h j s ; n Þ / p ð s j h ; n Þ p ð h Þ ; ð 4 Þ which says that the posterior is proportional to the likelihood times the prior. The solid line in Fig. 1 shows the posterior distribution for h , which is obtained when the uniform prior is updated with data s 1⁄4 9 and n 1⁄4 10. The central tendency of a posterior distribution is often summarized by its mean, median, or mode. Note that with a uniform prior, the mode of a posterior distribution coincides with the classical maximum likelihood estimate or MLE, ^ h 1⁄4 s = n 1⁄4 0 : 9 ( Myung, 2003 ). The spread of a posterior distribution is most easily captured by a Bayesian x % confidence inteval that extends from the ð x = 2 Þ th to the ð 100 x = 2 Þ th percentile of the posterior distribution. For the posterior distribution in Fig. 1 , a 95% Bayesian confidence interval for h extends from 0.59 to 0.98",
    "chunk_id": "bayesian_hypothesis_testing_for_psychologists_a_tutorial_on_the_savage–dickey_method.json_chunk_6"
  },
  {
    "document_type": "research_paper",
    "title": "Bayesian hypothesis testing for psychologists: A tutorial on the Savage–Dickey method",
    "author": "\"Eric-Jan Wagenmakers; Tom Lodewyckx; Himanshu Kuriyal; Raoul Grasman\"",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\bayesian_hypothesis_testing_for_psychologists.pdf",
    "date_published": "2010-03-03",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". For the posterior distribution in Fig. 1 , a 95% Bayesian confidence interval for h extends from 0.59 to 0.98. In contrast to the classical or orthodox confidence interval, the Bayesian confidence interval has a direct and intuitive interpretation: after observing the data, we can be 95% confident that the true value of h lies in between 0.59 and 0.98. Now suppose we design a new set of five questions, of equal difficulty as before. How can we fomalize our expectations about your performance on this new set? In other words, how can we use the posterior distribution p ð h j n 1⁄4 10 ; s 1⁄4 9 Þ —which after all represents everything that we know about h from the old set—to predict the number of correct responses out of the new set of n new 1⁄4 5 questions? The mathematical solution is to integrate over the posterior, p ð s new j n new 1⁄4 5 Þ 1⁄4 Z 1 0 p ð s new j h ; n new 1⁄4 5 Þ p ð h j n 1⁄4 10 ; s 1⁄4 9 Þ d h ; ð 5 Þ where s new is the predicted number of correct responses out of the additional set of five questions. Computationally, one may think of this procedure as repeatedly drawing a random value h i from the posterior, and using that value to every time determine a single s new i by means of Eq. (1) . The end result, p ð s new j n new 1⁄4 5 Þ , is the predictive density of the possible number of correct responses in the additional set of five questions. The important point is that by integrating over the posterior, all predictive uncertainty is taken into account. In contrast, much of classical inference relies on the ‘‘plug-in principle” that in this case would lead us to predict p ð s new j n new 1⁄4 5 Þ solely based on ^ h , the maximum likelihood estimate. Plug-in procedures ignore uncertainty in h , and hence lead to preditions that are overconfident, that is, predictions that are less variable than they should be ( Aitchison & Dunsmore, 1975 ). 3 You are now presented with the new set of five questions. You answer 3 out of 5 correctly",
    "chunk_id": "bayesian_hypothesis_testing_for_psychologists_a_tutorial_on_the_savage–dickey_method.json_chunk_7"
  },
  {
    "document_type": "research_paper",
    "title": "Bayesian hypothesis testing for psychologists: A tutorial on the Savage–Dickey method",
    "author": "\"Eric-Jan Wagenmakers; Tom Lodewyckx; Himanshu Kuriyal; Raoul Grasman\"",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\bayesian_hypothesis_testing_for_psychologists.pdf",
    "date_published": "2010-03-03",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". 3 You are now presented with the new set of five questions. You answer 3 out of 5 correctly. How do we combine this new information with the old? Or, in other words, how do we update our knowledge of h ? Consistent with intuition, Bayes’ rule entails that the prior that should be updated based on your performance for the new set is the posterior that was obtained based on your performance for the old set. Or, as Lindley put it, ‘‘today’s posterior is tomorrow’s prior” ( Lindley, 1972, p. 2 ). When all the data have been collected, however, the precise order in which this was done is irrelevant; the results from the 15 questions could have been analyzed as a single batch, they could have been analyzed sequetially, one-by-one, they could have been analyzed by first considering the set of 10 questions and next the set of 5, or vice versa. For all these cases, the end result, the final posterior distribution for h , is identical. This again contrasts with classical inference, in which inference for sequential designs is diferent from that for non-sequential designs (for a discussion, see e.g., Anscombe, 1963 ). 3 It should be acknowledged that classical statisticians can account for uncertainty in the estimation of h by repeatedly drawing a bootstrap sample from the data, calculating the associated bootstrap MLE, and finding the corresponding prediction for s new (e.g., Wagenmakers, Ratcliff, Gomez, & Iverson, 2004 ). E.-J. Wagenmakers et al. / Cognitive Psychology 60 (2010) 158–189 161 Thus, a posterior distribution describes our uncertainty with respect to a parameter of interest, and the posterior is useful—or, as a Bayesian would have it, necessary—for probabilistic prediction and for sequential updating. Unfortunately, the posterior distribution or any of its summary measures can only be obtained in closed form for a restricted set of relatively simple models",
    "chunk_id": "bayesian_hypothesis_testing_for_psychologists_a_tutorial_on_the_savage–dickey_method.json_chunk_8"
  },
  {
    "document_type": "research_paper",
    "title": "Bayesian hypothesis testing for psychologists: A tutorial on the Savage–Dickey method",
    "author": "\"Eric-Jan Wagenmakers; Tom Lodewyckx; Himanshu Kuriyal; Raoul Grasman\"",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\bayesian_hypothesis_testing_for_psychologists.pdf",
    "date_published": "2010-03-03",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Unfortunately, the posterior distribution or any of its summary measures can only be obtained in closed form for a restricted set of relatively simple models. To illustrate in the case of our binomial example, the uniform prior is a so-called beta distribution with parameters a 1⁄4 1 and b 1⁄4 1, and when combined with the binomial likelihood this yields a posterior that is also a beta ditribution, be it with parameters a þ s and b þ n s . In simple conjugate cases such as these, where the prior and the posterior belong to the same distributional family, it is possible to obtain closed form solutions for the posterior distribution, but in other more interesting cases it is not. For a long time, researchers did not know how to proceed with Bayesian inference when the poterior could not be obtained in close form. As a result, practitioners interested in models of realistic complexity did not much use Bayesian inference. This situation changed with the advent of coputer-driven sampling methodology generally known as Markov chain Monte Carlo (i.e., MCMC; e.g., Gamerman & Lopes, 2006; Gilks, Richardson, & Spiegelhalter, 1996 ). Using MCMC techniques such as Gibbs sampling or the Metropolis–Hastings algorithm, researchers can now directly sample squences of values from the posterior distribution of interest, foregoing the need for closed form anlytic solutions. At the time of writing, the adage is that Bayesian models are limited only by the user’s imagination. To provide a concrete and simple illustration of Bayesian inference using MCMC, we revisit our binomial example of 9 correct responses out of 10 questions, and the associated inference problem for h , the probability of answering any one question correctly",
    "chunk_id": "bayesian_hypothesis_testing_for_psychologists_a_tutorial_on_the_savage–dickey_method.json_chunk_9"
  },
  {
    "document_type": "research_paper",
    "title": "Bayesian hypothesis testing for psychologists: A tutorial on the Savage–Dickey method",
    "author": "\"Eric-Jan Wagenmakers; Tom Lodewyckx; Himanshu Kuriyal; Raoul Grasman\"",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\bayesian_hypothesis_testing_for_psychologists.pdf",
    "date_published": "2010-03-03",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Throughout this article, we use the general-purpose WinBUGS program ( Lunn, Thomas, Best, & Spiegelhalter, 2000; Lunn, Spiegelhalter, Thomas, & Best, 2009 ; an introduction for psychologists is given by Sheu & O’Curry, 1998 ) that allows the user to specify and fit models without having to hand-code the MCMC algorithms. Although WinBUGS does not work for every application, it will work for most applications in the field of psychology. The WinBUGS program is easy to learn and is supported by a large community of active researchers. 4 The WinBUGS program requires the user to construct a file that contains the model specification, a file that contains initial values for the model parameters, and a file that contains the data. The model specification file is most important. For our binomial example, we set out to obtain samples from the prior and the posterior of h . The associated WinBUGS model specification code is three lines long: model { theta dbeta(1,1) # the uniform prior for updating by the data k dbin(theta,n) # the data; in our example, k = 9 and n = 10 thetaprior dbeta(1,1) # a uniform prior not for updating } In this code, the ‘‘ ” or twiddle symbol denotes ‘‘is distributed as”, dbeta(a,b) indicates the beta distribution with parameters a and b , and dbin(theta,n) indicates the binomial distribution with rate theta and n observations. These and many other distributions are build in to the WinBUGS system. The ‘‘#” or hash sign is used for commenting out what should not be compiled. As WinBUGS is a declarative language, the order of the three lines is inconsequential. When this code is executed, the user obtains a sequence of samples (i.e., an MCMC chain) from the posterior p ð h j D Þ and a sequence of samples from the prior p ð h Þ . In more complex models, it may take some time before the chain converges from its starting value to what is called its stationary distribtion",
    "chunk_id": "bayesian_hypothesis_testing_for_psychologists_a_tutorial_on_the_savage–dickey_method.json_chunk_10"
  },
  {
    "document_type": "research_paper",
    "title": "Bayesian hypothesis testing for psychologists: A tutorial on the Savage–Dickey method",
    "author": "\"Eric-Jan Wagenmakers; Tom Lodewyckx; Himanshu Kuriyal; Raoul Grasman\"",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\bayesian_hypothesis_testing_for_psychologists.pdf",
    "date_published": "2010-03-03",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". In more complex models, it may take some time before the chain converges from its starting value to what is called its stationary distribtion. To make sure that we only use those samples that come from the stationary distribution (and are hence unaffected by the starting values) it is good practice to discard the first samples as ‘‘burn-in”, and to diagnose convergence by running multiple chains. For instance, Fig. 2 shows the first 100 iterations for three chains that were set up to draw values from the posterior for h . The three chains are almost indistinguishable, and they do not have slow 4 For more information on WinBUGS see http://www.mrc-bsu.cam.ac.uk/bugs/ . 162 E.-J. Wagenmakers et al. / Cognitive Psychology 60 (2010) 158–189 upward or downward drift; these are two qualitative signs that the chains have converged and that samples are being drawn from the posterior distribution. Quantitative measures for diagnosing covergence are also available (e.g., the Gelman and Rubin (1992) b R statistic, that compares within-chain to between-chain variability; for more recommendations regarding convergence see e.g., Gamerman and Lopes (2006) , Gelman (1996) , and Gelman and Hill (2007) ). After assuring ourselves that the chains have converged, we can use the sampled values to plot a histogram, construct a density estimate, and compute values of interest. To illustrate, the three chains from Fig. 2 were run for 3000 iterations each, for a total of 9000 samples for the prior and the posterior of h . Fig. 3 plots histograms 5 for the prior (i.e., dotted line) and the posterior (i.e., thick solid line). In addition, the thin solid lines represent logspline nonparametric density estimates ( Stone, Hansen, Kooerberg, & Truong, 1997 ). The mode of the logspline density estimate for the posterior of h is 0.89, whereas the 95% confidence interval is (0.59, 0.98), matching the analytical result shown in Fig. 1",
    "chunk_id": "bayesian_hypothesis_testing_for_psychologists_a_tutorial_on_the_savage–dickey_method.json_chunk_11"
  },
  {
    "document_type": "research_paper",
    "title": "Bayesian hypothesis testing for psychologists: A tutorial on the Savage–Dickey method",
    "author": "\"Eric-Jan Wagenmakers; Tom Lodewyckx; Himanshu Kuriyal; Raoul Grasman\"",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\bayesian_hypothesis_testing_for_psychologists.pdf",
    "date_published": "2010-03-03",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". The mode of the logspline density estimate for the posterior of h is 0.89, whereas the 95% confidence interval is (0.59, 0.98), matching the analytical result shown in Fig. 1 . Of course, this example represents an ideal scenario; in more complicated models, convergence might be obtained only after many MCMC iterations—that is, chains may move very slowly from their starting point to the stationary distribution. This problem is often easy to diagnose by running multiple chains with overdispersed starting values. Another problem is that, even when the chains have arrived at the posterior distribution, consecutive samples might be highly correlated. This is less worrisome than the problem of nonconvergence (after all, the samples are draws from the correct posterior distribution), but it does mean that more samples need to be collected before the entire posterior is adequately covered. This problem is easy to diagnose by computing the autcorrelation of the chains. A relatively high autocorrelation suggests that we need to draw relatively many samples. Thus, for complex models it is important to use MCMC algorithms that are efficient, reliable, and quick. This is currently an active area of research. Nevertheless, the fundamental theoretical obstacles for Bayesian parameter estimation have been overcome. In fields such as statistics, artificial intelligence, and machine learning, MCMC algorithms are now used on a routine basis. MCMC Iteration Fig. 2. Three MCMC chains for binomial rate parameter h , after observing nine correct responses and one incorrect response. 5 These histograms were constructed such that the total area under each histogram equals one. E.-J. Wagenmakers et al. / Cognitive Psychology 60 (2010) 158–189 163 2.2. Bayesian hypothesis testing Up to this point we have concerned ourselves with parameter estimation, implicitly taking the appropriateness of the underlying model for granted. In much of social science, however, researchers entertain more than just a single statistical model",
    "chunk_id": "bayesian_hypothesis_testing_for_psychologists_a_tutorial_on_the_savage–dickey_method.json_chunk_12"
  },
  {
    "document_type": "research_paper",
    "title": "Bayesian hypothesis testing for psychologists: A tutorial on the Savage–Dickey method",
    "author": "\"Eric-Jan Wagenmakers; Tom Lodewyckx; Himanshu Kuriyal; Raoul Grasman\"",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\bayesian_hypothesis_testing_for_psychologists.pdf",
    "date_published": "2010-03-03",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". In much of social science, however, researchers entertain more than just a single statistical model. In fact, the statistical models often represent copeting theories or hypotheses, and the focus of interest is on which substantive theory or hypothesis is more correct, more plausible, and better supported by the data. For example, researchers might want to know whether the improvement of performance with practice follows a power function or an expnential function. As another example, we might want to know the extent to which your performance in our test (i.e., 9 correct answers out of 10 questions) is consistent with the hypothesis that you were just guessing. This may involve a test of M 1 : h 1⁄4 0 : 5 versus M 2 : h – 0 : 5. The fundamental and general Bayesian solution to the foregoing model selection of hypothesis tesing problems is as follows. For simplicity, assume that you contemplate two alternative accounts of the data, M 1 and M 2 , and that you seek to quantify model uncertainty in terms of probability. Consider first M 1 . Bayes’ rule dictates how your prior probability of M 1 ; p ð M 1 Þ , is updated through the observed data D to give the posterior probability of M 1 ; p ð M 1 j D Þ : p ð M 1 j D Þ 1⁄4 p ð M 1 Þ p ð D j M 1 Þ p ð M 1 Þ p ð D j M 1 Þ þ p ð M 2 Þ p ð D j M 2 Þ : ð 6 Þ In the same way, one can calculate the posterior probability of M 2 ; p ð M 2 j D Þ . The ratio of these posterior probabilities is given by p ð M 1 j D Þ p ð M 2 j D Þ 1⁄4 p ð M 1 Þ p ð M 2 Þ p ð D j M 1 Þ p ð D j M 2 Þ : ð 7 Þ This equation shows that the change from prior odds p ð M 1 Þ = p ð M 2 Þ to posterior odds p ð M 1 j D Þ = p ð M 2 j D Þ is determined entirely by the ratio of the marginal likelihoods p ð D j M 1 Þ = p ð D j M 2 Þ . This ratio is generally Density Density Fig. 3. MCMC-based Bayesian parameter estimation for binomial rate parameter h , after observing nine correct responses and one incorrect response. The thin solid lines indicate the fit of a nonparametric logspline density estimator",
    "chunk_id": "bayesian_hypothesis_testing_for_psychologists_a_tutorial_on_the_savage–dickey_method.json_chunk_13"
  },
  {
    "document_type": "research_paper",
    "title": "Bayesian hypothesis testing for psychologists: A tutorial on the Savage–Dickey method",
    "author": "\"Eric-Jan Wagenmakers; Tom Lodewyckx; Himanshu Kuriyal; Raoul Grasman\"",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\bayesian_hypothesis_testing_for_psychologists.pdf",
    "date_published": "2010-03-03",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". The thin solid lines indicate the fit of a nonparametric logspline density estimator. Based on this density estimator, the mode of the posterior distribution for h is approximately 0.89, and the 95% confidence interval extends from 0.59 to 0.98, closely matching the analytical results from Fig. 1 . The two black circles positioned at h 1⁄4 0 : 5 again help to illustrate the Savage–Dickey density ratio discussed later. 164 E.-J. Wagenmakers et al. / Cognitive Psychology 60 (2010) 158–189 known as the Bayes factor ( Jeffreys, 1961 ), and the Bayes factor, or the log of it, is often interpreted as the weight of evidence coming from the data ( Good, 1985 ). A hypothesis test based on the Bayes factor supports the model under which the observed data are most likely (for details see Berger & Pericchi, 1996; Bernardo & Smith, 1994, chap. 6; Klugkist, Laudy, & Hoijtink, 2002, cha 7; Klugkist et al., 2005a; Kass & Raftery, 1995; MacKay, 2003; Myung & Pitt, 1997; O’Hagan, 1995 ). Therefore, the Bayes factor represents ‘‘the standard Bayesian solution to the hypothesis testing and model selection problems” ( Lewis & Raftery, 1997, p. 648 ); in the following, we will use ‘‘Bayesian hypothesis test” as a shortcut for ‘‘a hypothesis test based on the Bayes factor”. Thus, when the Bayes factor for M 1 versus M 2 equals 2 (i.e., BF 12 1⁄4 2), this means that the data are twice as likely to have occurred under M 1 than under model M 2 . When the prior odds are equal, such that M 1 and M 2 are equally likely a priori, the Bayes factors can be converted to posterior probabilities: p ð M 1 j D Þ 1⁄4 BF 12 = ð BF 12 þ 1 Þ . This means that BF 12 1⁄4 2 translates to p ð M 1 j D Þ 1⁄4 2 = 3. To illustrate, consider again our binomial example of 9 correct responses out of 10 questions, and the test between two models for performance: guessing (i.e., M 1 : h 1⁄4 0 : 5) versus not guessing (i.e., M 2 : h – 0 : 5). From Eq. (1) , the marginal likelihood for M 1 ; p ð D j M 1 Þ , is simply 10 9 1 2 10",
    "chunk_id": "bayesian_hypothesis_testing_for_psychologists_a_tutorial_on_the_savage–dickey_method.json_chunk_14"
  },
  {
    "document_type": "research_paper",
    "title": "Bayesian hypothesis testing for psychologists: A tutorial on the Savage–Dickey method",
    "author": "\"Eric-Jan Wagenmakers; Tom Lodewyckx; Himanshu Kuriyal; Raoul Grasman\"",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\bayesian_hypothesis_testing_for_psychologists.pdf",
    "date_published": "2010-03-03",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". From Eq. (1) , the marginal likelihood for M 1 ; p ð D j M 1 Þ , is simply 10 9 1 2 10 . The marginal likelihood for model M 2 is more difficult to calculate, as h is a free parameter. In general, the marginal likelihood is obtained by integrating out the model parameters in accordance with the law of total probability: p ð D j M 2 Þ 1⁄4 Z p ð D j h ; M 2 Þ p ð h j M 2 Þ d h : ð 8 Þ This means that the marginal likelihood is computed by averaging the likelihood over the prior; conceptually, the likelihood is evaluated for every possible parameter value, weighted with its prior plausibility, and added to a summed total. When we again use the uniform distribution for h as a prior, such that p ð h j M 2 Þ Beta ð 1 ; 1 Þ , then Eq. (8) famously simplifies to p ð D j M 2 Þ 1⁄4 1 = ð n þ 1 Þ . Thus, in our binomial example, BF 12 1⁄4 10 9 1 2 10 ð n þ 1 Þ 0 : 107. This means that the data are 1 = 0 : 107 9 : 3 times more likely under M 2 than they are under M 1 . With unit prior odds, the posterior probability for M 1 is 0 : 107 = ð 0 : 107 þ 1 Þ : 10, which means that the complementary posterior probability for M 2 is approximately .90. These are probabilities assigned to hypotheses, and they are exactly what researchers (or, in Gigerenzer’s Freudian analogy, their Ids) want to know about. Posterior model probabilities are not just necessary to quantify our degree of belief or preference for the candidate models under consideration. They are also necessary for Bayesian model averaging (e.g., Draper, 1995; Hoeting, Madigan, Raftery, & Volinsky, 1999; Madigan & Raftery, 1994 ). For istance, in a regression context we might have one model, M 1 , that predicts a certain post-surgery survival rate by gender, age, weight, and history of smoking. A second model, M 2 , includes two addtional predictors, namely body-mass index and fitness. We compute posterior model probabilities and find that p ð M 1 j D Þ 1⁄4 : 6 and consequently p ð M 2 j D Þ 1⁄4 : 4",
    "chunk_id": "bayesian_hypothesis_testing_for_psychologists_a_tutorial_on_the_savage–dickey_method.json_chunk_15"
  },
  {
    "document_type": "research_paper",
    "title": "Bayesian hypothesis testing for psychologists: A tutorial on the Savage–Dickey method",
    "author": "\"Eric-Jan Wagenmakers; Tom Lodewyckx; Himanshu Kuriyal; Raoul Grasman\"",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\bayesian_hypothesis_testing_for_psychologists.pdf",
    "date_published": "2010-03-03",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". We compute posterior model probabilities and find that p ð M 1 j D Þ 1⁄4 : 6 and consequently p ð M 2 j D Þ 1⁄4 : 4. For a given patient, M 1 predicts a survival rate of 90%, and M 2 predicts a survival rate of 80%. What is our best prediction for our patient’s suvival rate? It is tempting to base our prediction solely on M 1 , which is after all the preferred model. However, this would ignore the uncertainty inherent in the model selection procedure, and it would ignore the very real possibility that the best model is M 2 , according to which the survival rate is 10% lower than it is for M 1 . The Bayesian solution is to weight the two competing predictions with their associated posterior model probabilities, fully taking into account the uncertainty in the model selection procedure. In our example, the model-averaged prediction for survival rate would be : 6 90 % þ : 4 80 % 1⁄4 86 % . 2.2.1. Additional advantages of Bayesian hypothesis testing We have seen how Bayes factors and posterior model probabilities describe the relative support or preference for a set of candidate models, and how they can be used for model averaged predictions. Other advantages of Bayesian hypothesis testing include the following ( Wagenmakers, Lee, Lodwyckx, & Iverson, 2008; see also Berger & Pericchi, 2001; Dennis, Lee, & Kinnell, 2008; Kass & Raftery, 1995 ): E.-J. Wagenmakers et al. / Cognitive Psychology 60 (2010) 158–189 165 1. Coherence is guaranteed. Suppose we have a set of three candidate models, M 1 ; M 2 , and M 3 . As p ð D j M 1 Þ p ð D j M 3 Þ 1⁄4 p ð D j M 1 Þ p ð D j M 2 Þ p ð D j M 2 Þ p ð D j M 3 Þ ; ð 9 Þ this means that BF 13 1⁄4 BF 12 BF 23 . For instance, when the data are five times as likely to occur under M 1 than under M 2 , and seven time as likely under M 2 than under M 3 , it follows that the data are 5 7 1⁄4 35 times as likely under M 1 than under M 3 . No comparable result exists in clasical statistics. 2. Parsimony is automatically rewarded",
    "chunk_id": "bayesian_hypothesis_testing_for_psychologists_a_tutorial_on_the_savage–dickey_method.json_chunk_16"
  },
  {
    "document_type": "research_paper",
    "title": "Bayesian hypothesis testing for psychologists: A tutorial on the Savage–Dickey method",
    "author": "\"Eric-Jan Wagenmakers; Tom Lodewyckx; Himanshu Kuriyal; Raoul Grasman\"",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\bayesian_hypothesis_testing_for_psychologists.pdf",
    "date_published": "2010-03-03",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". No comparable result exists in clasical statistics. 2. Parsimony is automatically rewarded. The main challenge of hypothesis testing or model selection is to identify the model with the best predictive performance (e.g., Myung, Forster, & Browne, 2000; Wagenmakers & Waldorp, 2006 ). However, it is not immediately obvious how this should be done; complex models will generally provide a better fit to the observed data than simple models, and therefore one cannot simply prefer the model with the best ‘‘goodness-of-fit”—such a strategy would lead to overfitting. Intuition suggest that this tendency for overfitting should be counteracted by putting a premium on simplicity. This intuition is consistent with the law of pasimony or ‘‘Ockham’s razor” which states that, when everything else is equal, simple models are to be preferred over complex models ( Jaynes, 2003, chap. 20; Myung & Pitt, 1997 ). Formal model selection methods try to quantify the tradeoff between goodness-of-fit and parsmony. Many of these methods measure a model’s overall performance by the sum of two coponents, one that measures descriptive accuracy and one that places a premium on parsimony. The latter component is also known as the Ockham factor ( MacKay, 2003, chap. 28 ). For many model selection methods, the crucial issue is how to determine the Ockham factor. One of the attractive features of Bayesian hypothesis testing is that it automatically determines the model with the best predictive performance – Bayesian hypothesis testing therefore incorporates what is known as an automatic Ockham’s razor ( Myung & Pitt, 1997 ). To see why this is the case, consider that every statistical model makes a priori predictions. Coplex models have a relatively large parameter space, and are therefore able to make many more predictions and cover many more eventualities than simple models. However, the drawback for complex models is that they need to spread out their prior probability across their entire paraeter space",
    "chunk_id": "bayesian_hypothesis_testing_for_psychologists_a_tutorial_on_the_savage–dickey_method.json_chunk_17"
  },
  {
    "document_type": "research_paper",
    "title": "Bayesian hypothesis testing for psychologists: A tutorial on the Savage–Dickey method",
    "author": "\"Eric-Jan Wagenmakers; Tom Lodewyckx; Himanshu Kuriyal; Raoul Grasman\"",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\bayesian_hypothesis_testing_for_psychologists.pdf",
    "date_published": "2010-03-03",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". However, the drawback for complex models is that they need to spread out their prior probability across their entire paraeter space. In the limit, a model that predicts almost everything has to spread out its prior proability so thinly that the occurrence of any particular event will not greatly add to that model’s credibility. As shown by Eq. (8) , the marginal likelihood for a model M is calculated by averaging the likelihood p ð D j h ; M Þ over the prior p ð h j M Þ . When the prior is very spread out, it will occupy a relatively large part of the parameter space in which the likelihood is almost zero, and this greatly decreases the average or marginal likelihood. Consider for instance the situation shown in Fig. 1 . The prior on the rate parameter h was assumed to be uniform from 0 to 1, h U 1⁄2 0 ; 1 . A different, more parsimonious model could take into account the prior knowledge that h is unlkely to be lower than 0.5, as this would mean that your ability would be lower than chance (recall that the questions were true/false, such that the absence of any knowledge corresponds to h 1⁄4 0 : 5). This more informed model could be instantiated as h U 1⁄2 0 : 5 ; 1 , and we could then use the Bayes factor to compute the relative plausibility of model M 1 : h U 1⁄2 0 ; 1 versus M 2 : h U 1⁄2 0 : 5 ; 1 . The more complex model M 1 kept its options open by assigning half of its prior mass to values for h that are smaller than 0.5. This could have been advantageous when the data would have turned out differently (e.g., 1 correct answer instead of 9). As it is, the values of h that are smaller than 0.5 are very unlikely; hence, the average likelihood is almost twice as high for the parsimonious model M 2 than it is for the more complex model M 1 . 3. Evidence can be obtained in favor of the null hypothesis. Bayesian hypothesis testing allows one to obtain evidence in favor of the null hypothesis",
    "chunk_id": "bayesian_hypothesis_testing_for_psychologists_a_tutorial_on_the_savage–dickey_method.json_chunk_18"
  },
  {
    "document_type": "research_paper",
    "title": "Bayesian hypothesis testing for psychologists: A tutorial on the Savage–Dickey method",
    "author": "\"Eric-Jan Wagenmakers; Tom Lodewyckx; Himanshu Kuriyal; Raoul Grasman\"",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\bayesian_hypothesis_testing_for_psychologists.pdf",
    "date_published": "2010-03-03",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". 3. Evidence can be obtained in favor of the null hypothesis. Bayesian hypothesis testing allows one to obtain evidence in favor of the null hypothesis. Because theories and models often predict the absence of a difference, it is vital for scientific progress to be able to quantify evidence in favor of the null hypothesis (e.g., Gallistel, 2009; Rouder et al., 2009; Wetzels et al., 2009 ). In the field of visual word recognition, for instance, the entry-opening theory ( Forster, Mohan, & Hector, 2003 ) predicts that masked priming is absent for items that do not have a lexical representation; 166 E.-J. Wagenmakers et al. / Cognitive Psychology 60 (2010) 158–189 Another example from that literature concerns the work by Bowers, Vigliocco, and Haan (1998) , who have argued that priming effects are equally large for words that look the same in lower and upper case (e.g., kiss/KISS) or that look different (e.g., edge/EDGE), a finding supportive of the hypothesis that priming depends on abstract letter identities. A final example comes from the field of recognition memory, where Dennis and Humphreys’ bind cue decide model of episodic memory (BCDMEM) predicts the absence of a list-length effect and the absence of a list-strength effect ( Dennis & Humphreys, 2001 ). This radical prediction of a null effect allows researchers to distinguish between context-noise and item-noise theories of infeence in memory ( Dennis et al., 2008 ). In Bayesian statistics, the null hypothesis has no special status, and evidence for it is quantified just as it is for any other hypothesis. In classical statistics, support for informative predictions from null hypothesis can only be indirect. 4. Evidence may be monitored as it accumulates. Bayesian hypothesis testing allows one to monitor the evidence as the data come in ( Berger & Berry, 1988a ). In contrast to frequentist inference, Bayesian inference does not require special corrections for ‘‘optional stopping” ( Wagenmakers, 2007 )",
    "chunk_id": "bayesian_hypothesis_testing_for_psychologists_a_tutorial_on_the_savage–dickey_method.json_chunk_19"
  },
  {
    "document_type": "research_paper",
    "title": "Bayesian hypothesis testing for psychologists: A tutorial on the Savage–Dickey method",
    "author": "\"Eric-Jan Wagenmakers; Tom Lodewyckx; Himanshu Kuriyal; Raoul Grasman\"",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\bayesian_hypothesis_testing_for_psychologists.pdf",
    "date_published": "2010-03-03",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". In contrast to frequentist inference, Bayesian inference does not require special corrections for ‘‘optional stopping” ( Wagenmakers, 2007 ). Consider, for instance, a hypothetical experiment on the neural substrate of dissociative identity disorder. In this experiment, the researcher Lisa has decided in advance to use functional manetic resonance imaging (fMRI) to test 30 patients and 30 normal controls. Lisa inspects the data after 15 participants in each group have been tested, and finds that the results convincingly demonstrate the pattern she hoped to find. Unfortunately for Lisa, she cannot stop the experment and claim a significant result, as she would be changing the sampling plan halfway through and be guilty of ‘‘optional stopping”. She has to continue the experiment, wasting not just her time and money, but also the time and efforts of the people who undergo needless testing. In contrast, for Bayesian hypothesis testing there is nothing wrong with gathering more data, examining these data, and then deciding whether or not to stop collecting new data – no special corrections are needed. As stated by Edwards et al. (1963) , ‘‘( ) the rules governing when data collection stops are irrelevant to data interpretation. It is entirely appropriate to collect data until a point has been proven or disproven, or until the data collector runs out of time, money, or patience.” ( Edwards et al., 1963, p. 193 ). 2.2.2. Challenges for Bayesian hypothesis testing Bayesian hypothesis testing using Bayes factors (Eq. (7) ) faces two main challenges, one conceptual and one computational. The conceptual challenge is that the Bayesian hypothesis test is acutely sesitive to the specification of the prior distributions for the model parameters (e.g., Bartlett, 1957; Liu & Aitkin, 2008 ). This distinguishes hypothesis testing from parameter estimation, in which the data quickly overwhelm the prior; the accumulation of data forces prior opinions that are very different to converge to posterior opinions that are very similar",
    "chunk_id": "bayesian_hypothesis_testing_for_psychologists_a_tutorial_on_the_savage–dickey_method.json_chunk_20"
  },
  {
    "document_type": "research_paper",
    "title": "Bayesian hypothesis testing for psychologists: A tutorial on the Savage–Dickey method",
    "author": "\"Eric-Jan Wagenmakers; Tom Lodewyckx; Himanshu Kuriyal; Raoul Grasman\"",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\bayesian_hypothesis_testing_for_psychologists.pdf",
    "date_published": "2010-03-03",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". For parameter estimation then, the choice of a prior distribution is not really all that critical unless there are very few data points. In contrast, for Bayesian hypothesis testing the prior distributions are crucial and have a lasting impact. This occurs because the marginal likelihood is an average taken with respect to the prior. Cosider for instance the prior for the mean l of a Normal distribution with known variance. One might be tempted to use an ‘‘uninformative” prior, one that does not express much preference for one value of l over the other. One such vague prior could be a Normal distribution with mean zero and variance 10,000. But, from a marginal likelihood perspective, this prior is consistent with almost any value of l . When one hedges one’s bets to such an extreme degree, the Bayes factor is likely to show a preerence for a simple model (e.g., one in which l 1⁄4 0), even when the data appear wildly inconsistent with it. The main problem here is not that the Bayesian hypothesis test corrects for model complexity as manifested in the prior distribution. This is the automatic Ockam’s razor that is an asset, not a liability, of the Bayesian hypothesis test. Instead, the problem seems to be that researchers have only a vague idea of the vagueness of their prior knowledge, or that researchers seek to use a prior that is ‘‘objetive”, and uses as little prior knowledge as possible. When the vagueness of the prior is arbitrary, so are the results from the Bayesian hypothesis test. When the vagueness of the prior is purposefully E.-J. Wagenmakers et al. / Cognitive Psychology 60 (2010) 158–189 167 large, the results from the Bayesian hypothesis test tend to indicate a preference for the simple model, regardless of the data",
    "chunk_id": "bayesian_hypothesis_testing_for_psychologists_a_tutorial_on_the_savage–dickey_method.json_chunk_21"
  },
  {
    "document_type": "research_paper",
    "title": "Bayesian hypothesis testing for psychologists: A tutorial on the Savage–Dickey method",
    "author": "\"Eric-Jan Wagenmakers; Tom Lodewyckx; Himanshu Kuriyal; Raoul Grasman\"",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\bayesian_hypothesis_testing_for_psychologists.pdf",
    "date_published": "2010-03-03",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Wagenmakers et al. / Cognitive Psychology 60 (2010) 158–189 167 large, the results from the Bayesian hypothesis test tend to indicate a preference for the simple model, regardless of the data. In order to increase the robustness of Bayesian hypothesis testing to the vagueness of the prior, several procedures have been proposed, including the local Bayes factor ( Smith & Spiegelhalter, 1980 ), the intrinsic Bayes factor ( Berger & Mortera, 1999; Berger & Pericchi, 1996 ), the fractional Bayes factor ( O’Hagan, 1995 ), and the partial Bayes factor ( O’Hagan, 1995 ; for a summary see Gill, 2002, chap. 7 ). The idea of the partial Bayes factor is to sacrifice a small part of the data to obtain a posterior that is robust to the various priors one might entertain. The Bayes factor is then calculated by integraing the likelihood over this posterior instead of over the original prior. Procedures such as these are still undergoing further development and deserve more study. The problem of vague priors is particularly evident for parameters that can take on values across the entire real line, such as the mean l of a Normal distribution. We believe that in such cases, wheever possible, the construction of a prior should be guided by the substantive knowledge in the dmain of application. As Dennis Lindley has pointed out repeatedly, l is only a Greek letter, an abstraction that may obscure the fact that it refers to something about which we have detailed prior knowledge. When l stands for a person’s weight, few rational people would assign l an ‘‘uninformtive” Normal prior distribution with mean zero and variance 10,000. In this paper, we sidestep this conceptual challenge to some extent, as we focus completely on dicrete data problems (i.e., those that involve a hit or a miss, a success of a failure, a yes or a no). In such cases, a perfectly plausible prior assigns equal mass to every value of the underlying rate parameter h",
    "chunk_id": "bayesian_hypothesis_testing_for_psychologists_a_tutorial_on_the_savage–dickey_method.json_chunk_22"
  },
  {
    "document_type": "research_paper",
    "title": "Bayesian hypothesis testing for psychologists: A tutorial on the Savage–Dickey method",
    "author": "\"Eric-Jan Wagenmakers; Tom Lodewyckx; Himanshu Kuriyal; Raoul Grasman\"",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\bayesian_hypothesis_testing_for_psychologists.pdf",
    "date_published": "2010-03-03",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". In such cases, a perfectly plausible prior assigns equal mass to every value of the underlying rate parameter h . In some cases, we use order-restrictions and assign equal mass to every value of h greater than .5. We feel that in the absence of detailed prior knowledge, this assumption is reasonable. Note, however, that our approach in this paper is entirely general; when you are willing to defend and use a different prior, you are free to do so. The second challenge for Bayesian hypothesis testing—the one that is the focus of this article—is that the marginal likelihood and the Bayes factor are often quite difficult to compute. Earlier, we saw that with a uniform prior on the binomial rate parameter h (i.e., p ð h j M Þ Beta ð 1 ; 1 Þ ), the maginal likelihood R p ð D j h ; M Þ p ð h j M Þ d h simplifies to 1 = ð 1 þ n Þ . However, in all but a few simple moels, such simplifications are impossible. In order to be able to compute the marginal likelihood or the Bayes factor for more complex models, a series of different computational methods has been developed. A recent summary lists as many as 15 different methods ( Gamerman & Lopes, 2006, chap. 7 ). For instance, one method computes the marginal likelihood through what is called the candidates’ formula ( Besag, 1989 ) or the basic marginal likelihood identity ( Chib, 1995; Chib & Jeliazkov, 2001 ). One simply exchanges the roles of posterior and marginal likelihood to obtain p ð D Þ 1⁄4 p ð D j h Þ p ð h Þ p ð h j D Þ ; ð 10 Þ which holds for any value of h . When the posterior is available analytically, one only needs to plug in a single value of h and obtain the marginal likelihood immediately. This method can however also be applied when the posterior is only available through MCMC output, either from the Gibbs sampler ( Chib, 1995 ) or the Metropolis–Hastings algorithm ( Chib & Jeliazkov, 2001 )",
    "chunk_id": "bayesian_hypothesis_testing_for_psychologists_a_tutorial_on_the_savage–dickey_method.json_chunk_23"
  },
  {
    "document_type": "research_paper",
    "title": "Bayesian hypothesis testing for psychologists: A tutorial on the Savage–Dickey method",
    "author": "\"Eric-Jan Wagenmakers; Tom Lodewyckx; Himanshu Kuriyal; Raoul Grasman\"",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\bayesian_hypothesis_testing_for_psychologists.pdf",
    "date_published": "2010-03-03",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Another method to compute the marginal likelihood is to repeatedly sample parameter values from the prior, calculate the associated likelihoods, and then take the likelihood average. When the posteior is highly peaked compared to the prior—as will happen with many data or with a medium-sized parameter space—it becomes necessary to employ more efficient sampling methods, with a concoitant increase in computational complexity. Finally, it is also possible to compute the Bayes factor directly, without first calculating the costituent marginal likelihoods. The basic idea is to generalize the MCMC sampling routines for paraeter estimation to incorporate a ‘‘model indicator” variable. In the case of two competing models, the model indicator variable k , say, can take on two values—for instance, k 1⁄4 1 when the sampler is in model M 1 , and k 1⁄4 2 when the sampler is in model M 2 . The Bayes factor is then estimated by the relative frequency with which k 1⁄4 1 versus k 1⁄4 2. This MCMC approach to model selection 168 E.-J. Wagenmakers et al. / Cognitive Psychology 60 (2010) 158–189 is called transdimensional MCMC (e.g., Sisson, 2005 ), an approach that encompasses both reversible jump MCMC Green, 1995 and the product space technique ( Carlin & Chib, 1995; Lodewyckx et al., 2009 ). Almost all of these computational methods suffer from the fact that they become less efficient and more difficult to implement as the underlying models become more complex. We now turn to an alternative method, whose implementation is extremely straightforward. The methods’ main limittion is that it applies only to nested models, a limitation that also holds for p -values. 3. The Savage–Dickey density ratio In the simplest classical hypothesis testing framework, one contemplates two models: the null hypothesis, that fixes one of its parameters to a pre-specified value of substantive interest, say H 0 : / 1⁄4 / 0 ; and the alternative hypothesis, in which that parameter is free to vary, say H 1 : / – / 0",
    "chunk_id": "bayesian_hypothesis_testing_for_psychologists_a_tutorial_on_the_savage–dickey_method.json_chunk_24"
  },
  {
    "document_type": "research_paper",
    "title": "Bayesian hypothesis testing for psychologists: A tutorial on the Savage–Dickey method",
    "author": "\"Eric-Jan Wagenmakers; Tom Lodewyckx; Himanshu Kuriyal; Raoul Grasman\"",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\bayesian_hypothesis_testing_for_psychologists.pdf",
    "date_published": "2010-03-03",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Hence, the null hypothesis is nested under the alternative hypothesis, that is, H 0 can be obtained from H 1 by setting / equal to / 0 . Note that in the classical framework, H 0 is generally a sharp null hypotesis, or a ‘‘point null”. That is, the null hypothesis states that / is exactly equal to / 0 . For example, in the binomial example from Fig. 1 you answered 9 out of 10 questions correctly. Were you guessing or not? The classical and the Bayesian framework define H 0 : h 1⁄4 : 5 as the null hypothesis for chance performance. The alternative hypothesis under which H 0 is nested could be dfined as H 1 : h – : 5, or, more specifically, as H 1 : h Beta ð 1 ; 1 Þ , which states that h is free to vary from 0 to 1, and that it has a uniform prior distribution as shown in Fig. 1 . For the binomial example, the Bayes factor for H 0 versus H 1 could be obtained by analytically integrating out the model parameter h . However, the Bayes factor may likewise be obtained by only considering H 1 , and dividing the height of the posterior for h by the height of the prior for h , at the point of interest. This surprising result was first published by Dickey and Lientz (1970) , who attributed it to Leonard J. ‘‘Jimmie” Savage. The result is now generally known as the Svage–Dickey density ratio (e.g., Dickey, 1971; Gamerman & Lopes, 2006, pp. 72–74, pp. 79–80; Kass & Raftery, 1995, p. 780–781; O’Hagan & Forster, 2004, pp. 174–177 ; for extensions and generaliztions see Chen, 2005; Verdinelli & Wasserman, 1995 ). Mathematically, the Savage–Dickey density ratio says that BF 01 1⁄4 p ð D j H 0 Þ p ð D j H 1 Þ 1⁄4 p ð h 1⁄4 : 5 j D ; H 1 Þ p ð h 1⁄4 : 5 j H 1 Þ : ð 11 Þ A straightforward mathematical proof is presented in Appendix A (see also O’Hagan & Forster, 2004, pp. 174–177 ). In Fig. 1 , the two thick dots located at h 1⁄4 : 5 provide the required information",
    "chunk_id": "bayesian_hypothesis_testing_for_psychologists_a_tutorial_on_the_savage–dickey_method.json_chunk_25"
  },
  {
    "document_type": "research_paper",
    "title": "Bayesian hypothesis testing for psychologists: A tutorial on the Savage–Dickey method",
    "author": "\"Eric-Jan Wagenmakers; Tom Lodewyckx; Himanshu Kuriyal; Raoul Grasman\"",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\bayesian_hypothesis_testing_for_psychologists.pdf",
    "date_published": "2010-03-03",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". 174–177 ). In Fig. 1 , the two thick dots located at h 1⁄4 : 5 provide the required information. It is evident from the figure that after observing 9 out of 10 correct responses, the height of the density at h 1⁄4 : 5 has dcreased, so that one would expect these data to cast doubt on the null hypothesis and support the alternative hypothesis. Specifically, the height of the prior distribution at h 1⁄4 : 5 equals 1, and the height of the posterior distribution at h 1⁄4 : 5 equals 0.107. From Eq. (11) the corresponding Bayes fator is BF 01 1⁄4 0 : 107 = 1 1⁄4 0 : 107, and this corresponds exactly to the Bayes factor that was calculated by integrating out h . It is clear that the same procedure can be followed when the height of the posterior is not available in closed form, but instead has to be approximated from the histogram of MCMC samples. Fig. 3 shows the logspline estimates ( Stone et al., 1997 ) for the prior and the posterior densities as obtained from MCMC output. The estimated height of the prior and posterior distributions at h 1⁄4 : 5 equal 1.00 and 0.107, respectively. In most nested model comparisons, H 0 and H 1 have several free parameters in common. These parameters are usually not of direct interest, and they are not the focus of the hypothesis test. Hence, the common parameters are known as nuisance parameters . For instance, one might want to test whether or not the mean of a Normal distribution is zero (i.e., H 0 : l 1⁄4 l 0 versus H 1 : l – l 0 ), whereas the variance r 2 is common to both models and not of immediate interest. E.-J. Wagenmakers et al. / Cognitive Psychology 60 (2010) 158–189 169 In general then, the framework of nested models features a parameter vector h 1⁄4 ð / ; w Þ , where / denotes the parameter of substantive interest that is subject to test, and w denotes the set of nuisance parameters. The null hypothesis H 0 posits that / is constrained to some special value, i.e. / 1⁄4 / 0 . The alternative hypothesis H 1 assumes that / is free to vary",
    "chunk_id": "bayesian_hypothesis_testing_for_psychologists_a_tutorial_on_the_savage–dickey_method.json_chunk_26"
  },
  {
    "document_type": "research_paper",
    "title": "Bayesian hypothesis testing for psychologists: A tutorial on the Savage–Dickey method",
    "author": "\"Eric-Jan Wagenmakers; Tom Lodewyckx; Himanshu Kuriyal; Raoul Grasman\"",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\bayesian_hypothesis_testing_for_psychologists.pdf",
    "date_published": "2010-03-03",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". The null hypothesis H 0 posits that / is constrained to some special value, i.e. / 1⁄4 / 0 . The alternative hypothesis H 1 assumes that / is free to vary. Now consider H 1 , and let / ! / 0 ; this effetively means that H 1 reduces to H 0 —it is therefore reasonable to assume that p ð w j / ! / 0 ; H 1 Þ 1⁄4 p ð w j H 0 Þ (but see Consonni & Veronese, 2008 ). In other words, when / ! / 0 the prior for the nuisance parameters under H 1 should equal the prior for the nuisance parameters under H 0 . When this condtion holds, Appendix A shows that the nuisance parameters affect the Bayes factor only through the posterior for / , so that again BF 01 1⁄4 p ð D j H 0 Þ p ð D j H 1 Þ 1⁄4 p ð / 1⁄4 / 0 j D ; H 1 Þ p ð / 1⁄4 / 0 j H 1 Þ ; ð 12 Þ which equals the ratio of the heights for the posterior and the prior distribution for / at / 0 . Thus, the Savage–Dickey density ratio holds under relatively general conditions. Eq. (12) conveys several important messages: 1. Relevance of the prior for the parameter of interest. The denominator of Eq. (12) features the height of the prior for / at / 1⁄4 / 0 . This means that the choice of prior can greatly influence the Bayes factor, a fact that is also illustrated by Figs. 1 and 3 . The choice of prior will also influence the shape of the posterior, of course, but this influence quickly diminishes as the data accumulate. This point undescores the conceptual challenge for the Bayes factors that was noted earlier (e.g., Bartlett, 1957; Liu & Aitkin, 2008 ). For example, consider again a test for a Normal mean l , with H 0 : l 1⁄4 0 and H 1 : l – 0. Suppose the prior for l is a uniform distribution that ranges from a to a , and suppose that the number of observations is reasonably large. In this situation, the data will have ovewhelmed the prior, so that the posterior for l is relatively robust against changes in a",
    "chunk_id": "bayesian_hypothesis_testing_for_psychologists_a_tutorial_on_the_savage–dickey_method.json_chunk_27"
  },
  {
    "document_type": "research_paper",
    "title": "Bayesian hypothesis testing for psychologists: A tutorial on the Savage–Dickey method",
    "author": "\"Eric-Jan Wagenmakers; Tom Lodewyckx; Himanshu Kuriyal; Raoul Grasman\"",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\bayesian_hypothesis_testing_for_psychologists.pdf",
    "date_published": "2010-03-03",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". In this situation, the data will have ovewhelmed the prior, so that the posterior for l is relatively robust against changes in a . In contrast, the height of the prior at l 1⁄4 0 varies directly with a : if a is doubled, the height of the prior at l 1⁄4 0 becomes twice as small, and according to Eq. (12) this would about double the Bayes factor in favor of H 0 . In the limit, as a grows very large, the height of the prior at l 1⁄4 0 goes to zero, which means that the Bayes factor will go to infinity, indicating decisive support for the null hypothesis. 2. Irrelevance of the prior for nuisance parameters. In contrast to the prior for the parameter of interest / , Eq. (12) indicates that the prior for the nuisance parameters w is not critical. Hence, priors on the nuisance parameters can be vague or even improper (e.g., Hsiao, 1997, p. 659; Kass & Raftery, 1995, p. 783; Kass & Vaidyanathan, 1992 ). Intuitively, the prior vagueness of nuisance parameters is preent in both models and cancels out in the computation of the Bayes factor ( Rouder et al., 2009 ). 3. Relative ease of computing the Bayes factor in nested models. Eq. (12) shows that in nested models, under plausible assumptions on the prior structure for the nuisance parameters, computation of the Bayes factor is relatively straightforward. All that is needed is an estimate of posterior and prior ordinates under the alternative hypothesis H 1 . This computational shortcut is often much less involved than the more generic solution, which involves integrating out nuisance parameters w for H 0 , and parameters w and / for H 1 , as follows: BF 01 1⁄4 p ð D j H 0 Þ p ð D j H 1 Þ 1⁄4 R p ð D j / 1⁄4 / 0 ; w Þ p ð / 1⁄4 / 0 ; w Þ d w R R p ð D j w ; / Þ p ð w ; / Þ d w d / : ð 13 Þ To the best of our knowledge, the Savage–Dickey method has only been used in psychology once before, by Wetzels et al. (2009) , who used it to develop a WinBUGS implementation of the t -test prposed by Rouder et al. (2009) . 4",
    "chunk_id": "bayesian_hypothesis_testing_for_psychologists_a_tutorial_on_the_savage–dickey_method.json_chunk_28"
  },
  {
    "document_type": "research_paper",
    "title": "Bayesian hypothesis testing for psychologists: A tutorial on the Savage–Dickey method",
    "author": "\"Eric-Jan Wagenmakers; Tom Lodewyckx; Himanshu Kuriyal; Raoul Grasman\"",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\bayesian_hypothesis_testing_for_psychologists.pdf",
    "date_published": "2010-03-03",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". (2009) , who used it to develop a WinBUGS implementation of the t -test prposed by Rouder et al. (2009) . 4. Summary and prelude to the examples So far, we have introduced Bayesian parameter estimation, MCMC sampling, and the advantages and challenges of Bayesian hypothesis testing. In order to address the computational challenge that comes with Bayesian hypothesis testing, we outlined the Savage–Dickey density ratio method. This 170 E.-J. Wagenmakers et al. / Cognitive Psychology 60 (2010) 158–189 straightforward and exact method applies to nested models, and for its computation the user only rquires the height of the posterior and the height of the prior distribution—for the parameter that is tested, at the point of interest (see Eq. (12) and Figs. 1 and 3 ). Throughout the preceding sections, Bayesian concepts have been discussed by reference to a single, extremely simple binomial example. The next sections discuss three more complicated examples, using real data taken from the psychological literature. This reflects our belief that the advantages of Bayesian hypothesis testing and the practical feasibility of the Savage–Dickey method are best illutrated by concrete examples that are highly relevant to psychological practice. 5. Example 1: equality of proportions In their article ‘‘After the promise: the STD consequences of adolescent virginity pledges”, Brückner and Bearman (2005) analyzed a series of interviews conducted as part of the National Longitudinal Study of Adolescent Health ( Add Health ). The focus of the article was on the sexual behavior of adolecents, aged 18–24, who have made a virginity pledge , that is, a public or written pledge to remain a virgin until marriage. Scientific studies suggest that the sexual behavior of pledgers is not very diffeent from that of nonpledgers—except for the fact that pledgers are less likely to use condoms when they first have sex",
    "chunk_id": "bayesian_hypothesis_testing_for_psychologists_a_tutorial_on_the_savage–dickey_method.json_chunk_29"
  },
  {
    "document_type": "research_paper",
    "title": "Bayesian hypothesis testing for psychologists: A tutorial on the Savage–Dickey method",
    "author": "\"Eric-Jan Wagenmakers; Tom Lodewyckx; Himanshu Kuriyal; Raoul Grasman\"",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\bayesian_hypothesis_testing_for_psychologists.pdf",
    "date_published": "2010-03-03",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". The Brückner and Bearman (2005) study presents a wealth of data, but here our focus is on a small subset of the data: 424 out of 777 pledgers ( 54.6%) indicated that they had used a condom at first sex, versus 5416 out of 9072 nonpledgers ( 59.7%). To what extent does a statistical analysis support the assertion that pledgers are less likely than nonpledgers to use a condom at first sex? A frequentist test for equality of proportions indicates that p : 006, which tells us that when H 0 is true (i.e., the proportions of condom users are equal in the two groups), then the probability is about .006 that we would encounter a result at least as extreme as the one that was in fact observed. But this is not the kind of information that researchers really care about; researchers want to know the extent to which the data support the claim that pledgers are less likely than nonpledgers to use a condom at first sex. Our Bayesian model for these data is simple and general. We assume that the number of condom users ( s 1 1⁄4 424 and s 2 1⁄4 5416) among the pledgers and the nonpledgers ( n 1 1⁄4 777 and n 2 1⁄4 9072) is governed by binomial rate parameters h 1 and h 2 , respectively. Denote the difference between the two rate parameters by d , that is, d 1⁄4 h 1 h 2 . Fig. 4 shows this model in graphical model notation (for introductions, see Gilks, Thomas, & Spiegelhalter, 1994; Lauritzen, 1996; Lee, 2008; Spiegelhalter, 1998 ). In this notation, nodes represent variables of interest, and the graph structure is used to Fig. 4. Bayesian graphical model for the pledger data. E.-J. Wagenmakers et al. / Cognitive Psychology 60 (2010) 158–189 171 indicate dependencies between the variables, with children depending on their parents. Continuous variables are represented with circular nodes and discrete variables are represented with square nodes; observed variables are shaded and unobserved variables are not shaded",
    "chunk_id": "bayesian_hypothesis_testing_for_psychologists_a_tutorial_on_the_savage–dickey_method.json_chunk_30"
  },
  {
    "document_type": "research_paper",
    "title": "Bayesian hypothesis testing for psychologists: A tutorial on the Savage–Dickey method",
    "author": "\"Eric-Jan Wagenmakers; Tom Lodewyckx; Himanshu Kuriyal; Raoul Grasman\"",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\bayesian_hypothesis_testing_for_psychologists.pdf",
    "date_published": "2010-03-03",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Continuous variables are represented with circular nodes and discrete variables are represented with square nodes; observed variables are shaded and unobserved variables are not shaded. The double borders around the unobserved continuous variable d indicates that it is deterministic (i.e., calculated without noise from other variables) rather than stochastic. In Fig. 4 , for instance, the discrete observed variable s 1 indicates the number of condom users in the group of pledgers. This observed variable depends both on the (discrete, observed) number of pledgers n 1 , and on the continuous, unobserved binomial rate parameter h 1 . In our Bayesian model, we assume that the rate parameters h 1 and h 2 each have a uniform prior distribution (i.e., p ð h ðÞ Þ Beta ð 1 ; 1 Þ ). These uniform prior distributions induce a triangular prior distrbution for the difference parameter d : p ð d Þ 1⁄4 1 þ d for d 6 0 ; 1 d for d > 0 : ð 14 Þ The null hypothesis states that the rates h 1 and h 2 are equal, and hence H 0 : d 1⁄4 0. The unrestricted alternative hypothesis states that the rates are free to vary, H 1 : d – 0, and the restricted alternative hypothesis states that the rate is lower for the pledgers than for the nonpledgers, H 2 : d < 0. Below we examine these alternative hypothesis in turn. 5.1. Unrestricted analysis The problem of testing H 0 : d 1⁄4 0 versus H 1 : d – 0 is still relatively simple. The Bayes factor in suport for the null hypothesis (i.e., BF 01 1⁄4 p ð D j H 0 Þ = p ð D j H 1 Þ ) is given for instance by de Braganca Pereira and Stern (1999) : BF 01 1⁄4 n 1 s 1 n 2 s 2 n 1 þ n 2 s 1 þ s 2 ð n 1 þ 1 Þð n 2 þ 1 Þ n 1 þ n 2 þ 1 : ð 15 Þ For the pledger data, this yields BF 01 0 : 45, which means that the data are about 1 = 0 : 45 2 : 22 times more likely under the alternative hypothesis than under the null hypothesis. Note that although the Bayesian hypothesis test supports the alternative hypothesis, the result is much less convincing than a p -value of .006 suggests",
    "chunk_id": "bayesian_hypothesis_testing_for_psychologists_a_tutorial_on_the_savage–dickey_method.json_chunk_31"
  },
  {
    "document_type": "research_paper",
    "title": "Bayesian hypothesis testing for psychologists: A tutorial on the Savage–Dickey method",
    "author": "\"Eric-Jan Wagenmakers; Tom Lodewyckx; Himanshu Kuriyal; Raoul Grasman\"",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\bayesian_hypothesis_testing_for_psychologists.pdf",
    "date_published": "2010-03-03",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Note that although the Bayesian hypothesis test supports the alternative hypothesis, the result is much less convincing than a p -value of .006 suggests. To apply the Savage–Dickey method, we first draw samples from the posterior and the prior distrbutions for d (the WinBUGS code can be found in Appendix B). We ran three chains for 100,000 iteations each, and we discarded the first 1000 iterations of each chain as burn-in. After confirming by means of visual inspection and the Gelman and Rubin (1992) b R statistic that the chains had converged, we collapsed the samples across the three chains. The left panel of Fig. 5 shows the resulting histograms for the posterior and prior distributions for d plotted on their entire range. In this panel, the thin solid line for the prior indicates the analytical ditribution given in Eq. (14) . For the posterior distribution, the thin solid line indicates a logspline noparametric density estimate ( Stone et al., 1997 ), the procedure that we will use throughout this article to estimate distributions. The right panel of Fig. 5 zooms in on the relevant region around d 1⁄4 0. The almost flat line is the analytical distribution of the prior, and the sharply decreasing line is the logspline estimate for the posterior. The two dots mark the height of both densities at d 1⁄4 0. From a visual comparison of the height of the dots, it is clear that the point d 1⁄4 0 is supported about twice as much under the prior as it is under the posterior. That is, the data have decreased the support for d 1⁄4 0 by a factor of two. Application of the Savage–Dickey method (i.e., Eq. (12) ) yields BF 01 0 : 47, which leads to the conclusion that the data are about 2.17 times more likely under the alternative hypothesis than under the null. Thus, the result from the MCMC-based Savage–Dickey method (i.e., BF 10 1⁄4 2 : 17) and the anlytical solution (i.e., BF 10 1⁄4 2 : 22) are in reasonable agreement. 172 E.-J. Wagenmakers et al",
    "chunk_id": "bayesian_hypothesis_testing_for_psychologists_a_tutorial_on_the_savage–dickey_method.json_chunk_32"
  },
  {
    "document_type": "research_paper",
    "title": "Bayesian hypothesis testing for psychologists: A tutorial on the Savage–Dickey method",
    "author": "\"Eric-Jan Wagenmakers; Tom Lodewyckx; Himanshu Kuriyal; Raoul Grasman\"",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\bayesian_hypothesis_testing_for_psychologists.pdf",
    "date_published": "2010-03-03",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Thus, the result from the MCMC-based Savage–Dickey method (i.e., BF 10 1⁄4 2 : 17) and the anlytical solution (i.e., BF 10 1⁄4 2 : 22) are in reasonable agreement. 172 E.-J. Wagenmakers et al. / Cognitive Psychology 60 (2010) 158–189 Finally, note that the conclusions from the Bayesian hypothesis test (i.e., roughly twice as much evidence for H 1 as for H 0 ) are more conservative than those that follow from Bayesian parameter estmation; the Bayesian 95% confidence interval for the posterior of d is ð 0 : 09 ; 0 : 01 Þ and does not iclude 0. The reason for the discrepancy is that the Bayesian hypothesis test punishes H 1 for assigning prior mass to values of d that yield very low likelihoods (i.e., the automatic Ockham’s razor discussed previously, see Berger & Delampady, 1987 for a discussion). 5.2. Order-restricted analysis Many substantive psychological questions can be formulated as order-restrictions (e.g., Hoijtink, Klugkist, & Boelen, 2008; Klugkist et al., 2005a ). Here we focus on a test of H 0 : d 1⁄4 0 versus H 2 : d < 0, an order-restricted alternative hypothesis that states that the rate of condom use is lower for the pledgers than for the nonpledgers. In the Bayesian framework, order-restrictions can be implemented in several ways (e.g., O’Hagan & Forster, 2004, pp. 70–71 ). For instance, order-restrictions can be enforced before MCMC sampling, by appropriately constraining the prior distributions, or they can be implemented after the MCMC sapling, by retaining only those MCMC samples that obey the order-restriction (e.g., Gelfand, Smith, & Lee, 1992, p. 525 ). The left panel of Fig. 6 shows the histograms for the posterior and prior distributions for d under the restricted model H 2 : d < 0. These histograms were obtained by selecting from the previous unrstricted analysis only those MCMC samples that obey the order-restriction. For the prior, the thin solid line indicates the analytical distribution, and for the posterior it indicates the order-restricted logpline estimate",
    "chunk_id": "bayesian_hypothesis_testing_for_psychologists_a_tutorial_on_the_savage–dickey_method.json_chunk_33"
  },
  {
    "document_type": "research_paper",
    "title": "Bayesian hypothesis testing for psychologists: A tutorial on the Savage–Dickey method",
    "author": "\"Eric-Jan Wagenmakers; Tom Lodewyckx; Himanshu Kuriyal; Raoul Grasman\"",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\bayesian_hypothesis_testing_for_psychologists.pdf",
    "date_published": "2010-03-03",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". For the prior, the thin solid line indicates the analytical distribution, and for the posterior it indicates the order-restricted logpline estimate. Note that for the prior, the effect of the order-restriction is to double the mass on d 1⁄4 0, from a vlue of 1 to a value of 2. In contrast, the order-restriction does not much affect the posterior, as most of its mass was already smaller than 0. The right panel of Fig. 6 zooms in on the relevant area around d 1⁄4 0 and shows the effect of the order-restriction on the Bayesian hypothesis test. Again, the almost flat line is the analytical distribution of the order-restricted prior, and the associated dot indicates its height at d 1⁄4 0. The sharply decreasing line is the logspline estimate for the order-restricted posterior, Density Full Scale Density Zoomed in Density Fig. 5. Prior and posterior distributions of the rate difference d for the unrestricted analysis of the pledger data. The left panel shows the distributions across their entire range (prior: histogram and analytical result; posterior: histogram and logspline density estimate). The right panel zooms in on the area that is relevant for the test of H 0 : d 1⁄4 0 versus H 1 : d – 0 (prior: analytical result; posterior: logspline density estimate). The dots indicate the height of the two distributions at d 1⁄4 0. E.-J. Wagenmakers et al. / Cognitive Psychology 60 (2010) 158–189 173 and the associated solid dot indicates the logspline estimate of the height of the posterior based on the subset of MCMC samples that obey the order-restriction. The open dot immediately below indicates the height of the posterior estimated from an alternative method, one that is based on renormalizing the order-restricted posterior (i.e., dividing the height of the unrestricted posterior at d 1⁄4 0 by the area of the unrestricted posterior that lies to the left of d 1⁄4 0)",
    "chunk_id": "bayesian_hypothesis_testing_for_psychologists_a_tutorial_on_the_savage–dickey_method.json_chunk_34"
  },
  {
    "document_type": "research_paper",
    "title": "Bayesian hypothesis testing for psychologists: A tutorial on the Savage–Dickey method",
    "author": "\"Eric-Jan Wagenmakers; Tom Lodewyckx; Himanshu Kuriyal; Raoul Grasman\"",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\bayesian_hypothesis_testing_for_psychologists.pdf",
    "date_published": "2010-03-03",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". A visual comparison of the height of the prior and posterior at d 1⁄4 0 confirms that the order-restrition has increased the evidence in favor of the alternative hypothesis. Specifically, the logspline estmate yields BF 02 0 : 26 (i.e., BF 20 3 : 78), and the estimate based on renormalizing the posterior yields BF 02 0 : 23 (i.e., BF 20 4 : 34). Thus, both methods lead to the conclusion that there is roughly four times as much evidence for H 2 as for H 0 . The foregoing may lead one to conclude that the effect of order-restrictions are similar in the Bayesian and the frequentist framework; in the Bayesian framework, the order-restriction increased the evidence against H 0 roughly by a factor of two, and in the frequentist framework, a one-sided p -value provides twice as much evidence against H 0 as a two-sided p -value. However, this correspodence only holds because the posterior for d is largely consistent with the order-restriction. In general, one may distinguish between the following three situations, which form points on a continuum of possibilities: 1. Posterior largely consistent with the order-restriction. This situation occurred for the pledger data. The order-restriction increases the height of the prior by two, but it hardly increases the height of the posterior. This means that when the order-restriction is almost fully supported by the data, this can only increase the support in favor of the alternative hypothesis by a factor of two. For example, for the pledger data the unrestricted test of H 0 : d 1⁄4 0 versus H 1 : d – 0 yields BF 10 2 : 22. This means that the Bayes factor in favor of H 2 : d < 0 versus H 0 : d 1⁄4 0 cannot be lager than 2 : 22 2 1⁄4 4 : 44. 2. Posterior neither consistent nor inconsistent with the order-restriction",
    "chunk_id": "bayesian_hypothesis_testing_for_psychologists_a_tutorial_on_the_savage–dickey_method.json_chunk_35"
  },
  {
    "document_type": "research_paper",
    "title": "Bayesian hypothesis testing for psychologists: A tutorial on the Savage–Dickey method",
    "author": "\"Eric-Jan Wagenmakers; Tom Lodewyckx; Himanshu Kuriyal; Raoul Grasman\"",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\bayesian_hypothesis_testing_for_psychologists.pdf",
    "date_published": "2010-03-03",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". This means that the Bayes factor in favor of H 2 : d < 0 versus H 0 : d 1⁄4 0 cannot be lager than 2 : 22 2 1⁄4 4 : 44. 2. Posterior neither consistent nor inconsistent with the order-restriction. This situation occurs when the data are uninformative with respect to the direction of the effect, so that the posterior is symmerical around d 1⁄4 0 (assuming that d is the parameter of interest and 0 is the value at which the Density Full Scale Density Zoomed in Density Fig. 6. Prior and posterior distributions of the rate difference d for the order-restricted analysis of the pledger data. The left panel shows the distributions across their entire range (prior: histogram and analytical result; posterior: histogram and logspline density estimate). The right panel zooms in on the area that is relevant for the test of H 0 : d 1⁄4 0 versus H 2 : d < 0 (prior: analytical result; posterior: logspline density estimate). The dots indicate the height of the two distributions at d 1⁄4 0. 174 E.-J. Wagenmakers et al. / Cognitive Psychology 60 (2010) 158–189 alternative model collapses to the null model). In this case, the order-restriction increases the height of both the prior and the posterior by 2, so that the end result is unaffected. 3. Posterior largely inconsistent with the order-restriction. This situation occurs when the data suggest that the effect is in the direction opposite to that suggested by the order-restriction. In this case, the order-restriction again increases the height of the prior by 2, but it increases the height of the poterior much more. Consider, for instance, the right panel of Fig. 5 , and an order-restricted test of H 0 : d 1⁄4 0 versus H 3 : d > 0. To determine the height of the order-restricted posterior at d 1⁄4 0 one may divide the height of the unrestricted posterior (i.e., 0.47 according to the logspline method) by its area to the right of zero, which is approximately .003",
    "chunk_id": "bayesian_hypothesis_testing_for_psychologists_a_tutorial_on_the_savage–dickey_method.json_chunk_36"
  },
  {
    "document_type": "research_paper",
    "title": "Bayesian hypothesis testing for psychologists: A tutorial on the Savage–Dickey method",
    "author": "\"Eric-Jan Wagenmakers; Tom Lodewyckx; Himanshu Kuriyal; Raoul Grasman\"",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\bayesian_hypothesis_testing_for_psychologists.pdf",
    "date_published": "2010-03-03",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". The Bayes factor in favor of H 0 : d 1⁄4 0 versus H 3 : d > 0 would then be ð 0 : 47 =: 003 Þ = 2 78, which constitutes strong support for the null hypothesis. 6. Example 2: a hierarchical Bayesian one-sample t -test In their article ‘‘Priming in implicit memory tasks: Prior study causes enhanced discriminability, not only bias”, Zeelenberg et al. (2002) reported three experiments in two-alternative forced-choice perceptual identification. In the test phase of each experiment, a stimulus (e.g., a picture of a clothes pin) is briefly presented and masked. Immediately after the mask the participant is confronted with two choice options—the target (i.e., the picture of the clothes pin) and a similar foil alternative (e.g., the picture of a stapler; see Fig. 7 for an example); the participant’s goal is to identify the target. Prior to the test phase, the Zeelenberg et al. experiments featured a study phase, in which partiipants studied a subset of the choice alternatives that would also be presented in the later test phase. Two conditions were critical: the ‘‘study-neither” condition, in which neither choice alternative was studied, and the ‘‘study-both” condition, in which both choice alternatives were studied. In the first two experiments reported by Zeelenberg et al., participants choose the target stimulus more often in the study-both condition than in the study-neither condition. This both-primed benefit suggests that prior study leads to enhanced discriminability, not just a bias to prefer the studied altenative (e.g., Ratcliff & McKoon, 1997 ; for a discussion see also Bowers, 1999; Wagenmakers, Zeeleberg, & Raaijmakers, 2003 ). Here we focus on statistical inference for the Experiment 3 from Zeelenberg et al. (2002) . In the study phase of this experiment, all 74 participants were presented with 21 pairs of similar pictures (e.g., the clothes pin/stapler example shown in Fig. 7 ). In the test phase, all participants had to identify briefly presented target pictures among a set of two alternatives",
    "chunk_id": "bayesian_hypothesis_testing_for_psychologists_a_tutorial_on_the_savage–dickey_method.json_chunk_37"
  },
  {
    "document_type": "research_paper",
    "title": "Bayesian hypothesis testing for psychologists: A tutorial on the Savage–Dickey method",
    "author": "\"Eric-Jan Wagenmakers; Tom Lodewyckx; Himanshu Kuriyal; Raoul Grasman\"",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\bayesian_hypothesis_testing_for_psychologists.pdf",
    "date_published": "2010-03-03",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". 7 ). In the test phase, all participants had to identify briefly presented target pictures among a set of two alternatives. The test phase was composed of 42 pairs of similar pictures, 21 of which had been presented in the study phase. In order to assess the evidence in favor of the both-primed benefit, the authors carried out a stadard analysis and computed a one-sample t -test: ‘‘Mean percentage of correctly identified pictures was calculated for each participant. When neither the target nor the foil had been studied, 71.5% of the pictures were correctly identified. When both the target and the foil had been studied, 74.7% of the pictures were correctly identified. The diffeence between the study-both and study-neither conditions was significant, t ð 73 Þ 1⁄4 2 : 19 ; p < : 05.” This analysis has two main disadvantages. First, the t -test assumes that the data are Normally ditributed. For the Zeelenberg experiment, this assumption is certainly incorrect, as the difference btween two proportions is constrained to lie between 1 and 1 (see Example 1). Second, the analysis from Zeelenberg et al. ignores the fact that the experimental design is nested (i.e., trials are Fig. 7. Example pair of similar pictures used in Experiment 3 from Zeelenberg et al. (2002) . E.-J. Wagenmakers et al. / Cognitive Psychology 60 (2010) 158–189 175 nested within participants), a situation that calls for a hierarchical or multi-level analysis (e.g., Gelman & Hill, 2007; Rouder, Lu, Morey, Sun, & Speckman, 2008 ). In other words, it is unlikely that the botprimed benefit is a fixed effect, in the sense that it is the same for each and every participant—it is more reasonable to assume that the both-primed benefit is a random effect (cf. Rouder et al., 2007 ). Our Bayesian test of the both-primed benefit proceeds as follows. We start by assuming that for participant i the number of correct choices is binomially distributed with parameter h i . Unfortunately, h i is defined on the rate scale, which ranges from 0 to 1",
    "chunk_id": "bayesian_hypothesis_testing_for_psychologists_a_tutorial_on_the_savage–dickey_method.json_chunk_38"
  },
  {
    "document_type": "research_paper",
    "title": "Bayesian hypothesis testing for psychologists: A tutorial on the Savage–Dickey method",
    "author": "\"Eric-Jan Wagenmakers; Tom Lodewyckx; Himanshu Kuriyal; Raoul Grasman\"",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\bayesian_hypothesis_testing_for_psychologists.pdf",
    "date_published": "2010-03-03",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". We start by assuming that for participant i the number of correct choices is binomially distributed with parameter h i . Unfortunately, h i is defined on the rate scale, which ranges from 0 to 1. This is an awkward scale for modeling additive effects, as a change from .55 to .65 is not the same as a change from .85 to .95. Hence, we do not model h i , but instead choose to model / i , the deterministic probit transformation of h i . The probit transform is the inverse cumulative distribution function of the standard Normal distrbution, so that, for instance, a rate of h i 1⁄4 0 : 5 maps onto a probit rate of / i 1⁄4 0, and a rate of h i 1⁄4 0 : 975 maps onto a probit rate of / i 1⁄4 1 : 96. The probit transform is shown in Fig. 8 . In contrast to the rate scale, the probit scale covers the entire real line, and lends itself easily to hierarchical modeling (Rouder & Lu, 2005). For each participant i , the both-primed benefit a i is given by the difference between performance in the study-both and study-neither condition, a i 1⁄4 / SB ; i / SN ; i . Our model incorporates two random efects; first, each participant’s baseline level of performance / SN ; i is assumed to be drawn from a groulevel Normal distribution with mean l / and standard deviation r / . Second, each participant’s botprimed benefit is assumed to be drawn from a group-level Normal distribution with mean l a and standard deviation r a . Note that such normal distributions are easily defined on the probit scale, but not on the rate scale. Fig. 9 shows the model in graphical form. In order to accommodate the hierarchical structure of the model, we use plate notation, enclosing with square boundaries subsets of the graph that have independent replications. Because each participant contributes to both the study-neither and the study-both conditions, the design is ‘‘within-subjects” and the square boundaries therefore enclose both conditions",
    "chunk_id": "bayesian_hypothesis_testing_for_psychologists_a_tutorial_on_the_savage–dickey_method.json_chunk_39"
  },
  {
    "document_type": "research_paper",
    "title": "Bayesian hypothesis testing for psychologists: A tutorial on the Savage–Dickey method",
    "author": "\"Eric-Jan Wagenmakers; Tom Lodewyckx; Himanshu Kuriyal; Raoul Grasman\"",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\bayesian_hypothesis_testing_for_psychologists.pdf",
    "date_published": "2010-03-03",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Because each participant contributes to both the study-neither and the study-both conditions, the design is ‘‘within-subjects” and the square boundaries therefore enclose both conditions. For the parameters that are not subject to statistical test (i.e., l / ; r / , and r a ) we specified uninfomative priors. The prior for the group mean of the study-neither condition, l / , is a truncated standard Normal (i.e., greater than zero only on the positive real line), which on the rate scale translates to a uniform distribution from 0.5 to 1 (cf. Rouder & Lu, 2005, p. 588 ). For r / and r a , we chose priors that are uniform from 0 to 10. Fig. 8. The probit transformation. h 1⁄4 U ð / Þ and / 1⁄4 U 1 ð h Þ , where U denotes the cumulative distribution function of the standard normal distribution. 176 E.-J. Wagenmakers et al. / Cognitive Psychology 60 (2010) 158–189 Finally, and critically, our model incorporates a parameter d that quantifies effect size , d 1⁄4 l a = r a . Effect size is a dimensionless quantity, and this makes it relatively easy to define a principled prior. Reasonable default choices for priors on effect size include the Cauchy distribution (i.e., a t distribution with one degree of freedom) and the standard Normal distribution (e.g., Gönen, Johnson, Lu, & Westfall, 2005; Rouder et al., 2009 ). The latter prior is known as the ‘‘unit information prior”, as it carries as much information as a single observation (Kass & Wasserman, 1995). The standard Normal distribution is the prior for effect size that we will use in this example and the next. With the statistical model in place, we can now turn to hypothesis testing. The null hypothesis states that there is no both-primed benefit, and hence the effect size is zero: H 0 : d 1⁄4 0. The alternative, order-restricted hypothesis states that there is a both-primed benefit, and hence H 1 : d > 0. This test is, in fact, a hierarchical extension of the Bayesian one-sample t -test proposed by Gönen et al. (2005), Rouder et al",
    "chunk_id": "bayesian_hypothesis_testing_for_psychologists_a_tutorial_on_the_savage–dickey_method.json_chunk_40"
  },
  {
    "document_type": "research_paper",
    "title": "Bayesian hypothesis testing for psychologists: A tutorial on the Savage–Dickey method",
    "author": "\"Eric-Jan Wagenmakers; Tom Lodewyckx; Himanshu Kuriyal; Raoul Grasman\"",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\bayesian_hypothesis_testing_for_psychologists.pdf",
    "date_published": "2010-03-03",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". This test is, in fact, a hierarchical extension of the Bayesian one-sample t -test proposed by Gönen et al. (2005), Rouder et al. (2009) ; the difference is that our hierarchical t -test is defined on the level of individual parameters instead of raw data. Our model can therefore be thought of as a Bayesian hierarchical onsample t -test. We implemented our Bayesian hierarchical t -test by means of the Savage–Dickey method. First we drew MCMC samples from the posterior distribution for d (the WinBUGS code can be found in Appedix B). As in Example 1, we ran three chains for 100,000 iterations each, and we discarded the first 1000 iterations of each chain as burn-in. After confirming by means of visual inspection and the Gelman and Rubin (1992) b R statistic that the chains had converged, we collapsed the samples across the three chains. Fig. 9. Bayesian graphical model for the Zeelenberg data. In a within-subjects design, 74 participants performed a twalternative forced-choice perceptual identification task, in both ‘‘study-neither” (SN) and ‘‘study-both” (SB) conditions. E.-J. Wagenmakers et al. / Cognitive Psychology 60 (2010) 158–189 177 Fig. 10 visualizes the results—for the prior on effect size d , the thin solid line indicates the Normal distribution that has been truncated and renormalized to take into account the order restriction that d > 0. For the posterior order-restricted distribution on effect size d , the thin solid line indicates the logspline nonparametric density estimate, and the thick solid line indicates the histogram of MCMC samples. As in Example 1, the two dots mark the height of prior and posterior densities at d 1⁄4 0. From a visual comparison of the height of the dots, it is clear that the point d 1⁄4 0 is supported about four times as much under the prior as it is under the posterior. That is, the data have decreased the support for d 1⁄4 0 by a factor of four. Application of the Savage–Dickey method (i.e., Eq",
    "chunk_id": "bayesian_hypothesis_testing_for_psychologists_a_tutorial_on_the_savage–dickey_method.json_chunk_41"
  },
  {
    "document_type": "research_paper",
    "title": "Bayesian hypothesis testing for psychologists: A tutorial on the Savage–Dickey method",
    "author": "\"Eric-Jan Wagenmakers; Tom Lodewyckx; Himanshu Kuriyal; Raoul Grasman\"",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\bayesian_hypothesis_testing_for_psychologists.pdf",
    "date_published": "2010-03-03",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". That is, the data have decreased the support for d 1⁄4 0 by a factor of four. Application of the Savage–Dickey method (i.e., Eq. (12) ) yields BF 01 0 : 22, which leads to the conclusion that the data are about 4.49 times more likely under the alternative hypothesis than under the null hypothesis. Thus, the data support the assertion that there is a both-primed benefit, but the extent of this suport is somewhat weaker than is suggested by the p -value. 7. Example 3: a hierarchical Bayesian two-sample t -test In their article ‘‘How specific are executive functioning deficits in Attention Deficit Hyperactivity Disorder and autism?”, Geurts et al. (2004) studied the performance of children with ADHD and auism on a range of cognitive tasks. Here we focus on a small subset of the data and consider the quetion whether children that develop typically (i.e., ‘‘normal controls”) outperform children with ADHD on the Wisconsin Card Sorting Test (WCST; Grant & Berg, 1948; Heaton, Chelune, Talley, Kay, & Curtiss, 1993 ). The WCST requires that participants learn, by trial and error, to sort cards according to an implicit rule. The complication is that, over the course of the experiment, the sorting rule sometimes changes. This means that in order to avoid too many mistakes, participants have to suppress the tendency to perseverate and quickly discover and adopt the new rule. Because of these task demands, performance on the WCST is thought to quantify cognitive flexibility or set shifting ability. The experiment of interest contains data from 26 normal controls and 52 children with ADHD. Each child performed the WCST, and the measure of interest is the number of correctly sorted cards relative Density Fig. 10. Prior and posterior distribution of the effect size d for the hierarchical, order-restricted analysis of the Zeelenberg data. For the prior, the thin line gives the analytical result; for the posterior, the thick line gives the histogram and the thin line gives the logspline density estimate",
    "chunk_id": "bayesian_hypothesis_testing_for_psychologists_a_tutorial_on_the_savage–dickey_method.json_chunk_42"
  },
  {
    "document_type": "research_paper",
    "title": "Bayesian hypothesis testing for psychologists: A tutorial on the Savage–Dickey method",
    "author": "\"Eric-Jan Wagenmakers; Tom Lodewyckx; Himanshu Kuriyal; Raoul Grasman\"",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\bayesian_hypothesis_testing_for_psychologists.pdf",
    "date_published": "2010-03-03",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". For the prior, the thin line gives the analytical result; for the posterior, the thick line gives the histogram and the thin line gives the logspline density estimate. The dots indicate the height of the two distributions at d 1⁄4 0. 178 E.-J. Wagenmakers et al. / Cognitive Psychology 60 (2010) 158–189 to the total number of sorting opportunities. The WCST provides a maximum of 128 cards to sort, but, depending on a child’s performance, this number could also be lower. Overall, the group of normal controls sorted the cards correctly on 65.4% of the cases, and the group of ADHD children sorted the cards correctly on 66.9% of the cases. A between-subjects (i.e., two-sample) frequentist t -test on the proportion of correctly sorted cards does not allow one to reject the null hypothesis, t ð 40 : 2 Þ 1⁄4 0 : 37 ; p 1⁄4 : 72. But this statistic does not quantify the evidence in favor of the null hypothesis. Another problem with this frequentist t -test is that it ignores the fact that trials are nested in partiipants—a design that, as in Example 2, calls for a hierarchical/multi-level/random effects analysis. Our hierarchical model is specified as follows. We assume that for child i in the group of normal controls, the number of correctly sorted cards K NC ; i (out of N NC ; i opportunities) is binomially distriuted with rate parameter h NC ; i . As in the previous example, this rate parameter is then transformed to the probit scale (cf. Fig. 8 ), which yields the corresponding parameter / NC ; i . The comparable assumptions are made for child j in the group of ADHD children, resulting in the associated parameter / AD ; j . Next, our model incorporates random effects; for both the normal controls and the group of ADHD children, the probitized rates of correct responding (i.e., / NC ; and / AD ; ) are assumed to be drawn from group-level Normal distributions",
    "chunk_id": "bayesian_hypothesis_testing_for_psychologists_a_tutorial_on_the_savage–dickey_method.json_chunk_43"
  },
  {
    "document_type": "research_paper",
    "title": "Bayesian hypothesis testing for psychologists: A tutorial on the Savage–Dickey method",
    "author": "\"Eric-Jan Wagenmakers; Tom Lodewyckx; Himanshu Kuriyal; Raoul Grasman\"",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\bayesian_hypothesis_testing_for_psychologists.pdf",
    "date_published": "2010-03-03",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Denoting the grand mean by l , and the group difference in means by a , the group-level Normal distribution for the normal controls is defined as N ð l þ a = 2 ; r 2 Þ and that for the ADHD children as N ð l a = 2 ; r 2 Þ , where r denotes the standard deviation for the group-level distribution. Fig. 11 shows the model in graphical form. As in Fig. 9 , the hierarchical structure of the model is accommodated by plate notation, enclosing with square boundaries subsets of the graph that have independent replications. Because every child participants in only one of the two conditions, the dsign is ‘‘between-subjects” and the square boundaries enclose each condition separately. For the parameters that are not subject to statistical test (i.e., l and r ) we specified uninformative priors. The prior for the grant mean l is a standard Normal, which on the rate scale translates to a unform distribution from 0 to 1 (cf. Rouder & Lu, 2005, p. 588 ). For r , we chose a prior that is uniform from 0 to 10. As in the previous example, the key aspect of our model is a parameter d that quantifies effect size , d 1⁄4 a = r . We again use the ‘‘unit information” standard normal prior on d , completing the specification of the model. Hypothesis testing now proceeds as before. The null hypothesis states that normal controls and ADHD children perform the same on the WCST, and hence the effect size is zero: H 0 : d 1⁄4 0. The unrstricted alternative hypothesis states that there is a difference in performance, and hence H 1 : d – 0. Lastly, the order-restricted hypothesis states that normal controls perform better than ADHD children, such that H 2 : d > 0. These tests are hierarchical extensions of the Bayesian one-sample t -test ( Gönen et al., 2005; Rouder et al., 2009 ); as in Example 2, the difference is that our hierarchical t -tests are dfined on the level of individual parameters instead of raw data. Below we examine the unrestricted analysis (i.e., H 0 versus H 1 ) and the restricted analysis (i.e., H 0 versus H 2 ) in turn",
    "chunk_id": "bayesian_hypothesis_testing_for_psychologists_a_tutorial_on_the_savage–dickey_method.json_chunk_44"
  },
  {
    "document_type": "research_paper",
    "title": "Bayesian hypothesis testing for psychologists: A tutorial on the Savage–Dickey method",
    "author": "\"Eric-Jan Wagenmakers; Tom Lodewyckx; Himanshu Kuriyal; Raoul Grasman\"",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\bayesian_hypothesis_testing_for_psychologists.pdf",
    "date_published": "2010-03-03",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Below we examine the unrestricted analysis (i.e., H 0 versus H 1 ) and the restricted analysis (i.e., H 0 versus H 2 ) in turn. 7.1. Unrestricted analysis We implemented our Bayesian hierarchical two-sample t -test by means of the Savage–Dickey method. As in the previous two examples, we drew MCMC samples from the posterior distribution for d (the WinBUGS code can be found in Appendix B), we ran three chains for 100,000 iterations each, and we discarded the first 1000 iterations of each chain as burn-in. We also confirmed by means of visual inspection and the Gelman and Rubin (1992) b R statistic that the chains had converged, and we then collapsed the samples across the three chains. The left panel of Fig. 12 visualizes the result. The ADHD children performed slightly better than the normal controls, and this is reflected in a posterior distribution for d which is slightly asymmetrical around zero, assigning more mass to negative than to positive values of d . The Bayesian 95% confdence interval for d is ( 0.54, 0.42). The left panel of Fig. 12 also shows that the data have made the value d 1⁄4 0 more likely than it was before (i.e., at d 1⁄4 0, the posterior is higher than the prior). Specifically, the ratio of the heights yields BF 01 1⁄4 3 : 96, which indicates that the data are about four times more likely under H 0 than they are E.-J. Wagenmakers et al. / Cognitive Psychology 60 (2010) 158–189 179 under H 1 . Thus, the data support the claim that normal controls and ADHD children perform equally well on the WCST over the claim that these groups perform differently. 7.2. Order-restricted analysis The order-restricted hypothesis states that normal controls outperform children with ADHD on the WCST (i.e., H 2 : d > 0). This hypothesis may be entertained because it is plausible a priori ; However, the data show that, if anything, the reverse is true: the mean percentage of correct card selections was 1.5% higher for the group of ADHD children than for the normal controls",
    "chunk_id": "bayesian_hypothesis_testing_for_psychologists_a_tutorial_on_the_savage–dickey_method.json_chunk_45"
  },
  {
    "document_type": "research_paper",
    "title": "Bayesian hypothesis testing for psychologists: A tutorial on the Savage–Dickey method",
    "author": "\"Eric-Jan Wagenmakers; Tom Lodewyckx; Himanshu Kuriyal; Raoul Grasman\"",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\bayesian_hypothesis_testing_for_psychologists.pdf",
    "date_published": "2010-03-03",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". What can we expect when we test H 0 : d 1⁄4 0 versus H 2 : d > 0? First, note that the posterior for d is not far from being symmetrical around zero. If it were copletely symmetrical, we would have ‘‘case 2” discussed above: ‘‘Posterior neither consistent nor incosistent with the order-restriction”. In this case the height of both the prior and the posterior is multiplied by 2, so that their ratio stays the same. Second, the the posterior for d is not quite symmerical around zero, and assigns slightly more mass to values that are inconsistent with H 2 . This will slightly increase the support for H 0 over H 2 . These two considerations lead us to expect that the evdence in favor of H 0 over H 2 (i.e., BF 02 ) will be slightly larger than that of H 0 over H 1 (i.e., BF 01 1⁄4 3 : 96). The right panel of Fig. 12 shows the result of the order-restricted analysis. As before, the relatively flat line is the analytical distribution of the order-restricted prior, and the associated dot indicates its Fig. 11. Bayesian graphical model for the Geurts data. In a between-subjects design, 26 typically developing children (i.e, ‘‘normal controls”, NC) and 52 children with ADHD (AD) performed the Wisconsin Card Sorting Test. 180 E.-J. Wagenmakers et al. / Cognitive Psychology 60 (2010) 158–189 height at d 1⁄4 0. The sharply decreasing line is the logspline estimate for the order-restricted posterior, and the associated solid dot indicates the logspline estimate of the height of the posterior based on the subset of MCMC samples that obey the order-restriction. The alternative method based on renormaizing the order-restricted posterior yielded a virtually identical result. A quantitative comparison of the height of the prior and posterior at d 1⁄4 0 confirms our expectation that the order-restriction slightly increases the evidence in favor of H 0 . Specifically, the logspline estmate yields BF 02 1⁄4 4 : 94",
    "chunk_id": "bayesian_hypothesis_testing_for_psychologists_a_tutorial_on_the_savage–dickey_method.json_chunk_46"
  },
  {
    "document_type": "research_paper",
    "title": "Bayesian hypothesis testing for psychologists: A tutorial on the Savage–Dickey method",
    "author": "\"Eric-Jan Wagenmakers; Tom Lodewyckx; Himanshu Kuriyal; Raoul Grasman\"",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\bayesian_hypothesis_testing_for_psychologists.pdf",
    "date_published": "2010-03-03",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Specifically, the logspline estmate yields BF 02 1⁄4 4 : 94. Thus, under H 0 the data are about five times more likely than they are under the order-restricted alternative, a result that is slightly more convincing than the one obtained when H 0 is pitted against the unrestricted alternative. In sum, the data support the assertion that normal controls and children with ADHD perform similarly on the WCST, even though the evidence is not overwhelming. 8. Limitations of the Savage–Dickey density ratio So far we have focused on the advantages of the Savage-Dickey density ratio method. However, the method also has its limitations, and these include the following: 1. Markov chain Monte Carlo. The Savage–Dickey method depends directly on the posterior distribtion for the parameter that is subject to test. For most interesting models, this posterior is not avaiable in closed-form, but instead has to be approximated by MCMC techniques. Fortunately, these MCMC techniques are implemented in the popular WinBUGS program ( Lunn et al., 2000; Lunn et al., 2009; Ntzoufras, 2009 ); when using WinBUGS, all researchers have to do is to describe their model using an intuitive scripting language, and the details of the sampling process are automaically taken care of by WinBUGS (see Appendix B for examples). 2. Convergence. As explained in the section on Bayesian parameter estimation, with MCMC comes an obligation to monitor convergence; if the MCMC chains have not converged, the samples do not come from the posterior distribution, and the Savage–Dickey test will produce the wrong results. For the simple statistical models that are popular in psychology, convergence is generally very fast. Unrestricted Analysis Density Order−Restricted Analysis Density Fig. 12",
    "chunk_id": "bayesian_hypothesis_testing_for_psychologists_a_tutorial_on_the_savage–dickey_method.json_chunk_47"
  },
  {
    "document_type": "research_paper",
    "title": "Bayesian hypothesis testing for psychologists: A tutorial on the Savage–Dickey method",
    "author": "\"Eric-Jan Wagenmakers; Tom Lodewyckx; Himanshu Kuriyal; Raoul Grasman\"",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\bayesian_hypothesis_testing_for_psychologists.pdf",
    "date_published": "2010-03-03",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". For the simple statistical models that are popular in psychology, convergence is generally very fast. Unrestricted Analysis Density Order−Restricted Analysis Density Fig. 12. Prior and posterior distribution of the effect size d for the hierarchical analysis of the Geurts data (left panel: unrestricted analysis; right panel: order-restricted analysis) For the prior, the thin line gives the analytical result; for the posterior, the thick line gives the histogram and the thin line gives the logspline density estimate. The dots indicate the height of the two distributions at d 1⁄4 0. E.-J. Wagenmakers et al. / Cognitive Psychology 60 (2010) 158–189 181 3. Density estimation. For its computation, the Savage–Dickey method requires an estimate of the height of a uni-dimensional posterior distribution at a single point. In this article, we have used the logspline nonparametric density estimator proposed by Stone et al. (1997) . This estimator is implemented in in the R package polspline , and concrete examples of its use are provided in the online R code associated with this article. We chose the logspline density algorithm because it generally performs well when the posterior is restricted (e.g., only positive values are allowed), and we chose a nonparametric estimator because we wanted to avoid any assumptions about the form of the posterior distribution. Nevertheless, the nonparametric density estimators will not be reliable when the results are extreme, that is, when the point of interest lies in the extreme tail of the posterior distribution— in the tail, the information about height is based on relatively few samples. This problem can be diagnosed by using the Savage–Dickey method multiple times to see whether the result is stable. Also, one might argue that when the point of interest is far out in the tails of the posterior distrbution, the qualitative conclusion is evident and reliable (i.e., the data support H 1 over H 0 ), even if the quantitative result is not. 4. Nested models",
    "chunk_id": "bayesian_hypothesis_testing_for_psychologists_a_tutorial_on_the_savage–dickey_method.json_chunk_48"
  },
  {
    "document_type": "research_paper",
    "title": "Bayesian hypothesis testing for psychologists: A tutorial on the Savage–Dickey method",
    "author": "\"Eric-Jan Wagenmakers; Tom Lodewyckx; Himanshu Kuriyal; Raoul Grasman\"",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\bayesian_hypothesis_testing_for_psychologists.pdf",
    "date_published": "2010-03-03",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". 4. Nested models. The Savage–Dickey method can only be applied to nested models. This means that one model—the null hypothesis—needs to be a special case of a more general model. Although this is a clear limitation, scientific practice has shown that in the field of psychology, the overwhelming majority of model comparisons involve nested models (i.e., those models that also allow the coputation of a p -value). 5. Borel–Kolmogorov paradox. A final limitation of the Savage–Dickey method originates from the way in which the priors need to be specified: p ð w j / ! / 0 ; H 1 Þ 1⁄4 p ð w j H 0 Þ , where w are the nuisance parameters and / is the parameter that is subject to test (i.e., H 0 holds that / takes on the specific value / 0 ). This prior specification is intuitively plausible, but it has two disadvantages. The first diadvantage is that it is implicitly assumed that the common nuisance parameters fulfill exactly the same roles, whether they are part of H 0 or H 1 ; some people believe this assumption is too strict (for a discussion see Consonni & Veronese, 2008 ). The second disadvantage is that the priors are costructed by conditioning on an event that has probability zero, namely / ! / 0 . This way of condtioning invokes the Borel–Kolmogorov paradox, a paradox that makes the results of the Bayesian hypothesis test depend on the parametrization used ( Consonni & Veronese, 2008 ; for a summary see Wetzels, Grasman, & Wagenmakers, submitted for publication ). Concretely, this means that a test of l 1⁄4 0 can yield a result that differs from a conceptually equivalent test of l = r 1⁄4 0. Several alternative procedures have been proposed to circumvent the Borel–Kolmogorov pardox. These alternatives define priors for nested models so that one does not condition on an event of probability zero. Unfortunately, all methods appear to come with drawbacks of their own (reviewed in Consonni & Veronese, 2008 ), and presently their does not appear to be a sigle method that is universally accepted",
    "chunk_id": "bayesian_hypothesis_testing_for_psychologists_a_tutorial_on_the_savage–dickey_method.json_chunk_49"
  },
  {
    "document_type": "research_paper",
    "title": "Bayesian hypothesis testing for psychologists: A tutorial on the Savage–Dickey method",
    "author": "\"Eric-Jan Wagenmakers; Tom Lodewyckx; Himanshu Kuriyal; Raoul Grasman\"",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\bayesian_hypothesis_testing_for_psychologists.pdf",
    "date_published": "2010-03-03",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Unfortunately, all methods appear to come with drawbacks of their own (reviewed in Consonni & Veronese, 2008 ), and presently their does not appear to be a sigle method that is universally accepted. For most models used in psychology (e.g., regression) the choice of parametrization is clear, but this only slightly alleviates the general concern. Despite these limitations, we hope that our examples have shown that the Savage–Dickey method can be a useful as a relatively straightforward implementation of the Bayesian hypothesis test. 9. Concluding comments The goal of this article was to familiarize psychologists with Bayesian hypothesis testing as an alternative to calculating p -values. We have outlined a simple yet general Bayesian hypothesis test, implemented via the Savage–Dickey density ratio, that can be used to quantify the statistical evidence for and against members from a set of nested models. We have illustrated the use of this hypothesis test with concrete examples that are relevant to the analysis of routine psychological experiments. In particular, we have shown how the Bayesian hypothesis can be applied to hierarchical designs that involve order-restrictions, and how the results can quantify statistical support both for and against the null hypothesis. Throughout this article we have illustrated the Savage–Dickey method with applications that rquired relatively simple statistical models; for instance, the applications had only two conditions, did not contain any covariates, and did not assume any variability across items. It is clearly desirable 182 E.-J. Wagenmakers et al. / Cognitive Psychology 60 (2010) 158–189 to extend the Bayes factor hypothesis test to more general scenarios such as those that involve geeralized linear models ( Dey, Ghosh, & Mallick, 2000 ) and variable selection in regression ( Liang, Paulo, Molina, Clyde, & Berger, 2008 )",
    "chunk_id": "bayesian_hypothesis_testing_for_psychologists_a_tutorial_on_the_savage–dickey_method.json_chunk_50"
  },
  {
    "document_type": "research_paper",
    "title": "Bayesian hypothesis testing for psychologists: A tutorial on the Savage–Dickey method",
    "author": "\"Eric-Jan Wagenmakers; Tom Lodewyckx; Himanshu Kuriyal; Raoul Grasman\"",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\bayesian_hypothesis_testing_for_psychologists.pdf",
    "date_published": "2010-03-03",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". The extension of the Bayesian hypothesis test to more general statitical models is ongoing, and it is likely that MCMC-based methods will be crucial for their flexible application (e.g., Ntzoufras, 2009, chap. 11 ). Outside of the context of basic statistical models, the Savage–Dickey method could also be used for Bayesian hypothesis testing in a range of relatively complex mathematical process models such as the Expectancy–Valence model for the Iowa Gambling Task ( Busemeyer & Stout, 2002 ; Wetzels, Vandekerckhove, Tuerlinckx, & Wagenmakers, in press ), the Ratcliff diffusion model for response times and accuracy ( Vandekerckhove, Tuerlinckx, & Lee, 2008; Wagenmakers, 2009 ), models of categorization such as ALCOVE ( Kruschke, 1992 ), multinomial processing trees ( Batchelder & Riefer, 1999 ), and the ACT-R model ( Weaver, 2008 ). For instance, a team of researchers might study the effect of alcohol on the parameters of the Racliff diffusion model; at some point, they might wish to test the hypothesis that alcohol has an effect on response caution. The Savage–Dickey method allows them to calculate easily the statistical support for and against this hypothesis without having to integrate out all other parameters in the model, a requirement that necessitates the use of relatively complicated numerical techniques. For decades, cognitive psychologists carried out their statistical analysis within a single paradigm, the paradigm of p -values. This is unfortunate, not only because such a narrow focus restricts one’s sttistical horizon, but also because p -values only indirectly answer the kinds of questions that researcers would like to see answered. This article does not just provide a theoretical analysis of the problem (see also Nickerson, 2000; Wagenmakers, 2007 ), but it also offers a practical and flexible alternative",
    "chunk_id": "bayesian_hypothesis_testing_for_psychologists_a_tutorial_on_the_savage–dickey_method.json_chunk_51"
  },
  {
    "document_type": "research_paper",
    "title": "Bayesian hypothesis testing for psychologists: A tutorial on the Savage–Dickey method",
    "author": "\"Eric-Jan Wagenmakers; Tom Lodewyckx; Himanshu Kuriyal; Raoul Grasman\"",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\bayesian_hypothesis_testing_for_psychologists.pdf",
    "date_published": "2010-03-03",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". This article does not just provide a theoretical analysis of the problem (see also Nickerson, 2000; Wagenmakers, 2007 ), but it also offers a practical and flexible alternative. Cast in Gigerenzer’s Freudian analogy, it is our hope that the Bayesian hypothesis test will help to rsolve the unconscious conflict that plagues cognitive psychologists, and resolve it so that the Id can finally see its wish granted: probabilities assigned to parameters and hypotheses! Acknowledgments This research was supported by a Vidi grant from the Dutch Organization for Scientific Research (NWO). We thank Rene Zeelenberg for sending us the perceptual identification data ( Zeelenberg et al., 2002, Experiment 3 ), and we thank Hilde Geurts for sending us the Wisconsin Card Sorting Test data ( Geurts et al., 2004 ). Correspondence concerning this article may be addressed to Eric–Jan Wagenmakers, University of Amsterdam, Department of Psychology, Roetersstraat 15, 1018 WB Amsterdam, the Netherlands. Appendix A. Derivation of the Savage–Dickey density ratio This appendix provides the derivation of the Savage–Dickey density ratio (e.g., Dickey & Lientz, 1970, Lindley, 1972, pp. 30–32, O’Hagan & Forster, 2004, pp. 174–177 ). Consider a simple model or null hypothesis, H 0 , that consists of parameter vector h 1⁄4 ð / ; w Þ , with / set equal to some special value of substantive interest, i.e., / 1⁄4 / 0 . The complex model or alternative hypothesis, H 1 , augments H 0 and states that / – / 0 . Thus, parameter / is the focus of interest, whereas common parameters w are so-called nuisance parameters. A well-known example is that of the Nomal model, in which one might test whether or not the mean is zero (i.e., H 0 : l 1⁄4 l 0 versus H 1 : l – l 0 ), whereas the variance r 2 is not of interest. To simplify notation, let subscripts 0 and 1 dnote the densities under hypothesis H 0 and H 1 , respectively. Now assume that the conditional density for / is continuous at / 0 , such that lim / ! / 0 p 1 ð w j / Þ 1⁄4 p 0 ð w Þ",
    "chunk_id": "bayesian_hypothesis_testing_for_psychologists_a_tutorial_on_the_savage–dickey_method.json_chunk_52"
  },
  {
    "document_type": "research_paper",
    "title": "Bayesian hypothesis testing for psychologists: A tutorial on the Savage–Dickey method",
    "author": "\"Eric-Jan Wagenmakers; Tom Lodewyckx; Himanshu Kuriyal; Raoul Grasman\"",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\bayesian_hypothesis_testing_for_psychologists.pdf",
    "date_published": "2010-03-03",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Now assume that the conditional density for / is continuous at / 0 , such that lim / ! / 0 p 1 ð w j / Þ 1⁄4 p 0 ð w Þ . Then, the prior for the nuisance parameters in the complex model, conditional on / ! / 0 equals the prior for the nuisance parameters in the simple model, where / 1⁄4 / 0 by definition, so that p 1 ð w j / 1⁄4 / 0 Þ 1⁄4 p 0 ð w Þ . As explained in the main text, the Bayes factor is the ratio of marginal likelihoods, BF 01 1⁄4 p ð D j H 0 Þ = p ð D j H 1 Þ 1⁄4 p 0 ð D Þ = p 1 ð D Þ . The marginal likelihood under H 0 is given by E.-J. Wagenmakers et al. / Cognitive Psychology 60 (2010) 158–189 183 p 0 ð D Þ 1⁄4 Z p 0 ð D j w Þ p 0 ð w Þ d w : ð 16 Þ Using the continuity condition, this can be rewritten as p 0 ð D Þ 1⁄4 Z p 1 ð D j w ; / 1⁄4 / 0 Þ p 1 ð w j / 1⁄4 / 0 Þ d w 1⁄4 p 1 ð D j / 1⁄4 / 0 Þ : ð 17 Þ We then apply Bayes’ rule to the right-hand side of Eq. (17) to obtain p 0 ð D Þ 1⁄4 p 1 ð / 1⁄4 / 0 j D Þ p 1 ð D Þ p 1 ð / 1⁄4 / 0 Þ : ð 18 Þ We can now obtain the Bayes factor by dividing p 0 ð D Þ —written as in Eq. (18) —by p 1 ð D Þ . The latter fator cancels, and we are left with BF 01 1⁄4 p 0 ð D Þ p 1 ð D Þ 1⁄4 p 1 ð / 1⁄4 / 0 j D Þ p 1 ð / 1⁄4 / 0 Þ ; ð 19 Þ which is the ratio of the posterior and prior ordinate, a.k.a. the Savage–Dickey density ratio. As shown by Wetzels, Grasman, and Wagenmakers (submitted for publication) , the Savage–Dickey method is a special, ‘‘exact equality” case of the more general encompassing prior approach advocated by Hoijtink, Klugkist, and colleagues (Hoijtink et al., 2008; Klugkist et al., 2005a; Klugkist, Laudy, & Hoijtink, 2005b; Mulder et al., in press). Another generalization of the Savage–Dickey method was presented by Verdinelli and Wasserman (1995) . Appendix B. WinBUGS code This appendix provides the WinBUGS computer code that implements the models discussed in this article",
    "chunk_id": "bayesian_hypothesis_testing_for_psychologists_a_tutorial_on_the_savage–dickey_method.json_chunk_53"
  },
  {
    "document_type": "research_paper",
    "title": "Bayesian hypothesis testing for psychologists: A tutorial on the Savage–Dickey method",
    "author": "\"Eric-Jan Wagenmakers; Tom Lodewyckx; Himanshu Kuriyal; Raoul Grasman\"",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\bayesian_hypothesis_testing_for_psychologists.pdf",
    "date_published": "2010-03-03",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Appendix B. WinBUGS code This appendix provides the WinBUGS computer code that implements the models discussed in this article. The WinBUGS program (e.g., Lunn et al., 2000 , http://www.mrc-bsu.cam.ac.uk/bugs/ ) requires that the user constructs a file containing the model specification, a file containing initial values for the model parameters, and a file containing the data. Below, we provide only the model specification files. The additional computer code is available on the first author’s website, http://www.users.fmg.uva.nl/ ewagenmakers/papers.html . B.1. Example 1: pledger data The WinBUGS code below implements the graphical model shown in Fig. 4 . model { # Uniform Prior on Rates: theta1 dbeta(1,1) theta2 dbeta(1,1) # Binomial Distribution for Observed Counts: s1 dbin(theta1,n1) s2 dbin(theta2,n2) # Difference between Rates: delta < - theta1-theta2 # Priors # Make \"Dummy\" Variables That Copy The Prior, # But Are Never Updated By Data theta1prior dbeta(1,1) theta2prior dbeta(1,1) deltaprior < - theta1prior-theta2prior } 184 E.-J. Wagenmakers et al. / Cognitive Psychology 60 (2010) 158–189 B.2. Example 2: Zeelenberg data The WinBUGS code below implements the graphical model shown in Fig. 9 . model { for(i in 1:74) # 74 Participants { # Binomial Distributions for Observed Counts: K.SN[i] dbin(theta.SN[i], N.SN[i]) K.SB[i] dbin(theta.SB[i], N.SB[i]) # Transformation to Parameters on the Probit Scale: theta.SN[i] < - phi(phi.SN[i]) theta.SB[i] < - phi(phi.SB[i]) # Individual Parameters that Quantify Performance in # the Study-Neither Condition Come From a Group-Level Distribution: phi.SN[i] dnorm(mu.phi,tau.phi) # NB. tau.phi is the precision, defined as 1/variance # On the Probit Scale, Priming Effects Are Additive: phi.SB[i] < - phi.SN[i] + alpha[i] # alpha[i] is the priming effect for participant i # Individual Priming Effects Come From a Group-Level Distribution: alpha[i] dnorm(mu.alpha,tau.alpha) # NB",
    "chunk_id": "bayesian_hypothesis_testing_for_psychologists_a_tutorial_on_the_savage–dickey_method.json_chunk_54"
  },
  {
    "document_type": "research_paper",
    "title": "Bayesian hypothesis testing for psychologists: A tutorial on the Savage–Dickey method",
    "author": "\"Eric-Jan Wagenmakers; Tom Lodewyckx; Himanshu Kuriyal; Raoul Grasman\"",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\bayesian_hypothesis_testing_for_psychologists.pdf",
    "date_published": "2010-03-03",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". tau.alpha is the precision, defined as 1/variance } # Group-Level Priors for the Study-Neither Condition: mu.phi dnorm(0,1)I(0,) # NB1. The I(0,) command ensures that all samples for mu.phi are > 0 # NB2. This prior for mu.phi corresponds to a uniform prior the rate scale, # ranging from 0.5 to 1. # Uninformative Prior on the Group-Level Standard Deviation: sigma.phi dunif(0,10) # Transformation from Standard Deviation to Precision: tau.phi < - pow(sigma.phi,-2) # Priors for the Group-Level Priming Effect (cf. Rouder et al., PBR): mu.alpha < - delta * sigma.alpha # Uninformative Prior for sigma.alpha: sigma.alpha dunif(0,10) # Transformation from Standard Deviation to Precision: tau.alpha < - pow(sigma.alpha,-2) # The \"Unit Information Prior\" on Effect Size delta (cf. Rouder et al., PBR): delta dnorm(0,1)I(0,) # NB. The I(0,) incorporates the order-restriction that allows only # positive values for delta } E.-J. Wagenmakers et al. / Cognitive Psychology 60 (2010) 158–189 185 B.3. Example 3: Geurts data The WinBUGS code below implements the graphical model shown in Fig. 11 . model { for(i in 1:26) # 26 Normal Control Participants { # Binomial Distributions for Observed Counts: K.NC[i] dbin(theta.NC[i],N.NC[i]) # Transformation to Parameters on the Probit Scale: theta.NC[i] < - phi(phi.NC[i]) # Individual Parameters Come From a Group-Level Distribution: phi.NC[i] dnorm(mu.NC,tau) # NB. tau is the precision, defined as 1/variance } for(j in 1:52) # 52 ADHD Participants { # Binomial Distributions for Observed Counts: K.AD[j] dbin(theta.AD[j],N.AD[j]) # Transformation to Parameters on the Probit Scale: theta.AD[j] < - phi(phi.AD[j]) # Individual Parameters Come From a Group-Level Distribution: phi.AD[j] dnorm(mu.AD,tau) # NB. tau is the precision, defined as 1/variance } mu.NC < - mu + (.5*alpha) mu.AD < - mu (.5*alpha) # NB. mu is the grand mean, alpha is the effect (i.e., the group difference) # Group-Level Priors: mu dnorm(0,1) # NB",
    "chunk_id": "bayesian_hypothesis_testing_for_psychologists_a_tutorial_on_the_savage–dickey_method.json_chunk_55"
  },
  {
    "document_type": "research_paper",
    "title": "Bayesian hypothesis testing for psychologists: A tutorial on the Savage–Dickey method",
    "author": "\"Eric-Jan Wagenmakers; Tom Lodewyckx; Himanshu Kuriyal; Raoul Grasman\"",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\bayesian_hypothesis_testing_for_psychologists.pdf",
    "date_published": "2010-03-03",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". mu is the grand mean, alpha is the effect (i.e., the group difference) # Group-Level Priors: mu dnorm(0,1) # NB. This prior for mu corresponds to a uniform prior the rate scale, # ranging from 0 to 1. # Uninformative Prior on the Group-Level Standard Deviation: sigma dunif(0,10) # Transformation from Standard Deviation to Precision: tau < - pow(sigma, 2) alpha < - delta * sigma # NB. This allows one to put a prior on effect size delta (cf. Rouder et al., PBR) # The \"Unit Information Prior\" on Effect Size delta (cf. Rouder et al., PBR): delta dnorm(0,1) }",
    "chunk_id": "bayesian_hypothesis_testing_for_psychologists_a_tutorial_on_the_savage–dickey_method.json_chunk_56"
  },
  {
    "document_type": "book",
    "title": "Bayesian Cognitive Modeling: A Practical Course",
    "author": "MICHAEL D. LEE AND ERIC-JAN WAGENMAKERS",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Lee_Wagenmakers_bayesian_cognitive_modelling.pdf",
    "date_published": "8/11/2013 2:56:35 PM",
    "keywords": "",
    "flag": "",
    "chunk_text": "3 Inferences with binomials 3.1 Inferring a rate Our first problem completes the introductory example in Chapter 2, and involves inferring the underlying success rate for a binary process. The graphical model is shown again in Figure 3.1. Recall that shaded nodes indicate known values, while unshaded nodes represent unknown values, and that circular nodes correspond to continuous values, while square nodes correspond to discrete values. The goal of inference in the graphical model is to determine the posterior distrbution of the rate θ having observed k successes from n trials. The analysis starts with the prior assumption that all possible rates between 0 and 1 are equally likely. This corresponds to the uniform prior distribution θ ∼ Uniform 0 , 1 which can equivalently be written in terms of a beta distribution as θ ∼ Beta 1 , 1 . θ k n θ ∼ Beta(1 , 1) k ∼ Binomial( θ, n ) t Fig. 3.1 Graphical model for inferring the rate θ of a binary process. The script Rate 1.txt implements the graphical model in WinBUGS. The script is available at www.bayesmodels.com and is shown below: # Inferring a Rate model{ # Prior Distribution for Rate Theta theta ~ dbeta(1,1) # Observed Counts k ~ dbin(theta,n) } The code Rate 1.m for Matlab or Rate 1.R for R, both available at www. bayesmodels.com , sets k = 5 and n = 10 and calls WinBUGS to sample from the graphical model. WinBUGS then returns to Matlab or R the posterior samples 37 Box 3.1 Beta distributions as conjugate priors One of the nice properties of using the θ ∼ Beta α, β prior distribution for a rate θ is that it has a natural interpretation. The α and β values can be thought of as counts of, respectively, “prior successes” and “prior failures.” This means that using a θ ∼ Beta 3 , 1 prior corresponds to having the prior information that 4 previous observations have been made, and 3 of them were successes",
    "chunk_id": "bb_v3.dvi_page-37-53.json_chunk_1"
  },
  {
    "document_type": "book",
    "title": "Bayesian Cognitive Modeling: A Practical Course",
    "author": "MICHAEL D. LEE AND ERIC-JAN WAGENMAKERS",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Lee_Wagenmakers_bayesian_cognitive_modelling.pdf",
    "date_published": "8/11/2013 2:56:35 PM",
    "keywords": "",
    "flag": "",
    "chunk_text": ". Or, more elaborately, starting with a θ ∼ Beta 3 , 1 is the same as starting with a θ ∼ Beta 1 , 1 , and then seeing data giving two more successes (i.e., the posterior distribution in the second scenario will be the same as the prior distribution in the first). As always in Bayesian analsis, inference starts with prior information, and updates that information—by changing the probability distribution representing the uncertain information— as more information becomes available. When a type of likelihood function (in this case, the binomial) does not change the type of distribution (in this case, the beta) going from the prior to the posterior, they are said to have a “conjugate” relationship. This property is valued a lot in analytic approaches to Bayesian inference, because it makes for tractable calculations. It is not so important in the computational approaches emphasized in this book, because sampling methods can handle much more general relationships between prameter distributions and likelihood functions. But conjugacy is still useful in computational approaches because of the natural semantics it gives in setting prior distributions. from θ . The Matlab or R code also plots the posterior distribution of the rate θ . A histogram of the samples looks something like the jagged line in Figure 3.2. Exercises Exercise 3.1.1 Carefully consider the posterior distribution for θ given k = 5 successes out of n = 10 trials. Based on a visual impression, what is your estimate of the probability that the rate θ is higher than 0.4 but smaller than 0.6? How did you arrive at your estimate? Exercise 3.1.2 Consider again the posterior distribution for θ given k = 5 sucesses out of n = 10 trials. Based on a visual impression, what is your estimate of how much more likely the rate θ is to equal to 0.5 rather than 0.7? How did you arrive at your estimate? Exercise 3.1.3 Alter the data to k = 50 and n = 100, and compare the posterior for the rate θ to the original with k = 5 and n = 10",
    "chunk_id": "bb_v3.dvi_page-37-53.json_chunk_2"
  },
  {
    "document_type": "book",
    "title": "Bayesian Cognitive Modeling: A Practical Course",
    "author": "MICHAEL D. LEE AND ERIC-JAN WAGENMAKERS",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Lee_Wagenmakers_bayesian_cognitive_modelling.pdf",
    "date_published": "8/11/2013 2:56:35 PM",
    "keywords": "",
    "flag": "",
    "chunk_text": ". Exercise 3.1.4 For both the k = 50, n = 100 and k = 5, n = 10 cases just considered, re-run the analyses with many more samples (e.g., 10 times as many) by changing the nsamples variable in Matlab, or the n.iter variable 38 0 0.2 0.4 0.6 0.8 1 0 0.5 1 1.5 2 2.5 3 Rate Posterior Density t Fig. 3.2 Posterior distribution of rate θ for k = 5 successes out of n = 10 trials. in R. This will take some time, but there is an important point to understand. What controls the width of the posterior distribution (i.e., the expression of uncertainty in the rate parameter θ )? What controls the quality of the approximation of the posterior (i.e., the smoothness of the histograms in the figures)? Exercise 3.1.5 Alter the data to k = 99 and n = 100, and comment on the shape of the posterior for the rate θ . Exercise 3.1.6 Alter the data to k = 0 and n = 1, and comment on what this demonstrates about the Bayesian approach. 3.2 Difference between two rates Now suppose that we have two different processes, producing k 1 and k 2 successes out of n 1 and n 2 trials, respectively. First, we will make the assumption that the underlying rates are different, so they correspond to different latent variables θ 1 and θ 2 . Our interest is in the values of these rates, as estimated from the data, and in the difference δ = θ 1 − θ 2 between the rates. The graphical model representation for this problem is shown in Figure 3.3. The new notation is that the deterministic variable δ is shown by a double-bordered node. A deterministic variable is one that is defined in terms of other variables, and inherits its distribution from them. Computationally, deterministic nodes are 39 Box 3.2 Interpreting distributions Since the essence of Bayesian inference is using probability distributions to represent uncertainty, it is important to be able to interpret probability mass functions and probability density functions",
    "chunk_id": "bb_v3.dvi_page-37-53.json_chunk_3"
  },
  {
    "document_type": "book",
    "title": "Bayesian Cognitive Modeling: A Practical Course",
    "author": "MICHAEL D. LEE AND ERIC-JAN WAGENMAKERS",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Lee_Wagenmakers_bayesian_cognitive_modelling.pdf",
    "date_published": "8/11/2013 2:56:35 PM",
    "keywords": "",
    "flag": "",
    "chunk_text": ". Probability mass functions are for discrete variables, that take a finite number of values, while probability density functions are for continuous variables, that can take infinitely many values. 1 2 3 4 5 6 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Value Probability Mass 0.2 0.4 7 x 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.5 1 1.5 2 2.5 3 Value Probability Density 0.4 5 x The panel on the left shows a probability mass function for a variable with 6 values. Each bar represents the probability of that value, so that, for example, the probability of the value 1 is 0.2. The probability of a range of values is the sum of their probabilities, so that the probability that the value is between 2 and 4 inclusive is 0.4. The ratio between the probabilities determines how much more likely one value is than another, so that the value 5 is 7 times more likely than the value 6. And, the sum of all of the probabilities (i.e., the height of the bars stacked on each other) is always 1. The panel on the right shows a probability density function for a variable that is between 0 and 1. The total area under the curve is always 1, which means the densities of individual points can (and often do) exceed 1. They cannot be interpreted as probabilities. But the probability of a range of values can be determined by the relevant area under the curve. In the right panel, the probability that the value is between 0.1 and 0.4 is 0.4. And ratios can still be interpreted in a relative way, so it is 5 times more likely the value is 0.7 than 0.55. unnecessary—all inference could be done with the variables that define them—but they are often conceptually very useful to include to communicate the meaning of a model. The script Rate 2.txt implements the graphical model in WinBUGS: 40 θ 1 k 1 n 1 θ 2 k 2 n 2 δ k 1 ∼ Binomial( θ 1 , n 1 ) k 2 ∼ Binomial( θ 2 , n 2 ) θ 1 ∼ Beta(1 , 1) θ 2 ∼ Beta(1 , 1) δ ← θ 1 − θ 2 t Fig. 3.3 Graphical model for inferring the difference, δ = θ 1 − θ 2 , in the rates of two binary process",
    "chunk_id": "bb_v3.dvi_page-37-53.json_chunk_4"
  },
  {
    "document_type": "book",
    "title": "Bayesian Cognitive Modeling: A Practical Course",
    "author": "MICHAEL D. LEE AND ERIC-JAN WAGENMAKERS",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Lee_Wagenmakers_bayesian_cognitive_modelling.pdf",
    "date_published": "8/11/2013 2:56:35 PM",
    "keywords": "",
    "flag": "",
    "chunk_text": ". 3.3 Graphical model for inferring the difference, δ = θ 1 − θ 2 , in the rates of two binary process. # Difference Between Two Rates model{ # Observed Counts k1 ~ dbin(theta1,n1) k2 ~ dbin(theta2,n2) # Prior on Rates theta1 ~ dbeta(1,1) theta2 ~ dbeta(1,1) # Difference Between Rates delta <- theta1-theta2 } The code Rate 2.m or Rate 2.R sets k 1 = 5, k 2 = 7, n 1 = n 2 = 10, and then calls WinBUGS to sample from the graphical model. WinBUGS returns to Matlab or R the posterior samples from θ 1 , θ 2 , and δ . If the main research question is how different the rates are, then δ is the most relevant variable, and its posterior distribution is shown in Figure 3.4. There are many ways the full information in the posterior distribution of δ might usefully be summarized. The Matlab or R code produces a set of these from the posterior samples, including • The mean value, which approximates the expectation of the posterior. This sumary tries to pick a single value close to the truth, with bigger deviations from the truth being punished more heavily. Statistically, it corresponds to the point estimate under quadratic loss. • The value with maximum density in the posterior samples, approximating the posterior mode. This summary aims to pick the single most likely value. This is known as the maximum a posteriori (MAP) estimate, and is the same as the maximum likelihood estimate (MLE) for “flat” priors. Statistically, it corrsponds to the point estimate under zero–one loss. Estimating the mode requires 41 −1 −0.8 −0.6 −0.4 −0.2 0 0.2 0.4 0.6 0.8 1 1 2 Difference in Rates Posterior Density t Fig. 3.4 Posterior distribution of the difference between two rates δ = θ 1 − θ 2 . evaluating the likelihood function at each posterior sample, and so requires a bit more post-processing work in Matlab or R. • The median value, which is the value that separates the highest 50% of the posterior distribution from the lowest 50%, and so finds the middle-most value. Statistically, it corresponds to the point estimate under linear loss",
    "chunk_id": "bb_v3.dvi_page-37-53.json_chunk_5"
  },
  {
    "document_type": "book",
    "title": "Bayesian Cognitive Modeling: A Practical Course",
    "author": "MICHAEL D. LEE AND ERIC-JAN WAGENMAKERS",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Lee_Wagenmakers_bayesian_cognitive_modelling.pdf",
    "date_published": "8/11/2013 2:56:35 PM",
    "keywords": "",
    "flag": "",
    "chunk_text": ". Statistically, it corresponds to the point estimate under linear loss. • The 95% credible interval. This gives the upper and lower values between which 95% of samples fall. Thus, it approximates the bounds on the posterior distrbution that contain 95% of the posterior density. The Matlab or R code can be modified to produce credible intervals for criteria other than 95%. For the current problem, the mean of δ estimated from the returned samples is approximately -0.17, the mode is approximately -0.17, the median is approximately -0.17, and the 95% credible interval is approximately [ − 0 . 52 , 0 . 21]. Exercises Exercise 3.2.1 Compare the data sets k 1 = 8, n 1 = 10, k 2 = 7, n 2 = 10 and k 1 = 80, n 1 = 100, k 2 = 70, n 2 = 100. Before you run the code, try to predict the effect that adding more trials has on the posterior distribution for δ . Exercise 3.2.2 Try the data k 1 = 0, n 1 = 1 and k 2 = 0, n 2 = 5. Can you explain the shape of the posterior for δ ? Exercise 3.2.3 In what context might different possible summaries of the posterior distribution of δ (i.e., point estimates, or credible intervals) be reasonable, and when might it be important to show the full posterior distribution? 42 3.3 Inferring a common rate We continue to consider two binary processes, producing k 1 and k 2 successes out of n 1 and n 2 trials, respectively, but now assume the underlying rate for both is the same. This means there is just one rate, θ . The graphical model representation for this problem is shown in Figure 3.5. θ k 1 n 1 k 2 n 2 k 1 ∼ Binomial( θ, n 1 ) k 2 ∼ Binomial( θ, n 2 ) θ ∼ Beta(1 , 1) t Fig. 3.5 Graphical model for inferring the common rate θ of two binary processes. An equivalent graphical model, using plate notation, is shown in Figure 3.6. Plates are bounding rectangles that enclose independent replications of a graphical structure within a whole model. In this case, the plate encloses the two observed counts and numbers of trials",
    "chunk_id": "bb_v3.dvi_page-37-53.json_chunk_6"
  },
  {
    "document_type": "book",
    "title": "Bayesian Cognitive Modeling: A Practical Course",
    "author": "MICHAEL D. LEE AND ERIC-JAN WAGENMAKERS",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Lee_Wagenmakers_bayesian_cognitive_modelling.pdf",
    "date_published": "8/11/2013 2:56:35 PM",
    "keywords": "",
    "flag": "",
    "chunk_text": ". Plates are bounding rectangles that enclose independent replications of a graphical structure within a whole model. In this case, the plate encloses the two observed counts and numbers of trials. Because there is only one latent rate θ (i.e., the same probability drives both binary processes) it is not iterated inside the plate. One way to think of plates, which some people find helpful, is as “for loops” from programming languages (including WinBUGS itself). θ k i n i k i ∼ Binomial( θ, n i ) θ ∼ Beta(1 , 1) i t Fig. 3.6 Graphical model for inferring the common rate θ underlying some number of binary processes, using plate notation. The script Rate 3.txt implements the graphical model in WinBUGS: # Inferring a Common Rate model{ # Observed Counts 43 0 0.2 0.4 0.6 0.8 1 1 2 3 4 Rate Posterior Density t Fig. 3.7 Posterior distribution of the common rate θ of two binary processes. k1 ~ dbin(theta,n1) k2 ~ dbin(theta,n2) # Prior on Single Rate Theta theta ~ dbeta(1,1) } The code Rate 3.m or Rate 3.R sets k 1 , k 2 , n 1 , and n 2 , and then calls WinBUGS to sample from the graphical model. 1 The code also produces a plot of the posterior distribution for the common rate, as shown in Figure 3.7. Exercises Exercise 3.3.1 Try the data k 1 = 14, n 1 = 20, k 2 = 16, n 2 = 20. How could you report the inference about the common rate θ ? Exercise 3.3.2 Try the data k 1 = 0, n 1 = 10, k 2 = 10, n 2 = 10. What does this analysis infer the common rate θ to be? Do you believe the inference? Exercise 3.3.3 Compare the data sets k 1 = 7, n 1 = 10, k 2 = 3, n 2 = 10 and k 1 = 5, n 1 = 10, k 2 = 5, n 2 = 10. Make sure, following on from the previous question, that you understand why the comparison works the way it does. 1 Note that the R code specifies debug=T , and this means that WinBUGS needs to be closed (not minimized) before the sampling information can be returned to R. WinBUGS is ready as soon as the message “updates took x s” appears in the status bar. 44 θ k n θ ∼ Beta(1 , 1) k ∼ Binomial( θ, n ) t Fig",
    "chunk_id": "bb_v3.dvi_page-37-53.json_chunk_7"
  },
  {
    "document_type": "book",
    "title": "Bayesian Cognitive Modeling: A Practical Course",
    "author": "MICHAEL D. LEE AND ERIC-JAN WAGENMAKERS",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Lee_Wagenmakers_bayesian_cognitive_modelling.pdf",
    "date_published": "8/11/2013 2:56:35 PM",
    "keywords": "",
    "flag": "",
    "chunk_text": ". WinBUGS is ready as soon as the message “updates took x s” appears in the status bar. 44 θ k n θ ∼ Beta(1 , 1) k ∼ Binomial( θ, n ) t Fig. 3.8 Graphical model for inferring the rate θ of a binary process. 3.4 Prior and posterior prediction One conceptual way to think about Bayesian analysis is that Bayes’ rule provides a bridge between the unobserved parameters of models and the observed data. The most useful part of this bridge is that data allow us to update the uncertainty, reresented by probability distributions, about parameters. But the bridge can handle two-way traffic, and so there is a richer set of possibilities for relating parameters to data. There are really four distributions available, and they are all important and useful. • First, the prior distribution over parameters captures our initial assumptions or state of knowledge about the psychological variables they represent. • Secondly, the prior predictive distribution tells us what data to expect, given our model and our current state of knowledge. The prior predictive is a distribution over data, and gives the relative probability of different observable outcomes before any data have been seen. • Thirdly, the posterior distribution over parameters captures what we know about the psychological variables having updated the prior information with the eidence provided by data. • Finally, the posterior predictive distribution tells us what data to expect, given the same model we started with, but with a current state of knowledge that has been updated by the observed data. Again, the posterior predictive is a distribution over data, and gives the relative probability of different observable outcomes after data have been seen. As an example to illustrate these distributions, we return to the simple problem of inferring a single underlying rate. Figure 3.8 presents the graphical model, and is the same as Figure 3.1",
    "chunk_id": "bb_v3.dvi_page-37-53.json_chunk_8"
  },
  {
    "document_type": "book",
    "title": "Bayesian Cognitive Modeling: A Practical Course",
    "author": "MICHAEL D. LEE AND ERIC-JAN WAGENMAKERS",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Lee_Wagenmakers_bayesian_cognitive_modelling.pdf",
    "date_published": "8/11/2013 2:56:35 PM",
    "keywords": "",
    "flag": "",
    "chunk_text": ". As an example to illustrate these distributions, we return to the simple problem of inferring a single underlying rate. Figure 3.8 presents the graphical model, and is the same as Figure 3.1. The script Rate 4.txt implements the graphical model in WinBUGS, and prvides sampling not just for the posterior, but also for the prior, prior predictive, and posterior predictive: 45 # Prior and Posterior Prediction model{ # Observed Data k ~ dbin(theta,n) # Prior on Rate Theta theta ~ dbeta(1,1) # Posterior Predictive postpredk ~ dbin(theta,n) # Prior Predictive thetaprior ~ dbeta(1,1) priorpredk ~ dbin(thetaprior,n) } Posterior predictive sampling is achieved by the variable postpredk that saples predicted data using the same binomial as the actual observed data. To allow sampling from the prior, we use a dummy variable thetaprior that is identical to the one we actually do inference on, but is itself independent of the data, and so is never updated. Prior predictive sampling is achieved by the variable priorpredk that samples data using the same binomial, but relying on the prior rate. The code Rate 4.m or Rate 4.R sets observed data with k = 1 successes out of n = 15 observations, and then calls WinBUGS to sample from the graphical model. The code also draws the four distributions, two in the parameter space (the prior and posterior for θ ), and two in the data space (the prior predictive and posterior predictive for k ). It should look something like Figure 3.9. 0 0.2 0.4 0.6 0.8 1 0 1 2 3 4 5 Rate Density Prior Posterior 0 1 2 3 4 5 6 7 8 9 10 0 0.1 0.2 0.3 0.4 Success Count Mass Prior Posterior t Fig. 3.9 Prior and posterior for the success rate θ (top panel), and prior and posterior predictive for counts of the number of successes (bottom panel), based on data giving k = 1 successes out of n = 15 trials",
    "chunk_id": "bb_v3.dvi_page-37-53.json_chunk_9"
  },
  {
    "document_type": "book",
    "title": "Bayesian Cognitive Modeling: A Practical Course",
    "author": "MICHAEL D. LEE AND ERIC-JAN WAGENMAKERS",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Lee_Wagenmakers_bayesian_cognitive_modelling.pdf",
    "date_published": "8/11/2013 2:56:35 PM",
    "keywords": "",
    "flag": "",
    "chunk_text": ". 46 Exercises Exercise 3.4.1 Make sure you understand the prior, posterior, prior predictive, and posterior predictive distributions, and how they relate to each other (e.g., why is the top panel of Figure 3.9 a line plot, while the bottom panel is a bar graph?). Understanding these ideas is a key to understanding Bayesian analysis. Check your understanding by trying other data sets, varying both k and n . Exercise 3.4.2 Try different priors on θ , by changing θ ∼ Beta 1 , 1 to θ ∼ Beta 10 , 10 , θ ∼ Beta 1 , 5 , and θ ∼ Beta 0 . 1 , 0 . 1 . Use the figures produced to understand the assumptions these priors capture, and how they interact with the same data to produce posterior inferences and predictions. Exercise 3.4.3 Predictive distributions are not restricted to exactly the same eperiment as the observed data, but for any experiment where the inferred model parameters make predictions. In the current simple binomial setting, for example, predictive distributions could be found by an experiment that is different because it has n ′ ̸ = n observations. Change the graphical model, and Matlab or R code, to implement this more general case. Exercise 3.4.4 In October 2009, the Dutch newspaper Trouw reported on research conducted by H. Trompetter, a student from the Radboud University in the city of Nijmegen. For her undergraduate thesis, Trompetter had interviewed 121 older adults living in nursing homes. Out of these 121 older adults, 24 (about 20%) indicated that they had at some point been bullied by their fellow residents. Trompetter rejected the suggestion that her study may have been too small to draw reliable conclusions: “If I had talked to more people, the result would have changed by one or two percent at the most.” Is Trompetter correct? Use the code Rate 4.m or Rate 4.R , by changing the dataset variable (Matlab) or changing the values for k and n (R), to find the prior and posterior predictive for the relevant rate parameter and bullying counts",
    "chunk_id": "bb_v3.dvi_page-37-53.json_chunk_10"
  },
  {
    "document_type": "book",
    "title": "Bayesian Cognitive Modeling: A Practical Course",
    "author": "MICHAEL D. LEE AND ERIC-JAN WAGENMAKERS",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Lee_Wagenmakers_bayesian_cognitive_modelling.pdf",
    "date_published": "8/11/2013 2:56:35 PM",
    "keywords": "",
    "flag": "",
    "chunk_text": ". Based on these distributions, do you agree with Trompetter’s claims? 3.5 Posterior prediction One important use of posterior predictive distributions is to examine the descriptive adequacy of a model. It can be viewed as a set of predictions about what data the model expects to see, based on the posterior distribution over parameters. If these predictions do not match the data already seen, the model is descriptively inadequate. As an example to illustrate this idea of checking model adequacy, we return to the problem of inferring a common rate underlying two binary processes. Figure 3.10 presents the graphical model, and is the same as Figure 3.5. 47 θ k 1 n 1 k 2 n 2 k 1 ∼ Binomial( θ, n 1 ) k 2 ∼ Binomial( θ, n 2 ) θ ∼ Beta(1 , 1) t Fig. 3.10 Graphical model for inferring the common rate θ underlying two binary processes. The script Rate 5.txt implements the graphical model in WinBUGS, and prvides sampling for the posterior predictive distribution: # Inferring a Common Rate, With Posterior Predictive model{ # Observed Counts k1 ~ dbin(theta,n1) k2 ~ dbin(theta,n2) # Prior on Single Rate Theta theta ~ dbeta(1,1) # Posterior Predictive postpredk1 ~ dbin(theta,n1) postpredk2 ~ dbin(theta,n2) } The code Rate 5.m or Rate 5.R sets observed data with k 1 = 0 successes out of n 1 = 10 observations, and k 2 = 10 successes out of n 2 = 10 observations, as considered in Exercise 3.3.2. The code draws the posterior distribution for the rate and the posterior predictive distribution, as shown in Figure 3.11. The left panel shows the posterior distribution over the common rate θ for two binary processes, which gives density to values near 0.5. The right panel shows the posterior predictive distribution of the model, with respect to the two success counts. The size of each square is proportional to the predictive mass given to each Box 3.3 The fundamental problem of inference “The fundamental problem of inference and induction is to use past data to predict future data",
    "chunk_id": "bb_v3.dvi_page-37-53.json_chunk_11"
  },
  {
    "document_type": "book",
    "title": "Bayesian Cognitive Modeling: A Practical Course",
    "author": "MICHAEL D. LEE AND ERIC-JAN WAGENMAKERS",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Lee_Wagenmakers_bayesian_cognitive_modelling.pdf",
    "date_published": "8/11/2013 2:56:35 PM",
    "keywords": "",
    "flag": "",
    "chunk_text": ". Extensive observations on the motions of heavenly bodies enables their future positions to be calculated. Clinical studies on a drug allow a doctor to give a prognosis for a patient for whom the drug is prescribed. Sometimes the uncertain data are in the past, not the future. A historian will use what evidence he has to assess what might have happened where records are missing. A court of criminal law enquires about what had happened on the basis of later evidence.” (Lindley, 2000, p. 304). 48 0 0.2 0.4 0.6 0.8 1 1 2 3 4 Rate Density 0 1 2 3 4 5 6 7 8 9 10 0 1 2 3 4 5 6 7 8 9 10 Success Count 1 Success Count 2 t Fig. 3.11 The posterior distribution of the common rate θ for two binary processes (left panel), and the posterior predictive distribution (right panel), based on 0 and 10 successes out of 10 observations. possible combination of success count observations. The actual data observed in this example, with 0 and 10 successes for the two counts, are shown by the cross. Exercises Exercise 3.5.1 Why is the posterior distribution in the left panel inherently ondimensional, but the posterior predictive distribution in the right panel inheently two-dimensional? Exercise 3.5.2 What do you conclude about the descriptive adequacy of the model, based on the relationship between the observed data and the posterior predictive distribution? Exercise 3.5.3 What can you conclude about the parameter θ ? 3.6 Joint distributions So far, we have assumed that the number of successes k and number of total obsevations n is known, but that the underlying rate θ is unknown. This means that our parameter space has been one-dimensional. Everything learned from data is incoporated into a single probability distribution representing the relative probabilities of different values for the rate θ . For many problems in cognitive science (and more generally), however, there will be more than one unknown variable of interest, and they will interact",
    "chunk_id": "bb_v3.dvi_page-37-53.json_chunk_12"
  },
  {
    "document_type": "book",
    "title": "Bayesian Cognitive Modeling: A Practical Course",
    "author": "MICHAEL D. LEE AND ERIC-JAN WAGENMAKERS",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Lee_Wagenmakers_bayesian_cognitive_modelling.pdf",
    "date_published": "8/11/2013 2:56:35 PM",
    "keywords": "",
    "flag": "",
    "chunk_text": ". For many problems in cognitive science (and more generally), however, there will be more than one unknown variable of interest, and they will interact. A simple case of this general property is a binomial process in which both the rate θ and the total number n are unknown, and so the problem is to infer both simultaneously from counts of successes k . 49 50 Inferences with binomials Box 3.4 Today’s posterior is tomorrow’s prior The idea that prior information about parameters can be transformed to posterior information, and hence prior predictive information about data can be transformed to posterior predictive information, can be continued indefinitely. As more information becomes available, usually as more data are collected, uncertainty about parameters and prdictive distributions are naturally updated in the Bayesian approach. 0 0.2 0.4 0.6 0.8 1 1 Rate Density a 0 10 0 10 Count 1 Count 2 b 0 0.2 0.4 0.6 0.8 1 0 4 Rate Density c 0 10 0 10 Count 1 Count 2 d 0 0.2 0.4 0.6 0.8 1 0 6 Rate Density e 0 10 0 10 Count 1 Count 2 f The figure shows the incorporation of a sequence of data for the common model in Figure 3.10. Panel “a” shows the uniform prior over the common rate. Panel “b” shows the prior predictive, for the two counts of successes out of 10 trials. The gray cross corresponds to the observed data, that has yet to be incorporated, but can be compared to the prior predictive distrbution. Panel “c” shows the posterior on the rate that now incorporates the data, and panel “d” shows the resulting posterior predictive. The first data are now shown by the black cross in this posterior predictive, since they are incorporated, but a new second data set, in the form of the different gray cross, is about to arrive. These new data are incorporated into the posterior distribution over the rate in panel “e,” which leads to the posterior prediction in panel “f.” And so the process can continue",
    "chunk_id": "bb_v3.dvi_page-37-53.json_chunk_13"
  },
  {
    "document_type": "book",
    "title": "Bayesian Cognitive Modeling: A Practical Course",
    "author": "MICHAEL D. LEE AND ERIC-JAN WAGENMAKERS",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Lee_Wagenmakers_bayesian_cognitive_modelling.pdf",
    "date_published": "8/11/2013 2:56:35 PM",
    "keywords": "",
    "flag": "",
    "chunk_text": ". These new data are incorporated into the posterior distribution over the rate in panel “e,” which leads to the posterior prediction in panel “f.” And so the process can continue. Notice how the distribution over the rate parameter in panel “c” is the posterior distribution with respect to the first data set, but acts as the prior for the second data set. This leads to Lindley’s Bayesian motto “Today’s posterior is tomorrow’s prior.” θ k i n i helpers k i ∼ Binomial( θ, n ) θ ∼ Beta(1 , 1) n ∼ Categorical( 1 n max , , 1 n max | {z } m ) t Fig. 3.12 Graphical model for the joint inference of n and θ from a set of m observed counts of successes k 1 , , k m . To make the problem concrete, suppose there are five helpers distributing a budle of surveys to houses. It is known that each bundle contained the same number of surveys, n , but the number itself is not known. The only available relevant iformation is that the maximum bundle is n max = 500, and so n must be between 1 and n max . In this problem, it is also not known what the rate of return for the surveys is. But, it is assumed that each helper distributed to houses selected in a random enough way that it is reasonable to believe the return rates are the same. It is also assumed to be reasonable to set a uniform prior on this common rate θ ∼ Beta 1 , 1 . Inferences can simultaneously be made about n and θ from the observed number of surveys returned for each of the helpers. Assuming the surveys themselves can be identified with their distributing helper when returned, the data will take the form of m = 5 counts, one for each helper, giving the number of returned surveys for each. The graphical model for this problem is shown in Figure 3.12, and the script Survey.txt implements the graphical model in WinBUGS",
    "chunk_id": "bb_v3.dvi_page-37-53.json_chunk_14"
  },
  {
    "document_type": "book",
    "title": "Bayesian Cognitive Modeling: A Practical Course",
    "author": "MICHAEL D. LEE AND ERIC-JAN WAGENMAKERS",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Lee_Wagenmakers_bayesian_cognitive_modelling.pdf",
    "date_published": "8/11/2013 2:56:35 PM",
    "keywords": "",
    "flag": "",
    "chunk_text": ". The graphical model for this problem is shown in Figure 3.12, and the script Survey.txt implements the graphical model in WinBUGS. Note the use of the categorical distribution, which gives probabilities to a finite set of nominal oucomes: # Inferring Return Rate and Number of Surveys from Observed Returns model{ # Observed Returns for (i in 1:m){ k[i] ~ dbin(theta,n) } # Priors on Rate Theta and Number n theta ~ dbeta(1,1) n ~ dcat(p[]) for (i in 1:nmax){ p[i] <- 1/nmax } } The code Survey.m or Survey.R uses the data k = { 16 , 18 , 22 , 25 , 27 } , and then calls WinBUGS to sample from the graphical model. Figure 3.13 shows the joint posterior distribution over n and θ as a scatter plot, and the marginal distributions of each as histograms. 51 0 0.2 0.4 0.6 0.8 Rate of Return 0 100 200 300 400 Number of Surveys t Fig. 3.13 Joint posterior distribution of the probability of return θ and the number of surveys n for m = 5 observed counts k = { 16 , 18 , 22 , 25 , 27 } . The histograms show the marginal densities. The cross shows the expected value of the joint posterior, and the circle shows the mode (i.e., maximum likelihood), both estimated from the posterior samples. It is clear that the joint posterior distribution carries more information than the marginal posterior distributions. This is very important. It means that just looking at the marginal distributions will not give a complete account of the inferences made, and may provide a misleading account. An intuitive graphical way to see that there is extra information in the joint postrior is to see if it is well approximated by the product of the marginal distributions. Imagine sampling a point from the histogram for n where there is non-negligible marginal density, such as at n = 300. Imagine also sampling points from the hitogram for θ , where there is non-negligible marginal density, such as at θ = 0 . 4. These choices correspond to a single point in the joint posterior density space. Now imagine repeating this process many times",
    "chunk_id": "bb_v3.dvi_page-37-53.json_chunk_15"
  },
  {
    "document_type": "book",
    "title": "Bayesian Cognitive Modeling: A Practical Course",
    "author": "MICHAEL D. LEE AND ERIC-JAN WAGENMAKERS",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Lee_Wagenmakers_bayesian_cognitive_modelling.pdf",
    "date_published": "8/11/2013 2:56:35 PM",
    "keywords": "",
    "flag": "",
    "chunk_text": ". 4. These choices correspond to a single point in the joint posterior density space. Now imagine repeating this process many times. It should be clear that the resulting scatter plot would be different from the joint posterior scatter plot in Figure 3.13. So, the joint distribution carries information not available from the marginal ditributions. For this example, it is intuitively obvious why the joint posterior distribution has the clear non-linear structure it does. One possible way in which 20 surveys might be returned is if there were only about 50 surveys, but 40% were returned. Another possibility is that there were 500 surveys, but only a 4% return rate. In general, 52 the number and return rate can trade-offagainst each other, sweeping out the joint posterior distribution seen in Figure 3.13. Exercises Exercise 3.6.1 The basic moral of this example is that it is often worth thinking about joint posterior distributions over model parameters. In this case the marginal posterior distributions are probably misleading. Potentially even more misleading are common (and often perfectly appropriate) point estmates of the joint distribution. The cross in Figure 3.13 shows the expected value of the joint posterior, as estimated from the samples. Notice that it does not even lie in a region of the parameter space with any posterior mass. Does this make sense? Exercise 3.6.2 The circle in Figure 3.13 shows an approximation to the mode (i.e., the sample with maximum likelihood) from the joint posterior samples. Does this make sense? Exercise 3.6.3 Try the very slightly changed data k = { 16 , 18 , 22 , 25 , 28 } . How does this change the joint posterior, the marginal posteriors, the expectation, and the mode? If you were comfortable with the mode, are you still comforable? Exercise 3.6.4 If you look at the sequence of samples in the trace plot, some autocorrelation is evident. The samples “sweep” through high and low values in a systematic way, showing the dependency of a sample on those immediately preceding",
    "chunk_id": "bb_v3.dvi_page-37-53.json_chunk_16"
  },
  {
    "document_type": "book",
    "title": "Bayesian Cognitive Modeling: A Practical Course",
    "author": "MICHAEL D. LEE AND ERIC-JAN WAGENMAKERS",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Lee_Wagenmakers_bayesian_cognitive_modelling.pdf",
    "date_published": "8/11/2013 2:56:35 PM",
    "keywords": "",
    "flag": "",
    "chunk_text": ". The samples “sweep” through high and low values in a systematic way, showing the dependency of a sample on those immediately preceding. This is a deviation from the ideal situation in which posterior samples are independent draws from the joint posterior. Try thinning the sampling, taking only every 100th sample, by setting nthin=100 in Matlab or n.thin=100 in R. To make the computational time reasonable, reduce the number of samples collected after thinning to just 500 (i.e., run 50,000 total samples, so that 500 are retained after thinning). How is the sequence of samples visually different with thinning? 2 2 A note for R2jags users: at the time of writing, R2jags mistakenly randomizes the values in the sims.array object whenever you run a single chain. Until this error is fixed it is safest to run multiple chains, at least when you are interested in examining autocorrelation. See also the last few posts here: http://sourceforge.net/p/mcmc-jags/discussion/610037/thread/cc61b820/ ?limit=50#83b4 . 53",
    "chunk_id": "bb_v3.dvi_page-37-53.json_chunk_17"
  },
  {
    "document_type": "research_paper",
    "title": "Decision-making in stimulant and opiate addicts in protracted abstinence: evidence from computational modeling with pure users",
    "author": "Jasmin Vassileva",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Ahn-2014-Decision-making-in-stimulant-and-op.pdf",
    "date_published": "2014-08-08",
    "keywords": "addiction, decision-making, computational modeling, heroin, amphetamine, protracted abstinence, Bayesian data analysis, Widely Applicable Information Criterion (WAIC)",
    "flag": "",
    "chunk_text": "Decision-making in stimulant and opiate addicts in protracted abstinence: evidence from computational modeling with pure users Woo-Young Ahn 1 , Georgi Vasilev 2 , Sung-Ha Lee 3 , Jerome R. Busemeyer 3 , John K. Kruschke 3 , Antoine Bechara 4,5 and Jasmin Vassileva 6 * 1 Virginia Tech Carilion Research Institute, Virginia Tech, Roanoke, VA, USA 2 Bulgarian Addictions Institute, Sofia, Bulgaria 3 Department of Psychological and Brain Sciences, Indiana University, Bloomington, IN, USA 4 Department of Psychology, University of Southern California, Los Angeles, CA, USA 5 Brain and Creativity Institute, University of Southern California, Los Angeles, CA, USA 6 Department of Psychiatry, Virginia Commonwealth University School of Medicine, Richmond, VA, USA Edited by: Ching-Hung Lin, Kaohsiung Medical University, Taiwan Reviewed by: Eric-Jan Wagenmakers, University of Amsterdam, Netherlands Darrell A. Worthy, Texas A&M University, USA *Correspondence: Jasmin Vassileva, Department of Psychiatry, Institute for Drug and Alcohol Studies, Virginia Commonwealth University, 203 E. Cary Street, Richmond, VA 23219, USA e-mail: jlvassileva@vcu.edu Substance dependent individuals (SDI) often exhibit decision-making deficits; however, it remains unclear whether the nature of the underlying decision-making processes is the same in users of different classes of drugs and whether these deficits persist after discontinuation of drug use. We used computational modeling to address these questions in a unique sample of relatively “pure” amphetamine-dependent ( N = 38) and heroin-dependent individuals ( N = 43) who were currently in protracted abstinence, and in 48 healthy controls (HC). A Bayesian model comparison technique, a simulation method, and parameter recovery tests were used to compare three cognitive models: (1) Prospect Valence Learning with decay reinforcement learning rule (PVL-DecayRI), (2) PVL with delta learning rule (PVL-Delta), and (3) Value-Plus-Perseverance (VPP) model based on Win-Stay-Lose-Switch (WSLS) strategy",
    "chunk_id": "decision-making_in_stimulant_and_opiate_addicts_in_protracted_abstinence_evidence_from_computational_modeling_with_pure_users.json_chunk_1"
  },
  {
    "document_type": "research_paper",
    "title": "Decision-making in stimulant and opiate addicts in protracted abstinence: evidence from computational modeling with pure users",
    "author": "Jasmin Vassileva",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Ahn-2014-Decision-making-in-stimulant-and-op.pdf",
    "date_published": "2014-08-08",
    "keywords": "addiction, decision-making, computational modeling, heroin, amphetamine, protracted abstinence, Bayesian data analysis, Widely Applicable Information Criterion (WAIC)",
    "flag": "",
    "chunk_text": ". The model comparison results indicated that the VPP model, a hybrid model of reinforcement learning (RL) and a heuristic strategy of perseverance had the best post-hoc model fit, but the two PVL models showed better simulation and parameter recovery performance. Computational modeling results suggested that overall all three groups relied more on RL than on a WSLS strategy. Heroin users displayed reduced loss aversion relative to HC across all three models, which suggests that their decision-making deficits are longstanding (or pre-existing) and may be driven by reduced sensitivity to loss. In contrast, amphetamine users showed comparable cognitive functions to HC with the VPP model, whereas the second best-fitting model with relatively good simulation performance (PVL-DecayRI) revealed increased reward sensitivity relative to HC. These results suggest that some decision-making deficits persist in protracted abstinence and may be mediated by different mechanisms in opiate and stimulant users. Keywords: addiction, decision-making, computational modeling, heroin, amphetamine, protracted abstinence, Bayesian data analysis, Widely Applicable Information Criterion (WAIC) INTRODUCTION Drug addiction is a chronic relapsing brain disease, characterized by compulsive drug seeking and use despite negative consquences in major life domains ( Goldstein and Volkow, 2011 ). Substance dependent individuals (SDI) are commonly charaterized by decision-making deficits, both on laboratory tasks and in real life, manifested by lack of judgment and reduced concern for the consequences of their actions. What remains unknown, however, is whether these decision-making deficits are equally represented across addictions to different classes of drugs. Current theories consider addiction to different classes of drugs as a unitary phenomenon, in part based on evidence that most drugs of abuse act on the mesocortico/mesolimbic dopamine (DA) system ( Wise, 1978; Di Chiara and Imperato, 1988; Robinson and Berridge, 1993 )",
    "chunk_id": "decision-making_in_stimulant_and_opiate_addicts_in_protracted_abstinence_evidence_from_computational_modeling_with_pure_users.json_chunk_2"
  },
  {
    "document_type": "research_paper",
    "title": "Decision-making in stimulant and opiate addicts in protracted abstinence: evidence from computational modeling with pure users",
    "author": "Jasmin Vassileva",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Ahn-2014-Decision-making-in-stimulant-and-op.pdf",
    "date_published": "2014-08-08",
    "keywords": "addiction, decision-making, computational modeling, heroin, amphetamine, protracted abstinence, Bayesian data analysis, Widely Applicable Information Criterion (WAIC)",
    "flag": "",
    "chunk_text": ". More recently, however, anmal and human studies have begun to reveal important cognitive and neurobiological differences between addictions to different classes of drugs, such as stimulants and opiates ( Pettit et al., 1984; Rogers et al., 1999; Ersche et al., 2005b; Badiani et al., 2011 ). It is now well known that these two classes of drugs act on diffeent mechanisms of DA modulation ( Kreek et al., 2002, 2012 ). DA transmission mediates self-administration of stimulants, but not of opiates; in contrast, the μ -opiate receptor plays an important role for opiate, but not for stimulant self-administration ( Badiani et al., 2011 ). Further, genetic studies reveal minimal overlap of genes associated with stimulant and opiate addiction ( Yuferov et al., 2010 ). Preclinical studies reveal notable differences between stimlants and opiates, which exert fundamentally different behavioral effects, such that stimulants produce arousing and activating effects, whereas opiates produce mixed inhibitory and excitatory effects ( Stewart et al., 1984 ). Of note, the rewarding effects of stimulant self-administrations are greater in new and arousing environments than in familiar and safe environments, whereas the opposite is observed with the sedative effects of opiates ( Caprioli et al., 2008 ). Further, the neural pathway activated by aversive stimuli from lateral habenula to rostromedial tegmetal nucleus (RMTg) is affected by opiates, but not by stimulants ( Lecca et al., 2011 ). In contrast, studies comparing neurocognitive performance of human stimulant and opiate users have shown mixed results. Some studies reveal distinct performance patterns in stimulant vs. opiate users. Rogers et al. (1999) report that amphetamine users perform worse than healthy individuals on the Cambridge Gambling Task, whereas opiate users display intact performance on this decision task. In addition, duration of drug abuse was associated with suboptimal decision-making in stimulant users, but not in opiate users",
    "chunk_id": "decision-making_in_stimulant_and_opiate_addicts_in_protracted_abstinence_evidence_from_computational_modeling_with_pure_users.json_chunk_3"
  },
  {
    "document_type": "research_paper",
    "title": "Decision-making in stimulant and opiate addicts in protracted abstinence: evidence from computational modeling with pure users",
    "author": "Jasmin Vassileva",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Ahn-2014-Decision-making-in-stimulant-and-op.pdf",
    "date_published": "2014-08-08",
    "keywords": "addiction, decision-making, computational modeling, heroin, amphetamine, protracted abstinence, Bayesian data analysis, Widely Applicable Information Criterion (WAIC)",
    "flag": "",
    "chunk_text": ". In addition, duration of drug abuse was associated with suboptimal decision-making in stimulant users, but not in opiate users. In another study ( Ornstein et al., 2000 ), amphetamine and heroin abusers were characterized by diffeent attentional shifting deficits, with amphetamine users being impaired on the extra-dimensional (ED) and heroin users on the intra-dimensional (ID) shift component of the task. Also, cocaine users, but not heroin users show deficits in response inhibition ( Verdejo-Garcia et al., 2007b ). In contrast, other stuies reveal comparable neurocognitive profiles between users of these two classes of drugs. Both cocaine and heroin users show higher discounting of delayed rewards compared to alcohol users and healthy individuals ( Kirby and Petry, 2004 ). Further, on a task measuring reflection impulsivity, both amphetaminand opiate-dependent individuals sample less information and peform worse than healthy individuals ( Clark et al., 2006 ). Decision-making is one of the neurocognitive domains on which SDI are commonly impaired. It is typically indexed in the laboratory with tasks that simulate real-life decision-making such as the Iowa Gambling Task (IGT) ( Bechara et al., 1994 ), on which SDI often select choices that yield high immediate gains but have higher future losses ( Grant et al., 2000; Bechara et al., 2001; Bolla et al., 2003; Bechara and Martin, 2004; Gonzalez et al., 2007; Vassileva et al., 2007a; Verdejo-Garcia et al., 2007a ). Decisiomaking deficits among SDI are of immediate practical concern, in light of their associations with HIV risk behaviors ( Gonzalez et al., 2005 ) and clinical outcomes such as abstinence ( Passetti et al., 2008 ). The IGT is a complex task and poor behavioral performance could be the result of deficits in various distinct nerocognitive processes, such as hypersensitivity to reward and/or hyposensitivity to losses, failure to learn from past outcomes and losses, and/or erratic and impulsive response style. In a series of studies, Busemeyer et al",
    "chunk_id": "decision-making_in_stimulant_and_opiate_addicts_in_protracted_abstinence_evidence_from_computational_modeling_with_pure_users.json_chunk_4"
  },
  {
    "document_type": "research_paper",
    "title": "Decision-making in stimulant and opiate addicts in protracted abstinence: evidence from computational modeling with pure users",
    "author": "Jasmin Vassileva",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Ahn-2014-Decision-making-in-stimulant-and-op.pdf",
    "date_published": "2014-08-08",
    "keywords": "addiction, decision-making, computational modeling, heroin, amphetamine, protracted abstinence, Bayesian data analysis, Widely Applicable Information Criterion (WAIC)",
    "flag": "",
    "chunk_text": ". In a series of studies, Busemeyer et al. ( Busemeyer and Stout, 2002; Stout et al., 2004; Yechiam et al., 2005; Ahn et al., 2008 ) have deveoped mathematical models of the task that capture the complex interplay of cognitive and motivational processes involved in decision-making. The use of such models allows one to decopose behavioral performance on the task into distinct cogntive, motivational, and response processes, thereby providing a fine-grained analysis of the underlying decision-making processes and characterizing more precisely the decision-making deficits of different clinical groups. This approach yields quantifiable parameter estimates of such processes, which have been succesfully mapped in various clinical populations including cocaine users, cannabis users, alcohol users, individuals with Asperger’s disease, Huntington’s disease, schizophrenia, and bipolar disorder (for a review, see Yechiam et al., 2005 ), as well as in eating disoders ( Chan et al., 2014 ) and patients with HIV ( Vassileva et al., 2013 ). Studies applying this approach show that although behaioral performance may be similar across different clinical groups, the cognitive processes that underlie these behavioral profiles may vary across groups in clinically meaningful ways. The widespread polysubstance-dependence among SDI signiicantly complicates attempts to dissociate pre-existing biological or personality characteristics from the effects of chronic use of diferent classes of drugs on neurocognitive functioning ( FernándeSerrano et al., 2011; Gorodetzky et al., 2011; Baldacchino et al., 2012 ). Further, we still know very little about the reversibility of the observed neurocognitive deficits with abstinence, given that with few exceptions ( Ersche et al., 2005a,b; Clark et al., 2006 ) most studies to date have focused on current drug users or on SDI who have been abstinent for rather brief periods of time",
    "chunk_id": "decision-making_in_stimulant_and_opiate_addicts_in_protracted_abstinence_evidence_from_computational_modeling_with_pure_users.json_chunk_5"
  },
  {
    "document_type": "research_paper",
    "title": "Decision-making in stimulant and opiate addicts in protracted abstinence: evidence from computational modeling with pure users",
    "author": "Jasmin Vassileva",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Ahn-2014-Decision-making-in-stimulant-and-op.pdf",
    "date_published": "2014-08-08",
    "keywords": "addiction, decision-making, computational modeling, heroin, amphetamine, protracted abstinence, Bayesian data analysis, Widely Applicable Information Criterion (WAIC)",
    "flag": "",
    "chunk_text": ". The chronic relapsing nature of addiction suggests that some of the neurocognitive deficits, particularly those in decision-making, may persist with abstinence and may be critically implicated in increased susceptibility to relapse. In order to better understand the brain’s recovery of function with protracted abstinence and to refine treatment interventions at different stages of the addiction cycle, it is crucial to get a better understanding of the specificity and the persistence of the neurocognitive deficits observed in drug users. To address these challenges, we conducted the current study in Bulgaria, where polysubstance dependence is still relatively uncommon and where we have access to a unique population of fairly “pure” (monosubstance-dependent) amphetamine and heroin users who meet lifetime DSM-IV criteria for amphetamine or heroin dependence. The heroin epidemic in Bulgaria started in the early 1990s after the end of communism, when Bulgaria became a key transit country for heroin trafficking due to its strategic geographical position on the “Balkan Drug Route,” one of the main routes for international drug traffic from SoutWest Asia to Western Europe. Estimates show that at times up to 80% of heroin used in Western Europe passes through this route ( European Monitoring Center for Drugs and Drug Addiction, 2011 ). The heroin epidemic reached its peak in 1997– 1998, after which it plateaued. In the early 2000s, there were an estimated 20–30,000 regular heroin addicts in Bulgaria (poulation of ∼ 7,476,000 people), which number has remained steady over the last decade, with a recent trend for a slight decline. Typically, heroin addicts belong to a cohort of somewhat aging addicts, ∼ 30 years of age",
    "chunk_id": "decision-making_in_stimulant_and_opiate_addicts_in_protracted_abstinence_evidence_from_computational_modeling_with_pure_users.json_chunk_6"
  },
  {
    "document_type": "research_paper",
    "title": "Decision-making in stimulant and opiate addicts in protracted abstinence: evidence from computational modeling with pure users",
    "author": "Jasmin Vassileva",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Ahn-2014-Decision-making-in-stimulant-and-op.pdf",
    "date_published": "2014-08-08",
    "keywords": "addiction, decision-making, computational modeling, heroin, amphetamine, protracted abstinence, Bayesian data analysis, Widely Applicable Information Criterion (WAIC)",
    "flag": "",
    "chunk_text": ". Typically, heroin addicts belong to a cohort of somewhat aging addicts, ∼ 30 years of age. In contrast, the amphetamine epidemic in Bulgaria started more recently in the new millenium when Bulgaria became a major center for production of synthetic amphetamine-type stimulants and is currently one of the top five highest-prevalence countries in Europe ( European Monitoring Center for Drugs and Drug Addiction, 2011 ). Hence, amphetamine users are typically younger—normally in their late teens or early 20s. Notably, few SDI use the two types of drugs concurrently. We compared the decision-making performance of heroin and amphetamine users to that of healthy controls (HC) without any history of substance dependence. We followed these behaioral analyses by applying a computational modeling approach, in order to better characterize their decision-making styles and to disentangle the distinct neurocognitive processes underlying the decision-making performance of heroin and amphetamine users. The modeling results and their interpretations depend on which model we use. Therefore, we first identified the best-fitting model by comparing three existing computational models using a Bayesian model comparison technique, a simulation method, and parameter recovery tests (see Materials and Methods below for more details). Then, we compared groups in a Bayesian way using the best-fitting model, but also tested whether we would observe similar group differences with the other models. Based on previous animal and human studies, we hypothesized that amphetamine and heroin users would show distinct decisiomaking profiles. Specifically, we expected that amphetamine users would show increased reward sensitivity and heroin users would show reduced loss aversion compared to HC ( Spotts and Shontz, 1980; Stewart et al., 1984; Kreek et al., 2002 )",
    "chunk_id": "decision-making_in_stimulant_and_opiate_addicts_in_protracted_abstinence_evidence_from_computational_modeling_with_pure_users.json_chunk_7"
  },
  {
    "document_type": "research_paper",
    "title": "Decision-making in stimulant and opiate addicts in protracted abstinence: evidence from computational modeling with pure users",
    "author": "Jasmin Vassileva",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Ahn-2014-Decision-making-in-stimulant-and-op.pdf",
    "date_published": "2014-08-08",
    "keywords": "addiction, decision-making, computational modeling, heroin, amphetamine, protracted abstinence, Bayesian data analysis, Widely Applicable Information Criterion (WAIC)",
    "flag": "",
    "chunk_text": ". In light of the growing evidence for the relationship of extenalizing and internalizing personality traits and disorders with decision-making and drug addiction, in exploratory analyses we considered the relationship between impulsivity and psychopathy (externalizing spectrum) and depression and anxiety (internaizing spectrum) with decision-making. We hypothesized that externalizing but not internalizing traits and states would be associated with compromised decision-making. MATERIALS AND METHODS PARTICIPANTS Study participants included 129 individuals, enrolled in a larger study of impulsivity in heroin and amphetamine users in Sofia, Bulgaria. Potential participants were recruited via flyers placed at substance abuse clinics, cafes, bars, and night clubs in Sofia and screened via telephone and in-person on their medical and sustance use histories. SDI had lifetime DSM-IV histories of opiate or stimulant dependence. The current study included primarily monosubstance-dependent users with no history of dependence on alcohol or any drug other than opiates or stimulants (with the exception of nicotine, caffeine, and/or past cannabis depedence). Demographically similar individuals with no history of substance dependence were included as controls. Study particpants included 38 amphetamine users, 43 heroin users, and 48 HC. Most of the heroin and amphetamine users were in prtracted abstinence at the time of testing ( ∼ 2.9 years on average since they last met DSM-IV criteria for substance dependence, minimum 3 months post discontinuation of drug use). Among the 38 amphetamine users, 11 were in early ( < 12 months of abstinence) full ( n = 9; 24%) or partial ( n = 2; 5%) remision and 27 were in sustained ( > 12 months of abstinence) full ( n = 25; 66%) or partial ( n = 2; 5%) remission. Among the 43 heroin users, 12 (28%) were in early full remission, 30 (70%) were in sustained full and one (2%) was in sustained partial remission",
    "chunk_id": "decision-making_in_stimulant_and_opiate_addicts_in_protracted_abstinence_evidence_from_computational_modeling_with_pure_users.json_chunk_8"
  },
  {
    "document_type": "research_paper",
    "title": "Decision-making in stimulant and opiate addicts in protracted abstinence: evidence from computational modeling with pure users",
    "author": "Jasmin Vassileva",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Ahn-2014-Decision-making-in-stimulant-and-op.pdf",
    "date_published": "2014-08-08",
    "keywords": "addiction, decision-making, computational modeling, heroin, amphetamine, protracted abstinence, Bayesian data analysis, Widely Applicable Information Criterion (WAIC)",
    "flag": "",
    "chunk_text": ". Among the 43 heroin users, 12 (28%) were in early full remission, 30 (70%) were in sustained full and one (2%) was in sustained partial remission. Inclusion criteria consisted of age between 18 and 50 years, minimum of 8 years of formal education, ability to speak and read Bulgarian, estimated IQ greater than 80, negative breathalyzer test for alcohol and negative rapid urine toxicology screen for opiates, cannabis, amphetamines, methamphetamines, benzodiazepines, barbiturates, cocaine, MDMA, and methadone. Exclusion criteria included history of neurologic illness or injury, history of pschotic disorders, and current opioid substitution therapy (OST). All participants were HIV-seronegative, as verified by rapid HIV test. All participants provided written informed consent. Study procedures were approved by the Institutional Review Boards of the University of Illinois at Chicago and the Medical University in Sofia on behalf of the Bulgarian Addictions Institute. ASSESSMENT History of substance abuse and dependence was determined using the Structured Clinical Interview for DSM-IV Substance Abuse Module (SCID-SAM; First et al., 1996 ). The Raven’s Progressive Matrices was administered to index estimated IQ. For the exploratory analyses, the Barratt Impulsiveness Scale—11th revision (BIS-11; Patton and Stanford, 1995 ) indexed the pesonality trait of impulsivity. Psychopathy was assessed with the Psychopathy Checklist: Screening Version (PCL:SV; Hart et al., 1995 ). Current depression was assessed with the [Beck Depression Inventory-II (BDI-II); Beck et al., 1996 ] and anxiety with the [State-Trait Anxiety Inventory (STAI); Spielberger and Gorsuch, 1983 ]. For the exploratory analyses, we also tabulated several sustance use characteristics including number of years of drug use, length of abstinence from the primary drug of dependence, nuber of DSM-IV criteria met for the primary drug of dependence, severity of nicotine dependence, and history of past cannabis dependence",
    "chunk_id": "decision-making_in_stimulant_and_opiate_addicts_in_protracted_abstinence_evidence_from_computational_modeling_with_pure_users.json_chunk_9"
  },
  {
    "document_type": "research_paper",
    "title": "Decision-making in stimulant and opiate addicts in protracted abstinence: evidence from computational modeling with pure users",
    "author": "Jasmin Vassileva",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Ahn-2014-Decision-making-in-stimulant-and-op.pdf",
    "date_published": "2014-08-08",
    "keywords": "addiction, decision-making, computational modeling, heroin, amphetamine, protracted abstinence, Bayesian data analysis, Widely Applicable Information Criterion (WAIC)",
    "flag": "",
    "chunk_text": ". IOWA GAMBLING TASK Decision-making was measured with the computerized IGT ( Bechara et al., 1994, 2001 ), arguably the most popular decision task in the addiction literature. The task requires participants to select cards from one of four decks with the goal of maximizing profits. Unbeknownst to participants, two of the decks (decks C and D) are advantageous (“good”) and two (decks A and B) are disadvantageous (“bad”) in terms of their long-term payoffs. The frequencies of punishment also vary across decks such that punishment is more frequent in decks A and C (50%) than in decks B and D (10%). In the modified version of the IGT ( Bechara et al., 2001 ) used in the current study, each deck has up to 60 cards and the amounts of net gains or losses increased incrementally in every block of 10 cards. For example, the net loss of decks A and B in the first block of 10 cards is -$250, but across every block it goes up with $150 until it reaches $1000 in the sixth block. Similarly, the net gain of decks C and D goes up from $250 in the first block to $375 in the sixth block, with an increment of $25 in each block of 10 cards. The frequencies of punishment are identical to those in the original IGT version. Participants have to learn the task contingencies by trial-anerror. Healthy participants typically learn to select cards from the advantageous decks as the task progresses, thereby achieving a higher cumulative reward value. Behavioral performance analyses were based on the total net score, calculated by subtracting the number of disadvantageous deck selections from the number of advantageous deck selections. Trial-by-trial choice data of the HC, amphetamine, and heroin groups are available at http:// figshare.com/articles/IGT_raw_data_Ahn_et_al_2014_Frontiers_ in_Psychology/1101324",
    "chunk_id": "decision-making_in_stimulant_and_opiate_addicts_in_protracted_abstinence_evidence_from_computational_modeling_with_pure_users.json_chunk_10"
  },
  {
    "document_type": "research_paper",
    "title": "Decision-making in stimulant and opiate addicts in protracted abstinence: evidence from computational modeling with pure users",
    "author": "Jasmin Vassileva",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Ahn-2014-Decision-making-in-stimulant-and-op.pdf",
    "date_published": "2014-08-08",
    "keywords": "addiction, decision-making, computational modeling, heroin, amphetamine, protracted abstinence, Bayesian data analysis, Widely Applicable Information Criterion (WAIC)",
    "flag": "",
    "chunk_text": ". Trial-by-trial choice data of the HC, amphetamine, and heroin groups are available at http:// figshare.com/articles/IGT_raw_data_Ahn_et_al_2014_Frontiers_ in_Psychology/1101324. COMPUTATIONAL MODELING OF DECISION-MAKING From a statistical perspective, the IGT is a four-armed badit problem ( Berry and Fristedt, 1985 ), a special case of reiforcement learning (RL) problems in which an agent needs to learn an environment by choosing actions and experiening the outcomes of those actions. Poor performance on the IGT can be due to a number of distinct underlying neuroconitive processes such as poor learning/memory, hypersensitivity to reward, hyposensitivity to loss, or response inconsistency. In order to better characterize behavioral performance on the IGT and to disentangle the distinct neurocognitive processes undelying the performance of pure heroin and amphetamine users on the task, we next used the computational modeling approach ( Busemeyer and Stout, 2002; Yechiam et al., 2005; Ahn et al., 2008 ). We compared three of the most promising models of the IGT according to the literature (e.g., Ahn et al., 2008, 2011; Steingroever et al., 2013, 2014; Worthy et al., 2013b ): the Prospect Valence Learning (PVL) model with delta learning rule (PVDelta) ( Ahn et al., 2008 ), the PVL model with decay reinforcment learning rule (PVL-DecayRI) ( Ahn et al., 2008, 2011 ), and the Value-Plus-Perseverance model (VPP) ( Worthy et al., 2013b ). We used Watanabe-Akaike Information Criterion (also called Widely Applicable Information Criterion; WAIC) ( Watanabe, 2010 ) to compare the post-hoc fits of models. We also used a simulation method to examine whether a model with estimated parameters can generate the observed choice pattern ( Ahn et al., 2008; Steingroever et al., 2014 ). We describe the mathematical details of all models, which are also available in the previous pulication ( Worthy et al., 2013b ) as well as WAIC and the simulation method below",
    "chunk_id": "decision-making_in_stimulant_and_opiate_addicts_in_protracted_abstinence_evidence_from_computational_modeling_with_pure_users.json_chunk_11"
  },
  {
    "document_type": "research_paper",
    "title": "Decision-making in stimulant and opiate addicts in protracted abstinence: evidence from computational modeling with pure users",
    "author": "Jasmin Vassileva",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Ahn-2014-Decision-making-in-stimulant-and-op.pdf",
    "date_published": "2014-08-08",
    "keywords": "addiction, decision-making, computational modeling, heroin, amphetamine, protracted abstinence, Bayesian data analysis, Widely Applicable Information Criterion (WAIC)",
    "flag": "",
    "chunk_text": ". We describe the mathematical details of all models, which are also available in the previous pulication ( Worthy et al., 2013b ) as well as WAIC and the simulation method below. Prospect valence learning (PVL) models (PVL-Delta and PVL-DecayRI) The PVL models have three components. The PVL-Delta and PVL-DecayRI models are identical except that they use different learning rules. First, the outcome evaluation follows the Prospect utility function that has diminishing sensitivity to increases in magnitude and different outcome sensitivity to losses vs. gains (i.e., loss aversion). The utility, u(t) on trial t of each net outcome x(t) is expressed as: u ( t ) = x ( t ) α if x ( t ) ≥ 0 − λ | x ( t ) | α if x ( t ) < 0 (1) Here α (shape parameter, 0 < α < 2) governs the shape of the utility function and λ (loss aversion parameter, 0 < λ < 10) determines the sensitivity to losses compared to gains. Net outcomes were scaled (all payoff outcomes were divided by a fixed number) for cognitive modeling so that the median highest net gain across subjects in the first block of 10 trials becomes 1 and the largest net loss becomes − 11.5 ( Busemeyer and Stout, 2002 ). If an individual has a high value of α , it indicates that he/she has greater sensitivity to feedback outcomes than an individual with a low value of α . Here, we extended the upper bound of α to be greater than 1 as some individuals may have very high values of α (e.g., Fridberg et al., 2010 ). A value of λ less than 1 indicates that the individual is more sensitive to gains than to losses while a value of λ greater than 1 indicates that he/she is more sensitive to losses than to gains. Based on the outcome of the chosen option, the expectacies of the decks were computed using a learning rule",
    "chunk_id": "decision-making_in_stimulant_and_opiate_addicts_in_protracted_abstinence_evidence_from_computational_modeling_with_pure_users.json_chunk_12"
  },
  {
    "document_type": "research_paper",
    "title": "Decision-making in stimulant and opiate addicts in protracted abstinence: evidence from computational modeling with pure users",
    "author": "Jasmin Vassileva",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Ahn-2014-Decision-making-in-stimulant-and-op.pdf",
    "date_published": "2014-08-08",
    "keywords": "addiction, decision-making, computational modeling, heroin, amphetamine, protracted abstinence, Bayesian data analysis, Widely Applicable Information Criterion (WAIC)",
    "flag": "",
    "chunk_text": ". Based on the outcome of the chosen option, the expectacies of the decks were computed using a learning rule. Previous studies consistently show that the decay-reinforcement learning (decayRI; Erev and Roth, 1998 ) has better post-hoc model-fits than the delta (Rescorla-Wagner; Rescorla and Wagner, 1972 ) rule on the IGT ( Yechiam and Busemeyer, 2005, 2008; Ahn et al., 2008 ) but the delta rule outperforms the decayRI learning rule in simulation tests ( Ahn et al., 2008; Steingroever et al., 2014 ). In the decayRI learning rule, the expectancies of all decks are dicounted on each trial and then the expectancy of the chosen deck is updated by the current outcome utility: E j ( t + 1) = A · E j ( t ) + δ j ( t ) · u ( t ) (2) A ( recency parameter/learning rate , 0 < A < 1) determines how much the past expectancy is discounted. δ j ( t ) is a dummy varable which is 1 if deck j is chosen and 0 otherwise. On the other hand, in the delta rule, the expectancy of only the selected deck is updated and the expectancies of the other decks remain unchanged: E j ( t + 1) = E j ( t ) + A · δ j ( t ) · ( u ( t ) − E j ( t )) (3) A determines how much weight is placed on past experiences of the chosen deck vs. the most recent selection from the deck. A low learning rate indicates that the most recent outcome has a small influence on the expectancy and forgetting is more gradual. A high learning rate indicates that the recent outcome has a large influence on the expectancy of the chosen deck and forgetting is more rapid. Note that we used the same symbol ( A ) for the learing models in the two PVL models, but A has different meaning in each learning model (i.e., recency for the DecayRI and learning rate for the Delta model). The softmax choice rule ( Luce, 1959 ) was then used to copute the probability of choosing each deck j. θ (sensitivity) governs the degree of exploitation vs",
    "chunk_id": "decision-making_in_stimulant_and_opiate_addicts_in_protracted_abstinence_evidence_from_computational_modeling_with_pure_users.json_chunk_13"
  },
  {
    "document_type": "research_paper",
    "title": "Decision-making in stimulant and opiate addicts in protracted abstinence: evidence from computational modeling with pure users",
    "author": "Jasmin Vassileva",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Ahn-2014-Decision-making-in-stimulant-and-op.pdf",
    "date_published": "2014-08-08",
    "keywords": "addiction, decision-making, computational modeling, heroin, amphetamine, protracted abstinence, Bayesian data analysis, Widely Applicable Information Criterion (WAIC)",
    "flag": "",
    "chunk_text": ". The softmax choice rule ( Luce, 1959 ) was then used to copute the probability of choosing each deck j. θ (sensitivity) governs the degree of exploitation vs. exploration: Pr [ D ( t + 1) = j ] = e θ · E j ( t + 1) 4 k = 1 e θ · E k ( t + 1) (4) θ is assumed to be trial-independent and was set to 3 c − 1 ( Yechiam and Ert, 2007; Ahn et al., 2008 ). c is a consistency paraeter (choice sensitivity), which was limited from 0 to 5 so that the sensitivity ranges from 0 (random) to 242 (almost deterministic). Value-plus-perseverance model Recent work suggests that participants often use a simple wistay-lose-switch (WSLS) or perseverative strategy on the IGT, which cares only about the very last trial’s information for maing a decision on the current trial ( Worthy et al., 2013a ). Worthy et al. (2013a) compared the PVL-DecayRI and the WSLS moels of the IGT using model-comparison methods. They showed that the PVL-DecayRI had the best model fits for about half of the subjects, whereas the WSLS model was the best-fitting model for the other half. Based on these findings, Worthy et al. (2013b) developed a VPP model, which is a hybrid model (e.g., Daw et al., 2011 ) of the PVL-Delta and a heuristic strategy of perseverance. Worthy et al. (2013b) showed that the VPP model showed the best post-hoc model-fits and simulation performance compared to other models for the IGT in healthy individuals. The VPP model assumes that a participant keeps track of deck expectancies E j ( t ) and perseverance strengths ( P j ( t )). The expectancies are computed by the learning rule of the PVL-Delta model (Equation 3). For the perseverance strengths of unchosen decks on the current trial t , P j ( t + 1) = k · P j ( t ). For the chosen deck: P j ( t + 1) = k · P j ( t ) + ε p if x ( t ) ≥ 0 k · P j ( t ) + ε n if x ( t ) < 0",
    "chunk_id": "decision-making_in_stimulant_and_opiate_addicts_in_protracted_abstinence_evidence_from_computational_modeling_with_pure_users.json_chunk_14"
  },
  {
    "document_type": "research_paper",
    "title": "Decision-making in stimulant and opiate addicts in protracted abstinence: evidence from computational modeling with pure users",
    "author": "Jasmin Vassileva",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Ahn-2014-Decision-making-in-stimulant-and-op.pdf",
    "date_published": "2014-08-08",
    "keywords": "addiction, decision-making, computational modeling, heroin, amphetamine, protracted abstinence, Bayesian data analysis, Widely Applicable Information Criterion (WAIC)",
    "flag": "",
    "chunk_text": ". For the chosen deck: P j ( t + 1) = k · P j ( t ) + ε p if x ( t ) ≥ 0 k · P j ( t ) + ε n if x ( t ) < 0 . (5) Here, three additional free parameters related to perseverance are introduced: k (0 < k < 1) is a decay parameter similar to A in the PVL-DecayRI model, which determines how much the peseverance strengths of all decks (including unselected decks) are decayed on each trial. ε p and ε n indicate the impact of gain and loss on perseverance behavior, respectively. A positive value would indicate that the feedback reinforces a tendency to persevere on the same deck on the next trial whereas a negative value would indicate that the feedback reinforces a tendency to switch from the chosen deck. The overall value, V j ( t + 1), is the weighted sum of E j ( t + 1) and P j ( t + 1): V j ( t + 1) = ω · E j ( t + 1) + (1 − ω ) · P j ( t + 1) (6) Here ω is the RL weight (0 < ω < 1). A low value of ω would indicate that the subject would rely less on RL but more on the perseverance heuristic. A high value of ω would indicate that the subject would rely more on RL and less on the perseverance heuristic. In the VPP model, the choice probability was again using the softmax rule but with V j ( t + 1): Pr [ D ( t + 1) = j ] = e θ · V j ( t + 1) 4 k = 1 e θ · V k ( t + 1) . (7) STATISTICAL ANALYSES All data analyses were conducted using Bayesian data analysis, which has several advantages over null hypothesis significance testing (NHST) ( Wagenmakers, 2007; Kruschke, 2010, 2011b, 2013 ): In Bayesian analysis, decisions are based on posterior proabilities of parameters (which could be model indices), not on frequentist p values. Unlike posterior distributions, frequentist p values depend on the sampling and testing intentions of the analyst. Bayesian methods also seamlessly provide posterior ditributions for the type of complex hierarchical models we use here, more flexibly than deriving p values",
    "chunk_id": "decision-making_in_stimulant_and_opiate_addicts_in_protracted_abstinence_evidence_from_computational_modeling_with_pure_users.json_chunk_15"
  },
  {
    "document_type": "research_paper",
    "title": "Decision-making in stimulant and opiate addicts in protracted abstinence: evidence from computational modeling with pure users",
    "author": "Jasmin Vassileva",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Ahn-2014-Decision-making-in-stimulant-and-op.pdf",
    "date_published": "2014-08-08",
    "keywords": "addiction, decision-making, computational modeling, heroin, amphetamine, protracted abstinence, Bayesian data analysis, Widely Applicable Information Criterion (WAIC)",
    "flag": "",
    "chunk_text": ". Bayesian methods also seamlessly provide posterior ditributions for the type of complex hierarchical models we use here, more flexibly than deriving p values. For clarity and to accommodate readers more familiar with NHST, we report in parallel NHST results whenever appropriate and when there are compatible NHST approaches available. We used the posterior means of individual parameters for NHST and regression anayses. For Bayesian multiple regression and correlation analyses, we used robust regression methods so that outliers don’t critically affect the inferred regression coefficients and hierarchical models, which reduces the risk of “false alarms.” Posterior distributions on parameters are summarized by their central tendency (i.e., mean or mode) and by their highest density interval (HDI), which is the range of parameter values that span 95% of the distribution and have higher probability inside the interval than outside. The HDI can also be used to make decisions in conjunction with a region of practical equivalence (ROPE) around parameter values of interest such as zero ( Kruschke, 2011a,b ). If the ROPE excludes the HDI, then the ROPE’d value is said to be not credible. If the ROPE includes the HDI, then the ROPE’d value is said to be accepted for practical purposes. We leave the ROPE tacit in our analyses, as its exact size is not criical for our main conclusions. However, when the HDI excludes the value of interest (such as zero) but has a end not far from the value of interest, then a moderately large ROPE would overlap with the HDI and render the result indecisive. Hierarchical Bayesian parameter estimation The free parameters of each model were estimated using hierachical Bayesian analysis (HBA), an emerging method in cognitive science ( Lee, 2011 ). HBA allows for individual differences, while pooling information across individuals in a coherent way",
    "chunk_id": "decision-making_in_stimulant_and_opiate_addicts_in_protracted_abstinence_evidence_from_computational_modeling_with_pure_users.json_chunk_16"
  },
  {
    "document_type": "research_paper",
    "title": "Decision-making in stimulant and opiate addicts in protracted abstinence: evidence from computational modeling with pure users",
    "author": "Jasmin Vassileva",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Ahn-2014-Decision-making-in-stimulant-and-op.pdf",
    "date_published": "2014-08-08",
    "keywords": "addiction, decision-making, computational modeling, heroin, amphetamine, protracted abstinence, Bayesian data analysis, Widely Applicable Information Criterion (WAIC)",
    "flag": "",
    "chunk_text": ". HBA allows for individual differences, while pooling information across individuals in a coherent way. Unlike the conventional way of parameter estimation (maximum likelhood estimation; MLE), Bayesian methods estimate full posterior distributions of parameter values rather than only point estmates. In addition, commonalities across individuals are captured by letting group tendencies inform each individual’s parameter values. A recent simulation study also revealed that HBA yields much more accurate parameter estimates of the PVL-DecayRI model than non-hierarchical MLE methods. Specifically, a siulation study by Ahn et al. (2011) showed that non-hierarchical MLE estimates were often at the parameters’ boundary liits (e.g., learning rate = 1) whereas parameter estimates with HBA showed much less discrepancy with actual parameter vaues. These results suggest that HBA would be a better method to capture individual differences in model parameters. To perform HBA, we used a recently developed package called Stan 2.1.0 ( Stan Development Team, 2014 ), which uses Markov chain Monte Carlo (MCMC) sampling algorithms called Hamiltonian Monte Carlo (HMC). The HMC allows efficient sampling even for complex models with multilevel structures and those with highly correlated parameters. Individual parameters were assumed to be drawn from group-level normal distributions. Normal and uniform distributions were used for the priors of normal means ( μ ( . ) ) and standard deviations ( σ ( . ) ), respectively ( Wetzels et al., 2010; Steingroever et al., 2013 ). For parameters (say ζ for a general parameter for illustration purposes) that are bounded between 0 and 1 (e.g., A , k , ω ): μ ξ ′ ∼ Normal (0 , 1) , σ ξ ′ ∼ Uniform (0 , 1 . 5) , ξ ′ ∼ Normal ( μ ξ ′ , σ ξ ′ ) , ξ = Probit ( ξ ′ ) (8) While Worthy et al. (2013b) set the boundary limits of ε p and ε n at [ − 1, 1], we set no bound constraints on ε p and ε n . We believe such boundary limits are useful for practical purposes in MLE but not in HBA methods",
    "chunk_id": "decision-making_in_stimulant_and_opiate_addicts_in_protracted_abstinence_evidence_from_computational_modeling_with_pure_users.json_chunk_17"
  },
  {
    "document_type": "research_paper",
    "title": "Decision-making in stimulant and opiate addicts in protracted abstinence: evidence from computational modeling with pure users",
    "author": "Jasmin Vassileva",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Ahn-2014-Decision-making-in-stimulant-and-op.pdf",
    "date_published": "2014-08-08",
    "keywords": "addiction, decision-making, computational modeling, heroin, amphetamine, protracted abstinence, Bayesian data analysis, Widely Applicable Information Criterion (WAIC)",
    "flag": "",
    "chunk_text": ". We believe such boundary limits are useful for practical purposes in MLE but not in HBA methods. For those parameters with no bound constraints: ξ ∼ Normal ( μ ξ , σ ξ ) , μ ξ ∼ Normal (0 , 5) , σ ξ ∼ Uniform (0 , 1 . 5) (9) For parameters that are constrained to be greater than zero but with an upper limit ( = U ) (e.g., U = 2 for α , U = 10 for λ , U = 5 for c ), we used the following transformations to allow a flat prior distribution over a full range: μ ξ ′ ∼ Normal (0 , 1) , σ ξ ′ ∼ Uniform (0 , 1 . 5) , ξ ′ ∼ Normal ( μ ξ ′ , σ ξ ′ ) , ξ = U · Probit ( ξ ′ ) (10) We also reparameterized parameters (i.e., parameters are sampled as independent unit normals and then transformed accordingly for each parameter), which can be effective for coplex hierarchical models, as suggested by Stan developers (see Chapter 19 “Optimizing Stan Code” of the Stan 2.1.0 Manual; https://github.com/stan-dev/stan/releases/download/v2.1.0/stareference-2.1.0.pdf). A total of 2000 samples were drawn after 1000 burn-in saples for each of 3 chains ( = 2000 samples × 3 chains = a total of 6000 samples). We estimated individual and group parameters separately for each population (HC, amphetamine, and heroin groups). For each parameter, the Gelman-Rubin test ( Gelman and Rubin, 1992 ) was used to check the convergence of the chains (a.k.a. ˆ R statistic). ˆ R values close to 1.00 would indicate that MCMC chains are converged to the target distributions. In our data, all model parameters of all models had ˆ R values of 1.00. MCMC chains were also visually inspected, which confirmed excellent mixing of MCMC samples. Effective sample sizes (ESS) of model parameters, which are related to autocorrelation and mixing of MCMC chains (i.e., a smaller ESS is related to higher autocorrelation), were typically greater than 1000 (out of 6000 total samples). The minimum ESS of hyper-parameters was 561 in the two PVL models, and 372 in the VPP model",
    "chunk_id": "decision-making_in_stimulant_and_opiate_addicts_in_protracted_abstinence_evidence_from_computational_modeling_with_pure_users.json_chunk_18"
  },
  {
    "document_type": "research_paper",
    "title": "Decision-making in stimulant and opiate addicts in protracted abstinence: evidence from computational modeling with pure users",
    "author": "Jasmin Vassileva",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Ahn-2014-Decision-making-in-stimulant-and-op.pdf",
    "date_published": "2014-08-08",
    "keywords": "addiction, decision-making, computational modeling, heroin, amphetamine, protracted abstinence, Bayesian data analysis, Widely Applicable Information Criterion (WAIC)",
    "flag": "",
    "chunk_text": ". The minimum ESS of hyper-parameters was 561 in the two PVL models, and 372 in the VPP model. Visual inspection of the parameters with smaller ESSs confirmed their convergence to target distributions. Model comparisons using WAIC WAIC is a way to estimate a model’s predictive accuracy with bias correction from over-fitting like Akaike Information Criterion (AIC; Akaike et al., 1973 ) and Deviance Information Criterion (DIC; Spiegelhalter et al., 2002 ). As a measure of predictive accracy, the log predictive density or log-likelihood, log p ( y | θ ), is commonly used where y and θ indicate data and model paramters, respectively. WAIC is “a more fully Bayesian approach” that uses log pointwise posterior predictive density ( lppd ) and a corection (or penalty) term, each of which can be computed from MCMC samples made available from (hierarchical) Bayesian parameter estimation (for reviews and more details, see Gelman et al., 2013a,b ). Computed lppd (for each participant i ; subscript i is omitted for convenience) is defined as: T t = 1 log 1 S S s = 1 p y t | θ s (11) Here θ s are posterior MCMC samples ( s = 1 , 2 , , S) and T is the number of trials (data points). Note that the likelihood doinates the posterior under standard conditions where a posterior distribution approaches a normal distribution ( Degroot, 1970; Gelman et al., 2013a,b ). There is a correction term that adjusts for the effective number of parameters and overfitting. There are two types of adjustments ( p WAIC 1 and p WAIC 2 ) ( Gelman et al., 2013a,b ). Gelman et al. (2013a,b) recommended p WAIC 2 because of its closer relationship with leave-one-out cross validation than p WAIC 1 . We report results using p WAIC 2 but both adjustments yielded very similar values. Computed p WAIC 2 (for each participant i , subscript i is omitted for convenience here) is defined as: T t = 1 V S s = 1 log p y t | θ s (12) where V S s = 1 indicates the sample variance (i.e., the variance of log p ( y t | θ s ) over S samples)",
    "chunk_id": "decision-making_in_stimulant_and_opiate_addicts_in_protracted_abstinence_evidence_from_computational_modeling_with_pure_users.json_chunk_19"
  },
  {
    "document_type": "research_paper",
    "title": "Decision-making in stimulant and opiate addicts in protracted abstinence: evidence from computational modeling with pure users",
    "author": "Jasmin Vassileva",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Ahn-2014-Decision-making-in-stimulant-and-op.pdf",
    "date_published": "2014-08-08",
    "keywords": "addiction, decision-making, computational modeling, heroin, amphetamine, protracted abstinence, Bayesian data analysis, Widely Applicable Information Criterion (WAIC)",
    "flag": "",
    "chunk_text": ". WAIC i for each participant i is defined like the following so that its value is on the deviance scale like AIC, DIC, and BIC ( Schwartz, 1978 ). WAIC i = − 2 ∗ (lppd − p WAIC 2 ) (13) We computed lppd and p WAIC 2 by rewriting the separate liklihood function in R ( R Development Core Team, 2009 ) but it is also possible to implement WAIC in a Stan code directly (Vehtari and Gelman, under review). Specifically; we first radomly sampled 1,000 ( S = 1 , 000 in Equations 11 and 12) posterior samples from each subject’s individual posterior ditributions. We used posterior individual distributions (instead of group distributions) for the calculation because our goal was to replicate new data and evaluate predictive accuracy in exising groups. Then we prepared a matrix of each subject for trial-by-trial predictive density ( p ( y t | θ s ), matrix size = nuber of samples × number of trials = 1000 × 100). Trial-by-trial predictive density was computed for each subject using each posterior sample separately. Then, using Equations (11–13), we computed lppd, p WAIC 2 , and WAIC i for each participant, and then summed WAIC i over all participants for each model ( Table 3 ). The R codes for performing HBA and computing WAIC are available by request to the first author (Woo-Young Ahn; wooyoung.ahn@gmail.com). Simulation method We also used a simulation method to evaluate how accurately a model can generate observed choice pattern in new and unoserved payoff sequences based on parameter values alone ( Ahn et al., 2008; Fridberg et al., 2010; Steingroever et al., 2013, 2014 ). Using the procedure in Appendix B of Ahn et al. (2008) and indvidual posterior means as a subject’s best fitting parameters, we tested the simulation performance of each model. We set the maimum number of trials to 100 and used the payoff schedule of the modified IGT",
    "chunk_id": "decision-making_in_stimulant_and_opiate_addicts_in_protracted_abstinence_evidence_from_computational_modeling_with_pure_users.json_chunk_20"
  },
  {
    "document_type": "research_paper",
    "title": "Decision-making in stimulant and opiate addicts in protracted abstinence: evidence from computational modeling with pure users",
    "author": "Jasmin Vassileva",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Ahn-2014-Decision-making-in-stimulant-and-op.pdf",
    "date_published": "2014-08-08",
    "keywords": "addiction, decision-making, computational modeling, heroin, amphetamine, protracted abstinence, Bayesian data analysis, Widely Applicable Information Criterion (WAIC)",
    "flag": "",
    "chunk_text": ". We set the maimum number of trials to 100 and used the payoff schedule of the modified IGT. We only report the results using individual postrior means but we note that running simulations using random draws from individual posteriors ( Steingroever et al., 2013, 2014 ) yielded very similar results (not reported for brevity). Parameter recovery tests Using parameter recovery tests, we tested the adequacy of each model, specifically how well each model can recover true parameter values that were used to simulate synthetic data ( Ahn et al., 2011; Steingroever et al., 2013 ). We simulated HC paticipants’ performance on the modified IGT assuming that they behaved according to each model. We generated true parameter values based on the individual posterior means of the HC group. Then we simulated synthetic behavioral data based on the paraeters, and then recovered their parameter values using the HBA described in Section Hierarchical Bayesian Parameter Estimation. See Appendix for the details. Hierarchical Bayesian multiple regression analyses For multiple regression analyses, often many candidate predictors are included in the model, which increases the risk of erroneously deciding that a regression coefficient is non-zero. In many cases, regression coefficients are distributed like a t distribution, such that the predicted variable has non-significant correlations with most candidate predictors, but a sizable relationship with only a few predictors. Also, some predictors are substantially correlated with each other, which suggests that estimating regression coeffcients separately for each predictor can possibly be misleading. We assigned a higher-level distribution across the regresion coefficients of the various predictors. Specifically, regresion coefficients came from a t distribution with paramters (mean, scale, and df) estimated from the data. Because of this hierarchical structure, estimated regression coefficients experience shrinkage and are less likely to produce false alarms",
    "chunk_id": "decision-making_in_stimulant_and_opiate_addicts_in_protracted_abstinence_evidence_from_computational_modeling_with_pure_users.json_chunk_21"
  },
  {
    "document_type": "research_paper",
    "title": "Decision-making in stimulant and opiate addicts in protracted abstinence: evidence from computational modeling with pure users",
    "author": "Jasmin Vassileva",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Ahn-2014-Decision-making-in-stimulant-and-op.pdf",
    "date_published": "2014-08-08",
    "keywords": "addiction, decision-making, computational modeling, heroin, amphetamine, protracted abstinence, Bayesian data analysis, Widely Applicable Information Criterion (WAIC)",
    "flag": "",
    "chunk_text": ". Because of this hierarchical structure, estimated regression coefficients experience shrinkage and are less likely to produce false alarms. We used the program “MultiLinRegressHyperJAGS.R” from Kruschke (2011b) , available at http://www.indiana.edu/% 7Ekruschke/DoingBayesianDataAnalysis/Programs/. We used Just Another Gibbs Sampler (JAGS) for MCMC sampling and for posterior inference of regression analyses. For each analysis, a total of 50,000 samples per chain were drawn after 1000 adaptive and 1000 burn-in samples with three chains. For each parameter, the Gelman-Rubin test was run to confirm the convergence of the chains. ˆ R mean values were 1.00 for all parameters. Bayesian estimation for group comparisons For Bayesian estimation for group differences, (e.g., on behaioral performance, Figure 1 ), we used Bayesian estimation FIGURE 1 | Behavioral performance on the IGT (net score of “advantageous”—“disadvantageous” choices) of amphetamine, heroin, and healthy control groups. The 100 trials were divided into five blocks of 20 trials. Shaded regions indicate ± 1 s.e.m. (BEST) codes that are available at: http://www.indiana. edu/ ∼ kruschke/BEST/. The analysis is implemented in JAGS and we used a total of 50,000 samples after 1000 adaptive and 1000 burn-in samples were drawn. ˆ R mean values were 1.00 for all parameters. For more details about BEST, see Kruschke (2013) . RESULTS PARTICIPANTS’ CHARACTERISTICS Table 1 shows demographic and substance use characteristics of participants. The groups differed on age, such that HC indiviuals were younger than heroin users [95% HDI from 3.5 to 6.8, mean of HDI = 5.1; t (89) = 4 . 81, p = 6 . 11E-06] and older than amphetamine users [95% HDI from 0.1 to 3.4, mean of HDI = 1.8; t (84) = 2 . 11, p = 0 . 037], reflecting the timeline of heroin and amphetamine influx in Bulgaria. HC individuals had higher IQ than both amphetamine [95% HDI from 0.4 to 11.1, mean of HDI = 6.0; t (84) = 2 . 28, p = 0",
    "chunk_id": "decision-making_in_stimulant_and_opiate_addicts_in_protracted_abstinence_evidence_from_computational_modeling_with_pure_users.json_chunk_22"
  },
  {
    "document_type": "research_paper",
    "title": "Decision-making in stimulant and opiate addicts in protracted abstinence: evidence from computational modeling with pure users",
    "author": "Jasmin Vassileva",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Ahn-2014-Decision-making-in-stimulant-and-op.pdf",
    "date_published": "2014-08-08",
    "keywords": "addiction, decision-making, computational modeling, heroin, amphetamine, protracted abstinence, Bayesian data analysis, Widely Applicable Information Criterion (WAIC)",
    "flag": "",
    "chunk_text": ". 037], reflecting the timeline of heroin and amphetamine influx in Bulgaria. HC individuals had higher IQ than both amphetamine [95% HDI from 0.4 to 11.1, mean of HDI = 6.0; t (84) = 2 . 28, p = 0 . 025] and heroin users [95% HDI from 2.9 to 12.8, mean of HDI = 7.8; t (89) = 3 . 13, p = 0 . 002], but there was no difference between the two drug-using groups [95% HDI from − 7.8 to 3.6; mean of HDI = − 2 . 0; t (79) = 0 . 66, p = 0 . 510]. As reported in Table 2 , the two drug using groups scored higher on trait impulsivity (BIS-11) [HC vs. Amphetamine: 95% HDI from 5.5 to 14.9, mean of HDI = 10.2; t (83) = 4 . 66, p = 1 . 19E-05; HC vs. Heroin: 95% HDI from 5.6 to 13.7, mean of HDI = 9.7; t (88) = 4 . 87, p = 4 . 90E-06] and psychopathy (PCL:SV) [HC vs. Amphetamine: 95% HDI from 4.0 to 7.7, mean of HDI = 5.8; t (84) = 6 . 49, p = 5 . 72E-09; HC vs. Heroin: 95% HDI from 7.4 to 11.1, mean of HDI = 9.3; t (89) = 10 . 62, Table 1 | Demographic and substance use characteristics of participants. Healthy control (HC) Amphetamine (A) Heroin (H) Sig. f ( N = 48) ( N = 38) ( N = 43) Age a 24 . 7 (4 . 9) 22 . 7 (3 . 7) 29 . 7 (5 . 0) p < 0 . 001 Gender (%male) 79.2 76.3 81.4 p = 0 . 85 IQ b 112 . 5 (11 . 3) 106 . 7 (12 . 5) 104 . 9 (11 . 9) p = 0 . 007 Education (years) c 13 . 8 (2 . 2) 12 . 5 (1 . 7) 13 . 3 (2 . 5) p < 0 . 001 Years of amph./heroin use – 3 . 2 (2 . 3) 7 . 2 (3 . 5) p < 0 . 001 Years of any drug use – 6 . 5 (2 . 7) 10 . 8 (3 . 6) p < 0 . 001 # of amph./heroin DSM-IV dependence criteria met – 4 . 9 (1 . 3) 6 . 1 (1 . 0) p < 0 . 001 Time (years) since last met dependence criteria – 2 . 8 (1 . 6) 2 . 9 (2 . 2) p = 0 . 89 Fagerstrom test of nicotine dependence d 0 . 7 (1 . 6) 3 . 3 (2 . 8) 4 . 7 (2 . 7) p < 0 . 001 Min–Max days since last drug use – 90–2190 152–3285 – Past cannabis dependence (%) e 0 12 (32%) 6 (14%) p < 0 . 001 a H > HC > A (Bayesian and NHST t-tests yielded the same conclusions). b HC > A, H (Bayesian and NHST t-tests yielded same conclusions)",
    "chunk_id": "decision-making_in_stimulant_and_opiate_addicts_in_protracted_abstinence_evidence_from_computational_modeling_with_pure_users.json_chunk_23"
  },
  {
    "document_type": "research_paper",
    "title": "Decision-making in stimulant and opiate addicts in protracted abstinence: evidence from computational modeling with pure users",
    "author": "Jasmin Vassileva",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Ahn-2014-Decision-making-in-stimulant-and-op.pdf",
    "date_published": "2014-08-08",
    "keywords": "addiction, decision-making, computational modeling, heroin, amphetamine, protracted abstinence, Bayesian data analysis, Widely Applicable Information Criterion (WAIC)",
    "flag": "",
    "chunk_text": ". 001 a H > HC > A (Bayesian and NHST t-tests yielded the same conclusions). b HC > A, H (Bayesian and NHST t-tests yielded same conclusions). c HC > A (Bayesian and NHST t-tests yielded same conclusions). d H > A > HC (Bayesian and NHST t-tests yielded same conclusions). e A > H > HC (Bayesian and NHST χ -square tests yielded same conclusions). f Sig. results are based on omnibus NHST ANOVA tests. Table 2 | Personality and psychopathology characteristics of participants. HC A H Group comparisons BIS total 55 . 96 (9 . 1) 66 . 13 (11 . 0) 65 . 70 (9 . 9) HC < A, H BIS attention 14 . 28 (3 . 7) 16 . 32 (4 . 1) 16 . 56 (5 . 3) HC < A, H BIS motor 20 . 40 (3 . 8) 25 . 18 (5 . 2) 23 . 12 (5 . 0) HC < A, H BIS nonplanning 21 . 23 (4 . 3) 24 . 63 (4 . 4) 25 . 70 (3 . 9) HC < A, H PCL:SV 3 . 67 (3 . 2) 9 . 34 (4 . 9) 12 . 19 (4 . 4) HC < A < H BDI-II total 4 . 21 (4 . 1) 6 . 62 (5 . 6) 8 . 26 (6 . 4) HC < A, H State anxiety (STAI-S) 29 . 42 (5 . 9) 33 . 68 (7 . 7) 36 . 12 (10 . 1) HC < A, H Trait anxiety (STAI-T) 34 . 33 (8 . 7) 38 . 58 (9 . 3) 39 . 98 (10 . 1) HC < A, H All group comparison results are based on Bayesian tests. HC, healthy cotrols; A, amphetamine; H, heroin; BIS, Barratt Impulsiveness Scale; PCL:SV, Psychopathy Checklist: Screening Version; BDI-II, Beck Depression Inventory-II; STAI, State Trait Anxiety Inventory. p = 2 . 20E-16] than HC individuals. Comparisons between the two drug using groups revealed that heroin users had higher leels of psychopathy than amphetamine users [HDI from 0.8 to 5.1, mean of HDI = 3.0; t (79) = 2 . 73, p = 0 . 008]. Both amphetamine and heroin users scored higher on depression (BDI-II) [HC vs. Amphetamine: 95% HDI from − 4.4 to − 0.5, mean of HDI = − 2 . 3; t (82) = 2 . 26, p = 0 . 026; HC vs. Heroin: 95% HDI from − 5.8 to − 1.7, mean of HDI = − 3 . 8; t (88) = 3 . 59, p = 5 . 40E-04], state anxiety (STAI-S) [HC vs. Amphetamine: 95% HDI from − 7.7 to − 1.6, mean of HDI = − 4 . 5; t (84) = 2 . 90, p = 4 . 7E-04; HC vs. Heroin: 95% HDI from − 9.7 to − 2.5, mean of HDI = − 6",
    "chunk_id": "decision-making_in_stimulant_and_opiate_addicts_in_protracted_abstinence_evidence_from_computational_modeling_with_pure_users.json_chunk_24"
  },
  {
    "document_type": "research_paper",
    "title": "Decision-making in stimulant and opiate addicts in protracted abstinence: evidence from computational modeling with pure users",
    "author": "Jasmin Vassileva",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Ahn-2014-Decision-making-in-stimulant-and-op.pdf",
    "date_published": "2014-08-08",
    "keywords": "addiction, decision-making, computational modeling, heroin, amphetamine, protracted abstinence, Bayesian data analysis, Widely Applicable Information Criterion (WAIC)",
    "flag": "",
    "chunk_text": ". Amphetamine: 95% HDI from − 7.7 to − 1.6, mean of HDI = − 4 . 5; t (84) = 2 . 90, p = 4 . 7E-04; HC vs. Heroin: 95% HDI from − 9.7 to − 2.5, mean of HDI = − 6 . 4; t (89) = 3 . 90, p = 1 . 80E-04], and trait aniety (STAI-T) [HC vs. Amphetamine: 95% HDI from − 8.5 to − 0.3, mean of HDI = − 4 . 4; t (84) = 2 . 18, p = 0 . 032; HC vs. Heroin: 95% HDI from − 10.0 to − 1.3, mean of HDI = − 5 . 6; t (89) = 2 . 86, p = 0 . 005] than HC individuals. There were no differences between the two drug using groups on these measures. BEHAVIORAL RESULTS Behavioral results revealed that the HC group made more advatageous choices than the heroin group [difference of mean net score (advantageous—disadvantageous choices per five blocks of 20 trials) = 2.77, 95% HDI from 0.7 to 4.8, mean of HDI = 2.8; t (90) = 2 . 80, p < 0 . 010] and marginally than the amphetamine group [difference of mean net score = 1 . 14, 95% HDI from − 0.1 to 2.3, mean of HDI = 1 . 9; with 95.3% of the posterior saples were greater than 0; t (84) = 2 . 02, p = 0 . 047]. There were no behavioral differences between the two drug using groups in terms of net scores (see Figure 1 ). Further, the choice patterns of these two groups were qualitatively different from those of the HC group. As shown in Figures S1–S3 (left), whereas the HC group favored one of the advantageous decks (Deck D) as the task progressed, both amphetamine and heroin users consitently favored the disadvantageous deck B throughout the task. Decks B and D carry low-frequency losses and are usually chsen more often than decks with high-frequency losses such as A and C, yet one is disadvantageous (Deck B) whereas the other one is advantageous (Deck D). Our results demonstrate that past drug users who are currently in protracted abstinence continue to show similar preference for disadvantageous decks as curently dependent drug users ( Bechara et al., 2001; Yechiam et al., 2005 ). MODEL COMPARISONS RESULTS We first checked which model provided the best predictive accracy, as measured by WAIC",
    "chunk_id": "decision-making_in_stimulant_and_opiate_addicts_in_protracted_abstinence_evidence_from_computational_modeling_with_pure_users.json_chunk_25"
  },
  {
    "document_type": "research_paper",
    "title": "Decision-making in stimulant and opiate addicts in protracted abstinence: evidence from computational modeling with pure users",
    "author": "Jasmin Vassileva",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Ahn-2014-Decision-making-in-stimulant-and-op.pdf",
    "date_published": "2014-08-08",
    "keywords": "addiction, decision-making, computational modeling, heroin, amphetamine, protracted abstinence, Bayesian data analysis, Widely Applicable Information Criterion (WAIC)",
    "flag": "",
    "chunk_text": ". MODEL COMPARISONS RESULTS We first checked which model provided the best predictive accracy, as measured by WAIC. Table 3 presents WAIC scores for each model, summarized for each group. Note that the smaller a model’s values of WAIC scores are, the better its model-fits are. As noted in Table 3 , the VPP model provided the best model-fits Table 3 | WAIC scores of each model, computed separately for each group. Model WAIC HC WAIC A WAIC H WAIC Sum VPP 11659.4 9114.7 10168.1 30942.2 PVL-DecayRI 12145.6 9521.0 10752.4 32419.0 PVL-Delta 12448.8 9747.3 11036.4 33232.5 The best-fitting model in each group is underlined. HC, healthy controls; A, amphetamine; H, heroin. relative to the other models in all groups, followed by the PVDecayRI. These results are consistent with previous reports from Worthy et al. (2013b) . The simulation method and parameter recovery tests yielded somewhat different findings (Figures S1–S3). Consistent with previous reports ( Ahn et al., 2008; Fridberg et al., 2010; Steingroever et al., 2013, 2014 ), the PVL-Delta model showed good simulation performance in all three groups, adequately prdicting the rank order of four decks and good parameter recovery (Figure A3). The PVL-DecayRI model also captured the global pattern of deck preference in all groups even if it failed to fully capture the preference reversal of certain decks over trials (e.g., decks A and C in the heroin group, Figure S3). Parameter recoery tests yielded somewhat mixed results (Figure A2): A (decay rate) and c (response consistency) were recovered well, but peformance on α (reward sensitivity) and λ (loss aversion) were not as good as with the PVL-Delta. The VPP model, on the other hand, showed the worst simulation and parameter recovery peformance: the model over-estimated the preference of deck C in the HC and amphetamine groups and failed to predict the prefeence of deck C over deck A in the heroin group. These results are inconsistent with the simulation results of Worthy et al",
    "chunk_id": "decision-making_in_stimulant_and_opiate_addicts_in_protracted_abstinence_evidence_from_computational_modeling_with_pure_users.json_chunk_26"
  },
  {
    "document_type": "research_paper",
    "title": "Decision-making in stimulant and opiate addicts in protracted abstinence: evidence from computational modeling with pure users",
    "author": "Jasmin Vassileva",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Ahn-2014-Decision-making-in-stimulant-and-op.pdf",
    "date_published": "2014-08-08",
    "keywords": "addiction, decision-making, computational modeling, heroin, amphetamine, protracted abstinence, Bayesian data analysis, Widely Applicable Information Criterion (WAIC)",
    "flag": "",
    "chunk_text": ". These results are inconsistent with the simulation results of Worthy et al. (2013b) , in which the VPP model showed the best simulation performance. However, HC participants in Worthy et al. (2013b) continued to prefer the disadvantageous deck (Deck B) throughout the task, unlike our HC participants who preferred the advantageous Deck D. Worthy et al. (2013b) reported simulation performance by averaging choice probabilities across all trials in each deck (Figure 2A in Worthy et al., 2013b ). If we used the same criterion, the VPP model performs quite well for the heroin group, in which deck B is most strongly preferred and preference for decks A and C are similar on average. Another major difference between our study and Worthy et al. (2013b) is the parameters used for the simultion method: Worthy et al. (2013b) used MLE estimates whereas we used HBA estimates, which may lead to somewhat diffeent simulation performance. With respect to parameter recovery (Figure A1) with the VPP model, posterior distributions of seeral parameters were very broad (e.g., ω ) and some parameters were not well estimated (e.g., k ), which might be attributed to its higher number of parameters compared to the two PVL models (8 vs. 4). Next, we used the best-fitting (VPP) model to compare the three groups ( Figure 2 and Table 4 ). Heroin users displayed reduced loss aversion ( λ ) compared to HC [95% HDI from − 1.2 to − 0.2, mean of HDI = − 0 . 7; t (89) = 8 . 33, p = 9 . 024E-13] and amphetamine users [95% HDI from 0.1 to 1.1, mean of HDI = 0 . 6; t (79) = 6 . 82, p = 1 . 63E-09] (see Figure 3 for the 95% HDI of group differences between heroin and HC groups and Figures S4, S5 for the 95% HDI of group differences between amphetamine and other groups). In contrast, our hypothesis that reward senstivity ( α ) would be higher in amphetamine users compared to HC was not supported. The learning rate ( A ) was marginally different between the heroin and the HC groups [95% HDI from − 0.0 to 0.2, mean of HDI = 0.1; t (89) = 4 . 91, p = 4",
    "chunk_id": "decision-making_in_stimulant_and_opiate_addicts_in_protracted_abstinence_evidence_from_computational_modeling_with_pure_users.json_chunk_27"
  },
  {
    "document_type": "research_paper",
    "title": "Decision-making in stimulant and opiate addicts in protracted abstinence: evidence from computational modeling with pure users",
    "author": "Jasmin Vassileva",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Ahn-2014-Decision-making-in-stimulant-and-op.pdf",
    "date_published": "2014-08-08",
    "keywords": "addiction, decision-making, computational modeling, heroin, amphetamine, protracted abstinence, Bayesian data analysis, Widely Applicable Information Criterion (WAIC)",
    "flag": "",
    "chunk_text": ". The learning rate ( A ) was marginally different between the heroin and the HC groups [95% HDI from − 0.0 to 0.2, mean of HDI = 0.1; t (89) = 4 . 91, p = 4 . 08E-06, Figure 3 ]. We further checked whether the group differences we found using the best-fitting (VPP) model are consistent when tested with other models (PVL-DecayRI and PVL-Delta). Tables 5, 6 summarize the mean group parameter estimates of the PVDecayRI (see Figures S6–S8 for the 95% HDI of group diffeences) and PVL-Delta (see Figures S9–S11 for the 95% HDI of group differences), respectively. As seen in Figures 3 , S6, and S9, we consistently found reduced loss aversion in heroin users compared to HC, whichever model we used. The PVL-DecayRI model showed increased reward sensitivity ( α parameter) in amphetamine users compared to HC [Figure S7, 95% HDI from 0.0 to 0.5, mean of HDI = 0.3; t (84) = 6 . 26, p = 1 . 53E-08], which was not replicated with other models. Given that the groups differed on age, IQ, and education, we conducted NHST Analysis of Covariance (ANCOVA) tests to examine whether group differences on model parameters remain significant after controlling for these factors. Dependent variables were model parameter values (individual posterior means), group membership (e.g., HC vs. amphetamine groups) was the categorical independent variable, and covariates were age, IQ, and education. With any model (VPP, PVL-DecayRI, or PVL-Delta), group difference on loss aversion between heroin and HC groups remained significant [e.g., with the VPP model, F (1 , 86) = 26 . 06, p = 1 . 16E-13]. The group difference on reward sensitivity between amphetamine and HC groups with the PVL-DecayRI model also remained significant [ F (1 , 81) = 46 . 28, p = 1 . 61E-09]",
    "chunk_id": "decision-making_in_stimulant_and_opiate_addicts_in_protracted_abstinence_evidence_from_computational_modeling_with_pure_users.json_chunk_28"
  },
  {
    "document_type": "research_paper",
    "title": "Decision-making in stimulant and opiate addicts in protracted abstinence: evidence from computational modeling with pure users",
    "author": "Jasmin Vassileva",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Ahn-2014-Decision-making-in-stimulant-and-op.pdf",
    "date_published": "2014-08-08",
    "keywords": "addiction, decision-making, computational modeling, heroin, amphetamine, protracted abstinence, Bayesian data analysis, Widely Applicable Information Criterion (WAIC)",
    "flag": "",
    "chunk_text": ". 06, p = 1 . 16E-13]. The group difference on reward sensitivity between amphetamine and HC groups with the PVL-DecayRI model also remained significant [ F (1 , 81) = 46 . 28, p = 1 . 61E-09]. EXPLORATORY ANALYSES: ASSOCIATIONS OF MODEL PARAMETERS WITH SUBSTANCE USE AND PERSONALITY CHARACTERISTICS Next, we examined associations of model parameters of the impaired neurocognitive processes (loss aversion for heroin users using the VPP model) with substance use characteristics (nuber of years of drug use, length of abstinence from primary drug, number of DSM-IV criteria met for primary drug of dependence, nicotine dependence, and past cannabis dependence), impulsive personality traits (BIS-11) and impulse-related personality diorders (PCL:SV). As noted earlier, we used hierarchical robust Bayesian multiple linear regression, which has a hyperdistribution on regression coefficients across predictors and large-tail distrbutions to accommodate outliers. The results showed that loss aversion in heroin users was not predicted by any variable (Figure S12 for the robust Bayesian multiple linear regression results). None of the regressors were significant ( p < 0 . 05 with NHST). In contrast to our null findings with the VPP model, we found two associations when we used the affected parameters from the PVL-DecayRI model (loss aversion for heroin users and reward sensitivity for amphetamine users). In heroin users, FIGURE 2 | Density plots of posterior group parameter distributions with the Value-Plus-Perseverance (VPP) model. Bottom and top tick marks indicate HDI 95% range, and middle tick marks indicate mean values for each group. Density plots range from 0.01 to 99.99% of posterior distributions. HC, Healthy Control group; AMPH, Amphetamine group; HERO, Heroin group. Table 4 | Means and standard deviations (in parentheses) of group mean parameters with the VPP model. VPP parameters HC A H Learning rate ( A ) 0 . 010 (0 . 008) 0 . 019 (0 . 011) 0 . 070 (0 . 044) Reward sensitivity ( α ) 0 . 518 (0 . 149) 0 . 374 (0",
    "chunk_id": "decision-making_in_stimulant_and_opiate_addicts_in_protracted_abstinence_evidence_from_computational_modeling_with_pure_users.json_chunk_29"
  },
  {
    "document_type": "research_paper",
    "title": "Decision-making in stimulant and opiate addicts in protracted abstinence: evidence from computational modeling with pure users",
    "author": "Jasmin Vassileva",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Ahn-2014-Decision-making-in-stimulant-and-op.pdf",
    "date_published": "2014-08-08",
    "keywords": "addiction, decision-making, computational modeling, heroin, amphetamine, protracted abstinence, Bayesian data analysis, Widely Applicable Information Criterion (WAIC)",
    "flag": "",
    "chunk_text": ". VPP parameters HC A H Learning rate ( A ) 0 . 010 (0 . 008) 0 . 019 (0 . 011) 0 . 070 (0 . 044) Reward sensitivity ( α ) 0 . 518 (0 . 149) 0 . 374 (0 . 137) 0 . 481 (0 . 159) Response sensitivity ( c ) 2 . 017 (0 . 419) 1 . 894 (0 . 329) 1 . 368 (0 . 125) Loss aversion ( λ ) a 0 . 717 (0 . 273) 0 . 593 (0 . 275) 0 . 023 (0 . 033) Perseverance after gain ( ε p ) − 0 . 001 (0 . 154) − 0 . 181 (0 . 179) 0 . 050 (0 . 204) Perseverance after loss ( ε n ) − 0 . 726 (0 . 296) − 0 . 500 (0 . 297) − 0 . 249 (0 . 192) Perseverance decay rate ( k ) 0 . 481 (0 . 062) 0 . 404 (0 . 067) 0 . 337 (0 . 073) RL weight ( ω ) 0 . 825 (0 . 110) 0 . 714 (0 . 183) 0 . 677 (0 . 078) HC, healthy controls; A, amphetamine; H, heroin. a HC, A > H. loss aversion ( λ ) was predicted by impulsive personality traits (BIS-11 total score; mean coefficient = − 0 . 027, 95% HDI from − 0.05 to − 0.00, mean of HDI = − 0 . 03) (Figure S13). In cotrast, in amphetamine users, reward sensitivity was predicted by number of years of drug use (mean coefficient = 0.042, 95% HDI of group differences from 0.01 to 0.07, mean of HDI = 0.04, see Figure S14). Other variables were not associated with model parameters. Correlational analyses with internalizing characteritics (depression and anxiety) revealed no associations with model parameters. DISCUSSION This is the first human study that uses a computational modeing approach to investigate neurocognitive functioning in reltively pure amphetamine and heroin users. Our behavioral results reveal that heroin users show more disadvantageous decisiomaking performance than HC; however, their performance was not different from that of amphetamine users. These results are in line with the persistent nature of decision-making deficits observed among opiate addicts in particular ( Vassileva et al., 2007b; Fernández-Serrano et al., 2011; Li et al., 2013 )",
    "chunk_id": "decision-making_in_stimulant_and_opiate_addicts_in_protracted_abstinence_evidence_from_computational_modeling_with_pure_users.json_chunk_30"
  },
  {
    "document_type": "research_paper",
    "title": "Decision-making in stimulant and opiate addicts in protracted abstinence: evidence from computational modeling with pure users",
    "author": "Jasmin Vassileva",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Ahn-2014-Decision-making-in-stimulant-and-op.pdf",
    "date_published": "2014-08-08",
    "keywords": "addiction, decision-making, computational modeling, heroin, amphetamine, protracted abstinence, Bayesian data analysis, Widely Applicable Information Criterion (WAIC)",
    "flag": "",
    "chunk_text": ". Critically, our computational modeling findings suggest that amphetamine and heroin users may be characterized by dissociable decisiomaking biases even within the context of no overt behavioral differences in performance. When we compared groups using the best-fitting (VPP) model, heroin users showed reduced loss FIGURE 3 | Posterior distributions of differences of group mean parameters between the heroin and the healthy control (HC) groups, with the VPP model. HDI, highest density interval. Table 5 | Means and standard deviations (in parentheses) of group mean parameters with the PVL-DecayRI model. PVL DecayRI HC A H parameters Decay rate ( A ) 0.736 (0.068) 0.809 (0.072) 0.730 (0.087) Reward sensitivity ( α ) a 0.053 (0.043) 0.310 (0.129) 0.122 (0.074) Response sensitivity ( c ) 0.216 (0.038) 0.186 (0.040) 0.210 (0.050) Loss aversion ( λ ) b 1.262 (0.543) 0.910 (0.494) 0.110 (0.108) HC, healthy controls; A, amphetamine; H, heroin. a HC < A. b HC > H. aversion relative to amphetamine users and HC. Notably, the reduced loss aversion among heroin users compared to healthy individuals was robust across all models we tested. With regards to amphetamine users, we did not find any distinct decision-making profile using the best-fitting VPP model. However, when using the PVL-DecayRI model, which had the second best model-fits in our data, amphetamine users showed greater reward sensitivity than HC. These group differences were at the outcome evaluation stage according to a recent framework of value-based decisiomaking ( Rangel et al., 2008 ) and putatively reflect an emotional and activation type of self-regulation ( Bickel et al., 2012 ). We tested three existing cognitive models to compare the two drug user groups with HC. Consistent with previous reports ( Worthy et al., 2013b ), we found that the VPP model was the Table 6 | Means and standard deviations (in parentheses) of group mean parameters with the PVL-Delta model",
    "chunk_id": "decision-making_in_stimulant_and_opiate_addicts_in_protracted_abstinence_evidence_from_computational_modeling_with_pure_users.json_chunk_31"
  },
  {
    "document_type": "research_paper",
    "title": "Decision-making in stimulant and opiate addicts in protracted abstinence: evidence from computational modeling with pure users",
    "author": "Jasmin Vassileva",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Ahn-2014-Decision-making-in-stimulant-and-op.pdf",
    "date_published": "2014-08-08",
    "keywords": "addiction, decision-making, computational modeling, heroin, amphetamine, protracted abstinence, Bayesian data analysis, Widely Applicable Information Criterion (WAIC)",
    "flag": "",
    "chunk_text": ". PVL Delta parameters HC A H Learning rate ( A ) 0.037 (0.019) 0.035 (0.018) 0.172 (0.080) Reward sensitivity ( α ) 0.382 (0.126) 0.283 (0.116) 0.475 (0.123) Response sensitivity ( c ) 1.285 (0.204) 1.292 (0.181) 0.947 (0.147) Loss aversion ( λ ) a 0.650 (0.240) 0.376 (0.220) 0.060 (0.055) HC, healthy controls; A, amphetamine; H, heroin. a HC > H. best-fitting model when measured by WAIC, followed by the PVL-DecayRI and the PVL-Delta. However, it should be noted that the VPP model has twice as many parameters as other moels (8 vs. 4) and showed the worst simulation and parameter recovery performance compared to the two PVL models. In cotrast, Worthy et al. (2013b) show good simulation performance for the VPP model in their dataset; however, there are two major differences between their study and ours. First, in Worthy et al. (2013b) , control participants preferred the disadvantageous deck (Deck B) throughout the task, similar to the amphetamine and heroin groups in our study. Indeed, the simulation performance of the VPP model is quite good for the heroin group if we colapse trial-by-trial simulation performance over trials on each deck. Second, Worthy et al. (2013b) used MLE estimates instead of HBA estimates. Thus, it remains to be determined whether the poor simulation performance of the VPP model in our datasets is due to its over-complexity, the limited generalizability of specific behavioral patterns, or to differences in the parameter estimation methods. It would also be helpful to perform external validtion tests (e.g., Wallsten et al., 2005 ) because the parameters of a model with good model-fits do not necessarily reflect underlying psychological constructs ( Riefer et al., 2002 ). In this study, each participant performed only up to 100 trials: Even if hierarchcal modeling allowed us to pool information across individuals, 100 trials might not contain enough information to reliably estmate 8 free parameters and capture true underlying psychological constructs",
    "chunk_id": "decision-making_in_stimulant_and_opiate_addicts_in_protracted_abstinence_evidence_from_computational_modeling_with_pure_users.json_chunk_32"
  },
  {
    "document_type": "research_paper",
    "title": "Decision-making in stimulant and opiate addicts in protracted abstinence: evidence from computational modeling with pure users",
    "author": "Jasmin Vassileva",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Ahn-2014-Decision-making-in-stimulant-and-op.pdf",
    "date_published": "2014-08-08",
    "keywords": "addiction, decision-making, computational modeling, heroin, amphetamine, protracted abstinence, Bayesian data analysis, Widely Applicable Information Criterion (WAIC)",
    "flag": "",
    "chunk_text": ". It might be related to the fact that behaviorally the amphetamine group showed different choice patterns from the HC group but none of their model parameter values are credbly different from those of the HC group. As seen in Figure 2 , several parameters of the amphetamine group are “sub-optimal” compared to the HC group (e.g., ε n , k, and ω ) but the group differences did not reach the threshold of credible group diffeence. It is possible that deficits in the amphetamine group were decomposed into several parameters, instead of into one or two parameters in the VPP model. It may be necessary and helful to develop new models with fewer model parameters based on the psychological and neuroscience literature by using model comparison methods and performing external validation. There are a few previous studies using the PVL-DecayRI ( Vassileva et al., 2013 ) or the PVL-Delta ( Fridberg et al., 2010 ) model to study decision-making processes in drug users. Consistent with our results, both chronic (current) marijuana users ( Fridberg et al., 2010 ) and polysubstance (former) users ( Vassileva et al., 2013 ) showed reduced loss aversion compared to HC. On the other hand, chronic marijuana users also exhiited higher reward sensitivity, impaired learning/memory, and reduced response consistency compared to HC when tested with the PVL-Delta model ( Fridberg et al., 2010 ). Polysubstance use was also associated with impaired learning/memory when tested with the PVL-DecayRI model ( Vassileva et al., 2013 ). Stout et al. (2004) used the EVL model and MLE method for parameter estmation, and reported reduced attention weight to loss among current cocaine users compared to HC. In the EVL model, the w parameter (attention weight to loss vs. gain) incorporates both reward sensitivity and loss aversion; therefore, it is difficult to directly compare the findings from Stout et al. (2004) with our results. However, it is likely that one or both of the two processes was impaired in current cocaine users in the Stout et al",
    "chunk_id": "decision-making_in_stimulant_and_opiate_addicts_in_protracted_abstinence_evidence_from_computational_modeling_with_pure_users.json_chunk_33"
  },
  {
    "document_type": "research_paper",
    "title": "Decision-making in stimulant and opiate addicts in protracted abstinence: evidence from computational modeling with pure users",
    "author": "Jasmin Vassileva",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Ahn-2014-Decision-making-in-stimulant-and-op.pdf",
    "date_published": "2014-08-08",
    "keywords": "addiction, decision-making, computational modeling, heroin, amphetamine, protracted abstinence, Bayesian data analysis, Widely Applicable Information Criterion (WAIC)",
    "flag": "",
    "chunk_text": ". (2004) with our results. However, it is likely that one or both of the two processes was impaired in current cocaine users in the Stout et al. (2004) study. It should be also noted that the mean w parameter (RL weight) value was greater than 0.5 in all groups ( Figure 2 ), suggesting that overall RL was a primary strategy in all groups. Worthy et al. (2013b) reported that the mean w parameter of healthy individals was 0.49, which is the mean value of MLE individual estimates. In addition to the difference in parameter estimation methods, we also found some differences in the choice patterns of the three groups. As seen in Figure S1, healthy control individuals in our study eventually preferred the advantageous deck (Deck D) as the task progressed. On the other hand, healthy individuals in Worthy et al. (2013b) continued to prefer the disadvantageous deck (Deck B) throughout the task, which was the deck preferred by both heroin and amphetamine users in our study. It remains unclear why the two drug user groups, which showed similar behavioral patterns to participants in Worthy et al. (2013b) , showed w value greater than 0.5 on average. A future study will be necessary to replicate the findings. This is one of the very few studies that investigate amphetamine and heroin users in protracted abstinence ( Ersche et al., 2005a,b; Clark et al., 2006 ). Our results indicate that decision-making deficits previously reported with current drug users ( Bechara et al., 2001; Yechiam et al., 2005 ) may persist long after discontinuation of drug use and appear particularly pronounced in heroin users. These deficits and decision-making biases may have existed prior to onset of drug use and thereby could have contributed to an increased susceptibility to develop addiction, in line with longitudinal studies with adolescents, which show that poor response inhibition and behavioral dyfunction often precede onset of drug use and contribute to the development of addiction ( Nigg et al., 2006; Wong et al., 2006 )",
    "chunk_id": "decision-making_in_stimulant_and_opiate_addicts_in_protracted_abstinence_evidence_from_computational_modeling_with_pure_users.json_chunk_34"
  },
  {
    "document_type": "research_paper",
    "title": "Decision-making in stimulant and opiate addicts in protracted abstinence: evidence from computational modeling with pure users",
    "author": "Jasmin Vassileva",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Ahn-2014-Decision-making-in-stimulant-and-op.pdf",
    "date_published": "2014-08-08",
    "keywords": "addiction, decision-making, computational modeling, heroin, amphetamine, protracted abstinence, Bayesian data analysis, Widely Applicable Information Criterion (WAIC)",
    "flag": "",
    "chunk_text": ". Alternatively, these deficits and biases may reflect residual, enduring and possibly irreversible effects of chronic drug use; or an interaction between pre-existing predispositions and residual effects of drugs of abuse. Although our study revealed some dissciable decision-making biases in amphetamine and heroin users, our design does not allow us to determine whether they precede onset of drug use or whether they are consequences of chronic drug use. This crucial question should be investigated by future carefully designed prospective studies. Using the second best-fitting PVL-DecayRI model, we found that the distinct decision-making style of heroin users charaterized by reduced sensitivity to loss is associated with elevated trait impulsivity, as hypothesized. These findings are in line with reports that personality variables are related to decision-making performance on the IGT among heroin users on OST ( Lemenager et al., 2011 ). Our results indicate that similar associations are observable among heroin users in protracted abstinence who are not on OST. Speculatively, given the persistent nature of persoality traits such as impulsivity, which develop early and typically prior to onset of substance dependence, the reduced loss aversion in heroin users may have predated the development of addiction and may be of etiological significance for addiction to opiates in particular. In contrast, the decision-making bias displayed by stimulant users (reward sensitivity) was not associated with pesonality traits but was instead related to duration of stimulant use, which suggests that such biases may potentially reflect cumlative residual effects of chronic stimulant use. It is important to emphasize that we should exercise caution when interpreting these associations, as they were not replicated with the best-fitting (VPP) model",
    "chunk_id": "decision-making_in_stimulant_and_opiate_addicts_in_protracted_abstinence_evidence_from_computational_modeling_with_pure_users.json_chunk_35"
  },
  {
    "document_type": "research_paper",
    "title": "Decision-making in stimulant and opiate addicts in protracted abstinence: evidence from computational modeling with pure users",
    "author": "Jasmin Vassileva",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Ahn-2014-Decision-making-in-stimulant-and-op.pdf",
    "date_published": "2014-08-08",
    "keywords": "addiction, decision-making, computational modeling, heroin, amphetamine, protracted abstinence, Bayesian data analysis, Widely Applicable Information Criterion (WAIC)",
    "flag": "",
    "chunk_text": ". It is important to emphasize that we should exercise caution when interpreting these associations, as they were not replicated with the best-fitting (VPP) model. A question arises as to what is the clinical significance of the observed decision-making biases and deficits within the context of our participants’ history of protracted abstinence, which is the standard metric of success of most addiction treatment prgrams. Specifically, despite the observed decision-making deficits and biases among the two drug user groups, the majority of our participants have been remarkably successful in maintaining abstinence for long periods of time and without the help of any substitution therapy. In essence, the ability of our participants to abstain for such protracted periods of time suggests that this group could be comprised of some of the least impulsive SDI, expected to display more adaptive decision-making abilities than SDI who are unable to remain abstinent for long. Future stuies should determine the real-life significance of such decisiomaking deficits and biases and the role they play in the protracted abstinence stage. For example, we recently reported that some decision-making biases may have functional significance for HIV infected women with a history of illicit drug use, among whom they may be related to risky sexual behaviors and reduced adheence to HIV medication dosing schedules ( Vassileva et al., 2013 ). Similarly, we recently found that a composite neurocognitive index of reward-based decision-making (which includes the IGT) predicts recent (past 30-days) sexual HIV risk behaviors in heroin and amphetamine users in protracted abstinence (Wilson et al., under review). Overall, our results suggest that decision-making processes other than the ones we examined may be more relevant for the successful and prolonged maintenance of a state of abstnence. Further, our findings may be specific to decision-making under uncertainty and ambiguity, as measured by the IGT",
    "chunk_id": "decision-making_in_stimulant_and_opiate_addicts_in_protracted_abstinence_evidence_from_computational_modeling_with_pure_users.json_chunk_36"
  },
  {
    "document_type": "research_paper",
    "title": "Decision-making in stimulant and opiate addicts in protracted abstinence: evidence from computational modeling with pure users",
    "author": "Jasmin Vassileva",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Ahn-2014-Decision-making-in-stimulant-and-op.pdf",
    "date_published": "2014-08-08",
    "keywords": "addiction, decision-making, computational modeling, heroin, amphetamine, protracted abstinence, Bayesian data analysis, Widely Applicable Information Criterion (WAIC)",
    "flag": "",
    "chunk_text": ". Further, our findings may be specific to decision-making under uncertainty and ambiguity, as measured by the IGT. It is possible that SDI in protracted abstinence may display intact functioning in other aspects of decision-making (e.g., decisions under risk) that may have more direct relevance to the succesful maintenance of abstinence. On the other hand, the fact that such decision-making deficits and biases were observed in paticipants who have successfully maintained prolonged abstinence raises the question of whether users who are unable to maintain long-term abstinence are characterized by even more aberrant decision-making profiles. It would be crucial for future studies to determine how “successful” long-term abstainers such as our participants compare to currently active SDI or to SDI who are unable to abstain from drug use. Future studies should also detemine whether similar substance-specific biases are observable in opiate and stimulant users at other stages of the addiction cycle and ideally employ longitudinal designs to determine whether they are precursors or consequences of chronic substance use. While clearly of theoretical significance, the extent to which our findings have implications for prevention and intervetion remains to be determined. If replicated by future studies, such decision-making deficits and biases may inform treatment and recovery programs for opiate and stimulant dependent individuals. Within this context, pre-treatment decision-making assessments may represent a useful adjunct to help formulate pesonalized treatment plans ( Baldacchino et al., 2012 ), which could potentially include cognitive enhancement or training that have shown some promising results ( Nutt et al., 2007; Bickel et al., 2011 )",
    "chunk_id": "decision-making_in_stimulant_and_opiate_addicts_in_protracted_abstinence_evidence_from_computational_modeling_with_pure_users.json_chunk_37"
  },
  {
    "document_type": "research_paper",
    "title": "Decision-making in stimulant and opiate addicts in protracted abstinence: evidence from computational modeling with pure users",
    "author": "Jasmin Vassileva",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Ahn-2014-Decision-making-in-stimulant-and-op.pdf",
    "date_published": "2014-08-08",
    "keywords": "addiction, decision-making, computational modeling, heroin, amphetamine, protracted abstinence, Bayesian data analysis, Widely Applicable Information Criterion (WAIC)",
    "flag": "",
    "chunk_text": ". Our results from the PVL-DecayRI model suggest that interventions that target reduced loss aversion (punishment sesitivity) may be more suitable for heroin users, whereas others addressing increased reward sensitivity may hold promise with amphetamine users, though we should exercise caution with the latter, which failed to replicate with the best-fitting model. There are a number of limitations that need to be considered when evaluating the current findings. First, the fact that our paticipants were predominantly male should be taken into account when considering the generalizability of our findings to females. Second, our findings could have been influenced by group diferences in age, IQ, and education, though the reduced loss aversion in heroin users and the increased reward sensitivity in the amphetamine group (with the PVL-DecayRI model) relative to HC remained robust even after controlling for those factors. Third, computational modeling parameter estimates, like many conceptual or quantitative interpretive tools, are useful heuristics in the evaluation of observed behavior patterns, not explanatory mechanisms of the phenomena at hand. Interpretations should be rendered accordingly, though the reduced loss aversion in heroin users was robust across all models we tested. In sum, by recruiting relatively pure amphetamine and heroin users in protracted abstinence and by parcellating their decisiomaking performance into distinct neurocognitive processes by using computational modeling and Bayesian tools, we revealed that heroin users displayed reduced loss aversion relative to HC while being in protracted abstinence. Future studies utlizing other experimental paradigms probing different aspects of decision-making and computational models will be necesary to examine which mechanisms may be at play in the decision-making performance of heroin and amphetamine users at different stages of the addiction cycle",
    "chunk_id": "decision-making_in_stimulant_and_opiate_addicts_in_protracted_abstinence_evidence_from_computational_modeling_with_pure_users.json_chunk_38"
  },
  {
    "document_type": "research_paper",
    "title": "Decision-making in stimulant and opiate addicts in protracted abstinence: evidence from computational modeling with pure users",
    "author": "Jasmin Vassileva",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Ahn-2014-Decision-making-in-stimulant-and-op.pdf",
    "date_published": "2014-08-08",
    "keywords": "addiction, decision-making, computational modeling, heroin, amphetamine, protracted abstinence, Bayesian data analysis, Widely Applicable Information Criterion (WAIC)",
    "flag": "",
    "chunk_text": ". ACKNOWLEDGMENTS The authors thank all volunteers for their participation in this study; Kiril Bozgunov, Rada Naslednikova, and Ivaylo Raynov for testing study participants; Warren K. Bickel and reviewers of ealier drafts for helpful comments on the manuscript; and Helen Steingroever for her feedback on our implementation of WAIC. This publication was made possible by R01DA021421 grant from the National Institute on Drug Abuse (NIDA) and the Fogarty International Center (FIC) to Jasmin Vassileva. Its contents are solely the responsibility of the authors and do not necessarily represent the official views of the National Institutes of Health (NIH). SUPPLEMENTARY MATERIAL The Supplementary Material for this article can be found online at: http://www . frontiersin . org/journal/10 . 3389/fpsyg . 2014 . 00849/abstract REFERENCES Ahn, W.-Y., Busemeyer, J. R., Wagenmakers, E.-J., and Stout, J. C. (2008). Comparison of decision learning models using the generalization crterion method. Cogn. Sci. 32, 1376–1402. doi: 10.1080/03640210802 352992 Ahn, W.-Y., Krawitz, A., Kim, W., Busemeyer, J. R., and Brown, J. W. (2011). A model-based fMRI analysis with hierarchical bayesian parameter estimation. J. Neurosci. Psychol. Econ. 4, 95–110. doi: 10.1037/a0020684 Akaike, H., Petrov, B. N., and Csaki, F. (1973). “Information theory as an extension of the maximum likelihood principle,” in Second International Symposium on Information Theory , (Akademiai Kiado), 267–281. Badiani, A., Belin, D., Epstein, D., Calu, D., and Shaham, Y. (2011). Opiate versus psychostimulant addiction: the differences do matter. Nat. Rev. Neurosci. 12, 685–700. doi: 10.1038/nrn3104 Baldacchino, A., Balfour, D., Passetti, F., Humphris, G., and Matthews, K. (2012). Neuropsychological consequences of chronic opioid use: a quantittive review and meta-analysis. Neurosci. Biobehav. Rev. 36, 2056–2068. doi: 10.1016/j.neubiorev.2012.06.006 Bechara, A., Damasio, A. R., Damasio, H., and Anderson, S. (1994)",
    "chunk_id": "decision-making_in_stimulant_and_opiate_addicts_in_protracted_abstinence_evidence_from_computational_modeling_with_pure_users.json_chunk_39"
  },
  {
    "document_type": "research_paper",
    "title": "Decision-making in stimulant and opiate addicts in protracted abstinence: evidence from computational modeling with pure users",
    "author": "Jasmin Vassileva",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Ahn-2014-Decision-making-in-stimulant-and-op.pdf",
    "date_published": "2014-08-08",
    "keywords": "addiction, decision-making, computational modeling, heroin, amphetamine, protracted abstinence, Bayesian data analysis, Widely Applicable Information Criterion (WAIC)",
    "flag": "",
    "chunk_text": ". Neurosci. Biobehav. Rev. 36, 2056–2068. doi: 10.1016/j.neubiorev.2012.06.006 Bechara, A., Damasio, A. R., Damasio, H., and Anderson, S. (1994). Insensitivity to future consequences following damage to human prefrontal cortex. Cognition 50, 7–15. doi: 10.1016/0010-0277(94)90018-3 Bechara, A., Dolan, S., Denburg, N., Hindes, A., Anderson, S. W., and Nathan, P. E. (2001). Decision-making deficits, linked to a dysfunctional ventromedial prfrontal cortex, revealed in alcohol and stimulant abusers. Neuropsychologia 39, 376–389. doi: 10.1016/S0028-3932(00)00136-6 Bechara, A., and Martin, E. M. (2004). Impaired decision making related to woring memory deficits in individuals with substance addictions. Neuropsychology 18, 152–162. doi: 10.1037/0894-4105.18.1.152 Beck, A. T., Steer, R. A., and Brown, G. K. (1996). Manual for the Beck Depression Inventory-II . San Antonio, TX: The Psychological Corporation. Berry, D. A., and Fristedt, B. (1985). Bandit Problems: Sequential Allocation of Experiments (Monographs on Statistics and Applied Probability) . London: Chapman & Hall. Bickel, W. K., Jarmolowicz, D. P., Mueller, E. T., Gatchalian, K. M., and Mcclure, S. M. (2012). Are executive function and impulsivity antipodes? A conceptual reconstruction with special reference to addition. Psychopharmacology (Berl). 221, 361–387. doi: 10.1007/s00213-012- 2689-x Bickel, W. K., Yi, R., Landes, R. D., Hill, P. F., and Baxter, C. (2011). Remember the future: working memory training decreases delay discounting among stimulant addicts. Biol. Psychiatry 69, 260–265. doi: 10.1016/j.biopsych.2010. 08.017 Bolla, K. I., Eldreth, D. A., London, E. D., Kiehl, K. A., Mouratidis, M., Contoreggi, C., et al. (2003). Orbitofrontal cortex dysfunction in abstinent cocaine abusers performing a decision-making task. Neuroimage 19, 1085–1094. doi: 10.1016/S1053-8119(03)00113-7 Busemeyer, J. R., and Stout, J. C. (2002). A contribution of cognitive decsion models to clinical assessment: decomposing performance on the Bechara gambling task. Psychol. Assess",
    "chunk_id": "decision-making_in_stimulant_and_opiate_addicts_in_protracted_abstinence_evidence_from_computational_modeling_with_pure_users.json_chunk_40"
  },
  {
    "document_type": "research_paper",
    "title": "Decision-making in stimulant and opiate addicts in protracted abstinence: evidence from computational modeling with pure users",
    "author": "Jasmin Vassileva",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Ahn-2014-Decision-making-in-stimulant-and-op.pdf",
    "date_published": "2014-08-08",
    "keywords": "addiction, decision-making, computational modeling, heroin, amphetamine, protracted abstinence, Bayesian data analysis, Widely Applicable Information Criterion (WAIC)",
    "flag": "",
    "chunk_text": ". R., and Stout, J. C. (2002). A contribution of cognitive decsion models to clinical assessment: decomposing performance on the Bechara gambling task. Psychol. Assess. 14, 253–262. doi: 10.1037/1040-3590.14. 3.253 Caprioli, D., Celentano, M., Paolone, G., Lucantonio, F., Bari, A., Nencini, P., et al. (2008). Opposite environmental regulation of heroin and amphetamine self-administration in the rat. Psychopharmacology (Berl). 198, 395–404. doi: 10.1007/s00213-008-1154-3 Chan, T. W., Ahn, W.-Y., Bates, J. E., Busemeyer, J. R., Guillaume, S., Redgrave, G. W., et al. (2014). Differential impairments underlying decision making in anorexia nervosa and bulimia nervosa: a cognitive modeling analysis. Int. J. Eat. Disord. 47, 157–167. doi: 10.1002/eat.22223 Clark, L., Robbins, T. W., Ersche, K. D., and Sahakian, B. J. (2006). Reflection impulsivity in current and former substance users. Biol. Psychiatry 60, 515–522. doi: 10.1016/j.biopsych.2005.11.007 Daw, N. D., Gershman, S. J., Seymour, B., Dayan, P., and Dolan, R. J. (2011). Modebased influences on humans’ choices and striatal prediction errors. Neuron 69, 1204–1215. doi: 10.1016/j.neuron.2011.02.027 Degroot, M. (1970). Optimal Statistical Decisions . New York, NY: McGraw-Hill. Di Chiara, G., and Imperato, A. (1988). Drugs abused by humans preferetially increase synaptic dopamine concentrations in the mesolimbic system of freely moving rats. Proc. Natl. Acad. Sci. U.S.A. 85, 5274–5278. doi: 10.1073/pnas.85.14.5274 Erev, I., and Roth, A. (1998). Predicting how people play games: reinforcement learning in experimental games with unique, mixed strategy equilibria. Am. Econ. Rev. 88, 848–881. Ersche, K. D., Fletcher, P. C., Lewis, S. J., Clark, L., Stocks-Gee, G., London, M., et al. (2005a). Abnormal frontal activations related to decision-making in current and former amphetamine and opiate dependent individuals. Psychopharmacology (Berl). 180, 612–623. doi: 10.1007/s00213-005-2205-7 Ersche, K. D., Roiser, J. P., Clark, L., London, M., Robbins, T. W., and Sahakian, B. J",
    "chunk_id": "decision-making_in_stimulant_and_opiate_addicts_in_protracted_abstinence_evidence_from_computational_modeling_with_pure_users.json_chunk_41"
  },
  {
    "document_type": "research_paper",
    "title": "Decision-making in stimulant and opiate addicts in protracted abstinence: evidence from computational modeling with pure users",
    "author": "Jasmin Vassileva",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Ahn-2014-Decision-making-in-stimulant-and-op.pdf",
    "date_published": "2014-08-08",
    "keywords": "addiction, decision-making, computational modeling, heroin, amphetamine, protracted abstinence, Bayesian data analysis, Widely Applicable Information Criterion (WAIC)",
    "flag": "",
    "chunk_text": ". Psychopharmacology (Berl). 180, 612–623. doi: 10.1007/s00213-005-2205-7 Ersche, K. D., Roiser, J. P., Clark, L., London, M., Robbins, T. W., and Sahakian, B. J. (2005b). Punishment induces risky decision-making in methadonmaintained opiate users but not in heroin users or healthy volunteers. Neuropsychopharmacology 30, 2115–2124. doi: 10.1038/sj.npp.1300812 European Monitoring Center for Drugs and Drug Addiction. (2011). Annual Report . Available online at: http://www . emcdda . europa . eu/publications/ annual-report/2011 Fernández-Serrano, M. J., Pérez-García, M., and Verdejo-García, A. (2011). What are the specific vs. generalized effects of drugs of abuse on neropsychological performance? Neurosci. Biobehav. Rev. 35, 377–406. doi: 10.1016/j.neubiorev.2010.04.008 First, M., Gibbon, M., Spitzer, R., and Williams, J. (1996). User’s Guide for the Structured Interview for DSM-IV Axis 1 Disorders-Research Version. New York, NY: Biometrics Research. Fridberg, D. J., Queller, S., Ahn, W.-Y., Kim, W., Bishara, A. J., Busemeyer, J. R., et al. (2010). Cognitive mechanisms underlying disadvantageous decisiomaking in chronic cannabis abusers. J. Math. Psychol. 54, 28–38. doi: 10.1016/j.jmp.2009.10.002 Gelman, A., Carlin, J. B., Stern, H. S., Dunson, D. B., Vehtari, A., and Rubin, D. B. (2013a). “Chapter 7. Evaluating, comparing, and expanding models,” in Bayesian Data Analysis , 3rd Edn., eds A. Gelman, J. B. Carlin, H. S. Stern, D. B. Dunson, A. Vehtari, and D. B. Rubin (Boca Raton, FL: CRC press), 165–196. Gelman, A., Hwang, J., and Vehtari, A. (2013b). Understanding predictive infomation criteria for Bayesian models. Stat. Comput. 1–20. doi: 10.1007/s11222- 013-9416-2 Gelman, A., and Rubin, D. B. (1992). Inference from iterative simulation using multiple sequences. Stat. Sci. 457–472. doi: 10.1214/ss/1177011136 Goldstein, R. Z., and Volkow, N. D. (2011). Dysfunction of the prefrontal cortex in addiction: neuroimaging findings and clinical implications. Nat. Rev. Neurosci. 12, 652–669",
    "chunk_id": "decision-making_in_stimulant_and_opiate_addicts_in_protracted_abstinence_evidence_from_computational_modeling_with_pure_users.json_chunk_42"
  },
  {
    "document_type": "research_paper",
    "title": "Decision-making in stimulant and opiate addicts in protracted abstinence: evidence from computational modeling with pure users",
    "author": "Jasmin Vassileva",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Ahn-2014-Decision-making-in-stimulant-and-op.pdf",
    "date_published": "2014-08-08",
    "keywords": "addiction, decision-making, computational modeling, heroin, amphetamine, protracted abstinence, Bayesian data analysis, Widely Applicable Information Criterion (WAIC)",
    "flag": "",
    "chunk_text": ". Z., and Volkow, N. D. (2011). Dysfunction of the prefrontal cortex in addiction: neuroimaging findings and clinical implications. Nat. Rev. Neurosci. 12, 652–669. doi: 10.1038/nrn3119 Gonzalez, R., Bechara, A., and Martin, E. M. (2007). Executive functions among individuals with methamphetamine or alcohol as drugs of choice: preliminary observations. J. Clin. Exp. Neuropsychol. 29, 155–159. doi: 10.1080/13803390600582446 Gonzalez, R., Vassileva, J., Bechara, A., Grbesic, S., Sworowski, L., Novak, R. M., et al. (2005). The influence of executive functions, sensation seeking, and HIV serostatus on the risky sexual practices of substance-dependent individuals. J. Int. Neuropsychol. Soc. 11, 121–131. doi: 10.1017/S1355617705050186 Gorodetzky, H., Sahakian, B. J., Robbins, T. W., and Ersche, K. D. (2011). Differences in self-reported decision-making styles in stimulant-dependent and opiate-dependent individuals. Psychiatry Res. 186, 437–440. doi: 10.1016/j.psychres.2010.07.024 Grant, S., Contoreggi, C., and London, E. D. (2000). Drug abusers show impaired performance in a laboratory test of decision making. Neuropsychologia 38, 1180–1187. doi: 10.1016/S0028-3932(99)00158-X Hart, S. D., Cox, D. N., and Hare, R. D. (1995). The Hare Psychopathy Checklist: Screening Version (PCL: SV). Toronto, ON: Multi-Health Systems, Incorporated. Kirby, K. N., and Petry, N. M. (2004). Heroin and cocaine abusers have higher discount rates for delayed rewards than alcoholics or non-drug-using controls. Addiction 99, 461–471. doi: 10.1111/j.1360-0443.2003.00669.x Kreek, M. J., Laforge, K. S., and Butelman, E. (2002). Pharmacotherapy of additions. Nat. Rev. Drug Discov. 1, 710–726. doi: 10.1038/nrd897 Kreek, M. J., Levran, O., Reed, B., Schlussman, S. D., Zhou, Y., and Butelman, E. R. (2012). Opiate addiction and cocaine addiction: underlying molecular neurobology and genetics. J. Clin. Invest. 122, 3387–3393. doi: 10.1172/JCI60390 Kruschke, J. K. (2010). What to believe: Bayesian methods for data analysis. Trends Cogn. Sci. 14, 293–300",
    "chunk_id": "decision-making_in_stimulant_and_opiate_addicts_in_protracted_abstinence_evidence_from_computational_modeling_with_pure_users.json_chunk_43"
  },
  {
    "document_type": "research_paper",
    "title": "Decision-making in stimulant and opiate addicts in protracted abstinence: evidence from computational modeling with pure users",
    "author": "Jasmin Vassileva",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Ahn-2014-Decision-making-in-stimulant-and-op.pdf",
    "date_published": "2014-08-08",
    "keywords": "addiction, decision-making, computational modeling, heroin, amphetamine, protracted abstinence, Bayesian data analysis, Widely Applicable Information Criterion (WAIC)",
    "flag": "",
    "chunk_text": ". J. Clin. Invest. 122, 3387–3393. doi: 10.1172/JCI60390 Kruschke, J. K. (2010). What to believe: Bayesian methods for data analysis. Trends Cogn. Sci. 14, 293–300. doi: 10.1016/j.tics.2010.05.001 Kruschke, J. K. (2011a). Bayesian assessment of null values via parameter estimtion and model comparison. Perspect. Psychol. Sci. 6, 299–312. doi: 10.1177/1745 691611406925 Kruschke, J. K. (2011b). Doing Bayesian Data Analysis: A Tutorial with R and BUGS . Burlington, MA: Academic Press/Elsevier. Kruschke, J. K. (2013). Bayesian estimation supersedes the t test. J. Exp. Psychol. Gen. 142, 573–603. doi: 10.1037/a0029146 Lecca, S., Melis, M., Luchicchi, A., Ennas, M. G., Castelli, M. P., Muntoni, A. L., et al. (2011). Effects of drugs of abuse on putative rostromedial tegmental neurons, inhibitory afferents to midbrain dopamine cells. Neuropsychopharmacology 36, 589–602. doi: 10.1038/npp.2010.190 Lee, M. D. (2011). How cognitive modeling can benefit from hierarchical Bayesian models. J. Math. Psychol. 55, 1–7. doi: 10.1016/j.jmp.2010.08.013 Lemenager, T., Richter, A., Reinhard, I., Gelbke, J., Beckmann, B., Heinrich, M., et al. (2011). Impaired decision making in opiate addiction correlates with aniety and self-directedness but not substance use parameters. J. Addict. Med. 5, 203–213. doi: 10.1097/ADM.0b013e31820b3e3d Li, X., Zhang, F., Zhou, Y., Zhang, M., Wang, X., and Shen, M. (2013). Decisiomaking deficits are still present in heroin abusers after short-to long-term abstnence. Drug Alcohol Depend. 130, 61–67. doi: 10.1016/j.drugalcdep.2012.10.012 Luce, R. (1959). Individual Choice Behavior. New York, NY: Wiley. Nigg, J. T., Wong, M. M., Martel, M. M., Jester, J. M., Puttler, L. I., Glass, J. M., et al. (2006). Poor response inhibition as a predictor of problem drinking and illicit drug use in adolescents at risk for alcoholism and other sustance use disorders. J. Am. Acad. Child Adolesc. Psychiatry 45, 468–475. doi: 10.1097/01.chi.0000199028.76452.a9 Nutt, D., Robbins, T., and Stimson, G. (2007)",
    "chunk_id": "decision-making_in_stimulant_and_opiate_addicts_in_protracted_abstinence_evidence_from_computational_modeling_with_pure_users.json_chunk_44"
  },
  {
    "document_type": "research_paper",
    "title": "Decision-making in stimulant and opiate addicts in protracted abstinence: evidence from computational modeling with pure users",
    "author": "Jasmin Vassileva",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Ahn-2014-Decision-making-in-stimulant-and-op.pdf",
    "date_published": "2014-08-08",
    "keywords": "addiction, decision-making, computational modeling, heroin, amphetamine, protracted abstinence, Bayesian data analysis, Widely Applicable Information Criterion (WAIC)",
    "flag": "",
    "chunk_text": ". J. Am. Acad. Child Adolesc. Psychiatry 45, 468–475. doi: 10.1097/01.chi.0000199028.76452.a9 Nutt, D., Robbins, T., and Stimson, G. (2007). Drugs futures 2025? Drugs and the Future: Brain Science, Addiction and Society . London: Academic Press. Ornstein, T. J., Iddon, J. L., Baldacchino, A. M., Sahakian, B. J., London, M., Everitt, B. J., et al. (2000). Profiles of cognitive dysfunction in chronic amphetamine and heroin abusers. Neuropsychopharmacology 23, 113–126. doi: 10.1016/S0893- 133X(00)00097-X Passetti, F., Clark, L., Mehta, M. A., Joyce, E., and King, M. (2008). Neuropsychological predictors of clinical outcome in opiate addiction. Drug Alcohol Depend. 94, 82–91. doi: 10.1016/j.drugalcdep.2007.10.008 Patton, J. H., and Stanford, M. S. (1995). Factor structure of the Barratt impulsiveness scale. J. Clin. Psychol. 51, 768–774. doi: 10.1002/1097- 4679(199511)51:6%3C768::AID-JCLP2270510607%3E3.0.CO;2-1 Pettit, H. O., Ettenberg, A., Bloom, F. E., and Koob, G. F. (1984). Destruction of dopamine in the nucleus accumbens selectively attenuates cocaine but not heroin self-administration in rats. Psychopharmacology (Berl.) 84, 167–73. doi: 10.1007/BF00427441 Rangel, A., Camerer, C., and Montague, P. R. (2008). A framework for studying the neurobiology of value-based decision making. Nat. Rev. Neurosci. 9, 545–556. doi: 10.1038/nrn2357 R Development Core Team. (2009). R: A Language and Environment for Statistical Computing . Vienna: R Foundation for Statistical Computing. Rescorla, R. A., and Wagner, A. R. (1972). A Theory of Pavlovian Conditioning: Variations in the Effectiveness of Reinforcement and Nonreinforcement. New York, NY: Appleton-Century-Crofts. Riefer, D. M., Knapp, B. R., Batchelder, W. H., Bamber, D., and Manifold, V. (2002). Cognitive psychometrics: assessing storage and retrieval deficits in special populations with multinomial processing tree models. Psychol. Assess. 14:184. doi: 10.1037/1040-3590.14.2.184 Robinson, T. E., and Berridge, K. C. (1993)",
    "chunk_id": "decision-making_in_stimulant_and_opiate_addicts_in_protracted_abstinence_evidence_from_computational_modeling_with_pure_users.json_chunk_45"
  },
  {
    "document_type": "research_paper",
    "title": "Decision-making in stimulant and opiate addicts in protracted abstinence: evidence from computational modeling with pure users",
    "author": "Jasmin Vassileva",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Ahn-2014-Decision-making-in-stimulant-and-op.pdf",
    "date_published": "2014-08-08",
    "keywords": "addiction, decision-making, computational modeling, heroin, amphetamine, protracted abstinence, Bayesian data analysis, Widely Applicable Information Criterion (WAIC)",
    "flag": "",
    "chunk_text": ". Psychol. Assess. 14:184. doi: 10.1037/1040-3590.14.2.184 Robinson, T. E., and Berridge, K. C. (1993). The neural basis of drug craving: an incentive-sensitization theory of addiction. Brain Res. Rev. 18, 247–291. doi: 10.1016/0165-0173(93)90013-P Rogers, R. D., Everitt, B. J., Baldacchino, A., Blackshaw, A. J., Swainson, R., Wynne, K., et al. (1999). Dissociable deficits in the decision-making cognition of chronic amphetamine abusers, opiate abusers, patients with focal daage to prefrontal cortex, and tryptophan-depleted normal volunteers: evidence for monoaminergic mechanisms. Neuropsychopharmacology 20, 322–339. doi: 10.1016/S0893-133X(98)00091-8 Schwartz, G. (1978). Estimating the dimension of a model. Ann. Stat. 5, 461–464. doi: 10.1214/aos/1176344136 Spiegelhalter, D. J., Best, N. G., Carlin, B. P., and Van Der Linde, A. (2002). Bayesian measures of model complexity and fit. J. R. Stat. Soc. B 64, 583–639. doi: 10.1111/1467-9868.00353 Spielberger, C. D., and Gorsuch, R. L. (1983). Manual for the State-Trait Anxiety Inventory STAI (Form Y) (“Self-Evaluation Questionnaire”) . Redwood City, CA: Mind Garden. Spotts, J. V., and Shontz, F. C. (1980). A life-theme theory of chronic drug abuse. NIDA Res. Monogr. 30, 59–70. Stan Development Team. (2014). Stan: A C++ Library for Probability and Sampling , Version 2.1. Available online at: http://mc-stan . org/rstan . html Steingroever, H., Wetzels, R., and Wagenmakers, E.-J. (2013). Validating the PVL-Delta model for the Iowa gambling task. Front. Psychol. 4:898. doi: 10.3389/fpsyg.2013.00898 Steingroever, H., Wetzels, R., and Wagenmakers, E.-J. (2014). Absolute perfomance of reinforcement-learning models for the Iowa Gambling Task. Decision 1, 161–183. doi: 10.1037/dec0000005 Stewart, J., De Wit, H., and Eikelboom, R. (1984). Role of unconditioned and conditioned drug effects in the self-administration of opiates and stimulants. Psychol. Rev. 91, 251–268. doi: 10.1037/0033-295X.91.2.251 Stout, J. C., Busemeyer, J. R., Lin, A., Grant, S. J., and Bonson, K. R. (2004)",
    "chunk_id": "decision-making_in_stimulant_and_opiate_addicts_in_protracted_abstinence_evidence_from_computational_modeling_with_pure_users.json_chunk_46"
  },
  {
    "document_type": "research_paper",
    "title": "Decision-making in stimulant and opiate addicts in protracted abstinence: evidence from computational modeling with pure users",
    "author": "Jasmin Vassileva",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Ahn-2014-Decision-making-in-stimulant-and-op.pdf",
    "date_published": "2014-08-08",
    "keywords": "addiction, decision-making, computational modeling, heroin, amphetamine, protracted abstinence, Bayesian data analysis, Widely Applicable Information Criterion (WAIC)",
    "flag": "",
    "chunk_text": ". Psychol. Rev. 91, 251–268. doi: 10.1037/0033-295X.91.2.251 Stout, J. C., Busemeyer, J. R., Lin, A., Grant, S. J., and Bonson, K. R. (2004). Cognitive modeling analysis of decision-making processes in cocaine abusers. Psychon. Bull. Rev. 11, 742–747. doi: 10.3758/BF03196629 Vassileva, J., Ahn, W. Y., Weber, K. M., Busemeyer, J. R., Stout, J. C., Gonzalez, R., et al. (2013). Computational modeling reveals distinct effects of HIV and history of drug use on decision-making processes in women. PLoS ONE 8:e68962. doi: 10.1371/journal.pone.0068962 Vassileva, J., Gonzalez, R., Bechara, A., and Martin, E. M. (2007a). Are all drug addicts impulsive? Effects of antisociality and extent of multidrug use on cognitive and motor impulsivity. Addict. Behav. 32, 3071–3076. doi: 10.1016/j.addbeh.2007.04.017 Vassileva, J., Petkova, P., Georgiev, S., Martin, E. M., Tersiyski, R., Raycheva, M., et al. (2007b). Impaired decision-making in psychopathic heroin addicts. Drug Alcohol Depend. 86, 287–289. doi: 10.1016/j.drugalcdep.2006.06.015 Verdejo-Garcia, A., Benbrook, A., Funderburk, F., David, P., Cadet, J. L., and Bolla, K. I. (2007a). The differential relationship between cocaine use and marijuana use on decision-making performance over repeat tesing with the Iowa Gambling Task. Drug Alcohol Depend. 90, 2–11. doi: 10.1016/j.drugalcdep.2007.02.004 Verdejo-Garcia, A. J., Perales, J. C., and Perez-Garcia, M. (2007b). Cognitive impusivity in cocaine and heroin polysubstance abusers. Addict. Behav. 32, 950–966. doi: 10.1016/j.addbeh.2006.06.032 Wagenmakers, E.-J. (2007). A practical solution to the pervasive problems ofp values. Psychon. Bull. Rev. 14, 779–804. doi: 10.3758/BF03194105 Wallsten, T. S., Pleskac, T. J., and Lejuez, C. W. (2005). Modeling behavior in a clinically diagnostic sequential risk-taking task. Psychol. Rev. 112, 862–880. doi: 10.1037/0033-295X.112.4.862 Watanabe, S. (2010). Asymptotic equivalence of Bayes cross validation and widely applicable information criterion in singular learning theory. J. Mach. Learn. Res",
    "chunk_id": "decision-making_in_stimulant_and_opiate_addicts_in_protracted_abstinence_evidence_from_computational_modeling_with_pure_users.json_chunk_47"
  },
  {
    "document_type": "research_paper",
    "title": "Decision-making in stimulant and opiate addicts in protracted abstinence: evidence from computational modeling with pure users",
    "author": "Jasmin Vassileva",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Ahn-2014-Decision-making-in-stimulant-and-op.pdf",
    "date_published": "2014-08-08",
    "keywords": "addiction, decision-making, computational modeling, heroin, amphetamine, protracted abstinence, Bayesian data analysis, Widely Applicable Information Criterion (WAIC)",
    "flag": "",
    "chunk_text": ". doi: 10.1037/0033-295X.112.4.862 Watanabe, S. (2010). Asymptotic equivalence of Bayes cross validation and widely applicable information criterion in singular learning theory. J. Mach. Learn. Res. 9999, 3571–3594. Wetzels, R., Vandekerckhove, J., Tuerlinckx, F., and Wagenmakers, E. (2010). Bayesian parameter estimation in the Expectancy Valence model of the Iowa gambling task. J. Math. Psychol. 54, 14–27. doi: 10.1016/j.jmp.2008.12.001 Wise, R. A. (1978). Catecholamine theories of reward: a critical review. Brain Res. 152, 215–247. doi: 10.1016/0006-8993(78)90253-6 Wong, M. M., Nigg, J. T., Zucker, R. A., Puttler, L. I., Fitzgerald, H. E., Jester, J. M., et al. (2006). Behavioral control and resiliency in the onset of alcohol and illicit drug use: a prospective study from preschool to adolescence. Child Dev. 77, 1016–1033. doi: 10.1111/j.1467-8624.2006.00916.x Worthy, D. A., Hawthorne, M. J., and Otto, A. R. (2013a). Heterogeneity of strategy use in the Iowa gambling task: a comparison of win-stay/lose-shift and reinforcement learning models. Psychon. Bull. Rev. 20, 364–371. doi: 10.3758/s13423-012-0324-9 Worthy, D. A., Pang, B., and Byrne, K. A. (2013b). Decomposing the roles of peseveration and expected value representation in models of the Iowa gambling task. Front. Psychol. 4:640. doi: 10.3389/fpsyg.2013.00640 Yechiam, E., and Busemeyer, J. R. (2005). Comparison of basic assumptions embeded in learning models for experience-based decision making. Psychon. Bull. Rev. 12, 387–402. doi: 10.3758/BF03193783 Yechiam, E., and Busemeyer, J. R. (2008). Evaluating generalizability and paraeter consistency in learning models. Games Econ. Behav. 63, 370–394. doi: 10.1016/j.geb.2007.08.011 Yechiam, E., Busemeyer, J. R., Stout, J. C., and Bechara, A. (2005). Using conitive models to map relations between neuropsychological disorders and human decision–making deficits. Psychol. Sci. 16, 973–978. doi: 10.1111/j.1467- 9280.2005.01646.x Yechiam, E., and Ert, E. (2007)",
    "chunk_id": "decision-making_in_stimulant_and_opiate_addicts_in_protracted_abstinence_evidence_from_computational_modeling_with_pure_users.json_chunk_48"
  },
  {
    "document_type": "research_paper",
    "title": "Decision-making in stimulant and opiate addicts in protracted abstinence: evidence from computational modeling with pure users",
    "author": "Jasmin Vassileva",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Ahn-2014-Decision-making-in-stimulant-and-op.pdf",
    "date_published": "2014-08-08",
    "keywords": "addiction, decision-making, computational modeling, heroin, amphetamine, protracted abstinence, Bayesian data analysis, Widely Applicable Information Criterion (WAIC)",
    "flag": "",
    "chunk_text": ". Psychol. Sci. 16, 973–978. doi: 10.1111/j.1467- 9280.2005.01646.x Yechiam, E., and Ert, E. (2007). Evaluating the reliance on past choices in adaptive learning models. J. Math. Psychol. 51, 75–84. doi: 10.1016/j.jmp.2006.11.002 Yuferov, V., Levran, O., Proudnikov, D., Nielsen, D. A., and Kreek, M. J. (2010). Search for genetic markers and functional variants involved in the development of opiate and cocaine addiction and treatment. Ann. N.Y. Acad. Sci. 1187, 184–207. doi: 10.1111/j.1749-6632.2009.05275.x Conflict of Interest Statement: The authors declare that the research was coducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest. Received: 11 April 2014; accepted: 17 July 2014; published online: 12 August 2014. Citation: Ahn W-Y, Vasilev G, Lee S-H, Busemeyer JR, Kruschke JK, Bechara A and Vassileva J (2014) Decision-making in stimulant and opiate addicts in protracted abstinence: evidence from computational modeling with pure users. Front. Psychol. 5 :849. doi: 10.3389/fpsyg.2014.00849 This article was submitted to Decision Neuroscience, a section of the journal Frontiers in Psychology. Copyright © 2014 Ahn, Vasilev, Lee, Busemeyer, Kruschke, Bechara and Vassileva. This is an open-access article distributed under the terms of the Creative Commons Attribution License (CC BY). The use, distribution or reproduction in other forums is permitted, provided the original author(s) or licensor are credited and that the original publication in this journal is cited, in accordance with accepted academic practice. No use, distribution or reproduction is permitted which does not comply with these terms.",
    "chunk_id": "decision-making_in_stimulant_and_opiate_addicts_in_protracted_abstinence_evidence_from_computational_modeling_with_pure_users.json_chunk_49"
  },
  {
    "document_type": "research_paper",
    "title": "Decision and Choice: Luce’s Choice Axiom",
    "author": "Timothy J. Pleskac",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Decision_and_Choice_Luce_s_Choice_Axiom.pdf",
    "date_published": "2014-02-14",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": "Decision and Choice: Luce’s Choice Axiom Timothy J. Pleskac ∗ Department of Psychology, Michigan State University September 23, 2012 Abstract Luce’s choice axiom (LCA) is a theory of individual choice behavior that has proven to be a powerful tool in the behavioral sciences for over 50 years. LCA is grounded in two fundamental properties: choice is probabilistic and the probability of choosing an option from one set of alternatives is related to the probability of choosing the same option from a different set. This entry reviews the basic properties of LCA. It also discusses crucial tests of predictions derived from LCA regarding the role of context. The historical connections of LCA and crucial applications of LCA are also reviewed. Keywords: decision; choice; psychology; economics; preference; learning; axiomatic; Luce; probability; stochastic; context; mathemaical model; 1 Introduction A subject in a psychology experiment (animal or human) identifies which of two stimuli are brighter; a diner at a restaurant selects a meal from a menu; an eyewitness determines a face in a line up. These are all specific examples ∗ Email: pleskact@msu.edu; Phone: (517) 303-5743. A grant from the National Science Foundation (0955410) supported this work. The author wishes to thank Mitchell Uitvlugt and Patrycja Zdziarska for help in editing the submission. 1 of a general behavior called choice where an individual selects one option from a larger set of alternatives. Owing to the generality of choice behavior, many different areas of the scial sciences have sought a mathematical description of choice. Luce’s (1959) choice axiom (LCA) is one such description of individual choice behavior. As Estes (1997) describes it, Luce, in developing a theory of individual choice behavior, did not take the standard approach of psychology",
    "chunk_id": "decision_and_choice_luce_s_choice_axiom.json_chunk_1"
  },
  {
    "document_type": "research_paper",
    "title": "Decision and Choice: Luce’s Choice Axiom",
    "author": "Timothy J. Pleskac",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Decision_and_Choice_Luce_s_Choice_Axiom.pdf",
    "date_published": "2014-02-14",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". As Estes (1997) describes it, Luce, in developing a theory of individual choice behavior, did not take the standard approach of psychology. 1 Instead of working from the bottom-up accumulating empirical data on a phenomenon of interest and eventually arriving at a general theory of choice behavior, Luce took the approach of theoretical physics and worked from the top-down. He employed intuition and reason to find a set of general assumptions that if true would allow the development of a theory and mathematical model usful for interpreting and understanding choice behavior. In short, LCA helped usher in the axiomatic method into psychology and more broadly the social sciences. Luce started with two basic tenets of individual choice behavior: (a) it is probabilistic; and (b) the probability of choosing an option from one set of alternatives is related to the probability of choosing the same option from a larger set of alternatives. The tenet that choice behavior is probabilistic is in contrast to assuming choice is deterministic. To understand this distinction, consider a situation where an agent chooses an option x from the set of alternatives T (e.g., possible entrees on a menu). Focusing on the special case of 2-alternative forced choice or paired comparison, deterministic theories assume a binary preference relation ≺ that is either true or false for any pair of alternatives, either x ≺ y , y ≺ x , or x ∼ y for all x, y ∈ T where ∼ is indifference. A probabilistic choice theory, like LCA, makes the more psychologically plausible assumption that it is only with some probability that an altenative is selected. Focusing again on a paired comparison, a probabilistic choice theory specifies a probability function P ( x, y ) that maps each pair of alternatives into the closed interval [0 , 1] . LCA is a multi-alternative choice theory so it is not limited to paired comparisons, but is applicable in the more general choice situation specifying the probability that x will be chosen from the set T, P T ( x )",
    "chunk_id": "decision_and_choice_luce_s_choice_axiom.json_chunk_2"
  },
  {
    "document_type": "research_paper",
    "title": "Decision and Choice: Luce’s Choice Axiom",
    "author": "Timothy J. Pleskac",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Decision_and_Choice_Luce_s_Choice_Axiom.pdf",
    "date_published": "2014-02-14",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Regardless, as a probabilistic theory, LCA adheres 1 Evidentally, a draft of the book was distributed as a pamphlet with a red cover during the Social Science Research Council Summer Instiute on Mathematical Training in the Social Scielces at Stanford in the summer of 1957. The pamphlet and the ideas in it were subsequently referred to as the \"red menace\" (Estes, 1997). 2 to the axioms of probability theory. These axioms are 1. For S ⊂ T, 0 ≤ P T ( S ) ≤ 1 2. P T ( T ) = 1 3. If R, S ⊂ T and R ∩ S = 0 , then P T ( R ∪ S ) = P T ( R ) + P T ( S ) . The probability axioms constrain each of the measures P T . The problem is that the axioms themselves offer no connection between measures over diferent sets composed of some of the same alternatives; yet, such a connection seems necessary for a theory of choice. Anecdotally, the probability that one chooses pan seared walleye from the dinner menu at a restaurant certainly seems related to the probability that he or she will choose the same entree from the lunch menu. This observation motivates a second tenet of choice behavior: how decision makers select an option from a smaller set of altenatives is related to how they would choose when the same option is in the context of a larger set of alternatives and vise versa. LCA formalizes this assumption. 2 The Choice Axiom The axiom has two parts. Part 1: If P ( X, Y ) ̸ = 0 , 1 for all x, y ∈ T, then for R ⊂ S ⊂ T P T ( R ) = P S ( R ) P T ( S ) (1) Part 2: If P ( X, Y ) = 0 for some x, y ∈ T, then for S ⊂ T P T ( S ) = P T −{ x } ( S −{ x } ) (2) Working backwards, Part 2 is more or less a housekeeping assumption. It allows alternatives that are never chosen in pairwise choices to be deleted from S without impacting the choice probabilities. If salted whitefish is never chosen in pairwise choices with trout, then in choices between salted whitefish, trout, and walleye, salted whitefish can be safely deleted reducing the choice to trout or walleye",
    "chunk_id": "decision_and_choice_luce_s_choice_axiom.json_chunk_3"
  },
  {
    "document_type": "research_paper",
    "title": "Decision and Choice: Luce’s Choice Axiom",
    "author": "Timothy J. Pleskac",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Decision_and_Choice_Luce_s_Choice_Axiom.pdf",
    "date_published": "2014-02-14",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Part 1 states that the probability of selecting the set of alternatives R (e.g., walleye or trout) from T is equal to the probability of selecting R 3 from S (e.g., walleye, trout, or salmon) multiplied by the probability of selecting S from T. When S = { x, y } then the probability measure P S reduces to a pairwise choice probability mentioned earlier. In other words, Part 1 addresses the issue of formally relating the choice probabilities for subsets of T to those of T itself. Another way to see this is to rewrite Equation 1 as a conditional probability P T ( R | S ) = P S ( R ) = P T ( R ) P T ( S ) (3) where R ⊂ S ⊂ T and P T ( S ) > 0 . Thus, the probability of selecting R from S equals the conditional probability that R is chosen from S when the full set T is available. To be clear, LCA is not an additional probability axiom. Rather, it is an empirical hypothesis that has a number of strong consequences. These consequences have been tested and in some places have been shown not to hold under specific circumstances. Nevertheless, LCA and the mathematical model it implies have proven quite useful in modeling choices whether they be higher level economic decisions or lower level perceptual choices. It has also motivated similar approaches in modeling probability judgments (Tversky & Koehler, 1994). 3 Implications Most well known is that LCA implies that there is a numerical ratio scale v over T such that for every x, y ∈ S ⊂ T the probability of choosing x can be found with the following mathematical model P S ( x ) = v ( x ) ! y ∈ S v ( y ) . (4) Psychologically v ( x ) is a response strength associated with the alternative x. One might see from Equation 4 that one measure of response strength is the observed choice probability v ( x ) = P T ( x ) . Other scales can be created by multiplying P T ( x ) by a positive constant k , v ( x ) = k · P T ( x ) . This means that v is a ratio scale of response strength, a provocative idea in psychology that is beset with ordinal scales",
    "chunk_id": "decision_and_choice_luce_s_choice_axiom.json_chunk_4"
  },
  {
    "document_type": "research_paper",
    "title": "Decision and Choice: Luce’s Choice Axiom",
    "author": "Timothy J. Pleskac",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Decision_and_Choice_Luce_s_Choice_Axiom.pdf",
    "date_published": "2014-02-14",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". This means that v is a ratio scale of response strength, a provocative idea in psychology that is beset with ordinal scales. Equation 4 is an intuitive way to model choice probabilities. So much so that others have proposed it as a model of choice. For example, Bradley 4 & Terry (1952) proposed a model consistent with Equation 4 for pairwise choices (see also Clark, 1957). This straightforward way to model choices via response strength also exposes why LCA has proven important in modeling choices in a variety of domains. Using Equation 4, one can also see that P ( x, y ) P ( y, x ) = P S ( x ) P S ( y ) . (5) This result is because both sides of Equation 5 are equal to v ( x ) v ( y ) . This rlationship is sometimes called the constant ratio rule . The constant ratio rule is a probabilistic form of what is called independence from irrelevant alternatives (Arrow, 1951). It implies that when LCA holds for a set of aternatives T and its subsets the ratio P S ( x ) /P S ( y ) is independent of S . In other words, the ratio of the probability of choosing one alternative to the probability of choosing another should be constant regardless of the set of options (or context). This constant ratio rule is revealing in terms of the strengths and weakness of LCA. A key strength is that pairwise choice probabilities can be predicted from choice probabilities observed in a larger set. A potential weakness is that psychologically the context of the situation (e.g., similarity to other choice alternatives) should impact the probability of choosing an option in some manner. Such a weakness speaks to the validity of LCA, and we will return to this idea in the validity section. LCA also constrains the possible pairwise probabilities. This constraint is known as the product rule which states that for alternatives x, y, z P ( x, y ) · P ( y, z ) · P ( z, x ) = P ( x, z ) · P ( z, y ) · P ( y, x ) . (6) To see how the product rule works, note that the left hand and right hand sides contain complementary pairwise choice probabilities",
    "chunk_id": "decision_and_choice_luce_s_choice_axiom.json_chunk_5"
  },
  {
    "document_type": "research_paper",
    "title": "Decision and Choice: Luce’s Choice Axiom",
    "author": "Timothy J. Pleskac",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Decision_and_Choice_Luce_s_Choice_Axiom.pdf",
    "date_published": "2014-02-14",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". (6) To see how the product rule works, note that the left hand and right hand sides contain complementary pairwise choice probabilities. Consequently, dividing the left hand side by the right hand side produces P ( x, y ) P ( y, x ) · P ( y, z ) P ( z, y ) · P ( z, x ) P ( x, z ) = 1 . (7) Each of the ratios of choice probabilities can, in turn, be rewritten as a ratio of response strengths by Equation 4. This allows each response strength to be cancelled offresulting in the product of the ratios equalling 1. The product 5 rule is another independence condition that implies the response strength for an alternative is the same regardless of the other alternative it is paired with. Just as with the constant ratio rule, the product rule identifies the strengths and potential weaknesses of LCA. The strength is that the product rule allows one to predict the pairwise choice probability P ( x, z ) if P ( x, y ) and P ( y, z ) are both known. The weakness is that again psychologically it seems that the context matters. Again the similarity between two alternatives seems like it should impact the response strength of an option. 4 Historical Connections LCA has a number of connections to other choice models. Perhaps most prominent is the connection to L.L. Thurstone’s (1927) law of comparative judgment. This theory assumes that alternatives have numerical psycholoical values that vary randomly from one choice occasion to another (i.e., the values are random variables). The decision maker is assumed to compare these values in order to make a choice. More precisely, if the psychological value of the alternatives x 1 , , x N are the random variables U 1 , U N , the probability of choosing x i from any set S is the probability that U i is currently the largest of the random variables { U j : x j ∈ S } . The most prominent vesion of Thurstone’s theory is Case V, which assumes the psychological values are normally, independent and identically distributed",
    "chunk_id": "decision_and_choice_luce_s_choice_axiom.json_chunk_6"
  },
  {
    "document_type": "research_paper",
    "title": "Decision and Choice: Luce’s Choice Axiom",
    "author": "Timothy J. Pleskac",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Decision_and_Choice_Luce_s_Choice_Axiom.pdf",
    "date_published": "2014-02-14",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". The most prominent vesion of Thurstone’s theory is Case V, which assumes the psychological values are normally, independent and identically distributed. This means U i can be rewritten as u i + ǫ i , where u i is a real constant (i.e., a scale value) and ǫ i is normally distributed with a mean of 0 and variance of 1, ǫ i ∼ N (0 , 1) . Luce (1959) showed that LCA and Case V make nearly identical preditions for pairwise choice probabilities: the numerical predictions were offby at most .02. In fact, if the differences between the psychological values have a logistic distribution rather than a normal distribution, then Thurstone’s law of comparative judgment and LCA make identical predictions (Adams & Messick, 1957). What Holman and Marley (cited in Luce & Suppes, 1965) subsequently showed is that a logistic distribution of differences arises in Thurstone’s (1927) framework if the normal random variables ǫ i are replaced by independent random variables that have a double exponential probability distribution. Yellott (1977), in the spirit of Luce’s top-down axiomatic approach, idetified an intuitively plausible assumption that would lead one to conclude the random variables ǫ i are double exponentially distributed. The assum6 tion is grounded in the property that that the asymptotic distribution of the maximum of n independent, identically distributed random variables is the double exponential when the underlying distribution has an upper exponetial tail. Using this property, Yellott proposed a thought experiment in which there are three basic alternatives, for example, beverages on a table: coffee, tea, and milk. Instead of 1 cup of each on the table, consider a situation like a party where there are n identical cups of coffee, n cups of tea, and n glasses of milk. One would expect that the probability of choosing any one of the beverages should be independent of n or how many replicas there are",
    "chunk_id": "decision_and_choice_luce_s_choice_axiom.json_chunk_7"
  },
  {
    "document_type": "research_paper",
    "title": "Decision and Choice: Luce’s Choice Axiom",
    "author": "Timothy J. Pleskac",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Decision_and_Choice_Luce_s_Choice_Axiom.pdf",
    "date_published": "2014-02-14",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". One would expect that the probability of choosing any one of the beverages should be independent of n or how many replicas there are. In fact, if this invariance assumption is met, then the distribution in a Thurstone model must be a double exponential and, as a result, LCA must hold. In the words of Luce (1977), \"Yellott’s condition is so compelling that this theorem means Thurstone’s modeland the choice axiom stand or fall together\" (p. 218). LCA also connects with a number of other models in experimental pschology. This came primarily via what is called the similarity choice model (Estes, 1997). This model is a generalization of the choice model in Equation 4 that Luce (1959) developed to account for response bias and later fully dveloped in Luce (1963) (see also Shipley, 1960). The similarity choice model decomposes the response strength v into two ratio scales representing two constructs of high interest to psychologists: discriminability and response bias. To see the extension, consider the situation where a participant in a psychology experiment must choose a response R j upon presentation of a stimulus V i (e.g., identify a letter upon the presentation of an obscured letter stimulus). The similarity choice model states the response probability is P i,j = M i,j · b j ! k M i,k · b k . (8) The scale value M i,j represents the similarity between stimulus V i and the stimulus corresponding with the response j , V j . The other scale value b j measures a subject’s bias to choose response j regardless of the stimulus. It should be noted that the similarity choice model is a generalization of the choice model (Equation 4), but not necessarily the axiom itself (Luce, 1963). Despite this restriction the similarity choice model can easily have some of the same context-free assumptions of LCA. The similarity choice model provided researchers with an alternative and more convenient means to model discriminability and response bias than with signal detection theory (Tanner & Swets, 1954)",
    "chunk_id": "decision_and_choice_luce_s_choice_axiom.json_chunk_8"
  },
  {
    "document_type": "research_paper",
    "title": "Decision and Choice: Luce’s Choice Axiom",
    "author": "Timothy J. Pleskac",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Decision_and_Choice_Luce_s_Choice_Axiom.pdf",
    "date_published": "2014-02-14",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". The similarity choice model provided researchers with an alternative and more convenient means to model discriminability and response bias than with signal detection theory (Tanner & Swets, 1954). This convenience facilitated the incorporation of the 7 similarity choice model as a choice rule into more complex models of cognitive processes including identification, recognition memory, categorization, and categorization learning (see Estes, 1997). 5 Validity of LCA The value of the axiomatic approach that underlies LCA is that it establishes precise and testable conditions that help establish when a theory is applicable and when it is not. In the case of LCA, examples were almost immediately identified that questioned its validity. One of the first examples came from Gerald Debreu (1960) in his pulished review of Individual Choice Behavior . 2 The example is as follows. Cosider a classical music lover who is choosing between a recording of the Dbussy quartet (option D ) and two different recordings of Beethoven’s Eighth Symphony (option B 1 and option B 2 ). For this example, assume the two Beethoven recordings are of equal quality (e.g., played by the same orchestra, but under the direction of different conductors). Lets assume the music lover is torn between adding a Debussy or a Beethoven recording to his collection. Therefore, in pairwise choices P ( B 1 , B 2 ) = P ( D, B 1 ) = P ( D, B 2 ) = 1 / 2 . LCA thus implies that when presented with the set S of all three options { D, B 1 , B 2 } simultaneously that P S ( D ) = 1 / 3 . However, this conclusion is not quite right intuitively. When the choice is between all three it seems that the choice is between Debussy or Beethoven. Put differently, P S ( D ) should remain closer to 1 / 2 while choice probability for the two Beethoven recordings should be split equally moving them closer to 1/4. Empirically, at least in preferential tasks, this is what happens and Tversky (1972) called this the similarity effect",
    "chunk_id": "decision_and_choice_luce_s_choice_axiom.json_chunk_9"
  },
  {
    "document_type": "research_paper",
    "title": "Decision and Choice: Luce’s Choice Axiom",
    "author": "Timothy J. Pleskac",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Decision_and_Choice_Luce_s_Choice_Axiom.pdf",
    "date_published": "2014-02-14",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Empirically, at least in preferential tasks, this is what happens and Tversky (1972) called this the similarity effect. 3 The similarity effect is inconsistent with the constant ratio rule of LCA (Equation 4). The implication of the similarity effect is actually stronger in that it is inconsistent with any probabilistic choice theory that assumes choice probability is a monotone function of scale values also known as simple scalability models (Tversky, 1972). 4 Generalizations of LCA can be developed to account for the similarity 2 A famous adaptation of Debreu’s example is the red-bus–blue-bus problem in tranportation research (Train, 2003). 3 Tversky (1972) found violations when subjets were asked to make choices between college applicants and gambles. However, the violations in a perceptual task of judging 8 Figure 1: A graphical representation of 3 alternatives each composed of a set of unique and shared aspects. effect. For example, Tversky (1972) proposed an alternative choice process called elimination by aspects where alternatives are sets of attributes or apects. Figure 5 depicts a three alternative set T = { a, b, d } . The aspects α β and δ are unique to alternatives a, b, and d , respectively. The other aspects αβ, αδ, and βδ are shared. Each aspect has a scale value u representing its utility. Because of the elimination by aspect assumption of the theory, apects shared among all alternatives are not used in this choice rule, hence the central area in Figure 5 is unlabeled. The basic idea in the theory is that an aspect is attended to with some probability (e.g., Beethoven). This probability is proportional to its utility relative to the sum of all the utilities K. For example, the probability of selecting αβ is u ( αβ ) /K. Alternatives that do not have that aspect (e.g., d ) are then eliminated and the probability of selecting say a is the pairwise choice probability scaled from the remaining aspects P ( a, b ) = u ( α ) + u ( αδ ) u ( α ) + u ( αδ ) + u ( β ) + u ( βδ )",
    "chunk_id": "decision_and_choice_luce_s_choice_axiom.json_chunk_10"
  },
  {
    "document_type": "research_paper",
    "title": "Decision and Choice: Luce’s Choice Axiom",
    "author": "Timothy J. Pleskac",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Decision_and_Choice_Luce_s_Choice_Axiom.pdf",
    "date_published": "2014-02-14",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". (9) In other words, elimination by aspects is consistent with one’s intuitive readot numeroscity were not statistically significant. 4 Similarity between alternatives also impacts pairwise choice probabilities and leads to violations of the product rule and other independence assumptions (Rumelhart & Greeno, 1971; Tversky & Russo, 1969). 9 tion to the Debreu’s (1960) Debussy/Beethoven example: after an alternative is eliminated choice probability gets divided among the remaining alternative. If an aspect is attended to that is unique to a particular alternative (e.g., α ), then the corresponding alternative (e.g., a ) is selected with probability 1. Thus, the probability of selecting alternative a from T is P T ( a ) = u ( α ) + u ( αβ ) · P ( a, b ) + u ( αδ ) · P ( a, d ) K . (10) Elimination by aspects is one hypothesis of how the similarity between the alternatives (i.e., shared aspects) interacts with the choice process. Using Figure 5, one can also see how elimination by aspects is a generalization of LCA: if alternatives are pairwise disjoint (i.e., no shared aspects between pairs of alternatives) then the predicted choice probabilities are consistent with LCA (Tversky, 1972). More broadly, the similarity effect demonstrates that context matters: the response strength of an alternative depends on the options that are in the choice set. Over the years, other context effects have been identified and studied that further attest to the importance of context (Rieskamp et al., 2006). A second context effect that questions the validity of LCA (as well as elimination by aspects) is known as the attraction effect. The attraction effect can be illustrated with an example from Simonson & Tversky (1992). They gave one group of subjects a choice between $6 and a nice Cross pen. The pen was chosen by 36% of the subjects while the remaining 64% chose $6. A second group was given a choice between three options: $6, a nice Cross pen, or another less attractive pen",
    "chunk_id": "decision_and_choice_luce_s_choice_axiom.json_chunk_11"
  },
  {
    "document_type": "research_paper",
    "title": "Decision and Choice: Luce’s Choice Axiom",
    "author": "Timothy J. Pleskac",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Decision_and_Choice_Luce_s_Choice_Axiom.pdf",
    "date_published": "2014-02-14",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". The pen was chosen by 36% of the subjects while the remaining 64% chose $6. A second group was given a choice between three options: $6, a nice Cross pen, or another less attractive pen. As one might expect, only 2% chose the less attractive pen. Yet, the mere addition of this asymmetrically dominated alternative boosted the proportion of subjects who chose the Cross pen to 46% (an increase of 33%). This behavior -no doubt well known among marketers and salespeopldoes not seem quite right from the view point of LCA and, for that matter, most probabilistic theories of choice: adding an alternative to a choice set of even minuscule value should reduce choice probabilities for the all the alternatives, not increase them. This condition is known as regularity. Stated formally for x ∈ S ⊂ T , P S ( x ) > P T ( x ) . The attraction effect demonstrates that in particular situations individuals violate regularity. A third context effect is the compromise effect. This effect can be demostrated with another example from Simonson & Tversky (1992) where paticipants made choices between hypothetical cameras. Camera A was high in 10 quality and price while Camera B was low in quality and price. Cameral C had intermediate quality and price. In pairwise probabilities, P ( A |{ A, C } = P ( C |{ A, C } ) . However, when Camera B at the other extreme is added to the choice set P ( C |{ A, C, B } ) > P ( A |{ A, C, B } ) . The compromise effect is another violation of independence from irrelevant alternatives. It quetions the validity of LCA as well as elimination by aspects (for a proof see Rieskamp et al., 2006). These empirical effects identify limitations of LCA as a model of human choice behavior. In particular, they demonstrate a third tenet of choice bhavior is that context does matter and it shape how individuals value an alternative. There are different psychological explanations for the role of context. Nevertheless, LCA and the choice rule that it implies have pesisted as a useful model of individual choice behavior",
    "chunk_id": "decision_and_choice_luce_s_choice_axiom.json_chunk_12"
  },
  {
    "document_type": "research_paper",
    "title": "Decision and Choice: Luce’s Choice Axiom",
    "author": "Timothy J. Pleskac",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Decision_and_Choice_Luce_s_Choice_Axiom.pdf",
    "date_published": "2014-02-14",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". There are different psychological explanations for the role of context. Nevertheless, LCA and the choice rule that it implies have pesisted as a useful model of individual choice behavior. There are at least two reasons for this. First, the basic idea that choice probability is monotonic with a response strength is intuitively quite plausible and one that has geerally persisted even as alternative models have been proposed to account for context effects. Second, the axiom and the choice rule are elegantly simple, allowing for both easy implication and easy explanation. 6 Applications in Preferential Decisions As the previous section examining the validity of LCA illustrates, there has been great interest in applying LCA to preferential choices. These are choices made over money and other alternatives (e.g., cameras, records, commuting routes, etc.) where there is no objectively correct answer. Luce (1959) very much anticipated applications of LCA and the choice rule in this domain, but great strides were made when (c.f., McFadden, 1976, 2001) developed an economic version of Luce’s choice model in the multinomial logit model. Formally, the probability of choosing alternative x from set S is P S ( x ) = exp [ u ( x )] ! y ∈ S exp [ u ( y )] , (11) where u ( x ) is the utility of alternative x and is a linear function of the attributes of x . The multinomial logit model proved useful in economic data analysis, but it is also connected to what are called random utility models. This connection 11 perfectly echoes the connection between LCA and Thurstonian choice moels discussed earlier. Random utility models -akin to Thurstonian modelassume the utility of an alternative is a random variable. McFadden (1976), independent from Yellott (1977), showed that if the linear combination of attributes has an error component that is identically and independently ditributed following an extreme value distribution (i.e., double exponential), then the result is the multinomial logit model",
    "chunk_id": "decision_and_choice_luce_s_choice_axiom.json_chunk_13"
  },
  {
    "document_type": "research_paper",
    "title": "Decision and Choice: Luce’s Choice Axiom",
    "author": "Timothy J. Pleskac",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Decision_and_Choice_Luce_s_Choice_Axiom.pdf",
    "date_published": "2014-02-14",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". The multinomial logit model has become one of the most common random utility models (Train, 2003). LCA has also contributed heavily in the further development of descritive theories of preferential choice (Rieskamp et al., 2006). In this area, the formal attributes of LCA have proven indispensable in forming testable hpotheses about how individuals make a choice. Doing so has validated the core tenets of LCA (i.e., choice is probabilistic and there is a connection between the propensity to choose alternatives between contexts). At the same time, as discussed in the previous section, LCA very much helped ucover other tenets such as the context dependence of choice. Psychologists and decision scientists have, in turn, sought to develop other formal theories that better account for these tenets. Examples (among others) include the context-dependent advantage model (Tversky & Simonson, 1993), decision field theory (Roe et al., 2001), and the leaky accumulator model (Usher & McClelland, 2004). The latter two theories perhaps represent the greatest departure from LCA in that they are grounded in a sequential sampling acount of choice. Such a move allows for the theories to describe both choice probabilities and the time taken to make a choice. This is an important step as perhaps a fourth tenet of choice behavior is that the process of making a choice takes time, a property LCA is silent on. One final application of LCA in preferential choices comes in the area of strategic games and game theory (McKelvey & Palphrey, 1995). Strategic games are situations when entities must decide how to act during interactions with other entities. Examples include two tennis players opposing each other in a match, roommates waiting for the other to purchase kitchen supplies, or research and development expenditures by competing pharmaceutical copanies. These are all examples of interactions where how one entity decides to act affects the outcomes of the other and vise versa",
    "chunk_id": "decision_and_choice_luce_s_choice_axiom.json_chunk_14"
  },
  {
    "document_type": "research_paper",
    "title": "Decision and Choice: Luce’s Choice Axiom",
    "author": "Timothy J. Pleskac",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Decision_and_Choice_Luce_s_Choice_Axiom.pdf",
    "date_published": "2014-02-14",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". These are all examples of interactions where how one entity decides to act affects the outcomes of the other and vise versa. This interaction is what distinguishes strategic games from the individual decisions where the outcomes an individual receives do not depend on the decisions of others. In game theory, each individual chooses among an action or strategy based on the utility of the outcomes that are expected to come from employing that 12 strategy. Typically the choice between strategies in game theory is deteministic. McKelvey & Palphrey (1995) adapted the multinomial logit model (Equation 11) to move away from the deterministic assumption to one where players probabilistically choose among their strategies and assume their oponents do so as well. The advantage of adapting a probabilistic choice rule in strategic games is two-fold. The first advantage is that the probabilistic choice rule provides a more psychologically plausible assumption than a deterministic selection of a strategy. This allows the best equilibrium strategy to be played more often than others (but not always). The second and related advantage is that this can aid in data analysis of games where observed behavior is probabilistic allowing measurement of interesting phenomena like learning during repeated play. 7 Applications in Learning Luce (1959) also discussed LCA’s application in modeling learning. Learning has long been of interest in the area of choice whether it be modeling the behavior of rats in a T-Maze as they learn a route to food or more recently a participant in a psychology experiment choosing repeatedly between gambles that deliver a reward and/or punishment with unknown probabilities. Luce’s idea called the beta model postulated operators that adjust the response strength of each alternative (e.g., v ( x ) ) rather than adjusting the choice probabilities. More formally, during a learning experiment on each trial n each alternative x ∈ S has a response strength v n ( x )",
    "chunk_id": "decision_and_choice_luce_s_choice_axiom.json_chunk_15"
  },
  {
    "document_type": "research_paper",
    "title": "Decision and Choice: Luce’s Choice Axiom",
    "author": "Timothy J. Pleskac",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Decision_and_Choice_Luce_s_Choice_Axiom.pdf",
    "date_published": "2014-02-14",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". More formally, during a learning experiment on each trial n each alternative x ∈ S has a response strength v n ( x ) . If alternative x was selected on trial n then the response strength for trial n + 1 is updated. To make a choice on the trial n + 1 the individual then uses the choice rule described in Equation 4. Thus, in the beta model, LCA is assumed to hold on any given trial, but between trails the probability changes via adjustments in response strength. This same basic idea is implemented in recent reinforcement learning algorithms that have become popular in a variety of areas including machine learning, control theory, game theory, and neuroscience. Perhaps the closest relation is with the Q-learning algorithm. According to this algorithm, after an agent selects an alternative x , the agent uses the experienced reward to update an expectation Q ( x ) for alternative x (Sutton & Barto, 1998). To make a choice between the available alternatives in the set S the algorithm 13 uses the following rule sometimes called softmax P ( x ) = exp [ Q ( x ) /τ ] ! y ∈ S exp [ Q ( y ) /τ ] . (12) The rule is a particular instance of Equation 4. The parameter τ moderates the degree to which the agent chooses the alternative with the largest expetation. As τ increases, the agent is less likely to choose the option with the largest expectation and instead explore other alternatives. Note unlike the similarity choice model (Equation 8), τ is not specific to the alternative so it characterizes general exploration rather than a bias to a specific alternative. In general, this means the probabilistic choice rule provides a mechanism to tradeoffbetween selecting an alternative that provides an immediate immdiate payoff(exploit) or selecting an alternative that provides information to develop an expectation about future choices (explore). Neuroscientists are beginning to understand the neural basis of these learning mechanisms (Niv, 2009)",
    "chunk_id": "decision_and_choice_luce_s_choice_axiom.json_chunk_16"
  },
  {
    "document_type": "research_paper",
    "title": "Decision and Choice: Luce’s Choice Axiom",
    "author": "Timothy J. Pleskac",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Decision_and_Choice_Luce_s_Choice_Axiom.pdf",
    "date_published": "2014-02-14",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Neuroscientists are beginning to understand the neural basis of these learning mechanisms (Niv, 2009). The softmax expression, in particular, has proved useful in begining to understand the neural mechanisms underlying the tradeoffbetween exploration and exploitation (Daw et al., 2006). Finally, these learning mecanisms with the softmax rule have are being integrated into larger cognitive architectures (Fu & Anderson, 2006). 8 Future Directions and Conclusion LCA challenged conventional theories of choice to move from a deterministic account to a probabilistic one. In so doing, LCA has proved to be a power and useful tool in the modeling toolboxes of social and cognitive scientists for over 50 years. A search among scholarly articles is certain to reveal its vast impact. Yet, there are still areas that are left to be explored with LCA and the accompanying mathematical model of choice. Behaviorally, one area that Luce (1959) discussed and has still remained largely unexplored is in the area of ranking alternatives. Luce (1959) proposed one way to adapt LCA to ranking where the individual essentially makes a series of covert choice first picking say the best alternative from the set, then the second best alternative from remaining items, and so on. This is called forward ranking. Another procedure called backward ranking works the opposite direction picking the worst, next worst and so on. Both procedures seem intuitively plausible; however, forward and backward ranking do not lead to the same solution 14 (Luce, 1959). For current work in this area see Marley & Louviere (2005) and Lee et al. (2012). As decision theorists continue to reconcile with the theoretical implictions of probabilistic choice behavior there are certainly more and more chalenges",
    "chunk_id": "decision_and_choice_luce_s_choice_axiom.json_chunk_17"
  },
  {
    "document_type": "research_paper",
    "title": "Decision and Choice: Luce’s Choice Axiom",
    "author": "Timothy J. Pleskac",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Decision_and_Choice_Luce_s_Choice_Axiom.pdf",
    "date_published": "2014-02-14",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". (2012). As decision theorists continue to reconcile with the theoretical implictions of probabilistic choice behavior there are certainly more and more chalenges. One challenge is a psychological one, which is to continue to develop a theory of choice behavior that is grounded in some of the core tenets of LCA (i.e., choice is probabilistic and that there is a relationship in how peple choose between contexts), but also reflects other important properties like the context dependence and time course of choice. A second challenge is a neural one, which is to understand the neural circuitry underlying choice behavior (Gold & Shadlen, 2007). A final challenge is a statistical one, which is to develop appropriate statistical methodology to to test probabilistic thories of choice appropriate variability in choice behavior Regenwetter et al. (2011). These are just some of the challenge we face. Regardless, LCA via its simple elegance is certain to continue to be an invaluable tool in helping us understand individual choice behavior. 9 Cross Reference • behavioral decision research • bounded rationality • heuristics for decision and choice • strategic and decision heuristics • economic psychology • paradoxes of choice • random utility models of choice and response time • utility and subjective probability • dynamic decision making • game theory • signal detection theory 15 • stochastic dynamic models • recognition",
    "chunk_id": "decision_and_choice_luce_s_choice_axiom.json_chunk_18"
  },
  {
    "document_type": "AU_course_page",
    "title": "Decision Making",
    "author": "Aarhus University",
    "source": "https://kursuskatalog.au.dk/en/course/123488/Decision-making",
    "flag": "",
    "date_published": "Unknown",
    "chunk_text": "Decision making Autumn semester 2024 Course Catalogue Save course ECTS 10 Forms of instruction Lecture etc. Form of examination Take-home assignment (Assign) Language of instruction English Level Master Location Aarhus Use arrow keys on your keyboard to explore Course content Read more see description of qualifications. Description of qualifications Read more Purpose: The purpose of the course is 1) to develop students’ knowledge of judgment, decision-making, and choice processes; 2) to develop students’ knowledge of decision making in relation to other cognitive functions (e.g. learning, memory, attention, social cognition); and 3) to introduce applied use cases for decision-making research. The course includes basic revision of important conceptual theories of judgment, decision-making, and choice; discussion of the psychological components of decision-making (e.g. learning, memory, attention, social cognition); discussion of philosophical, theoretical, and normative frameworks for assessing the quality of decision-making; and discussion of domains in which decision making research may be applied. The course provides students with conceptual knowledge to understand cognitive processes in judgement, choice, and decision making. These topics may also be covered in the advanced cognitive neuroscience course, and they may be revisited in advanced cognitive modelling. Academic objectives: In the evaluation of the student’s performance, emphasis is placed on the extent to which the student is able to: Knowledge: - explain conceptual theories of decision-making - explain how decision making relates to other cognitive processes - explain how empirical research on decision making relates to theory. Skills: - use philosophical, theoretical, or normative frameworks to assess decision making - analyze experimental methodologies relevant for evaluating theories of decision making. Competences: - apply conceptual theories, normative frameworks, or formal methods learned in the course to real world decision making",
    "chunk_id": "decision_making.json_chunk_1"
  },
  {
    "document_type": "AU_course_page",
    "title": "Decision Making",
    "author": "Aarhus University",
    "source": "https://kursuskatalog.au.dk/en/course/123488/Decision-making",
    "flag": "",
    "date_published": "Unknown",
    "chunk_text": ". Competences: - apply conceptual theories, normative frameworks, or formal methods learned in the course to real world decision making. See all ECTS 10 Level Master Semester MA, 1st semester Language of instruction English Hours - week - period Time and place will be announced no later than at the start of the semester here: https://timetable.au.dk/schedule Type of course Ordinary Primary programme Master's Degree Programme in Cognitive Science Department School of Communication and Culture Faculty Arts Location Aarhus STADS UVA code 147222U004 Copy UVA code Teaching Forms of instruction Lecture and classroom instruction Instructor See all Andreas Højlund Institut for Kommunikation og Kultur - Kognitionsvidenskab Comments on the form of instruction Read more Lectures and classroom instructions. Language of instruction: The rules governing language of exam and teaching are stated in section 2.1 of the academic regulations. Literature Read more Will be announced on Brightspace at the start of the semester. Examination Form of examination Take-home assignment on topic of student's choice Form of co-examination External co-examination Assessment 7-point grading scale Permitted exam aids Not specified Comments Read more Ordinary exam and re-examination: The exam is a take-home assignment on a topic of the student’s choice. The topic and method used in the assignment must be relevant in relation to the content of the course and is subject to the approval of the teacher. The assignment can be written individually or in groups of up to 4 students. Group assignments must be written in such a way that the contribution of each student, except for the introduction, thesis statement and conclusion, can form the basis of individual assessment. The assignment should clearly state which student is responsible for which section",
    "chunk_id": "decision_making.json_chunk_2"
  },
  {
    "document_type": "AU_course_page",
    "title": "Decision Making",
    "author": "Aarhus University",
    "source": "https://kursuskatalog.au.dk/en/course/123488/Decision-making",
    "flag": "",
    "date_published": "Unknown",
    "chunk_text": ". The assignment should clearly state which student is responsible for which section. Length for one student: 12-15 standard pages Length for two students: 19-25 standard pages Length for three students: 26-35 standard pages Length for four students: 33-45 standard pages The assignment must be submitted for assessment in WISEflow before the deadline set in the examination plan.",
    "chunk_id": "decision_making.json_chunk_3"
  },
  {
    "document_type": "online_article",
    "title": "Getting Started with JAGS, rjags, and Bayesian Modelling",
    "author": "Unknown",
    "source": "https://www.r-bloggers.com/2012/04/getting-started-with-jags-rjags-and-bayesian-modelling/",
    "date_published": "2012-04-11 05:50:00+00:00",
    "flag": "",
    "chunk_text": "Posted onApril 10, 2012byJeromy AngliminR bloggers| 0 Comments [This article was first published onJeromy Anglim's Blog: Psychology and Statistics, and kindly contributed toR-bloggers]. (You can report issue about the content on this pagehere)Want to share your content on R-bloggers?click hereif you have a blog, orhereif you don't. This post provides links to various resources on getting started with Bayesian modelling using JAGS and R. It discusses: (1) what is JAGS; (2) why you might want to perform Bayesian modelling using JAGS; (3) how to install JAGS; (4) where to find further information on JAGS; (5) where to find examples of JAGS scripts in action; (6) where to ask questions; and (7) some interesting psychological applications of Bayesian modelling. JAGS stands for Just Another Gibbs Sampler. To quote the program author, Martyn Plummer, “It is a program for analysis of Bayesian hierarchical models using Markov Chain Monte Carlo (MCMC) simulation” It uses a dialect of the BUGS language, similar but a little different to OpenBUGS and WinBUGS. The question of why you might want to use JAGS can be approached in several different ways: Why Bayesian rather than Null Hypothesis Significance Testing (NHST) approaches? Why JAGS/BUGS rather than coding in a low-level language? Why JAGS rather than WinBUGS or OpenBUGS? http://stats.stackexchange.com/questions/9202/openbugs-vs-jags More than anything I found that JAGS provided a useful entry point into the world of Bayesian modelling. This in turn appealed to me for several reasons: JAGS runs on Linux, Mac, and Windows. I run JAGS on Ubuntu through an interface with R calledrjags. The following sets out a basic installation process: Themanual for different versions of JAGS is located here. e.g.,the pdf of the manual for 3.1.0. Several particularly relevant sections include: Therjagshelp pdffor information about how to interface with JAGS from R",
    "chunk_id": "getting_started_with_jags,_rjags,_and_bayesian_modelling.json_chunk_1"
  },
  {
    "document_type": "online_article",
    "title": "Getting Started with JAGS, rjags, and Bayesian Modelling",
    "author": "Unknown",
    "source": "https://www.r-bloggers.com/2012/04/getting-started-with-jags-rjags-and-bayesian-modelling/",
    "date_published": "2012-04-11 05:50:00+00:00",
    "flag": "",
    "chunk_text": ". e.g.,the pdf of the manual for 3.1.0. Several particularly relevant sections include: Therjagshelp pdffor information about how to interface with JAGS from R. http://cran.r-project.org/web/views/Bayesian.html http://www.stat.columbia.edu/~gelman/bayescomputation/lunnbugswithcomments.pdf I find it easier to pick up a new language by playing with examples. The following provides links to example JAGS code, often with accompanying explanations: John Myles White John K. Kruschke BUGS Project Patrick J Mineault Miguel Lobo Simon Jackman Johannes Karreth Myself More broadly, examples and tutorials designed for WinBUGS can generally be adapted to be useful for JAGS. So for example, you can explore these WinBUGS examples: There are several places to ask questions about JAGS, R, and Bayesian statistics. In general, I prefer the Stack Exchange model for asking and answering questions on the internet, although the most important issue is typically where the experts are located. If you want to see some examples of Bayesian modelling applied to psychological data, I found the following articles quite interesting. PDFs are available online. If you know of any other interesting JAGS resources or have any comments about my choice of software for Bayesian data analysis, feel free to post a comment. Toleave a commentfor the author, please follow the link and comment on their blog:Jeromy Anglim's Blog: Psychology and Statistics.R-bloggers.comoffersdaily e-mail updatesaboutRnews and tutorials aboutlearning Rand many other topics.Click here if you're looking to post or find an R/data-science job.Want to share your content on R-bloggers?click hereif you have a blog, orhereif you don't. Copyright © 2022 |MH Corporate basic by MH Themes",
    "chunk_id": "getting_started_with_jags,_rjags,_and_bayesian_modelling.json_chunk_2"
  },
  {
    "document_type": "book",
    "title": "The Book of Why - chapter 1",
    "author": "Dana Mackenzie",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Book_of_why_chapter_1.pdf",
    "date_published": "2017-10-17",
    "keywords": "",
    "flag": "",
    "chunk_text": "The Book of Why: The New Science of Cause and Effect – Pearl and Mackenzie 1 Chapter 1: The Ladder of Causation In the BeginningI was probably six or seven years old when I first read the story of Adam and Eve in the Garden of Eden. My classmates and I were not at all surprised by God’s capricious demands, forbidding Adam from eating from the Tree of Knowledge. Deities have their reasons, we thought. What we were more intrigued by was the idea that as soon as they ate from the Tree of Knowledge, Adam and Eve became conscious, like us, of their nakedness. As teenagers, our interest shifted slowly to the more philosophical sides of the story. (In Israeli schools, Genesis is read several times a year.) Of primary concern to us was the notion that the emergence of human knowledge was not a joyful process but a painful one, accompanied by disobedience, guilt, and punishment. Was it worth giving up the carefree life of Eden? Some asked. Were the agricultural and scientific revolutions that followed worth the economic hardships, military conquests, and social injustices that modern life entails? Don’t get me wrong: we were no creationists; even our teachers were Darwinists at heart. We knew, however, that the author who choreographed the story of Genesis struggled to answer the most pressing philosophical questions of his time. We likewise suspected that this story bore the cultural footprints of the actual process by which Homo sapiens gained dominion over our planet. What, then, was the sequence of steps in this speedy, super-evolutionary process? My interest in these questions waned in my early career as a professor of engineering, but it was reignited suddenly in the 1990s, when I was writing my book Causality , and came to confront the Ladder of Causation. As I re-read Genesis for the hundredth time, I noticed a nuance that had somehow eluded my attention for all those years",
    "chunk_id": "microsoft_word_-_ch-1_final_withfigs.docx_page-1-33.json_chunk_1"
  },
  {
    "document_type": "book",
    "title": "The Book of Why - chapter 1",
    "author": "Dana Mackenzie",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Book_of_why_chapter_1.pdf",
    "date_published": "2017-10-17",
    "keywords": "",
    "flag": "",
    "chunk_text": ". As I re-read Genesis for the hundredth time, I noticed a nuance that had somehow eluded my attention for all those years. When God finds Adam hiding in the garden, he asks: “Have you The Book of Why: The New Science of Cause and Effect – Pearl and Mackenzie 2 eaten from the tree which I forbade you?” And Adam answers: The woman you gave me for a companion, she gave me fruit from the tree and I ate. “What is this you have done?” God asks Eve. She replies: The serpent deceived me, and I ate. As we know, this blame game did not work very well on the Almighty, who banished both of them from the garden. The interesting thing, though, is that God asked what and they answered why . God asked for the facts, and they replied with explanations. Moreover, both were thoroughly convinced that naming causes would somehow paint their actions in a different color. Where did they get this idea? For me, these nuances carried three profound messages. First, that very early in our evolution, humans came to realize that the world is not made up only of dry facts (what we might call data today), but that these facts are glued together by an intricate web of cause-effect relationships. Second, that causal explanations, not dry facts, make up the bulk of our knowledge, and that satisfying our craving for explanation should be the cornerstone of machine intelligence. Finally, that our transition from processors of data to makers of explanations was not gradual—it required an external push from an uncommon fruit. This matched perfectly what I observed theoretically in the Ladder of Causation: no machine can derive explanations from raw data. It needs a push. If we seek confirmation of these messages from evolutionary science, we of course won’t find the Tree of Knowledge, but we still see a major unexplained transition. We understand now that humans evolved from ape-like ancestors over a period of 5-6 million years, and that such gradual evolutionary processes are not uncommon to life on Earth",
    "chunk_id": "microsoft_word_-_ch-1_final_withfigs.docx_page-1-33.json_chunk_2"
  },
  {
    "document_type": "book",
    "title": "The Book of Why - chapter 1",
    "author": "Dana Mackenzie",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Book_of_why_chapter_1.pdf",
    "date_published": "2017-10-17",
    "keywords": "",
    "flag": "",
    "chunk_text": ". We understand now that humans evolved from ape-like ancestors over a period of 5-6 million years, and that such gradual evolutionary processes are not uncommon to life on Earth. But in roughly the last 50,000 years, something unique happened, which some call the Cognitive Revolution and others (with a touch of irony) call the Great Leap Forward. Humans acquired the ability to modify their environment and their own abilities at a dramatically faster rate. The Book of Why: The New Science of Cause and Effect – Pearl and Mackenzie 3 For example, over millions of years, eagles and owls have evolved truly amazing eyesight—yet they never evolved eyeglasses, microscopes, telescopes, or night-vision goggles. Humans have produced these miracles in a matter of centuries. I call this phenomenon the “super-evolutionary speedup.” Some readers might object to my comparing apples and oranges, evolution to engineering, but that is exactly my point. Evolution has endowed us with the ability to engineer our lives, a gift she has not bestowed upon eagles and owls, and the question is again, Why? What computational facility did humans suddenly acquire that eagles lacked? Many theories have been proposed, but there is one I like because it is especially pertinent to the idea of causation. In his book Sapiens , historian Yuval Harari posits that our ancestors’ capacity to imagine non-existent things was the key to everything, for it allowed them to communicate better. Before this change, they could only trust people from their immediate family or tribe. Afterward their trust extended to larger communities, bound by common beliefs and common expectations (for example, beliefs in invisible yet imaginable deities, in the afterlife, and in the divinity of the leader). Whether you agree with Harari’s theory or not, the connection between imagining and causal relations is almost self-evident. It is useless to know the causes of things unless you can imagine their consequences",
    "chunk_id": "microsoft_word_-_ch-1_final_withfigs.docx_page-1-33.json_chunk_3"
  },
  {
    "document_type": "book",
    "title": "The Book of Why - chapter 1",
    "author": "Dana Mackenzie",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Book_of_why_chapter_1.pdf",
    "date_published": "2017-10-17",
    "keywords": "",
    "flag": "",
    "chunk_text": ". It is useless to know the causes of things unless you can imagine their consequences. Conversely, you cannot claim that Eve caused you to eat from the tree unless you can imagine a world in which, counter to facts, she did not hand you the apple. Back to our H. sapiens ancestors: their newly acquired causal imagination enabled them to do many things more efficiently, through a tricky process we call “planning.” Imagine a tribe preparing for a mammoth hunt. What would it take for them to succeed? My mammoth-hunting skills are rusty, I must admit, but as a student of thinking machines I have learned one thing. The only way a thinking entity (computer, caveman, or professor) can accomplish a task of such magnitude is to plan things in advance. To decide how many hunters to recruit; to gauge, given The Book of Why: The New Science of Cause and Effect – Pearl and Mackenzie 4 the wind conditions, what direction to approach the mammoth; and more. In short, to imagine and compare the consequences of several hunting strategies. To do this, it must possess, consult, and manipulate a mental model of its reality. Here is how we might draw such a mental model: Figure 1. Perceived causes of a successful mammoth hunt. Each dot in the diagram represents a cause of success. Note that there are multiple causes, and that none of them are deterministic. That is, we cannot be sure that more hunters will enable us to succeed, or that rain will prevent us from succeeding; but these factors do change our probability of success. The mental model is the arena where imagination takes place. It enables us to experiment with different scenarios, by making local alterations to the model. Somewhere in our hunters’ mental model was a subroutine that evaluated the effect of the number of hunters. When they considered adding more, they didn’t have to evaluate every other factor from scratch. They could make a local change to the model, replacing “Hunters = 8” by “Hunters = 9” and re-evaluating the probability of success",
    "chunk_id": "microsoft_word_-_ch-1_final_withfigs.docx_page-1-33.json_chunk_4"
  },
  {
    "document_type": "book",
    "title": "The Book of Why - chapter 1",
    "author": "Dana Mackenzie",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Book_of_why_chapter_1.pdf",
    "date_published": "2017-10-17",
    "keywords": "",
    "flag": "",
    "chunk_text": ". They could make a local change to the model, replacing “Hunters = 8” by “Hunters = 9” and re-evaluating the probability of success. This modularity is a key feature of causal models. . I don’t mean to imply, of course, that early humans actually drew a pictorial model like this one. Of course not! But when we seek to emulate human thought on a computer, or indeed when we try to solve unfamiliar scientific problems, drawing an explicit dots-and-arrows picture The Book of Why: The New Science of Cause and Effect – Pearl and Mackenzie 5 is extremely useful. You will see many in this book, and I will call them causal diagrams. They are the computational core of the “causal inference engine” described in Chapter 1. The Three Levels of Causation So far I may have given the impression that the ability to organize our knowledge of the world into causes and effects was monolithic and acquired all at once. But in fact, my research on machine learning has taught me that there are at least three distinct levels that need to be conquered by a causal learner: seeing, doing, and imagining. The first cognitive ability, seeing or observation, is the detection of regularities in our environment, and it is shared by many animals as well as early humans before the Cognitive Revolution. The second ability, doing, stands for predicting the effect(s) of deliberate alterations of the environment, and choosing among these alterations to produce a desired outcome. Only a small handful of species have demonstrated elements of this skill. Usage of tools, provided they are designed for a purpose and not just picked up by accident or copied from one’s ancestors, could be taken as a sign of reaching this second level. Yet even tool users do not necessarily possess a “theory” of their tool that tells them why their tool works and what to do when it doesn’t. For that, you need to be at a level of understanding that permits imagining",
    "chunk_id": "microsoft_word_-_ch-1_final_withfigs.docx_page-1-33.json_chunk_5"
  },
  {
    "document_type": "book",
    "title": "The Book of Why - chapter 1",
    "author": "Dana Mackenzie",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Book_of_why_chapter_1.pdf",
    "date_published": "2017-10-17",
    "keywords": "",
    "flag": "",
    "chunk_text": ". For that, you need to be at a level of understanding that permits imagining. It was primarily this third level that prepared us for further revolutions in agriculture and science, and led to a sudden and drastic change in our species’ impact on planet Earth. I cannot prove this, but what I can prove mathematically is that the three levels are fundamentally different, each unleashing capabilities that the ones below it do not. The framework I will use to show this goes back to Alan Turing, the pioneer of research in artificial intelligence, who proposed to classify a cognitive system in terms of the queries it can answer . The Book of Why: The New Science of Cause and Effect – Pearl and Mackenzie 6 The Book of Why: The New Science of Cause and Effect – Pearl and Mackenzie 7 Figure 2. The Ladder of Causation, with representative organisms at each level. Most animals as well as present-day learning machines are on the first rung, learning from association. Tool users, such as early humans, are on the second rung, if they act by planning and not merely by imitation. We can also use experiments to learn the effects of interventions, and presumably this is how babies acquire much of their causal knowledge. On the top rung, counterfactual learners can imagine worlds that do not exist and infer reasons for observed phenomena. The Book of Why: The New Science of Cause and Effect – Pearl and Mackenzie 8 This is an exceptionally fruitful approach when we are talking about causality, because it bypasses long and unproductive discussions of “What is causality exactly?” and focuses instead on the concrete and answerable question, “What can a causal reasoner do?” Or more precisely, what can an organism possessing a causal model compute that one lacking such a model cannot? While Turing was looking for a binary classification—human or non-human—ours has three tiers, corresponding to progressively more powerful causal queries",
    "chunk_id": "microsoft_word_-_ch-1_final_withfigs.docx_page-1-33.json_chunk_6"
  },
  {
    "document_type": "book",
    "title": "The Book of Why - chapter 1",
    "author": "Dana Mackenzie",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Book_of_why_chapter_1.pdf",
    "date_published": "2017-10-17",
    "keywords": "",
    "flag": "",
    "chunk_text": ". Using these criteria, we can assemble the three levels of queries into one Ladder of Causation (Figure 2), a metaphor that we will return to again and again. Let’s take some time to consider each rung of the ladder in detail. At the first level, Association, we are looking for regularities in observations. This is what an owl does when it observes how a rat moves and figures out where it is likely to be a moment later, and it is what a computer go program does when it studies a database of millions of go games so that it can figure out which moves are associated with a higher percentage of wins. We say that one event is associated with another if observing one changes the likelihood of observing the other. The first rung of the ladder calls for predictions based on passive observations. It is characterized by the question: “ What if we see [X]?” For instance, imagine a marketing director at a department store, who asks, “How likely is it that a customer who bought toothpaste will also buy dental floss?” Such questions are the bread and butter of statistics, and they are answered, first and foremost, by collecting and analyzing data. In our case, the question can be answered by first taking the data consisting of the shopping behavior of all customers, selecting only those who bought toothpaste, and, focusing on the latter group, computing the proportion who also bought dental floss. This proportion, also known as a “conditional probability,” measures (for large data) the degree of association between “buying toothpaste” and “buying The Book of Why: The New Science of Cause and Effect – Pearl and Mackenzie 9 floss.” Symbolically, we can write it as P(Floss|Toothpaste). The “P” stands for “probability,” and the vertical line means, “given that you see.” Statisticians have developed many elaborate methods to reduce a large body of data and identify associations between variables",
    "chunk_id": "microsoft_word_-_ch-1_final_withfigs.docx_page-1-33.json_chunk_7"
  },
  {
    "document_type": "book",
    "title": "The Book of Why - chapter 1",
    "author": "Dana Mackenzie",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Book_of_why_chapter_1.pdf",
    "date_published": "2017-10-17",
    "keywords": "",
    "flag": "",
    "chunk_text": ". A typical measure of association, which we will mention often in this book, is called “correlation” or “regression,” which involves fitting a line to a collection of data points and taking the slope of that line. Some associations might have obvious causal interpretations. Other associations may not. But statistics alone cannot tell which is the cause and which is the effect, toothpaste or floss. From the point of view of the sales manager, it may not really matter. Good predictions need not have good explanations. The owl can be a good hunter without understanding why the rat always goes from point A to point B. Some readers may be surprised to see that I have placed present-day learning machines squarely on rung one of the Ladder of Causation, sharing their wisdom with an owl. We hear almost every day, it seems, about rapid advances in machine learning systems—self-driving cars, speech-understanding systems, and especially in recent years, deep-learning algorithms (or deep neural networks). How could it be that they are still only at level one? The successes of deep learning have been truly remarkable, and have caught many of us by surprise. Nevertheless, deep learning has succeeded primarily by showing that certain questions or tasks we thought were difficult are in fact not so difficult. It has not addressed the truly difficult questions that continue to prevent us from achieving human-like AI. The result is that the public believes that “strong AI,” machines that think like humans, is just around the corner or maybe even here already. In reality, nothing could be farther from the truth. I fully agree with Gary Marcus, a neuroscientist at New York University, who recently wrote in the New York Times that the field of artificial intelligence is “bursting with microdiscoveries”—the sort of things that make good press releases—but that machines are still disappointingly far from The Book of Why: The New Science of Cause and Effect – Pearl and Mackenzie 10 human-like cognition",
    "chunk_id": "microsoft_word_-_ch-1_final_withfigs.docx_page-1-33.json_chunk_8"
  },
  {
    "document_type": "book",
    "title": "The Book of Why - chapter 1",
    "author": "Dana Mackenzie",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Book_of_why_chapter_1.pdf",
    "date_published": "2017-10-17",
    "keywords": "",
    "flag": "",
    "chunk_text": ". My colleague in computer science at UCLA, Adnan Darwiche, has just (as of July 2017) written a position paper called “Human-Level Intelligence or Animal-Like Abilities?” which I think frames the question in just the right way. The goal of strong AI is to produce machines with human-like intelligence, able to converse with humans and guide us. What we have gotten from deep learning instead is machines with abilities—truly impressive abilities—but no intelligence. The difference is profound, and lies in the absence of a model of reality. Just as they did 30 years ago, machine-learning programs (including those with deep neural networks) operate almost entirely in an associational mode. They are driven by a stream of observations to which they attempt to fit a function, in much the same way that a statistician tries to fit a line to a collection of points. Deep neural networks have added many more layers to the complexity of the fitted function but still, what drives the fitting process is raw data. They continue to improve in accuracy as more data are fitted, but they do not benefit from the “supeevolutionary speedup” that we encountered above. They end up with a brittle, special-purpose system that is inscrutable even to its programmers. The architects of a program like AlphaGo (which recently defeated the best human go players) do not really know why it works, only that it does. The lack of flexibility, adaptability, and transparency is not in the least bit surprising; it is inevitable in any system that works at the first level of the Ladder of Causation. We step up to the next level of causal queries when we begin to change the world. A typical question for this level is, “What will happen to our floss sales if we double the price of toothpaste?” This already calls for a new kind of knowledge, absent from the data, which we find at rung two of the Ladder of Causation, Intervention. Intervention ranks higher than Association because it involves not just seeing what is, but changing what is",
    "chunk_id": "microsoft_word_-_ch-1_final_withfigs.docx_page-1-33.json_chunk_9"
  },
  {
    "document_type": "book",
    "title": "The Book of Why - chapter 1",
    "author": "Dana Mackenzie",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Book_of_why_chapter_1.pdf",
    "date_published": "2017-10-17",
    "keywords": "",
    "flag": "",
    "chunk_text": ". Intervention ranks higher than Association because it involves not just seeing what is, but changing what is. Seeing smoke tells us a totally different story about the likelihood of fire than The Book of Why: The New Science of Cause and Effect – Pearl and Mackenzie 11 making smoke. Questions about interventions cannot be answered by using passively collected data, no matter how big the data or how deep your neural network. It has been quite traumatic for many scientists to learn that none of the methods they learn in statistics are sufficient even to articulate, let alone answer, a simple question like, “What happens if we double the price?” I know this because I have had many occasions to help them climb to the next rung of the ladder. Why can’t we answer our floss question just by observation? Why not just go into our vast database of previous purchases and see what happened previously when toothpaste cost twice as much? The reason is that on the previous occasions, the price may have been higher for different reasons. For example, the product may have been in short supply, and every other store also had to raise its price. But now you are considering a deliberate intervention that will set a new price regardless of market conditions. The result might be quite different from what it was when the customer couldn’t find a better deal anywhere else. If you had data on the market conditions that existed on the previous occasions, perhaps you could figure it outbut what data do you need? And then, how would you figure it out? Those are exactly the questions the science of causal inference allows us to answer. One very direct way to predict the result of an intervention is to experiment with it under carefully controlled conditions. Big Data companies like Facebook know this, and they constantly perform experiments to see what happens if items on the screen are arranged differently, or if the customer is given a different prompt (or even a different price)",
    "chunk_id": "microsoft_word_-_ch-1_final_withfigs.docx_page-1-33.json_chunk_10"
  },
  {
    "document_type": "book",
    "title": "The Book of Why - chapter 1",
    "author": "Dana Mackenzie",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Book_of_why_chapter_1.pdf",
    "date_published": "2017-10-17",
    "keywords": "",
    "flag": "",
    "chunk_text": ". What is more interesting, and less widely known—even in Silicon Valley—is that successful predictions of the effects of interventions can sometimes be made even without an experiment. For example, the sales manager could develop a model of consumer behavior that includes market conditions. Even if she doesn’t have data on every factor, she might have data on enough key surrogates to make the prediction. A sufficiently strong and accurate causal The Book of Why: The New Science of Cause and Effect – Pearl and Mackenzie 12 model can allow us to use rung-one (observational) data to answer rung-two (interventional) queries. Without the causal model, we could not go from rung one to rung two. This is why deep-learning systems (as long as they use only rung-one data and do not have a causal model) will never be able to answer questions about interventions, which by definition break the rules of the environment the machine was trained in. As these examples illustrate, the defining query of the second rung of the Ladder of Causation is, “ What if we do ?” What will happen if we change the environment? We can write this kind of query as P(Floss| do (Toothpaste)), the probability that we will sell floss at a certain price, given that we set the price of toothpaste at another price. Another popular question at the second level of causation is “How?”, which is a cousin of “What if we do?” For instance, the manager may tell us that we have too much toothpaste in our warehouse. “How can we sell it?” he asks. That is, at what price should we set it? Again, the question refers to an intervention, which we want to perform mentally before we decide whether and how to do it in real life. That requires a causal model. Interventions occur all the time in our daily lives, although we don’t usually use such a fancy term for them. For example, when we take aspirin to cure a headache, we are intervening on one variable (the quantity of aspirin in our body) in order to affect another one (our headache status)",
    "chunk_id": "microsoft_word_-_ch-1_final_withfigs.docx_page-1-33.json_chunk_11"
  },
  {
    "document_type": "book",
    "title": "The Book of Why - chapter 1",
    "author": "Dana Mackenzie",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Book_of_why_chapter_1.pdf",
    "date_published": "2017-10-17",
    "keywords": "",
    "flag": "",
    "chunk_text": ". For example, when we take aspirin to cure a headache, we are intervening on one variable (the quantity of aspirin in our body) in order to affect another one (our headache status). If we are correct in our causal belief about aspirin, the “outcome” variable will respond by changing from “headache” to “no headache.” While reasoning about interventions is an important step on the causal ladder, it still does not answer all questions of interest. We often wish to ask: My headache is gone now, but why ? Was it the aspirin I took? The food that I ate? The good news I heard? These queries take us to the top rung of the Ladder of Causation, the level of Counterfactuals, because to answer them we must go back in time, change history and ask, “What would have happened if I had not taken the The Book of Why: The New Science of Cause and Effect – Pearl and Mackenzie 13 aspirin?” No experiment in the world can deny treatment to an already treated person and compare the two outcomes, so we must import a whole new kind of knowledge. Counterfactuals have a particularly problematic relationship with data because data are, by definition, facts. They cannot tell us what will happen in a counterfactual or imaginary world, in which some observed facts are bluntly negated. Yet the human mind does make such explanation-seeking inferences, reliably and repeatably. Eve did it when she identified “The serpent deceived me” as the reason for her action. This is the ability that most distinguishes human from animal intelligence, as well as model-blind versions of AI and machine learning. You may be skeptical that science can make any useful statement about “would haves,” worlds that do not exist and things that have not happened. But it does, and it always has. The laws of physics, for example, can be interpreted as counterfactual assertions, such as: Had the weight on this spring doubled, its length would have doubled as well (Hooke’s Law)",
    "chunk_id": "microsoft_word_-_ch-1_final_withfigs.docx_page-1-33.json_chunk_12"
  },
  {
    "document_type": "book",
    "title": "The Book of Why - chapter 1",
    "author": "Dana Mackenzie",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Book_of_why_chapter_1.pdf",
    "date_published": "2017-10-17",
    "keywords": "",
    "flag": "",
    "chunk_text": ". The laws of physics, for example, can be interpreted as counterfactual assertions, such as: Had the weight on this spring doubled, its length would have doubled as well (Hooke’s Law). This statement is, of course, backed by a wealth of experimental (rung-two) evidence, on hundreds of springs, in dozens of laboratories and on thousands of different occasions. However, once anointed with the term “law,” physicists interpret it as a functional relationship that governs this very spring, at this very moment of time, under hypothetical values of the weight. All of these different worlds, where the weight is x pounds and the length of the spring is L x inches, are treated as being objectively knowable, and simultaneously active, even though only one of them actually exists. Going back to the toothpaste example, a top-rung question would be, “What is the probability that a customer who bought toothpaste would still have bought it if we had doubled the price?” We are comparing the real world (where we know that the customer bought the toothpaste at the current price) to a fictitious world (where the price is twice as high). The Book of Why: The New Science of Cause and Effect – Pearl and Mackenzie 14 The rewards of having a causal model that can answer counterfactual questions are immense. Finding out why a blunder occurred allows us to take the right corrective measures in the future. Finding out why a treatment worked on some people and not on others can lead to a new cure for a disease. Answering the question “What if things had been different?” allows us to learn from history and from the experience of others, something that no other species appears to do. It is not surprising that the ancient Greek philosopher Democritus (460-370 BC) said, “I would rather discover one cause than be the King of Persia.” The position of counterfactuals at the top of the Ladder of Causation explains why I place such emphasis on them as a key moment in the evolution of human consciousness",
    "chunk_id": "microsoft_word_-_ch-1_final_withfigs.docx_page-1-33.json_chunk_13"
  },
  {
    "document_type": "book",
    "title": "The Book of Why - chapter 1",
    "author": "Dana Mackenzie",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Book_of_why_chapter_1.pdf",
    "date_published": "2017-10-17",
    "keywords": "",
    "flag": "",
    "chunk_text": ". I totally agree with Yuval Harari that the depiction of imaginary creatures was a manifestation of a new ability, which he calls the cognitive revolution. His prototypical example is the Lion Man sculpture, found in Stadel Cave in southwestern Germany and now held at the Ulm Museum (see Figure 3). The Lion Man, roughly 40 thousand years old, is a mammoth tusk that has been sculpted in the form of a chimera, half man and half lion. We do not know who sculpted the Lion Man or what its purpose was, but we do know it was made by anatomically modern humans and that it represents a break with any art or craft that had gone before. Previously, humans had fashioned tools and representational art, from beads to flutes to spear points to elegant carvings of horses and other animals. The Lion Man is different: a creature of pure imagination. As a manifestation of our newfound ability to imagine things that have never existed, the Lion Man is the precursor to every philosophical theory, scientific discovery, and technological innovation, from microscopes to airplanes to computers. Every one of these had to take shape in someone’s imagination before it was realized in the physical world. The Book of Why: The New Science of Cause and Effect – Pearl and Mackenzie 15 Figure 3. The Lion Man of Stadel Cave. The earliest known representation of an imaginary creature (half man and half lion), it is emblematic of a newly developed cognitive ability, the ability to reason about counterfactuals. The Book of Why: The New Science of Cause and Effect – Pearl and Mackenzie 16 This leap forward in cognitive ability was as profound and important to our species as any of the anatomical changes that made us human. Within 10,000 years after the Lion Man’s creation, all other hominids (except for the very geographically isolated Flores hominids) had become extinct. And humans have continued to change the natural world with incredible speed, using our imagination to survive, adapt, and ultimately take over",
    "chunk_id": "microsoft_word_-_ch-1_final_withfigs.docx_page-1-33.json_chunk_14"
  },
  {
    "document_type": "book",
    "title": "The Book of Why - chapter 1",
    "author": "Dana Mackenzie",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Book_of_why_chapter_1.pdf",
    "date_published": "2017-10-17",
    "keywords": "",
    "flag": "",
    "chunk_text": ". And humans have continued to change the natural world with incredible speed, using our imagination to survive, adapt, and ultimately take over. The advantage we gained from imagining counterfactuals was the same then as it is today: flexibility, the ability to reflect on and improve upon past actions and, perhaps even more significant, our willingness to take responsibility for past and current actions. As shown in Figure 2, the characteristic queries for the third rung of the Ladder of Causation are “What if I had done?” and “Why?” Both of these involve comparing the observed world to a counterfactual world. Such questions cannot be answered by experiments alone. While rung one deals with the seen world, and rung two deals with a brave new world that is seeable , rung three deals with a world that cannot be seen (because it contradicts what is seen). To bridge the gap, we need a model of the underlying causal process, sometimes called a “theory” or even (in cases where we are extraordinarily confident) a “law of nature.” In short, we need understanding.This is, of course, one of the holy grails of any branch of science—the development of a theory that will enable us to predict what will happen in situations we have not even envisioned yet. But it goes even further: having such laws permits us to violate them selectively, so as to create worlds that contradict ours. Our next section will feature such violations in action. The Mini-Turing Test The Book of Why: The New Science of Cause and Effect – Pearl and Mackenzie 17 In 1950, Alan Turing asked what it would mean for a computer to think like a human. He suggested a practical test, which he called “the imitation game,” but every AI researcher since then has called it the “Turing test.” For all practical purposes, a computer could be called a thinking machine if an ordinary human, communicating with the computer by typewriter, would not be able to tell whether he was talking with a human or a computer",
    "chunk_id": "microsoft_word_-_ch-1_final_withfigs.docx_page-1-33.json_chunk_15"
  },
  {
    "document_type": "book",
    "title": "The Book of Why - chapter 1",
    "author": "Dana Mackenzie",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Book_of_why_chapter_1.pdf",
    "date_published": "2017-10-17",
    "keywords": "",
    "flag": "",
    "chunk_text": ". Turing was very confident that this was within the realm of feasibility. “I believe that in about fifty years’ time it will be possible to program computers,” he wrote, “to make them play the imitation game so well that an average interrogator will not have more than a 70 percent chance of making the right identification after five minutes of questioning.” Turing’s prediction was slightly off. Every year the Loebner Prize competition identifies the most human-like “chatbot” in the world, with a gold medal and $100,000 offered to any program that succeeds in fooling all four judges into thinking that it is human. As of 2015, in 25 years of competition, not a single program has fooled all the judges or even half of them. Turing didn’t just suggest the “imitation game,” he also proposed a strategy to pass it. “Instead of trying to produce a program to simulate the adult mind, why not rather try to produce one which simulates the child’s?” he asked. If you could do that, then you could just teach it the same way you would teach a child and presto, twenty years later (or less, given a computer’s greater speed), you would have an artificial intelligence. “Presumably the child brain is something like a notebook as one buys it from the stationer’s,” he wrote. “Rather little mechanism, and lots of blank sheets.” He was wrong about that: the child’s brain is rich in mechanisms and pre-stored templates. Nonetheless, I think that Turing’s instinct had more than a kernel of truth. We probably will not succeed in creating human-like intelligence until we can create child-like intelligence, and a key component in this intelligence is the mastery of causation",
    "chunk_id": "microsoft_word_-_ch-1_final_withfigs.docx_page-1-33.json_chunk_16"
  },
  {
    "document_type": "book",
    "title": "The Book of Why - chapter 1",
    "author": "Dana Mackenzie",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Book_of_why_chapter_1.pdf",
    "date_published": "2017-10-17",
    "keywords": "",
    "flag": "",
    "chunk_text": ". We probably will not succeed in creating human-like intelligence until we can create child-like intelligence, and a key component in this intelligence is the mastery of causation. The Book of Why: The New Science of Cause and Effect – Pearl and Mackenzie 18 How can machines acquire causal knowledge? That is still a major challenge which undoubtedly will involve an intricate combination of inputs from active experimentation, passive observation, and (not least) input from the programmer—much the same inputs that a child receives, with evolution, parents, and peers substituted for the programmer. However, we can answer a slightly less ambitious question: How can machines (and people) represent causal knowledge, in a way that would enable them to access the necessary information swiftly, answer questions correctly, and do it with ease, as a three-year-old child can? In fact, this is the main question we address in this book. I call this the mini-Turing test. The idea is to take a simple story, encode it on a machine in some way, and then test to see if the machine can correctly answer causal questions that a human can answer. It is “mini” for two reasons. First, because it is confined to causal reasoning, excluding other aspects of human intelligence such as vision and natural language. Second, we allow the contestant to encode the story in any convenient representation, unburdening the machine from the task of acquiring the story from its own personal experience. Passing this mintest has been my life’s work—consciously for the last twenty-five years, and subconsciously even before that. Obviously, as we prepare to take the mini-Turing test, the question of representation needs to precede the question of acquisition. Without a representation, we wouldn’t know how to store information for future usage",
    "chunk_id": "microsoft_word_-_ch-1_final_withfigs.docx_page-1-33.json_chunk_17"
  },
  {
    "document_type": "book",
    "title": "The Book of Why - chapter 1",
    "author": "Dana Mackenzie",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Book_of_why_chapter_1.pdf",
    "date_published": "2017-10-17",
    "keywords": "",
    "flag": "",
    "chunk_text": ". Without a representation, we wouldn’t know how to store information for future usage. Even if we could let our robot manipulate its environment at will, whatever information we learned this way is destined to be forgotten, unless our robot is endowed with a template to encode the results of those manipulations. One major contribution of AI to the study of cognition has been the paradigm: “Representation first, acquisition second.” Often it turned out that the quest for a good representation led to insights on how the knowledge ought to be acquired, be it from data or a programmer. The Book of Why: The New Science of Cause and Effect – Pearl and Mackenzie 19 When I describe the mini-Turing test to people, one common reaction is to claim that it can easily be defeated by cheating. For example, take the list of all possible questions, store their correct answers, and then read them out from memory when asked. There is no way to distinguish (so the argument goes) between a machine that stores a dumb question-answer list and one that answers the way that you and I do it, that is, by understanding the question and producing an answer using a mental causal model. So what would the mini-Turing test prove, if cheating is so easy? This cheating possibility, known as the “Chinese Room Argument,” was introduced in 1980 by the philosopher John Searle to challenge Turing’s claim that the ability to fake intelligence amounts to having intelligence. Searle’s challenge has only one flaw: cheating is not easy; in fact it is impossible. Even with a small number of variables, the number of possible questions grows astronomically. Say that we have 10 causal variables, each of which takes only two values (0 or 1)",
    "chunk_id": "microsoft_word_-_ch-1_final_withfigs.docx_page-1-33.json_chunk_18"
  },
  {
    "document_type": "book",
    "title": "The Book of Why - chapter 1",
    "author": "Dana Mackenzie",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Book_of_why_chapter_1.pdf",
    "date_published": "2017-10-17",
    "keywords": "",
    "flag": "",
    "chunk_text": ". Even with a small number of variables, the number of possible questions grows astronomically. Say that we have 10 causal variables, each of which takes only two values (0 or 1). There are roughly 30 million possible queries that we could ask, such as “What is the probability that the outcome is 1, given that we see variable X equals 1 and we make variable Y equal 0 and variable Z equal 1?” If there were more variables, or more than two states for each one, the number of possibilities would grow beyond our ability to even imagine. Searle’s list would need to have more entries than the number of atoms in the universe. So it is clear that a dumb list of questions and answers will never be able to simulate the intelligence of a child, let alone an adult. Humans must have some compact representation of the information needed in their brains, as well as an effective procedure to interpret each question properly and extract the right answer from the stored representation. To pass the mini-Turing test, therefore, we need to equip machines with a similarly efficient representation and answer-extraction algorithm. The Book of Why: The New Science of Cause and Effect – Pearl and Mackenzie 20 Such a representation not only exists, but it has childlike simplicity: a causal diagram. We have already seen one example, the diagram for the mammoth hunt. Considering the extreme ease with which people can communicate their knowledge with dot-and-arrow diagrams, I believe that our brains indeed use a representation something like this. But more important for our purposes, these models pass the mini-Turing test; no other model is known to do so. Let’s look at some examples. Suppose that a prisoner is about to be executed by a firing squad. A certain chain of events has to occur for this to happen. First, the court has to order the execution. The order goes to a captain, who signals the soldiers on the firing squad (A and B) to fire",
    "chunk_id": "microsoft_word_-_ch-1_final_withfigs.docx_page-1-33.json_chunk_19"
  },
  {
    "document_type": "book",
    "title": "The Book of Why - chapter 1",
    "author": "Dana Mackenzie",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Book_of_why_chapter_1.pdf",
    "date_published": "2017-10-17",
    "keywords": "",
    "flag": "",
    "chunk_text": ". A certain chain of events has to occur for this to happen. First, the court has to order the execution. The order goes to a captain, who signals the soldiers on the firing squad (A and B) to fire. We’ll assume that they are obedient and expert marksmen, so they only fire on command and if either one of them shoots, the prisoner dies. Here is the diagram representing the story I just told: Figure 4. Causal diagram for the firing squad example. A and B represent (the actions of) soldiers A and B. In Figure 4, each of the unknowns (CO, C, A, B, D) is a true/false variable. For example, D = True means the prisoner is dead, D = False means the prisoner is alive. CO = False means the court order was not issued, CO = True means it was, and so on. CO Court Order ( ) D Death ( ) C Captain ( ) A B The Book of Why: The New Science of Cause and Effect – Pearl and Mackenzie 21 Using this diagram, we can start answering causal questions from different rungs of the ladder. First, we can answer questions of association, i.e., what one fact tells us about another. If the prisoner is dead, does that mean the court order was given? We (or a computer) can inspect the graph, trace the rules behind each of the arrows, and using ordinary logic, conclude that the two soldiers wouldn’t have fired without the captain’s command. Likewise, the captain wouldn’t have given the command if he didn’t have the order in his possession. Therefore the answer to our query is Yes. Alternatively, suppose we find out that A fired. What does that tell us about B? By following the arrows, the computer concludes that B must have fired, too. (A would not have fired if the captain hadn’t signaled, so B must have fired as well.) This is true even though A does not cause B (there is no arrow from A to B). Going up the Ladder of Causation, we can ask questions of intervention",
    "chunk_id": "microsoft_word_-_ch-1_final_withfigs.docx_page-1-33.json_chunk_20"
  },
  {
    "document_type": "book",
    "title": "The Book of Why - chapter 1",
    "author": "Dana Mackenzie",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Book_of_why_chapter_1.pdf",
    "date_published": "2017-10-17",
    "keywords": "",
    "flag": "",
    "chunk_text": ". Going up the Ladder of Causation, we can ask questions of intervention. What if soldier A decides on his own initiative to fire, without waiting for the captain’s command? Will the prisoner be dead or alive? This question in fact already has a contradictory flavor to it. I just told you that A only shoots if commanded to, and yet now we are asking what happens if he fired without a command. If you’re just using the rules of logic, as computers typically do, the question is meaningless. As the Robot in the 1960s sci-fi TV series Lost in Space used to say in such situations, “That does not compute!” If we want our computer to understand causation, we have to teach it how to break the rules. We have to teach it the difference between merely observing an event as compared to making it happen. “Whenever you make an event happen,” we tell the computer, “remove all arrows that point to that event and continue the analysis by ordinary logic, as if the arrows had never been there.” Thus, we erase all the arrows leading into the intervened variable (A). We also set that variable manually to its prescribed value (True). The rationale for this peculiar The Book of Why: The New Science of Cause and Effect – Pearl and Mackenzie 22 “surgery” is simple: making an event happen means that you emancipate it from all other influences and subject it to one and only one influence—that which enforces its happening. In our example, the resulting causal diagram is shown in Figure 5. Under this intervention, the result is inevitably the prisoner’s death. That is the causal meaning of the arrow leading from A to D. Note that this conclusion agrees with our intuitive judgment that A’s unauthorized firing will lead to the prisoner’s death, because the surgery leaves the arrow A  D intact. Also, our judgment would be that B (in all likelihood) did not shoot; nothing about A’s decision should affect variables in the model that are not effects of A’s shot. This bears repeating. If we see A Figure 5. Reasoning about interventions",
    "chunk_id": "microsoft_word_-_ch-1_final_withfigs.docx_page-1-33.json_chunk_21"
  },
  {
    "document_type": "book",
    "title": "The Book of Why - chapter 1",
    "author": "Dana Mackenzie",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Book_of_why_chapter_1.pdf",
    "date_published": "2017-10-17",
    "keywords": "",
    "flag": "",
    "chunk_text": ". This bears repeating. If we see A Figure 5. Reasoning about interventions. Soldier A decides to fire; arrow from C to A is deleted and A is assigned the value True. shoot, then we conclude that B shot too. But if A decides to shoot, or if we make A shoot, then the opposite is true 2 . This is the difference between seeing and doing . Only a computer capable of grasping this difference can pass the mini-Turing test. 2 Another way to say this is that when evaluating an intervention in a causal model, we make the minimum changes possible to enforce its immediate effect. So we “break” the model where it comes to A, but not B. CO Court Order ( ) D Death ( ) C Captain ( ) = True A B The Book of Why: The New Science of Cause and Effect – Pearl and Mackenzie 23 Note also that merely collecting big data would not have helped us go up the ladder and answer the above questions. Assume that you are a reporter collecting records of execution scenes day after day. Your data will consist of two kinds of events: either all five variables are true, or all of them are false. There is no way that this kind of data, in the absence of an understanding of who listens to whom, will enable you (or any machine learning algorithm) to predict the results of persuading marksman A not to shoot. Finally, to illustrate the third rung of the Ladder of Causation, let’s answer a counterfactual question. Suppose the prisoner is lying dead on the ground. From this we can conclude (using level one) that A shot, B shot, the captain gave the signal, and the court gave the order. If, contrary to fact, A had decided not to shoot, would the prisoner be alive? This question requires us to compare the real world with a fictitious and contradictory world where A didn’t shoot. In the fictitious world, the arrow leading into A is erased and A is set to False, but the past history of A stays the same as it was in the real world. So the fictitious world looks like Figure 6",
    "chunk_id": "microsoft_word_-_ch-1_final_withfigs.docx_page-1-33.json_chunk_22"
  },
  {
    "document_type": "book",
    "title": "The Book of Why - chapter 1",
    "author": "Dana Mackenzie",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Book_of_why_chapter_1.pdf",
    "date_published": "2017-10-17",
    "keywords": "",
    "flag": "",
    "chunk_text": ". In the fictitious world, the arrow leading into A is erased and A is set to False, but the past history of A stays the same as it was in the real world. So the fictitious world looks like Figure 6. To pass the mini-Turing test, our computer must conclude that the prisoner would be dead in the fictitious world as well, because B’s shot would have killed him. So A’s courageous change of heart would not have saved his life. Undoubtedly this is one of the reasons firing squads exist. They guarantee that the court’s order will be carried out, and they also lift some of the burden of responsibility off the individual shooters, who can say with a (somewhat) clean conscience that their action did not cause the prisoner’s death: “He would have died anyway.” The Book of Why: The New Science of Cause and Effect – Pearl and Mackenzie 24 Figure 6. Counterfactual reasoning. We observe that the prisoner is dead, and ask what would have happened if Soldier A had decided not to fire. It may seem as if we are going to a lot of trouble to answer toy questions whose answer was obvious anyway. I completely agree! Causal reasoning is easy for you because you are human, and you were once a three-year-old, and you had a marvelous three-year-old brain that understood causation better than any animal or computer. The whole point of the “mini-Turing problem” is to make causal reasoning feasible for computers, too; in the process, we might learn something about how humans do it. As we have seen in all three examples, we have to teach the computer how to selectively break the rules of logic. Computers are not good at breaking rules, a skill at which children excel. (Cavemen too! The Lion Man could not have been created without breaking the rules about what head goes with what body.) However, let’s not get too complacent about human superiority. There are a great many situations where humans may have a much harder time reaching correct causal conclusions",
    "chunk_id": "microsoft_word_-_ch-1_final_withfigs.docx_page-1-33.json_chunk_23"
  },
  {
    "document_type": "book",
    "title": "The Book of Why - chapter 1",
    "author": "Dana Mackenzie",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Book_of_why_chapter_1.pdf",
    "date_published": "2017-10-17",
    "keywords": "",
    "flag": "",
    "chunk_text": ". There are a great many situations where humans may have a much harder time reaching correct causal conclusions. For example, there could be many more variables, and they might not be simple binary (true-false) variables. Instead of predicting whether a prisoner is alive or dead, we might want to predict how much the unemployment rate would go up in the event of a raise in the minimum wage. This C Captain ( ) = True = True B = False A CO Court Order ( ) = True D Death ( ) = ? The Book of Why: The New Science of Cause and Effect – Pearl and Mackenzie 25 kind of quantitative causal reasoning is generally beyond the power of our intuition. Also, in the firing squad example we ruled out uncertainties: maybe the captain gave his order a split second after rifleman A decided to shoot, maybe rifleman B’s gun jammed, etc. To handle uncertainty we need information on how likely the alternatives are to occur. Let me give you an example in which probabilities make all the difference. It echoes the public debate that erupted in Europe when smallpox vaccination was first introduced. Unexpectedly, data showed that more people died from smallpox inoculations than from smallpox itself. Naturally, some people used this information to argue that inoculation should be banned when, in fact, it was saving lives by eradicating smallpox. Let’s look at some fictitious data to illustrate the effect and settle the dispute. Suppose that out of 1 million children, 99 percent are vaccinated and 1 percent are not. If a child is vaccinated, he or she has 1 chance in 100 of developing a reaction, and the reaction has 1 chance in 100 of being fatal. On the other hand, he or she has no chance of developing smallpox. Meanwhile, if a child is not vaccinated, he or she obviously has zero chance of developing a reaction to the vaccine, but he or she has 1 chance in 50 of developing smallpox. Finally, let’s assume that smallpox is fatal in one out of 5 cases. I think you would agree that vaccination looks like a good idea",
    "chunk_id": "microsoft_word_-_ch-1_final_withfigs.docx_page-1-33.json_chunk_24"
  },
  {
    "document_type": "book",
    "title": "The Book of Why - chapter 1",
    "author": "Dana Mackenzie",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Book_of_why_chapter_1.pdf",
    "date_published": "2017-10-17",
    "keywords": "",
    "flag": "",
    "chunk_text": ". Finally, let’s assume that smallpox is fatal in one out of 5 cases. I think you would agree that vaccination looks like a good idea. The odds of having a reaction are less than the odds of getting smallpox, and the reaction is much less dangerous than the disease. But now let’s look at the data. Out of 1 million children, 990 thousand get vaccinated; 9,900 get the reaction; and 99 die from the reaction. Meanwhile, 10 thousand don’t get vaccinated, 200 get smallpox, and 40 die from the disease. In summary, more children die from vaccination (99) than from the disease (40). I can empathize with the parents who might march to the health department with signs saying, “Vaccines killed our children!” And the data seem to be on their side; the vaccinations The Book of Why: The New Science of Cause and Effect – Pearl and Mackenzie 26 indeed are causing more death than smallpox itself. But is logic on their side? Should we ban vaccination, or take into account the deaths prevented? We can make this clear using the causal diagram shown in Figure 7. Figure 7. Causal diagram for vaccination example. Is vaccination beneficial or harmful? When we began, the vaccination rate was 99 percent. We now ask the counterfactual question: What if we had set the vaccination rate to 0? Using the probabilities I gave you above, we can conclude that out of 1 million children, 20 thousand would have gotten smallpox and 4,000 would have died. Comparing the counterfactual world with the real world, we see that the cost of not vaccinating was the death of 3,861 children (the difference between 4,000 and 139). We should thank the language of counterfactuals for helping us to avoid such costs. 3 The main lesson for a student of causality is that there is more to a causal model than merely writing arrows. Behind the arrows, there are probabilities. When we draw an arrow from X to Y, then implicitly we are saying that there is some probability rule or function specifying how Y would change if X were to change",
    "chunk_id": "microsoft_word_-_ch-1_final_withfigs.docx_page-1-33.json_chunk_25"
  },
  {
    "document_type": "book",
    "title": "The Book of Why - chapter 1",
    "author": "Dana Mackenzie",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Book_of_why_chapter_1.pdf",
    "date_published": "2017-10-17",
    "keywords": "",
    "flag": "",
    "chunk_text": ". When we draw an arrow from X to Y, then implicitly we are saying that there is some probability rule or function specifying how Y would change if X were to change. We might know what the rule is; more likely, we will have to estimate it from data. One of the most intriguing features of the Causal Revolution, 3 I should also mention here that counterfactuals allow us to talk about causality in individual cases: what would have happened to Mr. Smith, who was not vaccinated and died of smallpox, if he had not been vaccinated? Such questions, the backbone of personalized medicine, cannot be answered from rung-two information. Vaccination Death Reaction Smallpox The Book of Why: The New Science of Cause and Effect – Pearl and Mackenzie 27 though, is the fact that we can in many cases leave those mathematical details completely unspecified. Very often the structure of the diagram itself enables us to estimate all sorts of causal and counterfactual relationships: simple or complicated, deterministic or probabilistic, linear or non-linear. From the computing perspective, another remarkable thing about our scheme for passing the mini-Turing test is the fact that we used the same routine in all three examples: Translate the story into a diagram, listen to the query, perform a surgery that corresponds to the given query (interventional or counterfactual; if the query is associational than no surgery is needed), and then use the modified causal model to compute the answer. We did not have to train the machine on a multitude of new queries each time we changed the story. The approach is flexible enough to work whenever we can draw a causal diagram, whether it has to do with mammoths, firing squads, or vaccinations. This is exactly what we want for a causal inference engine: it is the kind of flexibility we enjoy as humans. Of course, there is nothing inherently magic about a diagram",
    "chunk_id": "microsoft_word_-_ch-1_final_withfigs.docx_page-1-33.json_chunk_26"
  },
  {
    "document_type": "book",
    "title": "The Book of Why - chapter 1",
    "author": "Dana Mackenzie",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Book_of_why_chapter_1.pdf",
    "date_published": "2017-10-17",
    "keywords": "",
    "flag": "",
    "chunk_text": ". This is exactly what we want for a causal inference engine: it is the kind of flexibility we enjoy as humans. Of course, there is nothing inherently magic about a diagram. The success of the diagram is attributable to the fact that it carries causal information; that is, when we constructed the diagram we asked ourselves, “Who could be a direct cause of the prisoner’s death?” or “What are the direct effects of vaccinations?” Had we constructed the diagram by asking about mere associations, it would not have given us these capabilities. For example, in Figure 7, if we reversed the arrow Vaccination  Smallpox we would get the same associations in the data, but we would erroneously conclude that smallpox affects vaccination. Decades of experience with these kinds of questions have given me a firm conviction that, in both a cognitive sense and a philosophical sense, the idea of causes and effects is much more fundamental than the idea of probability. We begin learning causes and effects before we understand language, and before we know any mathematics. (Research has shown that thre The Book of Why: The New Science of Cause and Effect – Pearl and Mackenzie 28 year-olds already understand the entire Ladder of Causation.) Likewise, the knowledge conveyed in a causal diagram is typically much more robust than the knowledge encoded in a probability distribution. For example, suppose that times have changed and a new vaccine is introduced which is much safer and more effective. Suppose, further, that due to improved hygiene and socioeconomic conditions, the danger of contracting smallpox has diminished. These changes will drastically affect all of the probabilities involved, yet, remarkably, the structure of the diagram would remain invariant. This is the key secret of causal modeling. Moreover, once we go through the analysis and find how to estimate the benefit of vaccination from data, we do not have to repeat the entire analysis from scratch",
    "chunk_id": "microsoft_word_-_ch-1_final_withfigs.docx_page-1-33.json_chunk_27"
  },
  {
    "document_type": "book",
    "title": "The Book of Why - chapter 1",
    "author": "Dana Mackenzie",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Book_of_why_chapter_1.pdf",
    "date_published": "2017-10-17",
    "keywords": "",
    "flag": "",
    "chunk_text": ". Moreover, once we go through the analysis and find how to estimate the benefit of vaccination from data, we do not have to repeat the entire analysis from scratch. As discussed in the Introduction, the same estimand (i.e., recipe for answering the query) will remain valid and, as long as the diagram does not change, it can be applied to the new data and produce a new estimate for our query. It is because of this robustness, I conjecture, that human intuition is organized around causal, not statistical relations. On Probabilities and Causation The recognition that causation is not reducible to probabilities has been very hard-won, both for me personally and for philosophers and scientists in general. The drive to understand what a “cause” means has been the focus of a long tradition of philosophers, from Hume and Mill in the 1700s and 1800s to Hans Reichenbach and Patrick Suppes in the mid-1900s, to Nancy Cartwright, Wolfgang Spohn and Christopher Hitchcock today. In particular, beginning with Reichenbach and Suppes, philosophers have tried to define causation in terms of probability, using the notion of “probability raising”: X causes Y if X raises the probability of Y. This concept is solidly ensconced in intuition. We say, for example, “reckless driving causes accidents” or “you will fail this course because of your laziness,” knowing quite well that The Book of Why: The New Science of Cause and Effect – Pearl and Mackenzie 29 the antecedents merely tend to make the consequences more likely, not absolutely certain. One would expect, therefore, that probability raising should become the bridge between rung one and rung two of the Ladder of Causation. Alas, this intuition has led to decades of failed attempts. What prevented the attempts from succeeding was not the idea itself but the way it was articulated formally. Almost without exception, philosophers expressed the sentence, “X raises the probability of Y” using conditional probabilities and wrote: P(Y|X) > P(Y)",
    "chunk_id": "microsoft_word_-_ch-1_final_withfigs.docx_page-1-33.json_chunk_28"
  },
  {
    "document_type": "book",
    "title": "The Book of Why - chapter 1",
    "author": "Dana Mackenzie",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Book_of_why_chapter_1.pdf",
    "date_published": "2017-10-17",
    "keywords": "",
    "flag": "",
    "chunk_text": ". Almost without exception, philosophers expressed the sentence, “X raises the probability of Y” using conditional probabilities and wrote: P(Y|X) > P(Y). This interpretation is wrong, as you surely noticed, because “raises” is a causal concept, connoting a causal influence that X has over Y. The expression P(Y|X) > P(Y), on the other hand, speaks only about observations, and means, “If we see X, then the probability of Y increases.” But this increase may come about for other reasons, including Y being a cause of X or some other variable (Z) being the cause of both of them. That’s the catch! It puts the philosophers back on square one, trying to eliminate those “other reasons.” Probabilities, as given by expressions like P(Y|X), lie on the first rung of the Ladder of Causation and they cannot ever (by themselves) answer queries on the second or third rung. Any attempt to “define” causation in terms of simpler, first-rung concepts must fail. That is why I have not attempted to define causation anywhere in this book; definitions demand reduction and reduction demands going to a lower rung. Instead, I have pursued the ultimately more constructive program of explaining how to answer causal queries and what information is needed to answer them. If this seems odd, consider that mathematicians take exactly the same approach to Euclidean geometry. Nowhere in a geometry book will you find a definition of the terms “point” and “line.” Yet we can answer any and all queries about them on the basis of Euclid’s axioms (or even better, the various modern versions of Euclid’s axioms). 4 4 To be more precise: in geometry, undefined terms like “point” and “line” are primitives. The primitive in causal inference is the relation of “listening to,” indicated by an arrow. The Book of Why: The New Science of Cause and Effect – Pearl and Mackenzie 30 But let’s look at this criterion of probability raising more carefully and see where it runs aground",
    "chunk_id": "microsoft_word_-_ch-1_final_withfigs.docx_page-1-33.json_chunk_29"
  },
  {
    "document_type": "book",
    "title": "The Book of Why - chapter 1",
    "author": "Dana Mackenzie",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Book_of_why_chapter_1.pdf",
    "date_published": "2017-10-17",
    "keywords": "",
    "flag": "",
    "chunk_text": ". The Book of Why: The New Science of Cause and Effect – Pearl and Mackenzie 30 But let’s look at this criterion of probability raising more carefully and see where it runs aground. The issue of a common cause or confounder of X and Y, mentioned above, was one of the most vexing ones for philosophers. If we take the probability-raising criterion at face value, we would have to conclude that high ice cream sales cause crime, because the probability of crime is higher in months when more ice cream is sold. In this particular case, we can explain the phenomenon because both ice cream sales and crime are higher in summer, when the weather is warmer. Nevertheless, the question remains: what general philosophical criterion could tell us that weather is the cause, not ice cream sales? Philosophers tried hard to repair the definition by conditioning on what they called “background factors” (another word for confounders), yielding the criterion P(Y|X, K = k ) > P(Y|K = k ), where K stands for some background variables. In fact, this criterion works for our ice cream example, if we treat temperature as a background variable. For example, if we look only at days when the temperature is 90 degrees (K = 90), we will find no residual association between ice cream sales and crime. It’s only when we compare 90-degree days to 30-degree days that we get the illusion of a probability raising. Still, no philosopher has been able to give a convincingly general answer to the question: Which variables need to be included in the background set K and conditioned on? The reason is obvious; confounding too is a causal concept, hence defies probabilistic formulation. In 1983, Nancy Cartwright broke this deadlock and enriched the description of the background context with a causal component. She proposed that we should condition on any factor that is “causally relevant” to the effect. By borrowing a concept from rung two of the Ladder of Causation she essentially gave up on the idea of defining causes from probability alone",
    "chunk_id": "microsoft_word_-_ch-1_final_withfigs.docx_page-1-33.json_chunk_30"
  },
  {
    "document_type": "book",
    "title": "The Book of Why - chapter 1",
    "author": "Dana Mackenzie",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Book_of_why_chapter_1.pdf",
    "date_published": "2017-10-17",
    "keywords": "",
    "flag": "",
    "chunk_text": ". By borrowing a concept from rung two of the Ladder of Causation she essentially gave up on the idea of defining causes from probability alone. This was progress, but it opens the door to the criticism that we are defining a cause in terms of itself. The Book of Why: The New Science of Cause and Effect – Pearl and Mackenzie 31 Philosophical disputes over the appropriate content of K continued for more than two decades and reached an impasse. In fact, we will see a correct criterion in Chapter 4 and I will not spoil the surprise here. It will suffice for the moment to say that this criterion is practically impossible to enunciate without causal diagrams. In summary, confounding has always been the rock on which probabilistic causality has foundered. Every time the adherents of probabilistic causation try to patch up the ship with a new hull, the boat runs into the same rock and springs another leak. Once you misrepresent “probability raising” in the language of conditional probabilities, no amount of probabilistic patching will get you to the next rung of the ladder. As strange as it may sound, the notion of probability raising cannot be expressed in terms of probablities. The proper way to rescue the probability-raising idea would be with the do -operator: we could say that X causes Y if P(Y| do (X)) > P(Y). Since intervention is a rung-two concept, this definition can capture the causal notion of probability raising, and it can also be made operational through causal diagrams. In other words, if we have a causal diagram and data on hand and a researcher asks whether P(Y| do (X)) > P(Y), we can answer his question coherently and algorithmically, and thus decide if X is a cause of Y in the probability-raising sense. I usually pay a great deal of attention to what philosophers have to say about slippery concepts such as causation, induction, and the logic of scientific inference",
    "chunk_id": "microsoft_word_-_ch-1_final_withfigs.docx_page-1-33.json_chunk_31"
  },
  {
    "document_type": "book",
    "title": "The Book of Why - chapter 1",
    "author": "Dana Mackenzie",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Book_of_why_chapter_1.pdf",
    "date_published": "2017-10-17",
    "keywords": "",
    "flag": "",
    "chunk_text": ". I usually pay a great deal of attention to what philosophers have to say about slippery concepts such as causation, induction, and the logic of scientific inference. Philosophers have the advantage of standing apart from the hurly-burly of scientific debate and the practical realities of dealing with data. They have been less contaminated than other scientists by the anti-causal biases of statistics. They can call upon a tradition of thought about causation that goes back at least to Aristotle, and they can talk about causation without blushing or hiding it behind the label of “association.” The Book of Why: The New Science of Cause and Effect – Pearl and Mackenzie 32 However, in their effort to mathematize the concept of causation—itself a laudable idea—philosophers were too quick to commit to the only uncertainty-handling language they knew, the language of probability. They have for the most part gotten over this blunder, but unfortunately similar ideas are being pursued in econometrics even now, under names like “Granger causality” and “vector autocorrelation.” Now I have a confession to make: I made the same mistake, too. I did not always put causality first and probability second. Quite the opposite! When I started working in artificial intelligence, in the early 1980s, I thought that the most important thing missing from AI’s was uncertainty. Moreover, I was insisting that uncertainty be represented by probabilities. Thus, as I will explain in Chapter 3, I developed an approach to reasoning under uncertainty, called Bayesian networks, which mimics how an idealized, decentralized brain might incorporate probabilities into its decisions. Given that we see certain facts, Bayesian networks can swiftly compute how likely it is that certain other facts are true or false. Not surprisingly, Bayesian networks caught on immediately in the AI community, and even today they are considered one of the leading paradigms in artificial intelligence for reasoning under uncertainty",
    "chunk_id": "microsoft_word_-_ch-1_final_withfigs.docx_page-1-33.json_chunk_32"
  },
  {
    "document_type": "book",
    "title": "The Book of Why - chapter 1",
    "author": "Dana Mackenzie",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Book_of_why_chapter_1.pdf",
    "date_published": "2017-10-17",
    "keywords": "",
    "flag": "",
    "chunk_text": ". Though I am delighted with the ongoing success of Bayesian networks, they failed to bridge the gap between artificial and human intelligence. I’m sure you can figure out the missing ingredient: causality. True, causal ghosts were all over the place. The arrows invariably pointed from causes to effects, and practitioners often noted that diagnostic systems became unmanageable when the direction of the arrows was reversed. But for the most part we thought that this was a cultural habit, or an artifact of old thought patterns, not a central aspect of intelligent behavior. At the time, I was so intoxicated with the power of probabilities that I considered causality to be a subservient concept, merely a convenience or a mental shorthand for expressing The Book of Why: The New Science of Cause and Effect – Pearl and Mackenzie 33 probabilistic dependencies, and for distinguishing relevant variables from irrelevant ones. In my 1988 book Probabilistic Reasoning in Intelligent Systems , I wrote, “Causation is a language with which one can talk efficiently about certain structures of relevance relationships.” The words embarrass me today, because “relevance” is so obviously a rung 1 notion. Even by the time the book was published, I knew in my heart that I was wrong. To my fellow computer scientists, my book became the bible of reasoning under uncertainty, but I was already feeling like an apostate. Bayesian networks inhabit a world where all questions are reducible to probabilities, or (to put it in the terminology of this chapter) degrees of association between variables; they could not ascend to the second or third rungs of the Ladder of Causation. Fortunately, they required only two slight twists to climb to the top. First, in 1991, the graph surgery idea empowered them to handle both observations and interventions. Another twist, in 1994, brought them to the third level and made them capable of handling counterfactuals. But these developments deserve a fuller discussion in a later chapter",
    "chunk_id": "microsoft_word_-_ch-1_final_withfigs.docx_page-1-33.json_chunk_33"
  },
  {
    "document_type": "book",
    "title": "The Book of Why - chapter 1",
    "author": "Dana Mackenzie",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Book_of_why_chapter_1.pdf",
    "date_published": "2017-10-17",
    "keywords": "",
    "flag": "",
    "chunk_text": ". Another twist, in 1994, brought them to the third level and made them capable of handling counterfactuals. But these developments deserve a fuller discussion in a later chapter. The main point is this: While probabilities encode our beliefs about a static world, causality tells us whether and how probabilities change when the world changes , be it by intervention or by act of imagination.",
    "chunk_id": "microsoft_word_-_ch-1_final_withfigs.docx_page-1-33.json_chunk_34"
  },
  {
    "document_type": "research_paper",
    "title": "National inequality, social capital, and public goods decision-making",
    "author": "Joshua C. Skewes",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\national_inequality_social_capital.pdf",
    "date_published": "2023-05-03",
    "keywords": "\"Inequality\"; \"Gini\"; \"Cooperation\"; \"Public Goods Game\"; \"Trust\"; \"Civic Norms\"",
    "flag": "",
    "chunk_text": "Current Research in Ecological and Social Psychology 4 (2023) 100112 Contents lists available at ScienceDirect Current Research in Ecological and Social Psychology journal homepage: www.elsevier.com/locate/cresp National inequality, social capital, and public goods decision-making Joshua C. Skewes a , b , ∗ , Laila Nockur c a Department of Linguistics, Cognitive Science, and Semiotics, Aarhus University, Denmark b Interacting Minds Centre, Aarhus University, Denmark c Department of Psychology and Behavioural Sciences, Aarhus University, Denmark a r t i c l e i n f o Keywords: Inequality Gini Cooperation Public Goods Game Trust Civic Norms a b s t r a c t Inequality affects how people make social decisions. Laboratory research has shown that when income inequality is simulated using cooperative economic games, groups with higher inequality often generate less wealth overall, with poorer group members receiving the worst outcomes. This study links these experimental findings to real world inequality and applies a decision model to explain the effects in terms of social decision-making dynamics. Using a pre-existing dataset from 255 groups playing a public goods game in thirteen economically diverse soceties, we show that in nations with higher inequality, groups contribute less (Research question (RQ) 1). Further, we find that higher inequality is associated with lower optimism regarding others’ contributions at the outset of the game and increased sensitivity to others’ contributions, which accelerates the decay of cooperation (RQ2). These effects might be explained by national differences in social capital as expressed by trust and adherence to civic norms (RQ3). Using the European Values Survey, we replicate the negative association between inequality and contributions to a public good by examining national volunteering rates (RQ4). 1",
    "chunk_id": "national_inequality,_social_capital,_and_public_goods_decision-making.json_chunk_1"
  },
  {
    "document_type": "research_paper",
    "title": "National inequality, social capital, and public goods decision-making",
    "author": "Joshua C. Skewes",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\national_inequality_social_capital.pdf",
    "date_published": "2023-05-03",
    "keywords": "\"Inequality\"; \"Gini\"; \"Cooperation\"; \"Public Goods Game\"; \"Trust\"; \"Civic Norms\"",
    "flag": "",
    "chunk_text": ". Using the European Values Survey, we replicate the negative association between inequality and contributions to a public good by examining national volunteering rates (RQ4). 1. Introduction People are averse to inequality ( Fehr and Schmidt, 1999 ) and most report being happier in more equal societies ( Alesina et al., 2004 ; see however Starmans et al., 2017 ). Countries with lower inequality also perform better on a range of outcomes, including reduced health prolems and lower crime rates ( Wilkinson and Pickett, 2017 ). This may be because societies which are more equal are better able to increase colletive welfare, and to decrease resource conflicts, by more efficiently prviding public goods ( Bouchey, 2019 ). At the policy level, countries with lower income inequality are more likely to favor more re-distributive fical policies ( Lindert, 1996 ). At the civic level, communities with lower income inequality are more likely to have members who contribute to shared social and economic welfare ( Goldin and Katz, 1999 ; Costa and Kahn, 2003 ; La Ferrara, 2002 ). There is much research aimed at understanding how equality and social welfare are related to the provision of public goods. Most of this work is focused on understanding inequality at the structural or macro-scale level (e.g. Piketty, 2013 ; Krugman and Venables, 1995 ; Fligstein and Shin, 2004 ), however important work has also focused on the social contextual and psychological processes related to inequaity. Suggested psychological processes include reduction of cooperation ( Cherry, Kroll, and Shogren, 2005 ; Nishi et al., 2015 ); stigmatization of poverty ( Jachimowicz et al., 2020 ); and the perception that the s∗ Corresponding author at: Jens Chr. Skous Vej 4, Building 1483, 3. 8000 Aarhus C, Denmark E-mail address: filjcs@cas.au.dk (J.C. Skewes) . cial environment is more competitive ( Sánchez-Rodriguez, Willis et al., 2019 )",
    "chunk_id": "national_inequality,_social_capital,_and_public_goods_decision-making.json_chunk_2"
  },
  {
    "document_type": "research_paper",
    "title": "National inequality, social capital, and public goods decision-making",
    "author": "Joshua C. Skewes",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\national_inequality_social_capital.pdf",
    "date_published": "2023-05-03",
    "keywords": "\"Inequality\"; \"Gini\"; \"Cooperation\"; \"Public Goods Game\"; \"Trust\"; \"Civic Norms\"",
    "flag": "",
    "chunk_text": ". Skous Vej 4, Building 1483, 3. 8000 Aarhus C, Denmark E-mail address: filjcs@cas.au.dk (J.C. Skewes) . cial environment is more competitive ( Sánchez-Rodriguez, Willis et al., 2019 ). The purpose of the present research is to investigate a connection between structural and psychological levels of analysis, by linking icome inequality at the national level to public goods decision-making at the individual level. We start by investigating whether national level inequality predicts cooperation in an experimental public goods game (Research Question 1). We then examine how national level inequality is related to individual decision-making to explain why, in cognitive prcessing terms, people living in more unequal societies might contribute less to the public good in the experimental game (Research Question 2). We then explore which national level social contextual factors can explain the relation between inequality and people’s decision-making in the experimental game (Research Question 3). Finally, we generalize our findings to behavior beyond the laboratory, and show how the cotextual processes identified in our analysis could also explain the effects of inequality on national level differences in real world public goods behavior (Research Question 4). To preface our conclusions, we show that in less equal nations, peple do cooperate less in the experimental public goods game (RQ1). We use cognitive modeling to show that people in less equal nations are less optimistic about others’ contributions at the outset of the game. At the same time, they are more sensitive to others’ contribution levels when choosing how much to contribute themselves, which might foster https://doi.org/10.1016/j.cresp.2023.100112 Received 29 June 2022; Received in revised form 10 April 2023; Accepted 27 April 2023 2666-6227/© 2023 The Author(s). Published by Elsevier B.V. This is an open access article under the CC BY license ( http://creativecommons.org/licenses/by/4.0/ ) J.C. Skewes and L",
    "chunk_id": "national_inequality,_social_capital,_and_public_goods_decision-making.json_chunk_3"
  },
  {
    "document_type": "research_paper",
    "title": "National inequality, social capital, and public goods decision-making",
    "author": "Joshua C. Skewes",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\national_inequality_social_capital.pdf",
    "date_published": "2023-05-03",
    "keywords": "\"Inequality\"; \"Gini\"; \"Cooperation\"; \"Public Goods Game\"; \"Trust\"; \"Civic Norms\"",
    "flag": "",
    "chunk_text": ". Published by Elsevier B.V. This is an open access article under the CC BY license ( http://creativecommons.org/licenses/by/4.0/ ) J.C. Skewes and L. Nockur Current Research in Ecological and Social Psychology 4 (2023) 100112 a race-to-the-bottom social dynamic in the game (RQ2). We show that the social contextual factors trust and adherence to civic norms are also related to contributions in the game, such that these might explain the relationship between inequality and cooperation (RQ3). We generalize this result by using a different and larger dataset to show that inequality is associated with reduced social volunteering – an in-kind contribution to the social public good ( Sugden, 1984 ) – and that this effect of inequaity can also be explained by national differences in social trust (RQ4). 2. Research questions 2.1. Research question 1: does national inequality predict contributions in the public goods game? Experimental research investigating the relationship between iequality and cooperation has mainly focused on the public goods game. This research has shown reliable effects of experimentally produced iequality on individual behavior in the laboratory. In the public goods game, a group of participants are given a fixed number of tokens, which they may either keep for themselves or contribute to a public good. All contributions to the public good are then multiplied by some factor and redistributed equally to all group members independent of their own contributions. The best outcome occurs for the group if all individuals contribute all their tokens to the public good. If this happens, then the maximum number of tokens will be multiplied and returned to the idividuals. However, the best outcome for each individual occurs if all other participants contribute all their tokens, while the individual theselves contributes nothing. The public goods game is thus a canonical example of a social dilemma, where individual and group outcomes are in opposition",
    "chunk_id": "national_inequality,_social_capital,_and_public_goods_decision-making.json_chunk_4"
  },
  {
    "document_type": "research_paper",
    "title": "National inequality, social capital, and public goods decision-making",
    "author": "Joshua C. Skewes",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\national_inequality_social_capital.pdf",
    "date_published": "2023-05-03",
    "keywords": "\"Inequality\"; \"Gini\"; \"Cooperation\"; \"Public Goods Game\"; \"Trust\"; \"Civic Norms\"",
    "flag": "",
    "chunk_text": ". The public goods game is thus a canonical example of a social dilemma, where individual and group outcomes are in opposition. In practice, most participants split their tokens and invest about half in the private good and half in the public good, with contribtions declining as the game is repeated ( Ledyard, 1995 ; Kopelman et al., 2002 ; Zelmer, 2003 ). Explanations for this decline range from intrpersonal mechanisms like reward-based learning about diminishing rturns during the game (e.g. Burton-Chellew et al., 2015 ; Camerer and Ho, 1999 ), to social processes related to weak-reciprocity and condtional cooperation (e.g. Fischbacher and Gächter, 2010 ). Experimental research has shown that individual contributions in the public goods game are influenced by inequality in the distribution of tokens given. Chan et al. (1996) found that individuals who were given more tokens on each round contributed less than they othewise would have: inequality led people to contribute less than their fair share. Subsequent laboratory research has supported and extended on this finding. Rather than manipulating the number of tokens received on a trial, Andersen et al. (2008) induced inequality between partiipants by paying different show-up fees. This manipulation induced the same effect as the unequal distribution of tokens, and people cotributed less than they otherwise would have (1996). Similar results have been reproduced in a wide range of laboratory settings, using diferent variants of the experimental public goods game, and different methods for simulating inequality ( Tavoni et al., 2011 ; Schlösser et al., 2020 ; Burton-Chellew et al., 2013 ; Hauser et al., 2019 ). Experimentally induced inequality leads to lower cooperation overall ( Anderson et al., 2008 ; Hauser et al., 2019 ; Zelmer, 2003 )",
    "chunk_id": "national_inequality,_social_capital,_and_public_goods_decision-making.json_chunk_5"
  },
  {
    "document_type": "research_paper",
    "title": "National inequality, social capital, and public goods decision-making",
    "author": "Joshua C. Skewes",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\national_inequality_social_capital.pdf",
    "date_published": "2023-05-03",
    "keywords": "\"Inequality\"; \"Gini\"; \"Cooperation\"; \"Public Goods Game\"; \"Trust\"; \"Civic Norms\"",
    "flag": "",
    "chunk_text": ". Experimentally induced inequality leads to lower cooperation overall ( Anderson et al., 2008 ; Hauser et al., 2019 ; Zelmer, 2003 ). To address our first research question, we re-analyze open data from an experimental implementation of the public goods game played by groups from a range of economically diverse nations ( Herrmann et al., 2008 ; Herrmann et al., 2017 ). We correlate the contributions made by each group in the game with the Gini coefficient for the country from which the experimental participants were sampled. The Gini coefficient is a standard measure of inequality. It quantifies the extent to which the distribution of wealth or income in a society departs from perfect equality. We focus on income inequality. Scores can range from zero to one, with zero indicating perfect income equality and one indicating perfect inequality. If national income inequality reduces cooperation in the experimental public goods game, we should observe a negative corelation between national Gini coefficient and contributions made in the experimental public goods game when played in different countries. 2.2. Research question 2: how is national income inequality related to decision-making processes in the public goods game? Our second research question concerns the nature of the decisiomaking processes by which inequality might reduce cooperation. Expeimental researchers have urged theorists to develop behavioral models to explain empirical departures from game theoretic equilibria in the public goods game ( Chan et al, 1996 ). A range of cognitive/behavioral models of choices in the game now exist for this purpose. These moels rely on two major mechanisms thought to be involved public goods decision-making. One is reinforcement learning, whereby people simply update their preferences for contributing a given number of tokens as a result of feedback (e.g. Camerer and Ho, 1999 ; Erev and Roth, 1998 ; Roth and Erev, 1995 )",
    "chunk_id": "national_inequality,_social_capital,_and_public_goods_decision-making.json_chunk_6"
  },
  {
    "document_type": "research_paper",
    "title": "National inequality, social capital, and public goods decision-making",
    "author": "Joshua C. Skewes",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\national_inequality_social_capital.pdf",
    "date_published": "2023-05-03",
    "keywords": "\"Inequality\"; \"Gini\"; \"Cooperation\"; \"Public Goods Game\"; \"Trust\"; \"Civic Norms\"",
    "flag": "",
    "chunk_text": ". Camerer and Ho, 1999 ; Erev and Roth, 1998 ; Roth and Erev, 1995 ). The second mechanism is social beliefs or expetations, whereby people adjust their own contributions as a function of what they believe others will contribute during the game, depending on their preference for matching or undermatching others’ contribtions (e.g. Fischbacher and Gächter, 2010 ; Larrouy and Lecouteux, 2017 ; Masel, 2007 ). To explore how inequality in participants’ home country is related to their decision-making in the game, we develop a formal implementation of Fischbacher and Gächter’s (2010) conditional cooperation schema. This model includes both social belief and social learning processes (see Masel, 2007 ; Larrouy and Lecouteux, 2017 for similar models). The model’s central assumption is that each individual has preferences for how much to contribute on a round, given what they believe others will contribute. The goal of the model is to infer the effects of social dnamics within the group both on individuals’ contribution on each trial, and on their beliefs about others’ contributions. Given these beliefs and preferences, the model assumes that contribution amounts are chosen according to the following process. We begin by modeling the contribution c of individual s in group g on trial t as a draw from a Poisson distribution. The Poisson distrbution is an appropriate representation for this process because token contribution is a discrete outcome variable whose variance (or paramter uncertainty) increases with the size of contribution c g,s,t : c g,s,t ∼ P oisson ( P g,s,t (1) We interpret the parameter of the Poisson distribution as the indvidual’s latent contribution preference on that trial, denoted P g,s,t . We then model contribution preferences P g,s,t as a function of the indiviual’s beliefs about the group contribution on the trial, denoted G b g,s,t : P g,s,t = ρ g,s .G b g,s,t (2) The parameter ρ g,s is a scaling or contribution matching paramter",
    "chunk_id": "national_inequality,_social_capital,_and_public_goods_decision-making.json_chunk_7"
  },
  {
    "document_type": "research_paper",
    "title": "National inequality, social capital, and public goods decision-making",
    "author": "Joshua C. Skewes",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\national_inequality_social_capital.pdf",
    "date_published": "2023-05-03",
    "keywords": "\"Inequality\"; \"Gini\"; \"Cooperation\"; \"Public Goods Game\"; \"Trust\"; \"Civic Norms\"",
    "flag": "",
    "chunk_text": ". It represents the individual’s preferences for conditional coopertion ( Fischbacher and Gächter, 2010 ). In this way, equation 2 captures the fact that a more cooperative person may prefer to match what they believe the rest of the group will contribute, whereas a less cooperative person may prefer to under-match, and save more for themselves. The parameter ρ g,s must be inferred, and is assumed to be between 0 and 1. If ρ g,s is inferred to be equal to 0, then the individual is copletely non-cooperative, and will always contribute zero tokens regarless of their belief about the group. If ρ g,s is inferred to be equal to 1, then the individual is completely conditionally cooperative, and will aways match what they believe the group will contribute. Values between represent a preference to more or less under-match what the individual believes the group will contribute ( Fischbacher and Gächter, 2010 ). We then model individuals’ belief about the group contribution, G b g,s,t , as the outcome of learning over trials. This belief is updated acording to the learning rule G b g,s,t = (1 − ω g,s ) .G b g,s,t −1 + ω g,s .G a g,s,t −1 (3) J.C. Skewes and L. Nockur Current Research in Ecological and Social Psychology 4 (2023) 100112 where G b g,s,t −1 denotes the individual’s belief about the group’s contrbution on the previous trial, G a g,s,t −1 denotes the average contribution observed on the previous trial, and ω s,g is a weighting for the influence of the observed contribution, relative to the individual’s prior beliefs. In this way, equation 3 captures the fact that a person who is more senstive to others’ contributions may quickly update their beliefs about what the rest of the group will contribute on the following round, whereas a person who is less sensitive to others’ contributions may update their beliefs less quickly. Because the average contribution G a g,s,t −1 is observed, it is included in the model as data. The parameter ω g,s must be inferred and is asumed to be between 0 and 1",
    "chunk_id": "national_inequality,_social_capital,_and_public_goods_decision-making.json_chunk_8"
  },
  {
    "document_type": "research_paper",
    "title": "National inequality, social capital, and public goods decision-making",
    "author": "Joshua C. Skewes",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\national_inequality_social_capital.pdf",
    "date_published": "2023-05-03",
    "keywords": "\"Inequality\"; \"Gini\"; \"Cooperation\"; \"Public Goods Game\"; \"Trust\"; \"Civic Norms\"",
    "flag": "",
    "chunk_text": ". Because the average contribution G a g,s,t −1 is observed, it is included in the model as data. The parameter ω g,s must be inferred and is asumed to be between 0 and 1. If ω g,s is inferred to be equal to 0, then the individual is completely insensitive to the group’s behavior and will never update their beliefs about what the group will contribute. They will fix a belief at the beginning of the game, and it will not change. If ω g,s is inferred to be equal to 1, then the individual is maximally senstive to the group’s behavior, and their beliefs about contributions on the next trial will always reflect exactly what they observed on the last trial. Values in between represent more or less sensitivity to others, defined as more or less rapid belief updating ( Fishbacher and Gächter, 2010 ; Masel, 2007 ). Finally, we model individuals’ initial beliefs – or optimism – about what others will contribute prior to starting the game. Initial beliefs are modeled as part of the Poisson draw on the first trial: G b g,s, 1 ∼ P oisson ( α g,s (4) Parameter α g,s thus represents participants’ initial beliefs about the group contribution. In this way, equation 4 captures the fact that idividuals may be more or less optimistic at the outset, assuming that others will give more or less on the first round. A perfectly pessimistic player will believe that others will contribute none of their tokens on the first round, and α g,s will be equal to 0. A perfectly optimistic player will believe that others will contribute all their tokens on the first round, and α g,s will be equal to 20. Values in between represent more or less optimism about the contributions to be offered in the game. The model therefore has three decision parameters for inference",
    "chunk_id": "national_inequality,_social_capital,_and_public_goods_decision-making.json_chunk_9"
  },
  {
    "document_type": "research_paper",
    "title": "National inequality, social capital, and public goods decision-making",
    "author": "Joshua C. Skewes",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\national_inequality_social_capital.pdf",
    "date_published": "2023-05-03",
    "keywords": "\"Inequality\"; \"Gini\"; \"Cooperation\"; \"Public Goods Game\"; \"Trust\"; \"Civic Norms\"",
    "flag": "",
    "chunk_text": ". Values in between represent more or less optimism about the contributions to be offered in the game. The model therefore has three decision parameters for inference. These are ρ g,s , which represents the individual’s preference for condtional cooperation or matching to group contributions ( Fishbacher and Gächter, 2010 ); ω g,s which represents the individual’s sensitivity to iformation about the rest of the group’s contributions in updating their beliefs ( Masel, 2007 ); and α g,s , which represents the individual’s otimism about what the rest of the group will contribute prior to the first trial. Given this model, if national inequality undermines economic cooperation and has stable effects on individuals’ decision-making prcesses, then groups should have identifiable differences in one or more of these decision model parameters, depending on the inequality in their country. 2.3. Research question 3: which national level social contextual factors can explain the relationship between national inequality and public goods decision-making? Our third research question concerns the social contextual variables that might be associated with inequality, and that might also be related to decision-making in the public goods game. Research suggests two main kinds of contextual factor which might share connections both to national inequality and to public goods game decision-making. The first is the degree to which individuals in a society rely on others versus relying on themselves. It has been shown that in less equal societies, people feel that it is more necessary to be self-reliant to overcome fnancial hardship ( Jachimowcz et al, 2020 ). People are more likely to endorse norms related to self-enhancement ( Sánchez-Rodriguez et al., 2020 ), possibly as a way of coping with increased threat of relative poverty. This suggests that effects of a nation’s level of inequality on public goods decision-making may be explainable by a tendency of that nation’s inhabitants towards greater individualism",
    "chunk_id": "national_inequality,_social_capital,_and_public_goods_decision-making.json_chunk_10"
  },
  {
    "document_type": "research_paper",
    "title": "National inequality, social capital, and public goods decision-making",
    "author": "Joshua C. Skewes",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\national_inequality_social_capital.pdf",
    "date_published": "2023-05-03",
    "keywords": "\"Inequality\"; \"Gini\"; \"Cooperation\"; \"Public Goods Game\"; \"Trust\"; \"Civic Norms\"",
    "flag": "",
    "chunk_text": ". This suggests that effects of a nation’s level of inequality on public goods decision-making may be explainable by a tendency of that nation’s inhabitants towards greater individualism. To investigate this possibility, we include national level measures of trait individualism ( Hofstede et al., 2010 ) in our models. The second contextual factor which may be related to both inequaity and public goods decision-making is the “social capital ” available to members of a society. A society has more social capital if there are social ties among its members that make their interactions more honest and effective ( Granovetter, 2017 ). In societies with more social capital, there is less need for formal institutions to regulate cooperation, because cooperation is regulated by interpersonal relationships and norms. Scial capital is “capital ”, then, in the sense that societies with more of it can save resources on administration of sanctions against anti-social behavior. There is broad agreement that social capital has two main eements. The first is trust. Trust has been defined as the expecttion of future reciprocity, or the belief that others will do no harm ( Granovetter, 2017 ). This belief motivates cooperation ( Alós-Ferrer and Farolfi, 2019 ; Ostrom and Walker, 2003 ; see however Chaudhuri et al., 2002 ), and research has shown that individuals in more trusting envronments are more likely to contribute to a public good, both in the laboratory (e.g. Iacono and Sonmez, 2020 ) and in natural behavior (e.g. Sønderskov, 2009 ). It is well known that general trust is lower in uequal environments ( Fiske et al., 2012 ). This suggests that the relatioship between national inequality and public goods decision-making may be explainable as effects of the level of generalized trust between people living in that nation ( Sønderskov, 2009 ). The other main element in social capital is the adherence to civic norms. Adherence to civic norms has been described as a “mirror refletion ” of trust ( Knack and Keefer, 1997 )",
    "chunk_id": "national_inequality,_social_capital,_and_public_goods_decision-making.json_chunk_11"
  },
  {
    "document_type": "research_paper",
    "title": "National inequality, social capital, and public goods decision-making",
    "author": "Joshua C. Skewes",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\national_inequality_social_capital.pdf",
    "date_published": "2023-05-03",
    "keywords": "\"Inequality\"; \"Gini\"; \"Cooperation\"; \"Public Goods Game\"; \"Trust\"; \"Civic Norms\"",
    "flag": "",
    "chunk_text": ". The other main element in social capital is the adherence to civic norms. Adherence to civic norms has been described as a “mirror refletion ” of trust ( Knack and Keefer, 1997 ). Whereas trust is defined by a belief that others will not do harm, adherence to civic norms is charaterized by a belief that one is worthy of being trusted by others, because one’s choices and behavior will reliably follow social expectations for good interactions ( Knack and Keefer, 1997 ; Granovetter, 2017 ). People in more equal societies are more likely to participate in civic institutions ( Costa and Kahn, 2003 ; Levin-Waldman, 2012 ; van Holm, 2019 ), and field research has shown that trustworthiness, separately from trustinness, drives real world public goods contributions ( Karlan, 2005 ). Therfore, any relationship between inequality and public goods decisiomaking might also be explainable by the general level of adherence to civic norms in a society. 2.4. Research question 4: does our analysis of laboratory results generalize to national level public goods behavior? Our fourth research question concerns the generalizability of our findings. To answer the first three questions, we focus on a dataset with a limited number of countries that is collected mostly with university students. University students are famously unrepresentative of national populations. Also, these data were collected in cities that vary in how well they represent their national economic and cultural contexts, which causes some uncertainty about our inferences concerning national level variables. It is therefore important, where possible, to assess whether our results generalize to more nationally representative samples. Aother concern is that the laboratory version of the public goods game is an artificial situation, with artificial rules explicitly designed to model behavior with respect to theoretically well-defined equilibria",
    "chunk_id": "national_inequality,_social_capital,_and_public_goods_decision-making.json_chunk_12"
  },
  {
    "document_type": "research_paper",
    "title": "National inequality, social capital, and public goods decision-making",
    "author": "Joshua C. Skewes",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\national_inequality_social_capital.pdf",
    "date_published": "2023-05-03",
    "keywords": "\"Inequality\"; \"Gini\"; \"Cooperation\"; \"Public Goods Game\"; \"Trust\"; \"Civic Norms\"",
    "flag": "",
    "chunk_text": ". Ideally, we would also like to generalize any patterns found in our analysis to more natural kinds of public goods actions ( Levitt and List, 2007 ). To address these concerns, we apply the same statistical models used to answer RQ1-RQ3 to a different dataset. Here we use the European Vaues Survey to investigate the effects of inequality and our other national level social contextual variables on national rates of social volunteering, a typical public goods behavior ( Sugden, 1984 ). To recap, the present study aims to address four main questions. These are: J.C. Skewes and L. Nockur Current Research in Ecological and Social Psychology 4 (2023) 100112 • RQ1) what is the relationship between national level inequality and contributions in an experimental public goods game? • RQ2) What are the decision-making mechanisms involved? • RQ3) What other social contextual processes might explain how iequality is related to public goods decision-making? and • RQ4) Can any insights we draw from our analysis be generalized to real public goods actions measured in larger nationally representtive samples? 3. Method 3.1. Datasets The experimental data used to answer RQ1, RQ2, and RQ3 were colected by Herrmann and colleagues (2008) . The researchers have made this data freely available ( Herrmann et al., 2017 ). Participants in the experiment were asked to play a ten round public goods game in stable groups of four. On each round, participants were allocated 20 tokens to keep or to contribute to the public good. On each round, all of the tokens contributed to the public good were multiplied by a factor of 1.6, and the new total was redistributed to all group members indpendent of their contributions. Each group played two versions of the game, in counterbalanced order. The first was the standard game. The second was a version in which it was also possible for group members to punish each other. We focus exclusively on data from the standard game",
    "chunk_id": "national_inequality,_social_capital,_and_public_goods_decision-making.json_chunk_13"
  },
  {
    "document_type": "research_paper",
    "title": "National inequality, social capital, and public goods decision-making",
    "author": "Joshua C. Skewes",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\national_inequality_social_capital.pdf",
    "date_published": "2023-05-03",
    "keywords": "\"Inequality\"; \"Gini\"; \"Cooperation\"; \"Public Goods Game\"; \"Trust\"; \"Civic Norms\"",
    "flag": "",
    "chunk_text": ". The first was the standard game. The second was a version in which it was also possible for group members to punish each other. We focus exclusively on data from the standard game. Most participants completed the standard game before the vesion with punishment ( Herrmann et al., 2008 ). Excluding participants who experienced the punishment version first did not alter the results of any analyses. 280 groups participated in the experiment for a total of 1120 paticipants. Data were collected from 15 economically and culturally dverse nations. These were Australia, Belarus, China, Denmark, Germany, Greece, South Korea, Oman, Russia, Saudi Arabia, Switzerland, Turkey, the UK, Ukraine, and the USA. Gini coefficients for the years 2002-2006 were retrieved from the World Bank (n.d) for as many of the participant countries as possible. Gini coefficients were unavailable for Oman and Saudi Arabia, and so data collected from participants in these nations were not included in the analysis. Data from the other 13 countries were included. Only 25 groups were excluded from analysis for this reason. For some countries, Gini data were not available for all years. Averages from the available years were used. The Gini data used are available as Table 1A in Apendix 1. The experimental data included in the analysis are from 10 groups from Australia, 17 groups from Belarus, 24 groups from China, 17 groups from Denmark, 15 groups from Germany, 11 groups from Greece, 21 groups from Korea, 38 groups from Russia, 47 groups from Switzerland, 16 groups from Turkey, 14 groups from the UK, 11 groups from Ukraine, and 14 groups from the USA. For remaining national level variables in the analysis of the expermental data, values reported in Herrmann and colleagues (2008) were used. They acquired trait individualism scores from Hofstede and Hofsede (2004) , a standard source for national level survey data for cultural traits. For Russia, Belarus, and Ukraine, we added updated scores from the revised edition by Hofstede et al. (2010)",
    "chunk_id": "national_inequality,_social_capital,_and_public_goods_decision-making.json_chunk_14"
  },
  {
    "document_type": "research_paper",
    "title": "National inequality, social capital, and public goods decision-making",
    "author": "Joshua C. Skewes",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\national_inequality_social_capital.pdf",
    "date_published": "2023-05-03",
    "keywords": "\"Inequality\"; \"Gini\"; \"Cooperation\"; \"Public Goods Game\"; \"Trust\"; \"Civic Norms\"",
    "flag": "",
    "chunk_text": ". For Russia, Belarus, and Ukraine, we added updated scores from the revised edition by Hofstede et al. (2010) . Following the methodoogy established in Knack and Keefer (1997) , Hermann and colleagues retrieved national level social capital variables from the World Values Survey ( Inglehart et al., 2018 ). Trust was defined as the national rate of positive answers to the question “Most people can be trusted ”, and adherence to civic norms was defined as the national level mean score (out of 10) for responses to questions about the justifiability of falsely claiming welfare entitlements, tax avoidance, and fare evasion on pulic transport. Greater adherence to civic norms was defined as belieing that these trespasses are less justifiable (i.e. the items were reverse scored in analysis). See Knack and Keefer (1997) , Granovetter (2017) , and Herrmann and colleagues (2008) for discussion of this method. To distinguish between an effect of unequal incomes within coutries and an effect of unequal incomes between countries, we icluded per capita GDP as an additional control. Per capita GDP data from the International Monetary Fund’s World Economic Outlook Database (2007) was used, as reported in Herrmann et al. (2008) . To answer RQ4, we used a separate dataset. This included national level economic indicators and data from the European Values Survey. Values for the variables trust, civic norms, and volunteering rate are calculated from the 2008 – 2010 wave of the survey (EVS/WVS, 2021). This wave was chosen because it included the highest number of coutries with responses to all relevant survey questions. Volunteering was defined as social volunteering, which was measured as the percentage of individuals within each country that responded that they had vounteered for one or more of the following types of organization: social welfare, religious, educational or cultural, human rights, environmetal conservation, ecology, animal rights, youth work, sports, women’s, peace movement, health, or consumer rights organizations",
    "chunk_id": "national_inequality,_social_capital,_and_public_goods_decision-making.json_chunk_15"
  },
  {
    "document_type": "research_paper",
    "title": "National inequality, social capital, and public goods decision-making",
    "author": "Joshua C. Skewes",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\national_inequality_social_capital.pdf",
    "date_published": "2023-05-03",
    "keywords": "\"Inequality\"; \"Gini\"; \"Cooperation\"; \"Public Goods Game\"; \"Trust\"; \"Civic Norms\"",
    "flag": "",
    "chunk_text": ". Volunteeing for political parties, political action groups, labor unions, and prfessional organizations was not counted. Trust and civic norms were dfined as for Herrmann et al. (2008) , using the corresponding trust and civic norms questions in the European Values Survey. Gini scores for the relevant countries were taken from the 2009 Human Development Report ( UNDP, 2009 ), and per capita GDP was taken from World Bank estimates for 2009 ( World Bank, n.d. ). Data from 46 countries were icluded, and the data table is available in Appendix 1. 3.2. Hierarchical model structure and overview of measures We use Bayesian hierarchical modeling for all inference ( Lee and Wgenmakers, 2013 ; McElreath, 2020 ; Gelman et al., 2020 ). Hierarchical modeling is appropriate whenever it is important to account for repeated measures across levels of analysis, or to account for the effects of other kinds of nesting in the data. In the present study, there are four possible levels of analysis, and different variables enter the analysis at different points in the models’ hierarchy. At the bottom is the trial level, or the ten rounds on which participants chose to contribute to the public good. Token contributions are the only data included at this level. Higher up is the participant level, with contributions assumed to be repeated saples from individual participants. Only the cognitive model parameters ρ g,s , α g,s , and ω g,s are represented in our analysis at this level. Next is the group level, or the four-person context in which participants play the experimental game in the laboratory. Overall group contributions are analyzed at this level. Individual participant contributions are also assumed to be constrained by the social dynamics in the group, and so individual level cognitive model parameters are assumed to have shared group-level variance. At the top is the national level, with each fouperson group assumed to be influenced by the national social context in which they are playing the game",
    "chunk_id": "national_inequality,_social_capital,_and_public_goods_decision-making.json_chunk_16"
  },
  {
    "document_type": "research_paper",
    "title": "National inequality, social capital, and public goods decision-making",
    "author": "Joshua C. Skewes",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\national_inequality_social_capital.pdf",
    "date_published": "2023-05-03",
    "keywords": "\"Inequality\"; \"Gini\"; \"Cooperation\"; \"Public Goods Game\"; \"Trust\"; \"Civic Norms\"",
    "flag": "",
    "chunk_text": ". At the top is the national level, with each fouperson group assumed to be influenced by the national social context in which they are playing the game. The variables included at this level are GDP, Gini coefficient, individualism, trust, adherence to civic norms, and national rate of social volunteering (depending on the model and the RQ). We use Bayesian hierarchical modeling because it allows us to codify all the necessary assumptions about how measures and model paraeters are related across levels, and thus affords more precise estimates of model parameters given the data ( Gelman et al., 2020 ). We can eplain each token contribution at the trial level in terms of the cognitive model, whose parameters are then interpretable at the individual level. We can represent the effects of group social dynamics as shared variance in cognitive model parameters between individuals at the group level, and we can make inferences about national level context by modeling the effects of national level measures on national level means of cogntive model parameters. Importantly, we can do this all within the same integrated model ( Lee and Wagenmakers, 2013 ). The alternative to this fully hierarchical statistical approach is a multi-step approach, in which one first fits models to each participant individually, and then runs regressions on participant level parameter J.C. Skewes and L. Nockur Current Research in Ecological and Social Psychology 4 (2023) 100112 estimates. The integrated Bayesian hierarchical approach is preferable, because it fully represents shared variance at group and national leels in the analysis, and it makes use of all uncertainty in the data. This ensures improved parameter estimation at all levels of analysis. This is because posterior estimates are regularized by assumptions of shared variance, which greatly increases the precision of the posterior distrbutions, improving our inferences about the parameters they represent ( Ketahira, 2016 ). 3.3",
    "chunk_id": "national_inequality,_social_capital,_and_public_goods_decision-making.json_chunk_17"
  },
  {
    "document_type": "research_paper",
    "title": "National inequality, social capital, and public goods decision-making",
    "author": "Joshua C. Skewes",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\national_inequality_social_capital.pdf",
    "date_published": "2023-05-03",
    "keywords": "\"Inequality\"; \"Gini\"; \"Cooperation\"; \"Public Goods Game\"; \"Trust\"; \"Civic Norms\"",
    "flag": "",
    "chunk_text": ". 3.3. Statistical analyses We developed four sets of statistical models: one to represent each of our four research questions. All models are specified here in full. All inference was done using MCMC sampling implemented in JAGS sofware ( Plummer, 2003 ) via the R2jags R package ( Su and Masano, 2012 ). For all models, we used three chains of 15000 samples, with 5000 saples discarded as burn-in. Code for default JZS priors (used for partial correlation in the regression models, see below) was adapted from the code for the BayesMed package ( Nuijten, et al., 2014 , Ntzoufras, 2009 ). We report posterior distributions and/or Bayesian credible intervals for parameters of interest in all models, and these can be interpreted as ntional level regression coefficients. No major divergences were observed in any of the traceplots for the models’ posterior distributions, and covergence diagnostics were acceptable with ̂ R < 1.1 for all parameters. Because our RQs are primarily exploratory, and we are not conducting hypotheses testing relative to point null hypotheses, we do not report Bayes Factors ( Gelman and Shalizi, 2013 ). All predictors were standarized before inclusion in a model. Our RQ1 is whether national inequality predicts contributions in the public goods game. We used a default Bayesian hierarchical correltion model to represent this question ( Wetzels and Wagenmakers, 2012 ). Data for this model was the overall contribution Y of each group g. This was calculated by adding all contributions on a trial, and then adding across all trials. The prior for contribution Y g was assumed to be: Y g ∼ Normal ( μ nation , τ ) (5) Here μ nation represents the expected average contribution for groups in a nation, and τ is the national level precision (inverse of the variance). An uninformative Gamma distribution was used as a prior for τ τ ∼ Gamma ( 0 . 01 , 0",
    "chunk_id": "national_inequality,_social_capital,_and_public_goods_decision-making.json_chunk_18"
  },
  {
    "document_type": "research_paper",
    "title": "National inequality, social capital, and public goods decision-making",
    "author": "Joshua C. Skewes",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\national_inequality_social_capital.pdf",
    "date_published": "2023-05-03",
    "keywords": "\"Inequality\"; \"Gini\"; \"Cooperation\"; \"Public Goods Game\"; \"Trust\"; \"Civic Norms\"",
    "flag": "",
    "chunk_text": ". An uninformative Gamma distribution was used as a prior for τ τ ∼ Gamma ( 0 . 01 , 0 . 01 ) (6) The relation between inequality (the national Gini coefficient) and the national level estimate of group contribution μ nation was modelled as a linear relationship: μ nation = β 0 + β Gini .Gin i nation (7) Because Gini was standardized before entry into the model, a stadard normal distribution was used as the prior for the model intercept β 0 . For the model slope, the Jeffreys–Zellner–Siow (JZS) prior was used ( Liang et al., 2008 , Wetzels and Wagenmakers, 2012 ). The general form of this is: β ∼ Normal 0 , g ( X T .X ) −1 ) (8) where φ is assigned the prior φ ∼ Gamma ( 0 . 01 , 0 . 01 ) (9) g is assigned the prior g = n ∕ 2 1∕2 1 2 ) g −3∕2 e − n ∕ ( 2 g ) (10) and n is the number of groups. The parameter of interest for this model is the effect of inequality β Gini . JAGS code for the model is included in Appendix 2. Our RQ2 concerns how inequality affects decision-making processes used in the public goods game. To represent this question, we used a dfault correlation model to model the relationship between national level Gini coefficient and national level estimates for each of the parameters in our decision model. We used the same fully hierarchical model to ifer decision parameters simultaneously for all participants, in all groups, and within each nation, and then predicted the inferred national level estimates for the decision model parameters from national level Gini coefficients. The decision model is specified above in Equations 1 to 4 . The preerence for conditional cooperation parameter ρ g,s and the sensitivity to others’ contributions parameter ω g,s are both bounded by 0 and 1. Therfore, we used beta regression to model effects at the group level. Each subject level parameter (e.g",
    "chunk_id": "national_inequality,_social_capital,_and_public_goods_decision-making.json_chunk_19"
  },
  {
    "document_type": "research_paper",
    "title": "National inequality, social capital, and public goods decision-making",
    "author": "Joshua C. Skewes",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\national_inequality_social_capital.pdf",
    "date_published": "2023-05-03",
    "keywords": "\"Inequality\"; \"Gini\"; \"Cooperation\"; \"Public Goods Game\"; \"Trust\"; \"Civic Norms\"",
    "flag": "",
    "chunk_text": ". Therfore, we used beta regression to model effects at the group level. Each subject level parameter (e.g. ρ g,s ) was modelled using a beta distribution with national level shape parameters ρ g,s ∼ Beta ( βshape 1 ρ nation , βshape 2 ρ nation (11) which were reparameterized in terms of national level mean μ ρ nation and concentration (or precision) σ ρ βshape 1 ρ nation = μ ρ nation .σ ρ nation (12) βshape 2 ρ nation = (1 − μ ρ nation ) .σ ρ nation (13) The concentration parameter was assigned a broad uniform prior σ ρ nation ∼ Uniform ( 1 , 100 ) (14) and the relationship between the probit transformed national level etimate and national level Gini coefficients was assumed to follow the group level linear model P robit ( μ ρ nation ) = β 0 + β Gini .Gin i nation (15) Because the Gini variable was standardized, the prior for the model intercept β 0 was assumed to be a standard normal distribution. The prior for the regressor β Gini was the same JZS prior that was applied in the contributions model Equations 8 to (10) . The relation between Gini and Learning rate ω g,s was modelled in the same way as contribution preferences ρ g,s , and so the specification is the same. The optimism or initial beliefs parameter α g,s can range continuously from 0 to 20. The subject level prior for this parameter was therefore assumed to follow a Gamma distribution α g,s ∼ Gamma ( γshape α nation , γrate α nation (16) which was reparameterised in terms of the mode and standard deviation γshape 1 α nation = 1 + μ α nation .γrate α nation (17) γrate α nation = μ α nation + μ α nation 2 + 4 . ( σ α nation ) 2 2 . ( σ α nation ) 2 (18) The standard deviation was transformed to precision and assigned an uninformative Gamma prior σ α nation = 1 √ τ α nation (19) τ α nation ∼ Gamma ( 0 . 01 , 0",
    "chunk_id": "national_inequality,_social_capital,_and_public_goods_decision-making.json_chunk_20"
  },
  {
    "document_type": "research_paper",
    "title": "National inequality, social capital, and public goods decision-making",
    "author": "Joshua C. Skewes",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\national_inequality_social_capital.pdf",
    "date_published": "2023-05-03",
    "keywords": "\"Inequality\"; \"Gini\"; \"Cooperation\"; \"Public Goods Game\"; \"Trust\"; \"Civic Norms\"",
    "flag": "",
    "chunk_text": ". ( σ α nation ) 2 (18) The standard deviation was transformed to precision and assigned an uninformative Gamma prior σ α nation = 1 √ τ α nation (19) τ α nation ∼ Gamma ( 0 . 01 , 0 . 01 ) (20) and the log transformed national level estimate was assumed to have a linear relationship with national level Gini coefficients: l og ( μ α nation ) = β 0 + β Gini .G in i nation (21) The prior for the model intercept β 0 was assumed to be a standard normal distribution. The prior for the regressor β Gini was the same JZS parameter that we applied in the contributions model Equations 8 to (10) . JAGS code for the model is included in Appendix 2. Our RQ3 is whether any effects of inequality can be explained by the national level psychological variables individualism, trust, or aherence to civic norms? Two separate default partial correlation models J.C. Skewes and L. Nockur Current Research in Ecological and Social Psychology 4 (2023) 100112 were used to represent this RQ. Partial correlations were used to cotrol for effects across regressors, and the results from these models are interpretable as coming from standard multiple regression models. One model focused on group contributions. This was identical to the model used to correlate Gini and group level contributions Equations 5 to (10) , except that the linear equation included all five variables GDP, individualism, trust, adherence to civic norms, and Gini coefficient. For the parameters of the linear equation, the multivarate JZS prior for partial correlation was used Wetzels and Wagenmaers, 2012 ). JAGS code for the model is included in Appendix 2. The other model focused on decision model parameters. This was identical to the model used to correlate Gini coefficient and decision parameters ( Equations 1 to 4 and Equations 11 to (21) , except that the linear equtions ( Equation 15 and Equation 21 ) included all five variables GDP, individualism, trust, adherence to civic norms, and Gini. The multivarate JZS prior for partial correlation was again used",
    "chunk_id": "national_inequality,_social_capital,_and_public_goods_decision-making.json_chunk_21"
  },
  {
    "document_type": "research_paper",
    "title": "National inequality, social capital, and public goods decision-making",
    "author": "Joshua C. Skewes",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\national_inequality_social_capital.pdf",
    "date_published": "2023-05-03",
    "keywords": "\"Inequality\"; \"Gini\"; \"Cooperation\"; \"Public Goods Game\"; \"Trust\"; \"Civic Norms\"",
    "flag": "",
    "chunk_text": ". The multivarate JZS prior for partial correlation was again used. JAGS code for the model is included in Appendix 2. Our RQ4 is whether our findings from the analysis of the experimetal public goods game generalize to naturalistic public goods behavior, specifically national social volunteering rates. Because they are rates, the national volunteering variable Y nation is bounded by 0 and 1. This variable was therefore assumed to follow a Beta distribution, and the same beta regression model was used to represent this RQ as was used for the other rate variables/parameters Equations 11 to (15) . JAGS code for the model is included in Appendix 2. 4. Results Fig. 1 presents results relevant to our RQ1. Panel A presents the epirical relationship between national Gini coefficient and group contrbutions in the public goods game. The points represent the mean for the data collected within each nation, and the error bars represent standard deviations between groups recruited at the different national sites of the experiment. The plot suggests that in countries with higher income iequality, groups contributed less on average in the experimental game. Panel B presents the full posterior for the model of this relationship – the coefficient for the default Bayesian correlation model ( Wetzels and Wagenmakers, 2012 ) – which supports this inference. The panel shows that the mean of the posterior distribution is negative, indicating a neative effect of Gini, or a negative relationship between Gini and group contributions, and the 95% Bayesian Credible Intervals do not include zero (indicated with the red line). Fig. 2 presents the results relevant to our RQ2. These are the reltionships between national level inequality and national level estimates for our (hierarchical) cognitive model parameters. Panel A presents the posterior distribution for the effect of national inequality (i.e. Gini cefficient) on the initial optimism parameter in the model",
    "chunk_id": "national_inequality,_social_capital,_and_public_goods_decision-making.json_chunk_22"
  },
  {
    "document_type": "research_paper",
    "title": "National inequality, social capital, and public goods decision-making",
    "author": "Joshua C. Skewes",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\national_inequality_social_capital.pdf",
    "date_published": "2023-05-03",
    "keywords": "\"Inequality\"; \"Gini\"; \"Cooperation\"; \"Public Goods Game\"; \"Trust\"; \"Civic Norms\"",
    "flag": "",
    "chunk_text": ". Panel A presents the posterior distribution for the effect of national inequality (i.e. Gini cefficient) on the initial optimism parameter in the model. The panel shows that the mean of the posterior is negative, and the 95% Bayesian Credible Intervals do not include zero (indicated with the red line). This indicates that national level inequality is associated with a decrease in initial optimism. Panel B presents the posterior distribution for the efect of national inequality and the sensitivity to others’ contributions parameter in the model. The panel shows that the mean of the postrior is positive, and the 95% Bayesian Credible Intervals do not include zero. This indicates that national level inequality is associated with an increase in sensitivity to others’ contributions. Panel C presents the poterior distribution for the effect of national inequality on the conditional preferences to cooperate parameter in the model. The panel shows that the mean of the posterior is negative, but the 95% Bayesian Credible Intervals do include zero. This indicates that it is unlikely that inequaity is associated with preferences for conditional cooperation or that more data would be required to demonstrate an association between national level inequality and preferences to match others’ expected cotributions. Fig. 3 presents the results relevant to our RQ3. These results include our other national level social variables of interest. Panel A presents the Fig. 1. Panel A: Scatterplot for the relationship between national level Gini coeficient and total contribution amount within a nation in the experimental public goods game. Error bars represent standard deviation calculated for experimetal groups within a country. Panel B: Posterior distribution for the standardized effect of national Gini coefficient on contribution amount, as inferred using the default hierarchical correlation model",
    "chunk_id": "national_inequality,_social_capital,_and_public_goods_decision-making.json_chunk_23"
  },
  {
    "document_type": "research_paper",
    "title": "National inequality, social capital, and public goods decision-making",
    "author": "Joshua C. Skewes",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\national_inequality_social_capital.pdf",
    "date_published": "2023-05-03",
    "keywords": "\"Inequality\"; \"Gini\"; \"Cooperation\"; \"Public Goods Game\"; \"Trust\"; \"Civic Norms\"",
    "flag": "",
    "chunk_text": ". Panel B: Posterior distribution for the standardized effect of national Gini coefficient on contribution amount, as inferred using the default hierarchical correlation model. The point represents the mean of the posterior distribution of the effect of Gini coefficient on contribution amount, and the error bar represents the Bayesian Credible Interval. posteriors for the partial correlation model relating national inequality and group contributions. The panel shows that when the other national level predictors are included in the model, inequality (i.e. Gini coeffcient) is no longer associated with group contributions. The zero value for the effect of Gini coefficient is included in the 95% Bayesian Creible Interval. However, trust is associated positively with group contrbutions, and adherence to civic norms is associated negatively with cotributions. Zero values for neither effect is included in the 95% Bayesian Credible Interval (red lines). This indicates that as national level trust increases, and national level adherence to civic norms decreases, group contributions in the experimental public goods game increase. There is no clear association with national level individualism or national GDP. Panel B presents the posteriors for the partial correlation model rlating national inequality and initial optimism, as inferred using the dcision model. The panel shows that when the other national level prdictors are included in the model, inequality (i.e. Gini coefficient) is no longer associated with initial optimism. However, trust is associated positively with initial optimism, and zero is not included in the 95% Bayesian Credible Interval for this effect. This indicates that national level trust is associated with people’s initial optimism in the experimetal public goods game. There is no clear association with adherence to civic norms, inequality, individualism, or national GDP for this paraeter",
    "chunk_id": "national_inequality,_social_capital,_and_public_goods_decision-making.json_chunk_24"
  },
  {
    "document_type": "research_paper",
    "title": "National inequality, social capital, and public goods decision-making",
    "author": "Joshua C. Skewes",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\national_inequality_social_capital.pdf",
    "date_published": "2023-05-03",
    "keywords": "\"Inequality\"; \"Gini\"; \"Cooperation\"; \"Public Goods Game\"; \"Trust\"; \"Civic Norms\"",
    "flag": "",
    "chunk_text": ". There is no clear association with adherence to civic norms, inequality, individualism, or national GDP for this paraeter. Panel C presents the posteriors for the partial correlation model rlating national inequality and sensitivity to others’ contributions, as i J.C. Skewes and L. Nockur Current Research in Ecological and Social Psychology 4 (2023) 100112 Fig. 2. Posterior distributions for the standardized effects of national level Gini coefficient on decision model parameters, as inferred using the hierarchical conitive model. The points represent the means of the posterior distributions, and the error bar represents the Bayesian Credible Intervals. The figure shows that Gini coefficient is negatively associated with initial optimism (Panel A), and positively associated with sensitivity to others’ contributions in the game (Panel B). Gini coefficient is not clearly associated with preferences for conditional cooperation (Panel C). ferred using the decision model. The panel shows that when the other national level predictors are included in the model, inequality (i.e. Gini coefficient) is no longer associated with sensitivity to others’ contribtions. However, adherence to civic norms is associated negatively with sensitivity to others, and zero is not included in the 95% Bayesian Creible Interval. This indicates that national level adherence to civic norms is associated with increased sensitivity to others’ contributions in the eperimental public goods game. There is no clear association with trust, inequality, individualism, or national GDP for this parameter. Panel D presents the posteriors for the partial correlation model rlating national inequality and conditional preferences for cooperation, as inferred using the decision model. There is no clear association with national level trust, civic norms, individualism, national GDP, or ntional Gini coefficient for this parameter. Fig. 4 presents the results relevant to our RQ4",
    "chunk_id": "national_inequality,_social_capital,_and_public_goods_decision-making.json_chunk_25"
  },
  {
    "document_type": "research_paper",
    "title": "National inequality, social capital, and public goods decision-making",
    "author": "Joshua C. Skewes",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\national_inequality_social_capital.pdf",
    "date_published": "2023-05-03",
    "keywords": "\"Inequality\"; \"Gini\"; \"Cooperation\"; \"Public Goods Game\"; \"Trust\"; \"Civic Norms\"",
    "flag": "",
    "chunk_text": ". There is no clear association with national level trust, civic norms, individualism, national GDP, or ntional Gini coefficient for this parameter. Fig. 4 presents the results relevant to our RQ4. Panel A presents the empirical relationship between national Gini coefficient and national level volunteering. The plot suggests that in countries with higher icome inequality, volunteering rates are lower. Panel B presents the full posterior for the model of this relationship, and the model supports this inference. The panel shows that the mean of the posterior for the corelation is negative, and the 95% Bayesian Credible Intervals do not include zero (indicated with the red line). This indicates that national level inequality is associated with a lower national level volunteering rate. Fig. 3. Posterior distribution for the standardized effect of all national level scial contextual variables on contribution amount (Panel A) and decision model parameters (Panel B-D). The point represents the mean of the posterior distrbution, and the error bar represents the Bayesian Credible Intervals. Panel A shows that trust is positively associated with contribution amounts, and that adherence to civic norms is negatively associated with contributions. Panel B shows that trust is associated with initial optimism in the game. Panel C shows that adherence to civic norms is positively associated with sensitivity to others’ contributions. Panel D shows that contextual variables are unrelated to prefeences for conditional cooperation. Panel C presents the posteriors for the coefficients in the partial corelation model. The panel shows that when the other national level prdictors are included in the model, inequality (i.e. Gini coefficient) is no longer associated with volunteering. The zero value for Gini is included in the 95% Bayesian Credible Interval. However, both GDP and trust are associated positively with volunteering rate. There is no clear assocition with civic norms. 5",
    "chunk_id": "national_inequality,_social_capital,_and_public_goods_decision-making.json_chunk_26"
  },
  {
    "document_type": "research_paper",
    "title": "National inequality, social capital, and public goods decision-making",
    "author": "Joshua C. Skewes",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\national_inequality_social_capital.pdf",
    "date_published": "2023-05-03",
    "keywords": "\"Inequality\"; \"Gini\"; \"Cooperation\"; \"Public Goods Game\"; \"Trust\"; \"Civic Norms\"",
    "flag": "",
    "chunk_text": ". However, both GDP and trust are associated positively with volunteering rate. There is no clear assocition with civic norms. 5. Discussion These results provide the following answers to our research quetions. Concerning RQ1, national level income inequality is associated with reduced cooperation in the public goods game, measured as oveall reduced contributions. Previous experimental research has induced or simulated inequality, by for example using different show-up fees (e.g. Anderson et al., 2008 ) or by providing different amounts of tokens on each trial to simulate income inequality (e.g. Schlösser et al, 2020 ). By comparing peoples’ contributions to the public good across a range of societies with different Gini coefficients, the present research builds on these findings by investigating the effects of pre-existing inequality within different national communities. Our result suggests that research J.C. Skewes and L. Nockur Current Research in Ecological and Social Psychology 4 (2023) 100112 Fig. 4. Panel A: Scatterplot for the relationship between national level Gini coefficient and national level rate of social volunteering. Panel B: Posterior ditribution for the standardized effect of national Gini coefficient on volunteering rate as inferred using the default correlation model, and the standardized effects of all social contextual variables on volunteering rate as inferred using the dfault partial correlation model. The points represent the mean of the posterior distributions, and the error bars represents the Bayesian Credible Intervals. using simulated inequality in the lab is generalizable to more persistent forms of contextual inequality. A recent meta-analysis on cooperation over time found a contrasting result; a positive association between income inequality and coopertion in experimental games ( Yuan et al., 2022 )",
    "chunk_id": "national_inequality,_social_capital,_and_public_goods_decision-making.json_chunk_27"
  },
  {
    "document_type": "research_paper",
    "title": "National inequality, social capital, and public goods decision-making",
    "author": "Joshua C. Skewes",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\national_inequality_social_capital.pdf",
    "date_published": "2023-05-03",
    "keywords": "\"Inequality\"; \"Gini\"; \"Cooperation\"; \"Public Goods Game\"; \"Trust\"; \"Civic Norms\"",
    "flag": "",
    "chunk_text": ". A recent meta-analysis on cooperation over time found a contrasting result; a positive association between income inequality and coopertion in experimental games ( Yuan et al., 2022 ). It should be noted that this finding was obtained after controlling for a range of socio-economic variables which might impact the effect of inequality on cooperation, in a way similar to our own findings (see below). Also, data included in the meta-analysis was time-series cross-sectional, and from US participants only. Thus, the meta-analysis does not exclude the possibility that iequality has effects on cooperation which are not fully consistent across societies. Concerning RQ2, our modelling indicates which individual level dcision making processes might be responsible for reducing group contrbutions in less equal societies. Our model shows that national inequality is not related to preferences for conditional cooperation. In less equal scieties, there is no systematic tendency for people to undermatch what they believe others will contribute. People are roughly equal in their level of conditional cooperation across different national level income distributions. However, national inequality is associated with decreased initial optimism about what others will contribute. This means that even though inequality does not affect how conditionally cooperative people prefer to be in the game, it may lead them to enter the game with the assumption that others will withhold more of their tokens. Given their more pessimistic beliefs, they will then contribute less at the outset. With the bar for cooperation thus set low, contributions will remain lower, even if groups are willing to match one another’s contributions during the rest of the game. Our model also shows that national inequality is associated with increased sensitivity to others’ contributions",
    "chunk_id": "national_inequality,_social_capital,_and_public_goods_decision-making.json_chunk_28"
  },
  {
    "document_type": "research_paper",
    "title": "National inequality, social capital, and public goods decision-making",
    "author": "Joshua C. Skewes",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\national_inequality_social_capital.pdf",
    "date_published": "2023-05-03",
    "keywords": "\"Inequality\"; \"Gini\"; \"Cooperation\"; \"Public Goods Game\"; \"Trust\"; \"Civic Norms\"",
    "flag": "",
    "chunk_text": ". Our model also shows that national inequality is associated with increased sensitivity to others’ contributions. It is a well-known fining that in the experimental public goods game, group contribtions decrease throughout the course of the game ( Ledyard, 1995 ; Kopelman, Weber, and Messick, 2002 ; Zelmer, 2003 ). In this sort of cotext, people who are more sensitive to the group contribution will learn more quickly that others’ contributions are declining. This will cause them to reduce their own contributions more steeply, as they match their contributions more accurately to the dropping contribution rate. This learning may create a vicious cycle that hastens decay in provsion of the public good. Thus, the effect of national inequality on group contributions may be explained as a joint effect of decreased optimism about others’ contribution intentions at the outset of the game, and icreased sensitivity to others’ contributions during the game. Concerning RQ3, these relationships appear to be related to other national level social contextual variables. When other national economic and social variables (GDP, individualism, trust, and adherence to civic norms) were included in the models, there was no relation between Gini coefficient and contributions, and no relation between Gini coefficient and cognitive model parameters. Other social processes therefore seem important. Theoretical accounts exist to explain this importance. Sánchez-Rodriguez and colleagues have shown that inequality causes people to perceive the social environment as more individualitic and competitive ( Sánchez-Rodriguez et al, 2019 ). They have shown that in unequal environments, people are more likely to endorse vaues related to self-enhancement ( Sánchez-Rodriguez et al, 2020 ). This is relevant, because self-enhancement emphasizes the importance of indvidual agency in one’s placement within the resource distribution",
    "chunk_id": "national_inequality,_social_capital,_and_public_goods_decision-making.json_chunk_29"
  },
  {
    "document_type": "research_paper",
    "title": "National inequality, social capital, and public goods decision-making",
    "author": "Joshua C. Skewes",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\national_inequality_social_capital.pdf",
    "date_published": "2023-05-03",
    "keywords": "\"Inequality\"; \"Gini\"; \"Cooperation\"; \"Public Goods Game\"; \"Trust\"; \"Civic Norms\"",
    "flag": "",
    "chunk_text": ". This is relevant, because self-enhancement emphasizes the importance of indvidual agency in one’s placement within the resource distribution. Given that individualism was not related to contributions or model parameters, it is unlikely that these sorts of processes can account for the effects of iequality in the experimental public goods game. Further cross-national research will be required to reach a more definite conclusion. The present analysis does suggest a relationship between contribtions in the game and the social capital variables trust and adherence to civic norms. In more trusting nations, contributions were higher. Suprisingly, in nations where people expressed greater adherence to civic norms, the opposite was the case, and contributions were lower. Given that trust and civic norms are so closely related, this may appear contrdictory. The decision model provides a way to resolve this contradiction. In more trusting nations, people were more optimistic, and blieved others would contribute more to the public good on the game’s first round. Such a result is not so surprising ( Chaudhuri et al., 2002 ; Evans and Krueger, 2016 ; Fiske et al., 2012 ). The concept of trust has been associated with the expectation of future reciprocity, and this expectation is understood to motivate cooperative behavior ( AlóFerrer and Farolfi, 2019 ; Ostrom and Walker, 2003 ; see however Chaudhuri et al., 2002 ). Thus, it may be the case that as trust is rduced in less equal nations, people become less optimistic about oters’ contributions at the outset of the public goods game, leading to reduced overall group contributions as people match this lower expetation throughout the game. In nations with higher adherence to civic norms, people were more sensitive to others’ contributions, such that they more quickly updated their expectations about what others would contribute. Such a result is also not surprising",
    "chunk_id": "national_inequality,_social_capital,_and_public_goods_decision-making.json_chunk_30"
  },
  {
    "document_type": "research_paper",
    "title": "National inequality, social capital, and public goods decision-making",
    "author": "Joshua C. Skewes",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\national_inequality_social_capital.pdf",
    "date_published": "2023-05-03",
    "keywords": "\"Inequality\"; \"Gini\"; \"Cooperation\"; \"Public Goods Game\"; \"Trust\"; \"Civic Norms\"",
    "flag": "",
    "chunk_text": ". Such a result is also not surprising. Adherence to civic norms is characterized by a belief about whether one’s own and others’ behavior will reliably folow social expectations for good interactions ( Knack and Keefer, 1997 ; Granovetter, 2017 ). Thus we should expect that in nations with a higher adherence to civic norms, people monitor one another’s actions more closely, to determine whether norms are being satisfied. This may eplain the surprising result that groups in these nations contributed less. J.C. Skewes and L. Nockur Current Research in Ecological and Social Psychology 4 (2023) 100112 As already indicated, if preferences for cooperation are held equal, then greater sensitivity to others’ public goods contributions will lead to faster learning about reductions in contributions over trials, and faster decreases in one’s own matching contributions. In this way, it appears that adherence to civic norms may be associated with an acceleration of the race-to-the-bottom dynamics typically observed in the experimental public goods game. Thus, the following picture emerges. National level inequality is asociated with lower provision of public goods in experimental games. This may in turn be explainable as an effect of inequality on social caital variables like trust and civic norms. Reduced trust may operate on contributions by decreasing initial optimism, and civic norms may opeate by increasing sensitivity to the rest of the group, accelerating decay in cooperation. There are important caveats to these interpretations. Research indcates that people do not perceive national wealth and income inequality accurately, and overall they tend to underestimate the level of inequality in their country ( Kiatpongsan and Norton, 2014 ). It has further been prposed that it might be peoples’ (mis)perceptions – and not real national inequality – that determine people’s evaluations, including support for redistribution ( Hauser and Norton, 2017 )",
    "chunk_id": "national_inequality,_social_capital,_and_public_goods_decision-making.json_chunk_31"
  },
  {
    "document_type": "research_paper",
    "title": "National inequality, social capital, and public goods decision-making",
    "author": "Joshua C. Skewes",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\national_inequality_social_capital.pdf",
    "date_published": "2023-05-03",
    "keywords": "\"Inequality\"; \"Gini\"; \"Cooperation\"; \"Public Goods Game\"; \"Trust\"; \"Civic Norms\"",
    "flag": "",
    "chunk_text": ". It should, however, be noted that the perception of inequality seems to also depend on which method is used to assess it ( Eriksson and Simpson, 2012 ). Still, it might be an iteresting avenue for future research to explore how perceived inequality impacts decision-making in the cooperative provision of public goods. Further, any cross-national comparison ignores variation at more lcal levels. Inequality is not always uniform within a nation. Particularly in larger and more heterogeneous nations, some regions are more equal than others. The same is true of the other variables investigated. We nevertheless chose to use the national Gini coefficient as a measure of inequality, for two reasons. The first is that more local data was not available for many of the study sites. The second is that the research participants were university students, and it is therefore likely that at least some had been raised outside of the university regions in which the data were collected. Thus it is possible that more local Gini estmates are overly precise for this sample. Although these findings are indicative of persistent relationships between real-world inequality and decision making in the public goods game, efforts should be made to reproduce these results in more cleanly localized cultural and economic settings. It should further be considered that the student samples recruited, and/or the location within a country that they were recruited from, can differ in how well they represent the national population. Research seeing to replicate these findings should aim to recruit participants who are more representative of national populations than university students, and to selectively recruit participants from cities that more consistently reflect their national economic and social context. Despite these limitations, our results concerning RQ4 suggest that some of the insights gained from this research can be generalized",
    "chunk_id": "national_inequality,_social_capital,_and_public_goods_decision-making.json_chunk_32"
  },
  {
    "document_type": "research_paper",
    "title": "National inequality, social capital, and public goods decision-making",
    "author": "Joshua C. Skewes",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\national_inequality_social_capital.pdf",
    "date_published": "2023-05-03",
    "keywords": "\"Inequality\"; \"Gini\"; \"Cooperation\"; \"Public Goods Game\"; \"Trust\"; \"Civic Norms\"",
    "flag": "",
    "chunk_text": ". Despite these limitations, our results concerning RQ4 suggest that some of the insights gained from this research can be generalized. Ntional level social volunteering was related to national level inequality, with less equal nations also contributing less to the community public good by engaging in social volunteering. This result could be partially explained by national differences in GDP. This is not surprising, given that people in wealthier nations should be expected to have more leisure time to dedicate to social volunteering. More interestingly, trust was also related to increased volunteering. This should be expected from our decision model. In more trusting nations, people are more likely to be optimistic about others’ contributions, and so they are more likely to contribute more themselves, particularly at the outset. In the context of social volunteering, people may be more likely to sign-up to volunteer in more trusting and equal nations, because they appraise that there is more value in doing so when others will also be more likely to volunteer. The hands of many volunteers make light, and presumably more socially rewarding, work. More research is required to investigate how income distributions influence such social dynamics and the ways that they rlate to the decision to volunteer. The present study indicates which coceptual and methodological tools might be useful in this research. A further limitation of this study is that it cannot be used to make inferences about linear causal relationships. Although the models prsented do suggest promising ways to interpret relationships between iequality, cognitive processes in decision-making, social capital, and the provision of public goods, linear causal inference concerning these reltionships is only possible with time series data and/or experiments. The analyses presented here are not intended to answer causal questions, but to provide the building blocks for temporal models and experimetal investigations in the future",
    "chunk_id": "national_inequality,_social_capital,_and_public_goods_decision-making.json_chunk_33"
  },
  {
    "document_type": "research_paper",
    "title": "National inequality, social capital, and public goods decision-making",
    "author": "Joshua C. Skewes",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\national_inequality_social_capital.pdf",
    "date_published": "2023-05-03",
    "keywords": "\"Inequality\"; \"Gini\"; \"Cooperation\"; \"Public Goods Game\"; \"Trust\"; \"Civic Norms\"",
    "flag": "",
    "chunk_text": ". The analyses presented here are not intended to answer causal questions, but to provide the building blocks for temporal models and experimetal investigations in the future. In any case we do not want to claim that inequality simply causes diferences in the social capital of nations, which in turn causes differences in peoples’ decision-making in public goods contexts. More likely, the right causal story is highly complex, with multiple interacting causal chains. Moreover, these causal processes are likely to be identifiable at multiple levels of analysis in society; at the micro-level scale of idividual decision-makers, at the macro-level scale of cultures and ntions, and no less importantly, at the meso-level scale of social networks ( Granovetter, 2017 ). The present project is offered as a stimulus to uderstanding some of the relationships that might be involved in this larger perspective of explaining the effects of inequality on cooperative provision of public goods. Declaration of Competing Interest The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper. Data availability All data are publicly available and data sources are referred to in text. Ethics No data were collected specifically for this study. All data analyzed in this study have been made publicly available. All efforts have been made to make the data analysis as transparent as possible, including the inclusion of all statistical modeling code as an appendix. All efforts have been made to generalize responsibly from the data and the analysis. Supplementary materials Supplementary material associated with this article can be found, in the online version, at doi: 10.1016/j.cresp.2023.100112 .",
    "chunk_id": "national_inequality,_social_capital,_and_public_goods_decision-making.json_chunk_34"
  },
  {
    "document_type": "research_paper",
    "title": "A theory of Pavlovian conditioning: Variations in the effectiveness of reinforcement and nonreinforcement",
    "author": "Allan R. Wagner, RA. Rescorla",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\RescorlaWagner.1972.pdf",
    "date_published": "January 1972",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": "See discussions, stats, and author profiles for this publication at: https://www.researchgate.net/publication/233820243 A theory of Pavlovian conditioning: Variations in the effectiveness of reinforcement and nonreinforcement Chapter · January 1972 CITATIONS 7,653 READS 31,681 2 authors , including: Allan R Wagner Yale University 112 PUBLICATIONS 19,155 CITATIONS SEE PROFILE",
    "chunk_id": "rescorlawagner.1972.json_chunk_1"
  },
  {
    "document_type": "research_paper",
    "title": "Social Preferences, Beliefs, and the Dynamics of Free Riding in Public Goods Experiments",
    "author": "Unknown",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\gächter-fischbacher-2010-social-preferences-beliefs-and.pdf",
    "date_published": "2010-02-25",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": "541 In this paper we investigate the role of social preferences and beliefs for voluntary coopertion. Numerous public goods experiments have shown that many people contribute more to the public good than pure self-interest can easily explain. An equally important observation, hoever, is that free riding increases in repeatedly played public goods experiments across various parameters and participant pools. 1 The facts are clear, but their explanation is not. An obvious candidate for explaining the decline of cooperation was learning the free-rider strategy. However, Andreoni ( 1988 ) showed that cooperation resumed after a restart, which is inconsistent with a pure learning argument. In a subsequent paper he interpreted the decline in cooperation “to be due to frustrated attempts at kindness, rather than learning the free-riding incentives” ( Andreoni 1995, 900 ) . Several subsequent papers argue that contributions that are not due to confusion might possibly be explained by other-regarding preferences ( e.g., Thomas R. Palfrey and Jeffrey E. Prisbrey 1997; Jordi Brandts and Schram 2001; Jacob K. Goeree, Charles A. Holt, and Laury 2002; Daniel Houser and Robert Kurzban 2002; Paul J. Ferraro and Christian A. Vossler 2005; Ralph C. Bayer, Renner, and Rupert Sausgruber 2009 ) . One type of social preference—long argued by social psychologists ( e.g., Harold Kelley and Anthony Stahelski 1970 ) —is many people’s propensity to cooperate ( in lab and field environments ) provided others cooperate as well ( e.g., Robert Sugden 1984; Joel Guttman 1986; Keser and van Winden 2000; Fischbacher, Gächter, and Fehr 2001; Bruno S. Frey and Stephan Meier 2004; Croson, Fatas, and Neugebauer 2005; Croson 2007; Richard Ashley, Cheryl Ball, and Catherine Eckel forthcoming; Croson and Jen Shang 2008; see Gächter 2007 for an overview ) . Such “conditional ­cooperation” 1 See, for instance, R. Mark Isaac, James M. Walker, and Susan H. Thomas ( 1984 ) ; James Andreoni ( 1988, 1995 ) ; Joachim Weimann ( 1994 ) ; Susan K",
    "chunk_id": "social_preferences,_beliefs,_and_the_dynamics_of_free_riding_in_public_goods_experiments.json_chunk_1"
  },
  {
    "document_type": "research_paper",
    "title": "Social Preferences, Beliefs, and the Dynamics of Free Riding in Public Goods Experiments",
    "author": "Unknown",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\gächter-fischbacher-2010-social-preferences-beliefs-and.pdf",
    "date_published": "2010-02-25",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Such “conditional ­cooperation” 1 See, for instance, R. Mark Isaac, James M. Walker, and Susan H. Thomas ( 1984 ) ; James Andreoni ( 1988, 1995 ) ; Joachim Weimann ( 1994 ) ; Susan K. Laury, Walker, and Arlington Williams ( 1995 ) ; Rachel Croson ( 1996 ) ; Roberto Burlando and John Hey ( 1997 ) ; Gächter and Ernst Fehr ( 1999 ) ; Axel Ockenfels and Weimann ( 1999 ) ; Joep Sonnemans, Arthur Schram, and Theo Offerman ( 1999 ) ; Claudia Keser and Frans van Winden ( 2000 ) ; Fehr and Gächter ( 2000 ) ; Eun-Soo Park ( 2000 ) ; David Masclet et al. ( 2003 ) ; Croson, Enrique Fatas, and Tibor Neugebauer ( 2005 ) ; Jeffrey P. Carpenter ( 2007 ) ; Martin Sefton, Robert Shupp, and Walker ( 2007 ) ; Martijn Egas and Arno Riedl ( 2008 ) ; Gächter, Elke Renner, and Sefton ( 2008 ) ; Benedikt Herrmann, Christian Thöni, and Gächter ( 2008 ) ; Nikos Nikiforakis and Hans Normann ( 2008 ) ; and Neugebauer et al. ( 2009 ) . The decline of cooperation has also been observed in prisoner’s dilemma experiments. See, e.g., Reinhard Selten and Rolf Stoecker ( 1986 ) ; Andreoni and John H. Miller ( 1993 ) and Russell Cooper et al. ( 1996 ) . The breakdown of cooperation is also a frequent outcome in naturally occurring situations, like in the overdepletion of common resources and in environmental degradation. Social Preferences, Beliefs, and the Dynamics of Free Riding in Public Goods Experiments By Urs Fischbacher and Simon Gächter* * Fischbacher: University of Konstanz, PO Box D 131, D-78457 Konstanz, Germany ( e-mail: urs.fischbacher@uni-konstanz.de ) , and Thurgau Institute of Economics, Hauptstrasse 90, CH-8280, Kreuzlingen ( e-mail: fischbacher@twi-kreuzlingen.ch ) ; Gächter: CESifo, IZA, and University of Nottingham, School of Economics, Sir Clive Granger Building, University Park, Nottingham NG7 2RD, United Kingdom ( e-mail: simon.gaechter@ nottingham.ac.uk )",
    "chunk_id": "social_preferences,_beliefs,_and_the_dynamics_of_free_riding_in_public_goods_experiments.json_chunk_2"
  },
  {
    "document_type": "research_paper",
    "title": "Social Preferences, Beliefs, and the Dynamics of Free Riding in Public Goods Experiments",
    "author": "Unknown",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\gächter-fischbacher-2010-social-preferences-beliefs-and.pdf",
    "date_published": "2010-02-25",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". This paper is part of the MacArthur Foundation Network on Economic Environments and the Evolution of Individual Preferences and Social Norms and the Research Priority Program of the University of Zurich on “The Foundations of Human Social Behavior: Altruism versus Egoism.” Support from the EU-TMR Research Network ENDEAR (FMRX-CT98-0238) is gratefully acknowledged. Sybille Gübeli, Eva Poen, and Beatrice Zanella provided very able research assistance. We also thank very constructive referees and Nick Bardsley, Rachel Croson, Armin Falk, Ernst Fehr, Justina Fischer, Martin Kocher, Michael Kosfeld, Andreas Kuhn, Jo Morgan, Charles Noussair, Eva Poen, Daniel Schunk, Martin Sefton, Ran Spiegler, and various conference, workshop, and seminar participants for their helpful comments. Gächter thanks the University of St. Gallen, CES Munich, CMPO Bristol, the University of Copenhagen, and Bar-Ilan University for the hospitality he enjoyed while working on this paper. March 2010 542 THE AMERICAN ECONOMIC REVIEW is an interesting candidate for explaining the fragility of cooperation, because this motivation depends directly on how others behave or are believed to behave. Conditional cooperators who observe ( or believe ) that others free ride will reduce their contributions and thus contribute to the decline of cooperation. It is unknown, however, to what extent conditional cooperation, and inteindividual differences in this regard, can explain ( the decline of ) cooperation. Our paper aims to shed empirical light on this question. For a related theoretical approach see Attila Ambrus and Parag A. Pathak ( 2009 ) . The novelty of our paper is to combine two observations from previous research: beliefs about other people’s contributions matter, and people differ in their cooperative preferences ( some are free rider types, whereas others are conditional cooperators )",
    "chunk_id": "social_preferences,_beliefs,_and_the_dynamics_of_free_riding_in_public_goods_experiments.json_chunk_3"
  },
  {
    "document_type": "research_paper",
    "title": "Social Preferences, Beliefs, and the Dynamics of Free Riding in Public Goods Experiments",
    "author": "Unknown",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\gächter-fischbacher-2010-social-preferences-beliefs-and.pdf",
    "date_published": "2010-02-25",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". 2 In our approach we measure people’s cooperation preferences in a specially designed public goods game played in the straegy method ( called the “P-experiment” ) and then observe the same people in a sequence of ten one-shot games ( labeled the “C-experiment” ) , in which we also elicit their beliefs about others’ contributions. This allows us to quantify how preference heterogeneity and beliefs interact in voluntary cooperation. Specifically, we can disentangle whether contributions decline because of cooperation preferences and/or because of the way people form ( and change ) their beliefs about how others will behave. Our data from the P-experiment show that people differ strongly in their contribution prefeences. This is consistent with previous evidence ( see footnote 2 ) . Using the classification prposed by Fischbacher, Gächter, and Fehr ( 2001 ) , we have ( i ) 55 percent conditional cooperators who cooperate if others cooperate, ( ii ) 23 percent free riders who never contribute anything, irrespective of how much others contribute, ( iii ) 12 percent “triangle contributors” who increase their contributions with the contribution of others up to a point and then decrease their own contributions the more others contribute, and ( iv ) 10 percent unclassifiable. We push beyond this observation of preference heterogeneity by investigating how measured preferences and beliefs are related to observed contribution behavior. We have therefore designed our experiments such that we can use the P-experiment to make a point prediction for each participant about his or her contribution in the C-experiment, given his or her beliefs. Our approach allows us to answer our main research question—how do beliefs and preference heterogeneity affect the decline of cooperation? Our main result, which we detail in Section II, is that contributions decline because, on aveage, people are “imperfect conditional cooperators” who match others’ contributions only partly",
    "chunk_id": "social_preferences,_beliefs,_and_the_dynamics_of_free_riding_in_public_goods_experiments.json_chunk_4"
  },
  {
    "document_type": "research_paper",
    "title": "Social Preferences, Beliefs, and the Dynamics of Free Riding in Public Goods Experiments",
    "author": "Unknown",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\gächter-fischbacher-2010-social-preferences-beliefs-and.pdf",
    "date_published": "2010-02-25",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". The presence of free-rider types is not necessary for this result; contributions also decline if everyone is an imperfect conditional cooperator. We further show that belief formation can be described as a partial adjustment of one’s belief into the direction of the observed contribution of others in the previous period. More specifically, beliefs in a given period are a weighted average of what others contributed in the previous period and one’s own belief in the previous period. As we will show with the help of simulation methods, our estimated belief formation process implies that beliefs decline only if contributions decline, but not vice versa. Furthermore, we find that contributions are significantly positively correlated with predicted contributions, that is, the elicited preferences. In addition to their preferences, people’s contributions depend directly on their beliefs about others’ contributions. This implies that the P-experiment understates the extent of conditional cooperation that occurs in the C-experiment. 2 See, e.g., Fischbacher, Gächter, and Fehr ( 2001 ) ; Burlando and Francesco Guala ( 2005 ) ; Kurzban and Houser ( 2005 ) ; Nicholas Bardsley and Peter Moffatt ( 2007 ) ; Martin G. Kocher et al. ( 2008 ) ; Laurent Muller et al. ( 2008 ) ; John Duffy and Jack Ochs ( 2009 ) ; and Herrmann and Thöni ( 2009 ) . VOL. 100 NO. 1 543 Fischbacher AND Gächter: dynamics of free riding I. Design and Procedures Our basic decision situation is a standard linear public goods game. The participants are radomly assigned to groups of four persons. Each participant is endowed with 20 tokens, which he or she can either keep or contribute to a “project,” the public good. The payoff function is given as ( 1 ) π i = 20 − g i + 0.4 ​ ∑ j = 1 ​ 4 ​ g​ j , where the public good is equal to the sum of the contributions of all group members. Contributing a token to the public good yields a private marginal return of 0.4 and the social marginal benefit is 1.6",
    "chunk_id": "social_preferences,_beliefs,_and_the_dynamics_of_free_riding_in_public_goods_experiments.json_chunk_5"
  },
  {
    "document_type": "research_paper",
    "title": "Social Preferences, Beliefs, and the Dynamics of Free Riding in Public Goods Experiments",
    "author": "Unknown",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\gächter-fischbacher-2010-social-preferences-beliefs-and.pdf",
    "date_published": "2010-02-25",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Contributing a token to the public good yields a private marginal return of 0.4 and the social marginal benefit is 1.6. Standard assumptions, therefore, predict that all group members free ride completely, that is, g j = 0 for all j . This leads to a socially inefficient outcome. The instructions ( see the Web Appendix, available at http://www.aeaweb.org/articles. php?doi=10.1257/aer.100.1.541 ) explained the public good problem to the participants. Since we want to measure subjects’ preferences as accurately as possible, we also took great care to ensure that the participants understood both the rules of the game and the incentives. Therefore, after participants had read the instructions, they had to answer ten control questions. The quetions tested the subjects’ understanding of the comparative statics properties of ( 1 ) to ensure that participants were aware of their money-maximizing incentives and the dilemma situation. We did not proceed until all participants had answered all questions correctly. We can thus safely assume that the participants understood the game. Within this basic setup we conducted two types of experiments. The first type of experiment ( the P-experiment ) elicits people’s contribution preferences in a linear one-shot public goods game. In the second type of experiment participants make contribution choices in a repeaedly played linear public goods environment ( labeled C-experiment ) . The C-experiment consists of ten rounds in the random matching mode. We chose a random matching protocol to minmize strategic effects from repeated play. All participants play both types of experiments. For example, participants first go through the preference elicitation experiment in the P-C sessions before making their contribution choices in the C-experiment. Our C-P sessions counterbalance the order of experiments to control for possible sequence effects",
    "chunk_id": "social_preferences,_beliefs,_and_the_dynamics_of_free_riding_in_public_goods_experiments.json_chunk_6"
  },
  {
    "document_type": "research_paper",
    "title": "Social Preferences, Beliefs, and the Dynamics of Free Riding in Public Goods Experiments",
    "author": "Unknown",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\gächter-fischbacher-2010-social-preferences-beliefs-and.pdf",
    "date_published": "2010-02-25",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Our C-P sessions counterbalance the order of experiments to control for possible sequence effects. The C-P sequence allows for a particularly strong test of measured preferences because people experience ten rounds of decsions in the C-experiment before their cooperation preferences are elicited in the P-experiment. The rationale of the P-experiment is to elicit people’s cooperation preferences: to what degree are people willing to cooperate given other people’s degrees of cooperation? 3 Being able to observe contributions as a function of other group members’ contributions without using decetion requires the observation of contributions that can be contingent on others’ contributions. Fischbacher, Gächter, and Fehr ( 2001 ) ( henceforth FGF ) introduced an experimental design that accomplishes this task. 4 Since we use exactly the same method as FGF, we refer the reader to FGF for all details. The central idea of the P-experiment is to apply a variant of the so-called “strategy method” ( Selten 1967 ) . The participants’ main task in the experiment is to make two decisions, an “uncoditional contribution” and a “conditional contribution.” In the conditional contribution a subject has to indicate—in an incentive-compatible way—how much he or she wants to contribute to the public good for each rounded average contribution level of other group members. Specifically, participants were shown a “contribution table” of the 21 possible values of the average ­contribution 3 Our approach does not require eliciting a utility function since we do not need a complete preference order for our purposes. It is sufficient to know subjects’ best replies conditional on others’ contributions. 4 Ockenfels ( 1999 ) developed a similar design independently of FGF. March 2010 544 THE AMERICAN ECONOMIC REVIEW of the other group members ( from 0 to 20 ) and were asked to state their corresponding contribtion for each of the 21 possibilities",
    "chunk_id": "social_preferences,_beliefs,_and_the_dynamics_of_free_riding_in_public_goods_experiments.json_chunk_7"
  },
  {
    "document_type": "research_paper",
    "title": "Social Preferences, Beliefs, and the Dynamics of Free Riding in Public Goods Experiments",
    "author": "Unknown",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\gächter-fischbacher-2010-social-preferences-beliefs-and.pdf",
    "date_published": "2010-02-25",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". March 2010 544 THE AMERICAN ECONOMIC REVIEW of the other group members ( from 0 to 20 ) and were asked to state their corresponding contribtion for each of the 21 possibilities. Since the FGF method elicits the contribution schedules in an incentive-compatible way, free-rider types have an incentive to enter a zero contribution for each of the 21 possible average contributions of other group members; conditional cooperators have an incentive to enter increasing contributions; and unconditional cooperators have an incentive to enter their preferred contribution level. 5 The experiment was played only once, and the paticipants knew this. We wanted to elicit subjects’ preferences, without intermingling preferences with strategic considerations. Participants in the P-C sessions ( C-P sessions ) were informed only after finishing the P-experiment ( C-experiment ) that they would participate in another experiment. When we explained the C-experiment, we emphasized that the groups of four would be randomly reshufled in each period. 6 After each period, participants were informed about the sum of contribtions in their group in that period. In addition to their contribution decisions, subjects also had to indicate their beliefs about the average contribution of the other three group members in the curent period. In addition to their earnings from the public good experiment, we paid participants based on the accuracy of their estimates. 7 We elicited beliefs for two reasons. First, we can assess the correlation between beliefs and contributions, which we expect to differ between types of players and which helps us to check on the player type as elicited in the P-experiment",
    "chunk_id": "social_preferences,_beliefs,_and_the_dynamics_of_free_riding_in_public_goods_experiments.json_chunk_8"
  },
  {
    "document_type": "research_paper",
    "title": "Social Preferences, Beliefs, and the Dynamics of Free Riding in Public Goods Experiments",
    "author": "Unknown",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\gächter-fischbacher-2010-social-preferences-beliefs-and.pdf",
    "date_published": "2010-02-25",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Second, by evaluating an elicited schedule at the elicited belief in a given period we can make a point prediction about an individual’s contribution in the C-experiment: if an individual in the P-experiment indicates that he or she will contribute y tokens if the other group members contribute x tokens on average, then the prediction for this individual in the C-experiment is to contribute y tokens if he or she believes that others contriute x tokens on average. We will later refer to this as the “predicted contribution.” The sequence of experiments was reversed in the C-P sessions. The comparison of results from the P-experiments in the C-P sequence with those of the P-C sequence allows us to assess the relevance of experience with the public goods game for elicited cooperation preferences. All experiments were computerized, using the software z-Tree ( Fischbacher 2007 ) . The expeiments were conducted in the computer lab of the University of Zurich. Our participants were undergraduates from various disciplines ( except economics ) from the University of Zurich and the Swiss Federal Institute of Technology ( ETH ) in Zurich. We conducted six sessions ( three in the P-C sequence and three in the C-P sequence ) . In each of five sessions we had 24 participants and in another session we had 20 participants. A postexperiment questionnaire confirmed that participants were largely unacquainted with one another. Our 140 participants were randomly assigned to cubicles in each session, where they took their decisions in complete anonymity from 5 The P-experiment is incentive compatible because a random draw selects three group members for whom the unconditional contribution is payoff relevant and one group member for whom the conditional contribution, given the average unconditional contributions of the other three members, is payoff relevant. The payoffs are equal to ( 1 ) . See FGF or Fischbacher and Gächter ( 2009 ) for further details",
    "chunk_id": "social_preferences,_beliefs,_and_the_dynamics_of_free_riding_in_public_goods_experiments.json_chunk_9"
  },
  {
    "document_type": "research_paper",
    "title": "Social Preferences, Beliefs, and the Dynamics of Free Riding in Public Goods Experiments",
    "author": "Unknown",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\gächter-fischbacher-2010-social-preferences-beliefs-and.pdf",
    "date_published": "2010-02-25",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". The payoffs are equal to ( 1 ) . See FGF or Fischbacher and Gächter ( 2009 ) for further details. 6 The likelihood in period 1 that a player would meet another player once again during the remaining nine periods was 72 percent. The likelihood that the same group of four players would meet was 2.58 percent. Since the experiment was conducted anonymously, however, subjects were unable to recognize whether they were matched with a particular player in the past. 7 Participants had a financial incentive for correct beliefs, but it was small, to avoid hedging. If their estimation was exactly right, subjects received three experimental money units (≈ $0.8 ) in addition to their other experimental earings. They received two additional money units if their estimation deviated by only one point from the other group members’ actual average contribution, one money unit if they deviated by two points, and no additional money if their estimation was off the actual contribution by more than three points. VOL. 100 NO. 1 545 Fischbacher AND Gächter: dynamics of free riding the other subjects. On average, participants earned 35 Swiss francs (CHF) ( roughly $30, incluing a show-up fee of 10 CHF ) . 8 Each session lasted roughly 90 minutes. II. Results We organize the discussion of our results as follows. In Section A, we document the decline of cooperation. In Section B, we present the extent of heterogeneity in people’s cooperation preerences and actual contribution patterns. In the remaining sections, we analyze behavior in the C-experiment. We show how subjects form their beliefs ( Section C ) and how their contribution decisions are related to the elicited preferences in the P-experiment ( Section D ) . We conclude in Section E with a simulation study in which we assess how the belief process and subjects’ prefeences affect the decline of cooperation. A. The Decline of Cooperation Figure 1 sets the stage for our analysis, which aims to explain the decline of cooperation",
    "chunk_id": "social_preferences,_beliefs,_and_the_dynamics_of_free_riding_in_public_goods_experiments.json_chunk_10"
  },
  {
    "document_type": "research_paper",
    "title": "Social Preferences, Beliefs, and the Dynamics of Free Riding in Public Goods Experiments",
    "author": "Unknown",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\gächter-fischbacher-2010-social-preferences-beliefs-and.pdf",
    "date_published": "2010-02-25",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". A. The Decline of Cooperation Figure 1 sets the stage for our analysis, which aims to explain the decline of cooperation. The figure shows the temporal patterns of cooperation and beliefs for each of our six sessions separately. The figure conveys four unambiguous messages. First, contributions and beliefs decline in six out of six sessions. Second, behavior in the six sessions is very similar. Third, contributions are lower than beliefs in almost all instances. Finally, mean period contributions and beliefs are sinificantly positively correlated in all six sessions ( Spearman rank correlation tests, p < 0.007 ) . This finding is consistent with previous observations in public goods games where beliefs were elicited ( e.g., Weimann 1994; Croson 2007; Neugebauer et al., forthcoming ) . B. Heterogeneous Preferences and Contributions Recall that we have a complete contribution schedule from each participant that indicates how much he or she is prepared to contribute as a function of others’ contributions. A simple way of characterizing heterogeneity is to look at the slope ( of a linear regression ) of the schedule and the mean contribution in the schedule. For instance, a free rider’s schedule consists of zero contribtions for all contribution levels of other group members. Therefore, his slope and mean contribtion are zero. An unconditional cooperator, who contributes 20 tokens for all others’ contribution levels has a mean contribution of 20 and a slope of 0. A perfect conditional cooperator, who contributes exactly the amount others contribute, has a slope of one and a mean contribution of ten tokens. Figure 2A depicts the results separately for the C-P and P-C experiments. The x -axis shows the slope of the schedules and the y -axis the average contribution in the schedule. The dots in Figure 2A correspond to individual observations, and the size of a dot to the number of observations it represents. Figure 2A shows two things. First, there is a large degree of heterogeneity",
    "chunk_id": "social_preferences,_beliefs,_and_the_dynamics_of_free_riding_in_public_goods_experiments.json_chunk_11"
  },
  {
    "document_type": "research_paper",
    "title": "Social Preferences, Beliefs, and the Dynamics of Free Riding in Public Goods Experiments",
    "author": "Unknown",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\gächter-fischbacher-2010-social-preferences-beliefs-and.pdf",
    "date_published": "2010-02-25",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Figure 2A shows two things. First, there is a large degree of heterogeneity. 9 Free riders ( located at 0–0 ) and perfect conditional cooperators ( at 1–10 ) are relatively the largest group of subjects. We also find a few participants who contribute an unconditional positive amount ( along the y -axis, at x = 0 ) . Many participants have a positive mean contribution and a positive slope; a 8 During the experiment subjects earned their payoffs in “points” ( according to ( 1 ) and the earnings from correct belief estimates ) . At the end of the experiment, we exchanged the accumulated sum of points at an exchange rate of one point = CHF 0.35 for the points earned in the P-experiment and at a rate of 1 point = CHF 0.07 for the points earned in the C-experiment. 9 This evidence is consistent with other studies using different methods. See footnote 2. March 2010 546 THE AMERICAN ECONOMIC REVIEW few participants have a negatively sloped schedule ( that is, they contribute more the less others contribute ) . Second, the distribution between the C-P and the P-C sessions is very similar. ManWhitney tests do not allow the rejection of the null hypotheses that both means and slopes are equally distributed between the treatments ( p > 0.87 ) . 10 Thus, elicitation of preferences before subjects actually experienced contributions to the public good ( in the P-C sessions ) or after ( in the C-P sessions ) did not affect the elicited preferences. This is an important finding for our interpretation that the P-experiment elicits cooperation preferences. It shows that participants in the C-P sessions who have experienced actual contribution behavior do not express different cooperation preferences than do participants in the P-C sessions who are inexperienced in actual game playing when they express their preferences",
    "chunk_id": "social_preferences,_beliefs,_and_the_dynamics_of_free_riding_in_public_goods_experiments.json_chunk_12"
  },
  {
    "document_type": "research_paper",
    "title": "Social Preferences, Beliefs, and the Dynamics of Free Riding in Public Goods Experiments",
    "author": "Unknown",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\gächter-fischbacher-2010-social-preferences-beliefs-and.pdf",
    "date_published": "2010-02-25",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". 11 Figure 2B shows a scatter plot of individual slopes of linear regressions ( estimated without intercepts ) of contributions on beliefs on the x -axis, and average contributions in the C-experiment on the y -axis. The construction of Figure 2B is similar to Figure 2A. As in Figure 2A, we ditinguish between the C-P and P-C sessions. We find no sequence effect, neither with respect to average contributions nor with respect to slopes ( Mann-Whitney tests, p > 0.21 ) . 12 10 In Figure 2A we looked at the slope and mean contribution of a subject’s schedule. However, qualitatively, we get very similar results if we look at Spearman rank order correlation coefficients, linear correlation coefficients, and slopes and intercepts of linear regressions. In all cases p -values of Mann-Whitney tests that compare the C-P and the P-C experiments yield p > 0.275. The absolute number of [ 0–0 ] -combinations in the P-experiments was as follows: 18 in the C-P sessions and 14 in the P-C sessions. Six ( seven ) people are located at [ 1–10 ] in the C-P ( P-C ) sessions. 11 The elicited contribution schedules in our study are also not significantly different from FGF ( χ 2 -test, p = 0.729 ) . See an earlier version ( Fischbacher and Gächter 2009 ) for further details. 12 In the C-experiments depicted in Figure 2B, nine people are located at [ 0–0 ] in each of the C-P and the P-C sessions. 1 2 3 4 5 6 7 8 9 10 Mean belief / contribution Period P-C session 1 1 2 3 4 5 6 7 8 9 10 Mean belief / contribution Period C-P session 1 1 2 3 4 5 6 7 8 9 10 Mean belief / contribution Period C-P session 2 1 2 3 4 5 6 7 8 9 10 Mean belief / contribution Period P-C session 2 1 2 3 4 5 6 7 8 9 10 Mean belief / contribution Period C-P session 3 1 2 3 4 5 6 7 8 9 10 Mean belief / contribution Period P-C session 3 20 18 16 14 12 10 8 6 4 2 0 20 18 16 14 12 10 8 6 4 2 0 20 18 16 14 12 10 8 6 4 2 0 20 18 16 14 12 10 8 6 4 2 0 20 18 16 14 12 10 8 6 4 2 0 20 18 16 14 12 10 8 6 4 2 0 Contribution Belief Figure 1",
    "chunk_id": "social_preferences,_beliefs,_and_the_dynamics_of_free_riding_in_public_goods_experiments.json_chunk_13"
  },
  {
    "document_type": "research_paper",
    "title": "Social Preferences, Beliefs, and the Dynamics of Free Riding in Public Goods Experiments",
    "author": "Unknown",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\gächter-fischbacher-2010-social-preferences-beliefs-and.pdf",
    "date_published": "2010-02-25",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Mean Beliefs and Contributions over Time VOL. 100 NO. 1 547 Fischbacher AND Gächter: dynamics of free riding Figure 2B reveals considerable heterogeneity in contribution behavior. Individual average cotributions ( depicted on the y -axis ) vary between 0 and 20 tokens, although most participants contribute fewer than ten tokens on average. Fourteen percent of all participants contribute exactly zero in all ten periods. We find that the individual estimated slopes of the schedules from the P-experiment ( Figure 2A ) and the slopes of individual linear contribution-belief regresions in the C-experiments ( Figure 2B ) are highly significantly positively correlated ( Spearman’s ρ = 0.39, p = 0.0000 ) . Average cooperation levels in the P-experiment and in the C-experiment are highly correlated as well ( Spearman’s ρ = 0.40, p = 0.0000 ) . We interpret this as a first piece of evidence that expressed cooperation preferences and actual cooperation behavior are correlated at the individual level. Before we investigate the link between beliefs, preferences, and contributions, we look at how people form beliefs in the C-experiment. Understanding belief formation is important because previous evidence, and our own, suggests that beliefs have an influence on contributions ( see Section IID ) . It is therefore possible that belief formation contributes to the decay of coopertion if people reduce their beliefs per se, that is, independently of contributions. In Section E we will address this possibility and a competing hypothesis suggested by our findings on contribtion preferences ( Figure 2A ) : contributions decline because people are imperfect conditional cooperators. C. The Formation of Beliefs With the help of three econometric models, we investigate the question of how people form their beliefs about their group members’ contribution in a given period. The estimation method is OLS with robust standard errors clustered on sessions as the independent units of observation",
    "chunk_id": "social_preferences,_beliefs,_and_the_dynamics_of_free_riding_in_public_goods_experiments.json_chunk_14"
  },
  {
    "document_type": "research_paper",
    "title": "Social Preferences, Beliefs, and the Dynamics of Free Riding in Public Goods Experiments",
    "author": "Unknown",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\gächter-fischbacher-2010-social-preferences-beliefs-and.pdf",
    "date_published": "2010-02-25",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". The estimation method is OLS with robust standard errors clustered on sessions as the independent units of observation. 13 13 We estimated all models with random and fixed effects specifications, as well as with Tobit, with very similar results. For instance, the correlation coefficient of predicted values of the Tobit estimation and the OLS is 0.9995. Since the estimation results are very similar, we report the OLS results only for ease of interpretation. –5 0 5 10 15 20 25 –0.5 0 0.5 1 1.5 Average contribution in schedules Slope of schedule (from linear regression) Panel A. Heterogeneous preferences C-P sessions P-C sessions –5 0 5 10 15 20 25 –0.5 0 1.5 2.5 Individual mean contribution in C-experiments Slope of individual linear contribution-belief regressions Panel B. Heterogeneous contributions C-P sessions P-C sessions Figure 2. Heterogeneous Contribution Preferences ( panel A ) and Actual Contributions as a Function of Beliefs ( panel B ) March 2010 548 THE AMERICAN ECONOMIC REVIEW Model 1 in Table 1, which includes only “period,” simply confirms the impression from Figure 1 that beliefs decline significantly over time. However, this model cannot explain why there is a downward trend. Models 2 and 3 present our models of belief formation. We argue that people form their beliefs in period t on the basis of their beliefs in period t − 1 and the observation of others’ contributions in period t − 1. To see this, take periods 1 and 2. In period 1 a subject can rely only on his or her intuitive ( “home-grown” ) beliefs about others’ contributions. In period 2, he or she also makes an observation about others’ actual contribution in period 1. A subject may therefore update his or her period 2 belief on the basis of his or her period 1 belief and the observed period 1 contributions by others. A similar logic might hold in all remaining periods. Model 2 presents the estimates of this belief formation model",
    "chunk_id": "social_preferences,_beliefs,_and_the_dynamics_of_free_riding_in_public_goods_experiments.json_chunk_15"
  },
  {
    "document_type": "research_paper",
    "title": "Social Preferences, Beliefs, and the Dynamics of Free Riding in Public Goods Experiments",
    "author": "Unknown",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\gächter-fischbacher-2010-social-preferences-beliefs-and.pdf",
    "date_published": "2010-02-25",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". A similar logic might hold in all remaining periods. Model 2 presents the estimates of this belief formation model. We find that both “belief ( t − 1 ) ” and “others’ contribution ( t − 1 ) ” are highly significantly positive; “period” is insignificant, an order of magnitude smaller than in model 1, and not significantly different from zero. We also estimated model 2 separately for periods 1 to 5 and periods 6 to 10. The estimated coefficients are very similar in both halves of the experiment ( Chow-test, p > 0.1 ) . 14 In other words, the way people form beliefs does not change over time. Model 3 is the same as model 2 except that we drop the insignificant variable “period.” The sum of coefficients of “belief ( t − 1 ) ” and “others’ contribution ( t − 1 ) ” is insignificantly diffeent from 1 ( F ( 1, 5 ) = 0.41, p = 0.549 ) . 15 We will use this model in our simulations below. 14 We also applied an Arellano-Bond linear, dynamic panel-data estimation method ( Manuel Arellano and Stephen R. Bond 1991 ) . However, there is still significant second order correlation ( p < 0.05, Arellano-Bond test ) in the residals implying that its estimates are inconsistent ( Arellano and Bond 1991, 281–82 ) . Moreover, in simulations similar to those we discuss in Section IIE, it turned out that the Arellano-Bond estimates cannot explain the data patterns at all, whereas model 3 can. As a further robustness check of model 2, we included up to three lags for the variable “others’ contributions.” Only the first lag is significant; the higher lags are very small and insignificant. 15 The period coefficient in model 2 is insignificantly different from zero but highly significantly different from the period coefficient in model 1 ( seemingly unrelated regressions, p < 0.001 ) . For reasons of comparability with model 2, we estimated model 1 for periods 2–10 only. The period coefficient in model 1 for all periods equals − 0.753",
    "chunk_id": "social_preferences,_beliefs,_and_the_dynamics_of_free_riding_in_public_goods_experiments.json_chunk_16"
  },
  {
    "document_type": "research_paper",
    "title": "Social Preferences, Beliefs, and the Dynamics of Free Riding in Public Goods Experiments",
    "author": "Unknown",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\gächter-fischbacher-2010-social-preferences-beliefs-and.pdf",
    "date_published": "2010-02-25",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". For reasons of comparability with model 2, we estimated model 1 for periods 2–10 only. The period coefficient in model 1 for all periods equals − 0.753. Table 1—Forming Beliefs Dependent variable: Belief about other group members’ contribution Model ( 1 ) ( 2 ) ( 3 ) Period − 0.761*** − 0.079 ( 0.090 ) ( 0.042 ) Others’ contributions ( t − 1 ) 0.394*** 0.415*** ( 0.023 ) ( 0.020 ) Belief ( t − 1 ) 0.549*** 0.569*** ( 0.037 ) ( 0.036 ) Constant 10.711*** 0.835* 0.118 ( 0.864 ) ( 0.398 ) ( 0.148 ) Observations 1,260 1,260 1,260 R 2 0.26 0.64 0.64 Notes: OLS regressions with data from period 2 to 10. Robust standard errors ( clustered on sessions ) in parentheses. *** Significant at the 1 percent level. ** Significant at the 5 percent level. * Significant at the 10 percent level. VOL. 100 NO. 1 549 Fischbacher AND Gächter: dynamics of free riding Given these results, we can summarize the belief formation process as follows: a subject’s belief in a given period is a weighted average of what he or she believed about others in the prevous period and his or her observation of the others’ contributions in the previous period. We will use this result when we investigate in Section IIE the role of belief formation for explaining the dynamics of voluntary cooperation. D. Explaining Contributions In this section we investigate determinants of people’s contributions econometrically. We have three explanatory variables—“period,” “predicted contribution,” and “belief.” We estimated three basic models, which we document in Table 2. The estimation method is OLS with robust standard errors clustered on sessions as the independent units of observation. 16 Model 1, which includes only “period,” confirms the impression from Figure 1 that contribtions decline significantly over time. Model 2 adds the variables “predicted contribution” and “belief.” We find that both variables matter significantly. In other words, because “belief” is sinificant, there is conditional cooperation on top of contribution preferences in the C-experiments",
    "chunk_id": "social_preferences,_beliefs,_and_the_dynamics_of_free_riding_in_public_goods_experiments.json_chunk_17"
  },
  {
    "document_type": "research_paper",
    "title": "Social Preferences, Beliefs, and the Dynamics of Free Riding in Public Goods Experiments",
    "author": "Unknown",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\gächter-fischbacher-2010-social-preferences-beliefs-and.pdf",
    "date_published": "2010-02-25",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". In other words, because “belief” is sinificant, there is conditional cooperation on top of contribution preferences in the C-experiments. However, because “period” is an order of magnitude smaller than in model 1 and not signifcantly different from zero, the decline of cooperation must be due to “predicted contribution” and “belief.” Model 3 is the same as model 2, but drops the insignificant variable “period.” 17 16 As with belief formation, we estimated all models with random and fixed effects specifications, as well as with Tobit. Since the estimation results are very similar, we report only the OLS results. 17 One might worry about multicollinearity in models 2 and 3 because beliefs enter the calculation of “predicted cotributions.” Although “belief” and “predicted contribution” are correlated ( Spearman ρ = 0.395 ) , the variance inflation factor as an indicator of multicollinearity is 1.22, which is below the critical value of ten ( Damodar N. Gujarati 2003 ) . Table 2—Explaining Contributions Dependent variable: Contribution Model ( 1 ) ( 2 ) ( 3 ) ( 4a ) ( 4b ) ( 4c ) Periods used 1–10 1–10 1–10 1–10 1–5 6–10 Subjects excluded a No No No Yes Yes Yes Period − 0.639 − 0.060 ( 0.071 ) *** ( 0.056 ) Predicted contribution 0.242 0.242 0.443 0.385 0.614 ( 0.069 ) ** ( 0.069 ) ** ( 0.073 ) *** ( 0.074 ) *** ( 0.082 ) *** Belief 0.644 0.666 0.545 0.582 0.376 ( 0.071 ) *** ( 0.059 ) *** ( 0.065 ) *** ( 0.065 ) *** ( 0.116 ) ** Constant 8.343 0.005 − 0.473 − 0.318 − 0.204 − 0.116 ( 0.545 ) *** ( 0.569 ) ( 0.244 ) ( 0.312 ) ( 0.541 ) ( 0.378 ) Observations 1,400 1,400 1,400 1,260 630 630 R 2 0.10 0.34 0.34 0.38 0.33 0.33 Note: Robust standard errors in parentheses. a Models 4a to 4c exclude ( confused ) subjects who, on the basis of the P-experiment, could not be classified accoring to the FGF classification as either a “free rider,” “conditional cooperator,” or a “triangle contributor.” *** Significant at the 1 percent level. ** Significant at the 5 percent level. * Significant at the 10 percent level",
    "chunk_id": "social_preferences,_beliefs,_and_the_dynamics_of_free_riding_in_public_goods_experiments.json_chunk_18"
  },
  {
    "document_type": "research_paper",
    "title": "Social Preferences, Beliefs, and the Dynamics of Free Riding in Public Goods Experiments",
    "author": "Unknown",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\gächter-fischbacher-2010-social-preferences-beliefs-and.pdf",
    "date_published": "2010-02-25",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". ** Significant at the 5 percent level. * Significant at the 10 percent level. March 2010 550 THE AMERICAN ECONOMIC REVIEW The observations from models 2 and 3 raise two related questions: ( i ) Why is the coefficient on “predicted contribution” surprisingly low ( it should be one if the elicited preferences would predict perfectly ) ? ( ii ) Why do people condition their contribution decision based not only on their prefeences according to their predicted contribution but also on their beliefs? Regression models 4a to 4c shed light on the first question. These models are the same as model 3 but exclude “confused” subjects ( 10 percent ) who, according to the classification proposed by FGF, could not be classified as free riders, conditional cooperators, or triangle contributors. Model 4 shows that the coefficient on “predicted contributions” increases substantially ( and significantly according to a seemingly unrelated regression, p = 0.012 ) once the confused subjects are excluded ( the coefficient is still less than one, though, and beliefs still matter in addition to preferences ) . Regression models 4b and 4c reveal that there is also a time trend in the relative importance of “predicted contributions” and “beliefs.” “Beliefs” seem to be more important in the first half of the experiment than in the second half, where the coefficient on “predicted contributions” is substantially and significantly higher than in the first half ( p < 0.001 ) , and vice versa for the coefficient on “beliefs” ( p = 0.039 ) . 18 Why do beliefs matter in addition to contribution preferences? First, note that in models 4a to 4c, the constant is not significantly different from zero, and the sum of the coefficients for “prdicted contribution” and “belief” add up to a number not significantly different from one ( e.g., in Regression model 4a the sum equals 0.998; F ( 1, 5 ) = 0.08, p = 0.7863 )",
    "chunk_id": "social_preferences,_beliefs,_and_the_dynamics_of_free_riding_in_public_goods_experiments.json_chunk_19"
  },
  {
    "document_type": "research_paper",
    "title": "Social Preferences, Beliefs, and the Dynamics of Free Riding in Public Goods Experiments",
    "author": "Unknown",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\gächter-fischbacher-2010-social-preferences-beliefs-and.pdf",
    "date_published": "2010-02-25",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Hence, according to these regressions, subjects contribute a weighted average of “predicted contribution” and “belief.” A cotribution that matches the belief is, by definition, perfectly conditionally cooperative. Thus, subjects behave according to a contribution pattern that is in between their elicited contribution schedule and perfect conditional cooperation. Since most people’s elicited contribution preferences lie below the diagonal, that is, below the schedule of perfect conditional cooperators, this intermediate contribtion pattern lies above the predicted cooperation. This means that subjects are more conditionally cooperative in the C-experiment than predicted from their decisions in the P-experiment. Models 4b and 4c show that this is the case particularly in earlier periods; in later periods “predicted cotribution” becomes more important than “beliefs.” One potential explanation for why beliefs matter in addition to “predicted contribution” is subjects’ willingness to invest in cooperation in order to induce high beliefs and contributions in the population, even in our random matching design ( For some evidence in this regard, see Anabela Botelho et al., 2009. ) E. Why Do Contributions Decline? Because both beliefs and contribution preferences matter for determining contributions, the question arises as to how they each contribute to explaining the decline of cooperation. In this section we use simulation methods to understand why contributions decline. We distinguish among three fundamental possible causes: what individual preferences are, how beliefs change over the course of the game, and heterogeneity ( in preferences or beliefs ) . We use simulation methods because they allow us to use counterfactual assumptions, which are helpful in disentagling the role of preferences and beliefs. The simulations are based on a two-stage process. In the first stage, the simulated players form a belief about the other players’ contributions",
    "chunk_id": "social_preferences,_beliefs,_and_the_dynamics_of_free_riding_in_public_goods_experiments.json_chunk_20"
  },
  {
    "document_type": "research_paper",
    "title": "Social Preferences, Beliefs, and the Dynamics of Free Riding in Public Goods Experiments",
    "author": "Unknown",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\gächter-fischbacher-2010-social-preferences-beliefs-and.pdf",
    "date_published": "2010-02-25",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". The simulations are based on a two-stage process. In the first stage, the simulated players form a belief about the other players’ contributions. Then, players decide on a contribution, which they ( partially ) base on their beliefs. Before we address our two main questions, we make the following basic observations on the conditions under which such a two-stage process can explain the decline of cooperation. Contributions will not decline if contributions or beliefs are independent of experience and time, that is, if people are unconditionally cooperative or if they 18 However, the coefficients of “predicted contributions” and “beliefs” do not significantly differ from each other in the two regressions: ( F ( 1, 5 ) = 2.42, p = 0.181 and F ( 1, 5 ) = 1.60, p = 0.262 ) VOL. 100 NO. 1 551 Fischbacher AND Gächter: dynamics of free riding have unconditional beliefs . Thus, to explain the decline of cooperation, both beliefs and cotributions need to be conditional on the behavior of others. Of course, conditionality is only a necessary condition for the decline of cooperation. Suppose, for instance, that belief updating is naïve ( that is, beliefs are equal to the average contribution in the previous period ) and contribtions match beliefs. In this case, cooperation will be stable. Thus, cooperation will decline only if either beliefs are lower than naïve beliefs or if people are imperfect conditional cooperators. Our simulations will shed light on the relative importance of these two possibilities. To be able to disentangle, in our simulations, the roles of beliefs and contributions for the decay of cooperation, we make ( counterfactual ) assumptions about cooperation behavior and belief formation. With regard to cooperation behavior, we will assume that the simulated plaers ( i ) contribute according to preferences we have observed in the P-experiment, or ( ii ) they ( counterfactually ) are all perfect conditional cooperators. The second dimension concerns belief updating",
    "chunk_id": "social_preferences,_beliefs,_and_the_dynamics_of_free_riding_in_public_goods_experiments.json_chunk_21"
  },
  {
    "document_type": "research_paper",
    "title": "Social Preferences, Beliefs, and the Dynamics of Free Riding in Public Goods Experiments",
    "author": "Unknown",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\gächter-fischbacher-2010-social-preferences-beliefs-and.pdf",
    "date_published": "2010-02-25",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". The second dimension concerns belief updating. Here we assume that players either ( i ) update according to the weighted-average model outlined above ( model 3 of Table 1 ) , or ( ii ) ( counterfactually ) form their beliefs naïvely. Thus, we have 2 × 2 combinations of assumptions about cooperation behavior and belief formation. Starting from the benchmark of perfect conditional cooperation and naïve beliefs, we can hold one dimension constant and change the other to see whether belief formation or contributions are responsible for the decay of cooperation. The simulations use the exact matching structure that was in place in each period of a given session. 19 As starting values, we use the actual contributions and beliefs in period 1. The details of our 2 × 2-methodology are as follows: ( i ) In our benchmark model, the pCC N - model , we assume that all players are perfect condtional cooperators, that is, players match their beliefs exactly: Contribution ( t ) = Belief ( t ) . Beliefs are formed naïvely ( denoted by subindex N ) , that is, Belief ( t ) = Others’ Contribution ( t − 1 ) . Under these assumptions contributions are obviously stable at the intial level of contributions. ( ii ) The pCC A -model keeps the assumption of perfect conditional cooperation but assumes that beliefs are formed according to the actual beliefs estimated in model 3 in Table 1 ( denoted by subindex A ) . In this model, contributions will drop only if beliefs per se become inheently pessimistic. 20 Thus, this model reveals the extent to which the belief formation process can be responsible for the decay of cooperation. ( iii ) The aCC A -model keeps the actual beliefs assumption but replaces perfect conditional cooeration by actual conditional cooperation as elicited in the P-experiment ( denoted aCC ) . The weights on contribution preferences and beliefs correspond to the estimated parameters of model 3 in Table 2",
    "chunk_id": "social_preferences,_beliefs,_and_the_dynamics_of_free_riding_in_public_goods_experiments.json_chunk_22"
  },
  {
    "document_type": "research_paper",
    "title": "Social Preferences, Beliefs, and the Dynamics of Free Riding in Public Goods Experiments",
    "author": "Unknown",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\gächter-fischbacher-2010-social-preferences-beliefs-and.pdf",
    "date_published": "2010-02-25",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". The weights on contribution preferences and beliefs correspond to the estimated parameters of model 3 in Table 2. This simulation model shows the combined predicted effects of actual belief updating and actual contribution preferences for the decline of cooperation. ( iv ) Finally, in the aCC N -model , the simulated players determine their contributions according to the actual conditional contribution schedules, but beliefs are formed naïvely. By assuming naïve beliefs, this model reveals the extent to which the cooperation preferences themselves contribute to the decline of cooperation. 19 That is, in simulation models 3 and 4 described below, we replace each human participant by his or her contribtion schedule and observe how contributions evolve given our assumptions about belief updating. 20 “Virtual learning” ( Roberto Weber 2003 ) , that is, learning with no feedback by just thinking about the problem for several periods, is a possible reason for this “pessimism.” March 2010 552 THE AMERICAN ECONOMIC REVIEW We address the role of heterogeneity for the decline of cooperation with two counterfactual models in which we remove heterogeneity from the contribution process, thus, ending up with 3 × 2 combinations of assumptions. By comparing these models with the actual contributions, we can assess the role of heterogeneity. The models differ only in their assumptions of the belief formation process. One model assumes naïve beliefs and is thus comparable to the aCC N -model ; the other model uses the estimated belief formation and is thus comparable to aCC A : ( v ) In the iCC N -model players are assumed to be identical conditional cooperators ( iCC ) . As a schedule, we use an average linear one: Contribution = α + k × Contribution of oters . The estimates from the data of our P-experiment return α = 0.956 and k = 0.425. Therefore, in this model Contribution = 0.956 + 0.425 × Contribution of others . The iCC N -model assumes that belief formation is naïve",
    "chunk_id": "social_preferences,_beliefs,_and_the_dynamics_of_free_riding_in_public_goods_experiments.json_chunk_23"
  },
  {
    "document_type": "research_paper",
    "title": "Social Preferences, Beliefs, and the Dynamics of Free Riding in Public Goods Experiments",
    "author": "Unknown",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\gächter-fischbacher-2010-social-preferences-beliefs-and.pdf",
    "date_published": "2010-02-25",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Therefore, in this model Contribution = 0.956 + 0.425 × Contribution of others . The iCC N -model assumes that belief formation is naïve. Thus, in comparison to the aCC-moels , the iCC N -model informs us about the role of preference heterogeneity of players under naïve belief formation. ( vi ) Finally, the iCC A -model is the same as the iCC N -model but assumes actual belief formation. Figure 3 depicts the simulation results. We compare the simulation results to the actual aveage contributions ( “data” ) . Panel A illustrates the implications of our simulation models. For this purpose we use the average over all six sessions. Panel B depicts the predictive success of the aCC A -model at the session level. We illustrate the results of the aCC A -model because it is the only simulation model that does not use counterfactual assumptions. Since the average initial contribution is eight tokens, the pCC N -benchmark implies that cotributions are stable at the initial level. The pCC A -model predicts that contributions will decline to the extent beliefs decline. The simulation results return stable contributions. To understand this finding, recall that according to our model of actual belief formation ( model 3 of Table 1 ) Belief ( t ) = 0.415 × Others’ contribution ( t − 1 ) + 0.569 × Belief ( t − 1 ) + 0.118. By assumtion of perfect conditional cooperation Contribution ( t − 1 ) = Belief ( t − 1 ) for all players and therefore Belief ( t ) = ( 0.415 + 0.569 ) × Belief ( t − 1 ) . The sum of the two coefficients ( 0.415 and 0.569 ) equals 0.984, which is insignificantly different from 1 ( F -test, p = 0.549 ) . This observtion implies that, under perfect conditional cooperation, beliefs remain constant. Hence, we coclude that the belief formation process per se does not contribute to the decline of cooperation. 21 Put differently, beliefs decline because contributions decline, and not because people become inherently more pessimistic over time, irrespective of contribution behavior",
    "chunk_id": "social_preferences,_beliefs,_and_the_dynamics_of_free_riding_in_public_goods_experiments.json_chunk_24"
  },
  {
    "document_type": "research_paper",
    "title": "Social Preferences, Beliefs, and the Dynamics of Free Riding in Public Goods Experiments",
    "author": "Unknown",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\gächter-fischbacher-2010-social-preferences-beliefs-and.pdf",
    "date_published": "2010-02-25",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". 21 Put differently, beliefs decline because contributions decline, and not because people become inherently more pessimistic over time, irrespective of contribution behavior. The aCC A -model and the aCC N -models replace the assumption of perfect conditional cooperation with people’s actual contribution preferences as elicited in the P-experiment. Both simulation models predict a decline of cooperation. Since beliefs per se are not resposible for the unraveling of cooperation, we conclude that the decline is triggered by people’s contribution preferences. The aCC N -model predicts a much faster decline than we actually observe in the data. By contrast, the aCC A -model tracks the actual data quite well. To evauate this model statistically, we regress the actual contributions on the predicted contrbutions ( using OLS ) . We find that the model coefficient ( robust s.e. ) equals 1.002 ( 0.030 ) , which is not significantly different from one. The model constant ( robust s.e. ) equals –0.036 ( 0.188 ) , which is not significantly different from zero. Thus, on average, the aCC A -model 21 If we disregard the constant and take the coefficient of 0.984 literally, the belief formation process per se can account for a decline of cooperation of at most 14 percent ( i.e., 1 − ( 1 − 0.984 ) 9 = 0.135 ) over the nine remaining periods after period 1. VOL. 100 NO. 1 553 Fischbacher AND Gächter: dynamics of free riding predicts the data very well. This is also apparent from Figure 3B, which compares the session averages with the predictions from the aCC A -model applied to the respective session. 22 Finally, we can assess the importance of preference heterogeneity by comparing the aCmodels with the iCC-models ( under both naïve and actual belief updating ) . By construction, the iCC-models eliminate preference heterogeneity by replacing the individual preference scheules by the average preference schedule, whereas the aCC-models use the individual preference schedules",
    "chunk_id": "social_preferences,_beliefs,_and_the_dynamics_of_free_riding_in_public_goods_experiments.json_chunk_25"
  },
  {
    "document_type": "research_paper",
    "title": "Social Preferences, Beliefs, and the Dynamics of Free Riding in Public Goods Experiments",
    "author": "Unknown",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\gächter-fischbacher-2010-social-preferences-beliefs-and.pdf",
    "date_published": "2010-02-25",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". The comparison shows that preference heterogeneity is surprisingly unimportant in explaining the decay of cooperation because the aCC-models and the iCC-models match each 22 All other models perform worse. In the iCC A -model as the second best model, the regression of actual contribtions on the predicted contributions has a slope of 1.06, which is insignificantly different from one, and the constant equals − 0.432, which is weakly significantly different from 0 ( p = 0.061 ) . In all other models, the model constant is highly significantly different from zero or the slope is highly significantly different from 1 ( p < 0.01 ) . Furthermore, the correlation between actual and predicted contribution is highest for the aCC A -model ( Spearman correlation = 0.46 ) . It is lower in all other models ( all Spearman correlations p < 0.40 ) . Figure 3. Explaining the Decline of Cooperation – Simulation Results 0 1 2 3 4 5 6 7 8 9 10 1 2 3 4 5 6 7 8 9 10 Average contribution Period data aCC A iCC A pCC A aCC N iCC N pCC N 0 2 4 6 8 10 1 2 3 4 5 6 7 8 9 10 Average contribution Period P-C session 1 0 2 4 6 8 10 1 2 3 4 5 6 7 8 9 10 Average contribution Period C-P session 1 0 2 4 6 8 10 1 2 3 4 5 6 7 8 9 10 Average contribution Period C-P session 2 Data aCC A simulation 0 2 4 6 8 10 1 2 3 4 5 6 7 8 9 10 A v erage contribution Period P-C session 2 0 2 4 6 8 10 1 2 3 4 5 6 7 8 9 10 Average contribution Period C-P session 3 0 2 4 6 8 10 1 2 3 4 5 6 7 8 9 10 Average contribution Period P-C session 3 Panel A. Disentangling the sources of decline Panel B. Predicting the decline for each of the six sessions, using the aCC A -model March 2010 554 THE AMERICAN ECONOMIC REVIEW other closely under both naïve and actual belief updating. Heterogeneity matters only toward the end of the experiment. In the iCC-models, contributions stop declining toward the end while the models with heterogeneous preferences also correctly predict the decline in the last periods",
    "chunk_id": "social_preferences,_beliefs,_and_the_dynamics_of_free_riding_in_public_goods_experiments.json_chunk_26"
  },
  {
    "document_type": "research_paper",
    "title": "Social Preferences, Beliefs, and the Dynamics of Free Riding in Public Goods Experiments",
    "author": "Unknown",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\gächter-fischbacher-2010-social-preferences-beliefs-and.pdf",
    "date_published": "2010-02-25",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". In the iCC-models, contributions stop declining toward the end while the models with heterogeneous preferences also correctly predict the decline in the last periods. Due to more realistic belief updating, the iCC A -model matches the data better than the iCC N -model . III. Summary and Concluding Remarks Our goal in this study was to investigate the role of social preferences and beliefs about others’ contributions for the dynamics of free riding in public goods experiments. We achieved this by eliiting preferences in one specially designed game ( the P-experiment ) and observing contributions and beliefs in ten one-shot standard public goods games with random matching ( the C-experiment ) . Our findings show that contributions decline ( in randomly composed groups ) because, on average, people are imperfect conditional cooperators. After some time, all types behave like income-maximizing free riders, even though only a minority is motivated by pure income-maimization alone. Scholars across the social sciences ( Paul Samuelson 1954; Mancur Olson 1965; Garrett Hardin 1968 ) have long noted the inherent fragility of voluntary cooperation due to free-rider incetives in the voluntary provision of public goods, collective actions, and common pool resource management. Our study shows that voluntary cooperation is inherently fragile, even if most people are not free riders but conditional cooperators. Because most of them are only imperfectly conditionally cooperative, however, cooperation is bound nevertheless to unravel; the presence of free riders just speeds up the decline. Other mechanisms, like punishment or rewards ( Elinor Ostrom, Walker, and Roy Gardner 1992; Fehr and Gächter 2000; Sefton, Shupp, and Walker 2007 ) , communication ( Isaac and Walker 1988; Ostrom, Walker, and Gardner 1992; Jeannette Brosig, Ockenfels, and Weimann 2003 ) , tax-subsidy mechanisms ( Josef Falkinger et al",
    "chunk_id": "social_preferences,_beliefs,_and_the_dynamics_of_free_riding_in_public_goods_experiments.json_chunk_27"
  },
  {
    "document_type": "research_paper",
    "title": "Social Preferences, Beliefs, and the Dynamics of Free Riding in Public Goods Experiments",
    "author": "Unknown",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\gächter-fischbacher-2010-social-preferences-beliefs-and.pdf",
    "date_published": "2010-02-25",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". 2000; Jürgen Bracht, Charles Figuieres, and Marisa Ratto 2008 ) , or, in general, good institutional designs ( Ostrom 1990 ) are necessary to sustain cooperation.",
    "chunk_id": "social_preferences,_beliefs,_and_the_dynamics_of_free_riding_in_public_goods_experiments.json_chunk_28"
  },
  {
    "document_type": "research_paper",
    "title": "Straight Choices; The Psychology of Decision Making; 3",
    "author": "Newell Ben R.",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\straight_choices.pdf",
    "date_published": "2022-03-31",
    "keywords": "",
    "flag": "",
    "chunk_text": "Straight Choices Straight Choices provides a fascinating introduction to the psychology of decision making, enhanced by a discussion of relevant examples of decision problems faced in everyday life. Thoroughly revised and updated throughout, this edition provides an integrative account of the psychology of decision making and shows how psychological research can help us to understand our uncertain world. The book emphasizes the relationship between learning and decision making, arguing that the best way to understand how and why decisions are made is in the context of the learning and knowledge acquisition which precedes them, and the feedback which follows. The mechanisms of learning and the structure of environments in which decisions are made are carefully examined to explore their impact on our choices. The authors then consider whether we are all constrained to fall prey to cognitive biases, or whether, with sufficient exposure, we can find optimal decision strategies and improve our decision making. This edition highlights advances made in judgement and decision making research, with additional coverage of behavioural insights, nudging, artificial intelligence, and explanation-based decision making. Written in a non-technical manner, this book is an essential read for all students and researchers in cognitive psychology, behavioural economics, and the decision sciences, as well as anyone interested in the nature of decision making. Ben R. Newell is Professor of Cognitive Psychology and Deputy Head in the School of Psychology at the University of New South Wales, Australia. David A. Lagnado is Professor in Cognitive and Decision Sciences in the Division of Psychology and Language Sciences at University College London, UK. David R. Shanks is Professor of Psychology and Deputy Dean of the Faculty of Brain Sciences at University College London, UK. Straight Choices The Psychology of Decision Making Third edition Ben R. Newell, David A. Lagnado, and David R",
    "chunk_id": "straight_choices;_the_psychology_of_decision_making;_3.json_chunk_1"
  },
  {
    "document_type": "research_paper",
    "title": "Straight Choices; The Psychology of Decision Making; 3",
    "author": "Newell Ben R.",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\straight_choices.pdf",
    "date_published": "2022-03-31",
    "keywords": "",
    "flag": "",
    "chunk_text": ". Straight Choices The Psychology of Decision Making Third edition Ben R. Newell, David A. Lagnado, and David R. Shanks Cover image: © Getty Images Third edition published 2022 by Routledge 4 Park Square, Milton Park, Abingdon, Oxon, OX14 4RN and by Routledge 605 Third Avenue, New York, NY 10158 Routledge is an imprint of the Taylor & Francis Group, an informa business © 2022 Ben R.Newell, David A. Lagnado and David R. Shanks The right of Ben R.Newell, David A. Lagnado and David R. Shanks to be identified as authors of this work has been asserted in accordance with sections 77 and 78 of the Copyright, Designs and Patents Act 1988. All rights reserved. No part of this book may be reprinted or reproduced or utilised in any form or by any electronic, mechanical, or other means, now known or hereafter invented, including photocopying and recording, or in any information storage or retrieval system, without permission in writing from the publishers. Trademark notice : Product or corporate names may be trademarks or registered trademarks, and are used only for identification and explanation without intent to infringe",
    "chunk_id": "straight_choices;_the_psychology_of_decision_making;_3.json_chunk_2"
  },
  {
    "document_type": "research_paper",
    "title": "Straight Choices; The Psychology of Decision Making; 3",
    "author": "Newell Ben R.",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\straight_choices.pdf",
    "date_published": "2022-03-31",
    "keywords": "",
    "flag": "",
    "chunk_text": ". Trademark notice : Product or corporate names may be trademarks or registered trademarks, and are used only for identification and explanation without intent to infringe. First edition published by Psychology Press, 2007 Second edition published by Psychology Press 2015 British Library Cataloguing-in-Publication Data A catalogue record for this book is available from the British Library Library of Congress Cataloging-in-Publication Data A catalog record has been requested for this book ISBN: 978-1-032-26781-4 (hbk) ISBN: 978-1-032-26784-5 (pbk) ISBN: 978-1-003-28989-0 (ebk) DOI: 10.4324/9781003289890 Typeset in Bembo by MPS Limited, Dehradun Sandra, Zoila, Isabella and James Tracy Ray and Ella, Will and Miranda Contents Preface to the Third Edition ix Acknowledgements xi 1 Falling off the Straight and Narrow 1 2 Decision Quality and a Historical Context 15 3 Stages of Judgement I: Discovering, Acquiring, and Combining Information 27 4 Stages of Judgement II: Feedback Effects and Dynamic Environments 49 5 Appraising Probability Judgements 62 6 Judgemental Heuristics and Biases 77 7 Explanation-Based Decision Making 98 8 Analysing Decisions I: A General Framework 112 9 Analysing Decisions II: Prospect Theory and Preference Reversals 125 10 Decisions From Experience 146 11 Decisions Across Time 157 12 Learning to Choose, Choosing to Learn 177 13 Optimality and Expertise 195 14 Two Systems of Judgement and Decision Making? 208 15 Emotional Influences on Decision Making 226 16 Group Decision Making 241 17 Applying Psychological Insights to the World Outside the Laboratory 255 18 Learning to Make Good Decisions: When, How, and Why (Not)? 269 References 275 Index 313 viii Contents Preface to the Third Edition In Straight Choices, we present a scholarly yet accessible introduction to the psychology of decision making, enhanced by a discussion of relevant examples of decision problems faced in everyday life",
    "chunk_id": "straight_choices;_the_psychology_of_decision_making;_3.json_chunk_3"
  },
  {
    "document_type": "research_paper",
    "title": "Straight Choices; The Psychology of Decision Making; 3",
    "author": "Newell Ben R.",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\straight_choices.pdf",
    "date_published": "2022-03-31",
    "keywords": "",
    "flag": "",
    "chunk_text": ". We provide an integrative account in which clear connections are made between empirical results and how these results can help us to understand our uncertain world. An innovative feature of Straight Choices is the emphasis on an exploration of the relationship between learning and decision making. Our thesis is that the best way to understand how and why decisions are made is in the context of the learning that precedes them and the feedback that follows them. Decisions do not emerge out of thin air but rather are informed by our prior experience, and each decision yields some information (did it work out well or badly?) that we can add to our stock of experience for future benefit. This novel approach allows us to integrate findings from the decision and learning literatures to provide a unique perspective on the psychology of decision making. A lot has happened in the field of judgement and decision making since we wrote the second edition of Straight Choices seven years ago, not least the surge in popularity of behavioural insights and ‘nudging’, as well as developments in artificial intelligence that are making decision algorithms ubiquitous. This new edition highlights recent developments with expanded coverage of those topics among many others. All of the chapters have been updated with new sections and new references reflecting the advances in understanding. We have also added a new chapter on Explanation-based decision making which discusses the growing impact of that approach in elucidating how we make complex decisions. The book is divided into 18 easily digestible chapters and the material is presented in as non-technical a manner as possible. Each chapter begins with a ‘highlights’ section and concludes with some suggestions for further reading. New to the third edition, each chapter also includes Questions for Discussion which can be used by instructors to generate class discussion, or as questions for assessments, and by students as guides for further thinking and research",
    "chunk_id": "straight_choices;_the_psychology_of_decision_making;_3.json_chunk_4"
  },
  {
    "document_type": "research_paper",
    "title": "Straight Choices; The Psychology of Decision Making; 3",
    "author": "Newell Ben R.",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\straight_choices.pdf",
    "date_published": "2022-03-31",
    "keywords": "",
    "flag": "",
    "chunk_text": ". The book is highly appropriate and accessible for any student with an interest in decision making – be they students of psychology, economics, social science, marketing, or business. The book should also appeal to more senior scholars of decision making, or indeed any cognitive psychologists who are seeking an up-to-date review of current research and are interested in the novel learning-based perspective which we provide. Throughout the book, we have also tried to emphasize the practical applications of much of the research on decision making. We hope that by reading this book you will gain a greater understanding of the psychology of how – and how well – we make decisions and that you will apply that understanding to improve your own decision making. x Preface to the Third Edition Acknowledgements It is, of course, impossible to acknowledge all the people who have influenced our thinking about the issues discussed in this book, so we will not attempt to name them for fear of missing some. Very special thanks are due, however to Peter Ayton and John Maule who provided insightful and very helpful criticism of a draft of the first edition, Ken Manktelow and Linden Ball who provided very useful feedback on the proposal for the second edition, and anonymous reviewers who did the same for this third edition. We would also like to thank the Editorial Team at Psychology Press for their excellent assistance throughout the publication process. Ben Newell would like to thank his co-authors for agreeing to, once again, get the band back together and write this new edition. As with the first and second editions, it has been very educational and a pleasure to have shared the experience with two such wonderful colleagues. Thanks are also due to members of the UNSW Cognition lab for many stimulating discussions about the nature of judgement and decision making over the last several years. The continuing support of the Australian Research Council is gratefully acknowledged",
    "chunk_id": "straight_choices;_the_psychology_of_decision_making;_3.json_chunk_5"
  },
  {
    "document_type": "research_paper",
    "title": "Straight Choices; The Psychology of Decision Making; 3",
    "author": "Newell Ben R.",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\straight_choices.pdf",
    "date_published": "2022-03-31",
    "keywords": "",
    "flag": "",
    "chunk_text": ". The continuing support of the Australian Research Council is gratefully acknowledged. David Lagnado would like to thank Adam Harris and the members of the Causal Cognition Lab for continued discussion of key problems in decision making, and Toby Pilditch, Ulrike Hahn, Alice Liefgreen, Stephen Dewitt, Tamara Shengelia, Norman Fenton, and Martin Neil for research collaborations cited in the book. David Shanks would like to thank the UK Economic and Social Research Council, who for several years has provided funding for his research, and members of his research group and in particular Maarten Speekenbrink for many enlightening discussions about aspects of decision making and learning. Ben Newell, David Lagnado, and David Shanks, Sydney and London, October 2021. 1 Falling Off the Straight and Narrow Chapter Highlights • An overview of the book • Insights into decisions about health, wealth, and guilt vs. innocence The cult film Donnie Darko begins with the hero Donnie narrowly surviving (or does he?) a bizarre accident. Donnie is lying in bed in his suburban family home when he is woken by a strange voice. The voice ‘leads’ him down the stairs, out of the house, and into the street. Moments later, a horrendous screeching noise signals the arrival of an aeroplane’s jet engine crashing through the roof of the house. The engine completely destroys Donnie’s bedroom. Most of us would agree that being killed by a falling jet engine is an extremely unlikely, freak occurrence. Indeed, if we were asked the question which is more likely: being killed by falling aeroplane parts or being killed by a shark? – the majority of us would probably think a shark attack more likely (Plous, 1993), but we would be wrong. According to Newsweek (Death Odds, 1990), we are 30 times more likely to be killed by falling aeroplane parts than by sharks. The reason (or reasons) why we tend to err in answering this question is just one of the many intriguing, challenging, and fundamentally important issues that are addressed in this book",
    "chunk_id": "straight_choices;_the_psychology_of_decision_making;_3.json_chunk_6"
  },
  {
    "document_type": "research_paper",
    "title": "Straight Choices; The Psychology of Decision Making; 3",
    "author": "Newell Ben R.",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\straight_choices.pdf",
    "date_published": "2022-03-31",
    "keywords": "",
    "flag": "",
    "chunk_text": ". The reason (or reasons) why we tend to err in answering this question is just one of the many intriguing, challenging, and fundamentally important issues that are addressed in this book. Understanding the psychology of how – and how well – we make decisions can have a significant impact on how we live our lives (and how to avoid freak deaths). Even for a decision as simple as buying a book (a decision that you may well be contemplating right now), we can engage in a series of quite complex thought processes: noting the attributes of different alternatives (cost, apearance, recommendations), comparing different alternatives by making ‘trade-offs’ on these attributes (e.g., this one is cheaper but it was not rcommended), and deciding how to allocate our limited resources (e.g., money for books or beer). These processes, and many more besides, can be ivestigated in systematic ways to discover what leads us to make the decisions DOI: 10.4324/9781003289890-1 we do, how we should make decisions given the preferences we have, and why our decision making sometimes goes awry. Our Approach and the Plan of this Book In this book, we provide a novel perspective on judgement and decision making along with an accessible review and integration of many of the key research findings. Our perspective is novel in that we view judgement and decision making as often exquisitely subtle and well tuned to the world, especially in situations where we have the opportunity to respond repeatedly under similar conditions where we can learn from feedback. We argue that many of the well-documented errors or biases of judgement often occur in one-shot decision situations where we do not have the chance to learn adquately about the environment. Focusing on errors in these one-shot situations can be a very fruitful research strategy, as the ‘heuristics and biases’ approach which has dominated the field has demonstrated (Kahneman, Slovic, & Tversky, 1982)",
    "chunk_id": "straight_choices;_the_psychology_of_decision_making;_3.json_chunk_7"
  },
  {
    "document_type": "research_paper",
    "title": "Straight Choices; The Psychology of Decision Making; 3",
    "author": "Newell Ben R.",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\straight_choices.pdf",
    "date_published": "2022-03-31",
    "keywords": "",
    "flag": "",
    "chunk_text": ". However, the downside of this approach is that it can lead to an overly pessimistic view of human judgement and decision making (Gigerenzer, 1996; Lejarraga & Hertwig, 2021). Our perspective aims to reclaim the original reason for emphasizing errors, namely that errors can be thought of as quirks akin to visual illusions, and which reveal something about how the mind works. Like visual illusions, they arise in a system which is in general extremely accurate in its functioning. Take the sharks versus falling aeroplane parts example. In a one-shot dcision about the likelihood of death, we might choose sharks erroneously. One explanation for such a choice is that we base our decision on the ease with which we can recall instances of people being killed by sharks or by falling aeroplane parts. Shark attacks are likely to be easier to recall – presumably because they receive wider coverage in the media – and so we answer ‘sharks’. In general, using the ease-of-recall or ‘availability’ heuristic will serve us well, but in certain situations, particularly when we are insensitive to the distribtion of information in the environment (i.e., insensitive to the fact that shark attacks receive more media coverage than falling aeroplane parts), we make errors (cf., Tversky & Kahneman, 1974). One of the key messages of our approach is that being given the opportunity to learn about information in the environment through repetition and feedback often gives rise to exceptionally accurate judgements and decisions. This message is pursued most directly in Chapters 10, 12, and 13, although the theme of learning runs throughout the book. Some readers might find these chapters a little more challenging than the others but we encourage you to persevere. Chapters 1 and 2 introduce many of the concepts that will be relevant to our exploration of judgement and decision making, through considering some practical decisions (e.g., What medical treatment should I choose?) and by giving a brief historical overview of the field",
    "chunk_id": "straight_choices;_the_psychology_of_decision_making;_3.json_chunk_8"
  },
  {
    "document_type": "research_paper",
    "title": "Straight Choices; The Psychology of Decision Making; 3",
    "author": "Newell Ben R.",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\straight_choices.pdf",
    "date_published": "2022-03-31",
    "keywords": "",
    "flag": "",
    "chunk_text": ". Chapters 3 and 4 take us on a journey through the stages of judgement from the discovery of 2 Falling Off the Straight and Narrow information to the role of feedback. Chapter 5 presents some formal ways of appraising our probability judgements and then in Chapter 6 we look at how people actually make judgements. Chapter 7 explores how people tackle more complex problems, with a focus on evidential reasoning. Moving from judgments to decisions, Chapter 8 presents formal methods for analysing decisions and then Chapter 9 examines how people actually make decisions and choices under uncertainty. Chapter 11 extends this analysis to examine the influence of time on decisions. Chapter 14 assesses the popular idea that there are two ‘systems’ for decision making, a deliberative one and an intuitive one that operate in rather different ways. The next three chapters provide some insights into the role that emotion plays on our decisions (Chapter 15), the way groups make decisions (Chapter 16), and an investigation of some of the more practical methods for implementing what we have learned about decision making in the laboratory to the world outside (Chapter 17). Chapter 18 revisits the key questions about when, why and how to make good decisions in light of the major findings and theories discussed in the preceding chapters. The book can be read as a whole – cover-to-cover – or if you have particular interests then the chapters are, for the most part, self-contained enough to enable you to dip in and choose the parts that appeal. Our aims are twofold: to introduce you to this exciting field and to help you improve your own decision-making skills. Decisions, DecisionsWe are faced with a plethora of decisions, choices, and judgements every day and throughout our lives: what to have for lunch, where to go on holiday, what car to buy, whom to hire for a new faculty position, whom to marry, and so on",
    "chunk_id": "straight_choices;_the_psychology_of_decision_making;_3.json_chunk_9"
  },
  {
    "document_type": "research_paper",
    "title": "Straight Choices; The Psychology of Decision Making; 3",
    "author": "Newell Ben R.",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\straight_choices.pdf",
    "date_published": "2022-03-31",
    "keywords": "",
    "flag": "",
    "chunk_text": ". Such examples illustrate the abundance of decisions in our lives and thus the importance of understanding the how and why of decision making. Some of these decisions will have little impact on our lives (e.g., what to have for lunch); others will have long-lasting effects (e.g., whom to marry). To itroduce many of the relevant concepts, in this first chapter we consider three important decisions that we might face in the course of our lives: 1) which medical treatment should I choose, 2) is this person guilty or innocent, and 3) how should I invest my money? For each situation, we examine some of the factors that can influence the decisions we make. We cover quite a bit of ground in these three examples so do not worry if the amount of information is rather overwhelming. The aim here is simply to give a taste of the breadth of issues that can affect our decision making. There will be ample opportunity in later chapters to explore many of these issues in more depth. Which Medical Treatment Should I Choose? Martin and Simon have just received some devastating news: they have both been diagnosed with lung cancer. Fortunately, their cancers are still at relatively Falling Off the Straight and Narrow 3 early stages and should respond to treatment. Martin goes to see his doctor and is given the following information about two alternative therapies – radiation and surgery: Of 100 people having surgery, on average, 10 will die during treatment, 32 will have died by one year, and 66 will have died by five years. Of 100 people having radiation therapy, on average, none will die during treatment, 23 will die by one year and 78 will die by five years. Simon goes to see his doctor, who is different from Martin’s, and is told the following about the same two therapies: Of 100 people having surgery, on average, 90 will survive the treatment, 68 will survive for one year, and 34 will survive for five years",
    "chunk_id": "straight_choices;_the_psychology_of_decision_making;_3.json_chunk_10"
  },
  {
    "document_type": "research_paper",
    "title": "Straight Choices; The Psychology of Decision Making; 3",
    "author": "Newell Ben R.",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\straight_choices.pdf",
    "date_published": "2022-03-31",
    "keywords": "",
    "flag": "",
    "chunk_text": ". Of 100 people having radiation therapy, on average, all will survive the treatment, 77 will survive for one year, and 22 will survive for five years. Which treatment do you think Martin will opt for and which one will Simon opt for? If they behave in the same way as patients in a study by McNeil et al. (1982), then Martin will opt for the radiation treatment and Simon will opt for surgery. Why? You have probably noticed that the efficacy of the two treatments is equivalent in the information provided to Martin and Simon. In both cases, radiation therapy has lower long-term survival chances but no risk of dying during treatment, whereas surgery has better long-term prospects but there is a risk of dying on the operating table. The key difference between the two is the way in which the iformation is presented to the patients. Martin’s doctor presented or framed the information in terms of mortality , namely how many people will die from the two treatments, whereas Simon’s doctor framed the information in terms of how many people will survive . It appears that the risk of dying during treatment looms larger when it is presented in terms of mortality (in the framing adopted by Martin’s doctor) than in terms of survival (in the framing chosen by Simon’s doctor) – making surgery less attractive for Martin but more attractive for Simon. This simple change in the framing of information can have a large impact on the decisions we make. McNeil et al. (1982) found that across groups of ptients, students and doctors, on average radiation therapy was preferred to surgery 42% of the time when the negative mortality frame was used (proability of dying), but only 25% of the time when the positive survival frame (probability of living) was used (see also Tversky & Kahneman, 1981). Positive versus negative framing is not the only type of framing that can affect decisions about medical treatments. Edwards et al",
    "chunk_id": "straight_choices;_the_psychology_of_decision_making;_3.json_chunk_11"
  },
  {
    "document_type": "research_paper",
    "title": "Straight Choices; The Psychology of Decision Making; 3",
    "author": "Newell Ben R.",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\straight_choices.pdf",
    "date_published": "2022-03-31",
    "keywords": "",
    "flag": "",
    "chunk_text": ". Positive versus negative framing is not the only type of framing that can affect decisions about medical treatments. Edwards et al. (2001), in a coprehensive review, identified nine different types of framing including those comparing verbal, numerical, and graphical presentation of risk information, manipulations of the base rate (absolute risk) of treatments, using lay versus 4 Falling Off the Straight and Narrow medical terminology, and comparing the amount of information (number of factual statements) presented about choices. The largest framing effects were evident when relative, as opposed to absolute risk, information was presented to patients (Edwards et al., 2001). Relative and absolute risks are two ways of conveying information about the efficacy of a treatment, but unlike the previous example, they are not logically equivalent. Consider the following two statements adapted from an article about comunicating the efficacy of cholesterol-reducing drugs (Skolbekken, 1998; see also Gigerenzer, 2002): 1. ‘Simvastatin is proven to reduce the risk of a coronary mortality by 3.5%’. 2. ‘Simvastatin is proven to reduce the risk of a coronary mortality by 42%’. A person suffering from high cholesterol would presumably be far more willing to take the drug Simvastatin when presented with Statement 2 than when presented with Statement 1. Moreover, a doctor is more likely to prescribe the drug if presented by a pharmaceutical company with Statement 2. But is this willingness well placed? Implicit in Statement 1 is that the risk referred to is the absolute risk rduction – that is the proportion of patients who die without taking the drug (those who take a placebo) minus the proportion who die having taken the drug (Gigerenzer, 2002). In the study discussed by Skolbekken (1998), the proportion of coronary mortalities for people taking the drug was 5.0% compared to 8.5% of those on a placebo (a reduction of 3.5%)",
    "chunk_id": "straight_choices;_the_psychology_of_decision_making;_3.json_chunk_12"
  },
  {
    "document_type": "research_paper",
    "title": "Straight Choices; The Psychology of Decision Making; 3",
    "author": "Newell Ben R.",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\straight_choices.pdf",
    "date_published": "2022-03-31",
    "keywords": "",
    "flag": "",
    "chunk_text": ". In the study discussed by Skolbekken (1998), the proportion of coronary mortalities for people taking the drug was 5.0% compared to 8.5% of those on a placebo (a reduction of 3.5%). In Statement 2, absolute risk has been replaced by relative risk reduction – that is the absolute risk reduction divided by the proportion of patients who die without taking the drug. Recall that the absolute risk reduction was 3.5% and the proportion of deaths for patients on the placebo was 8.5%, thus the 42% reduction in the statement comes from dividing 3.5 by 8.5. Table 1.1 provides some simple examples of how the relative risk reduction can remain constant while the absolute risk reduction varies widely. Not surprisingly, several studies have found much higher percentages of patients assenting to treatment when relative as opposed to absolute risk reductions are presented. For example, Hux and Naylor (1995) reported that 88% of patients assented to lipid-lowering therapy when relative risk reduction information was provided, compared with only 42% when absolute risk reduction iformation was given. Similarly, Malenka et al. (1993) found that 79% of hpothetical patients preferred a treatment presented with relative risk benefits compared to 21% who chose the absolute risk option. As Edwards et al. (2001) conclude, ‘relative risk information appears much more “persuasive” than the corresponding absolute riskdata’ (p. 74), presumably just because the numbers are larger. So what is the best way to convey information about medical treatment? Zikmund-Fisher (2013) proposes a taxonomy of risk communication with seven different levels pertaining to increasing levels of precision about outcomes. Falling Off the Straight and Narrow 5 According to Zikmund-Fisher, risk formats should be tailored to patients’ needs. If the goal is simply to order risks then statements of possibility suffice (e.g., You are at risk of stroke)",
    "chunk_id": "straight_choices;_the_psychology_of_decision_making;_3.json_chunk_13"
  },
  {
    "document_type": "research_paper",
    "title": "Straight Choices; The Psychology of Decision Making; 3",
    "author": "Newell Ben R.",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\straight_choices.pdf",
    "date_published": "2022-03-31",
    "keywords": "",
    "flag": "",
    "chunk_text": ". If the goal is simply to order risks then statements of possibility suffice (e.g., You are at risk of stroke). However, if assessments of risk magnitude and trade-offs are required, then uncertainties need to be expressed more precisely. As an example, Skolbokken (1998) advocates an approach in which one avoids using value-laden words such as risk or chance, and carefully explains the absolute rather than relative risks. Thus, for a patient suffering from high cholesterol who is considering taking Simvastatin, a doctor should tell him or her something like: ‘If 100 people like you are given no treatment for five years, 92 will live and eight will die. Whether you are one of the 92 or one of the eight, I do not know. Then, if 100 people like you take a certain drug every day for five years, 95 will live and five will die. Again, I do not know whether you are one of the 95 or one of the five’ (Skolbokken, 1998, p. 1958). Zikmund-Fisher’s work suggests that this level of precision is likely to give patients the information they need and reduce errors or biases in decision making. Is This Person Guilty or Innocent? At some point in your life, it is quite likely that you will be called for jury duty. As a member of a jury, you will be required to decide about the guilt or innocence of a defendant. The way in which juries and the individuals that comprise them arrive at their decisions has been the topic of much research (e.g., Hastie, 1993). We will explore this work in much more detail in Chapter 7; here we focus on one aspect: the impact of scientific, especially DNA, evidence on jurors’ decisions about the guilt or innocence of defendants. Faced with DNA evidence in a criminal trial many jurors are inclined to think, ‘science does not lie’; these jurors appear to be susceptible to ‘white coat syndrome’, an unquestioning belief in the power of science which generates misplaced confidence and leads to DNA evidence being regarded as infallible (Goodman-Delahunty & Newell, 2004)",
    "chunk_id": "straight_choices;_the_psychology_of_decision_making;_3.json_chunk_14"
  },
  {
    "document_type": "research_paper",
    "title": "Straight Choices; The Psychology of Decision Making; 3",
    "author": "Newell Ben R.",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\straight_choices.pdf",
    "date_published": "2022-03-31",
    "keywords": "",
    "flag": "",
    "chunk_text": ". Indeed, some research confirms that people often overestimate the accuracy and reliability of scientific evidence (in comparison with other types of evidence, such as eyewitness testimony or confessions), thus assigning it undeserved probative value. For example, mock Table 1.1 Examples of absolute and relative risk reduction Treatment group Placebo group Survivals Mortalities Survivals Mortalities Relative risk reduction (%) Absolute risk reduction (%) 9,000 1,000 8,000 2,000 50 10 9,900 100 9,800 200 50 1 9,990 10 9,880 20 50 0.1 Note: Adapted from Skolbekken, J. A. (1998). Communicating the risk reduction achieved by chlesterol reducing drugs. British Medical Journal, 316 , 1956–1958. 6 Falling Off the Straight and Narrow jurors rated blood tests as significantly more reliable than testimony from an eyewitness (Goodman, 1992). Is it simply because we have so much trust in science that DNA evidence is so compelling, or are there other reasons? Consider the 2001 trial of Wayne Edward Butler in which he was convicted of murdering Celia Douty in Brampton Island, Queensland, Australia in 1983. Police had suspected Butler for a long time but it was not until DNA profiling was used that a case was brought against him. The victim’s body had been found covered by a red towel stained with semen. DNA profiling techniques unavailable in 1983 established the probability that the semen stains were Butler’s, and on the basis of this evidence, he was charged. At trial, a forensic expert told the jury that the probability of someone else having a DNA profile that matched the one obtained from the semen (i.e., the random match probability, RMP) was one in 43 trillion",
    "chunk_id": "straight_choices;_the_psychology_of_decision_making;_3.json_chunk_15"
  },
  {
    "document_type": "research_paper",
    "title": "Straight Choices; The Psychology of Decision Making; 3",
    "author": "Newell Ben R.",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\straight_choices.pdf",
    "date_published": "2022-03-31",
    "keywords": "",
    "flag": "",
    "chunk_text": ". Extreme probabilities such as this make it appear that there is no margin of error – the defendant must be guilty! It is not only the fact that DNA evidence is grounded in the scientific method that makes it appear more objective and indeed even foolproof, but also the manner in which DNA evidence is presented – the probabilities cited by the DNA experts—that make this evidence so influential and persuasive to jurors (Martire, Kemp, & Newell, 2013). Clearly, these numbers sound compelling, but what does an infinitesimal RMP like 1 in 43 trillion really mean? Assuming that no errors occurred in the laboratory processing and that the probability of a random match can be stated with some legitimacy, what should a conscientious juror conclude? Often people interpret the probability not simply as the likelihood that a randomly chosen other person will have the same DNA as that found on the towel (the correct interpretation), but as the probability that the defendant was not guilty (an incorrect interpretation). The leap from a ‘match probability’ to an iference about the guilt of the defendant is dubbed the ‘prosecutor’s fallacy’ (Thompson & Schumann, 1987) and its commission has been observed in many trials (Koehler, 1993). One famous example of the prosecutor’s fallacy is the case of People v. Collins (1968). In this case, the prosecution secured a conviction by erroneously caculating a 1 in 12 million probability that a random couple would possess a series of characteristics (a female with a blond ponytail, a man with black hair and a black beard) and then fallaciously equating this probability with the probability that the accused couple did not commit the robbery. Fortunately, the original conviction was overturned in the appeals court and a stern warning was given about the dangers of ‘trial by mathematics’ (Koehler, 1993). More recent work has examined the extent to which jurors understand the match probabilities that are often presented in trials",
    "chunk_id": "straight_choices;_the_psychology_of_decision_making;_3.json_chunk_16"
  },
  {
    "document_type": "research_paper",
    "title": "Straight Choices; The Psychology of Decision Making; 3",
    "author": "Newell Ben R.",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\straight_choices.pdf",
    "date_published": "2022-03-31",
    "keywords": "",
    "flag": "",
    "chunk_text": ". More recent work has examined the extent to which jurors understand the match probabilities that are often presented in trials. For example, Koehler, Chia, and Lindsey (1995) gave students written summaries of a murder case that included evidence about a DNA match between the defendant and a blood trace recovered from the victim’s fingernails. One group reviewed two items of information: 1) a random match probability of 1 in 1,000,000,000, and 2) a probability of 1 in 1,000 that a human error had occurred leading to Falling Off the Straight and Narrow 7 an incorrect match. A second group was told simply that the combined probability of error from random matches and laboratory mistakes was 1 in 1000. Both groups studied the evidence and then provided verdicts (guilty or not guilty). What is your intuition about the result? If you are like the students in the experiment then you will have found the evidence about the ‘1 in a billion’ random match probability compelling and be more likely to judge the dfendant ‘guilty’ faced with this number. In fact, Koehler et al. (1995) found that almost three times as many guilty verdicts were recorded in the group given that figure. This pattern of results was replicated with jurors. Figure 1.1 displays the results from the two participant populations. What is wrong with this inference? Why shouldn’t we be more covinced by the 1 in a billion figure? The answer lies in how we should correctly combine the random match probability and the human error probability. Koehler et al. (1995) use a baseball analogy to illustrate the problem: consider a baseball infielder who makes throwing errors less than one time in a million but makes fielding errors about two times in a hundred. The chance of the player making an error on the next attempt either because he drops the ball or because he makes a bad throw is at least two out of a hundred. If he makes an error it will almost certainly be a fielding error – but it is still an error",
    "chunk_id": "straight_choices;_the_psychology_of_decision_making;_3.json_chunk_17"
  },
  {
    "document_type": "research_paper",
    "title": "Straight Choices; The Psychology of Decision Making; 3",
    "author": "Newell Ben R.",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\straight_choices.pdf",
    "date_published": "2022-03-31",
    "keywords": "",
    "flag": "",
    "chunk_text": ". If he makes an error it will almost certainly be a fielding error – but it is still an error. The important point is that even if the player reduces his throwing error rate to one in a hundred million or one in a billion it will have very little effect on his overall error rate. So, as Koehler et al. (1995) point out ‘a baseball talent scout should be no more impressed by the infielder’s throwing ability than a legal factfinder should be upon 0 10 20 30 40 50 60 University Students Jurors Percentage of guilty verdict RMP Absent RMP 1 in a billion Figure 1.1 Percentage of guilty verdicts. RMP, random match probability. Drawn using data reported in Koehler, J.J, Chia, A., & Lindsey, S. (1995). The random match probability in DNA evidence: Irrelevant and prejudicial? Jurimetrics Journal, 35, 147–163. 8 Falling Off the Straight and Narrow hearing the vanishingly small random match probabilities’ in DNA evdence at trial (p. 211). In both cases, the lower-bound threshold for error estimates is set by the greater probability – fielding errors in the case of the infielder and laboratory errors in the case of DNA evidence (see also Chapter 5 for a more in-depth treatment of this issue). The example illustrates that the human error rate – the DNA laboratory error rate – is the number that really matters. Even if there is only a 1 in 43 trillion probability of a random match, if the lab conducting the analysis makes errors of the order of one in a hundred or a thousand samples, then the random match probability is essentially irrelevant. Forensic experts often know this. Koehler’s experiments show that, unfortunately, jurors may not, and can as a result make flawed judgements about the probative value or weight to accord to DNA evidence. Consistent with the medical studies discussed above, there are ways of portraying information to jurors that can improve the decisions they make",
    "chunk_id": "straight_choices;_the_psychology_of_decision_making;_3.json_chunk_18"
  },
  {
    "document_type": "research_paper",
    "title": "Straight Choices; The Psychology of Decision Making; 3",
    "author": "Newell Ben R.",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\straight_choices.pdf",
    "date_published": "2022-03-31",
    "keywords": "",
    "flag": "",
    "chunk_text": ". Consistent with the medical studies discussed above, there are ways of portraying information to jurors that can improve the decisions they make. One such modification is the presentation of DNA evidence in natural frquency formats (e.g., 1 in a 1,000,000 rather than probability formats (e.g., 0.0001%). In Chapter 6, we will discuss why such changes in format have a facilitative effect on decision making, and in Chapter 15, we will see how these formats can elicit different emotional reactions, but for now, we will briefly review a study relevant to the legal domain. Lindsey, Hertwig, and Gigerenzer (2003) presented jurors and law students with a sexual assault case which included expert testimony on DNA matching linking the suspect and the crime scene. One group received all information in a probability format, while a second group received identical information presented in a frequency format. Figure 1.2 displays the percentage of guilty 0 10 20 30 40 50 60 law students Jurors Percentage of guilty verdict Probabilities Natural Frequencies Figure 1.2 Percentage of guilty verdicts made by the two samples. From Lindsey, S., Hertwig, R., & Gigerenzer, G. (2003). Communicating statistical evidence. Jurimetrics Journal, 43, 147–163. Copyright 2003 by American Bar Association. Adapted with permission. Falling Off the Straight and Narrow 9 verdicts by the two groups of participants who received the different formats of expert numerical evidence. The results depicted in Figure 1.2 clearly show that the same statistical iformation presented in different formats has a strong impact on the decisions made by students and jurors. When frequency formats were used there were significantly fewer guilty verdicts. Once again, it is sobering to think that such a minor format change can have a major influence on both students’ and jurors’ decisions",
    "chunk_id": "straight_choices;_the_psychology_of_decision_making;_3.json_chunk_19"
  },
  {
    "document_type": "research_paper",
    "title": "Straight Choices; The Psychology of Decision Making; 3",
    "author": "Newell Ben R.",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\straight_choices.pdf",
    "date_published": "2022-03-31",
    "keywords": "",
    "flag": "",
    "chunk_text": ". Once again, it is sobering to think that such a minor format change can have a major influence on both students’ and jurors’ decisions. The results of the studies briefly reviewed here along with many others indicate that jurors’ decisions can be influenced strongly by variations in the presentation of scientific evidence (for additional examples see Martire et al., 2013). In the light of these findings, as Koehler and Macchi (2004) conclude, ‘it might be appropriate to present statistical evidence to jurors in multiple ways to minimize the influence of any particular bias’ (p. 545). This work is not only of academic interest but also has important implications for how legislation is developed regarding the presentation of scientific evidence in court (for an extensive discussion see the President’s Council on Science and Technology’s 2016 report on Forensic Science in Criminal Courts). How Should I Invest My Money? Imagine that you have just won a substantial sum of money on the lottery (if only!) and that you are faced with the enviable problem of deciding how best to invest your newfound wealth. Although you might be tempted to hide the cash under your mattress, you might also consider putting the money in the stock market – but what stocks should you invest in? The problem you face is to work out how to ‘beat’ the notoriously upredictable stock market. Unfortunately, modern theories of finance claim that players in the financial market are well informed, smart and greedy and that it is therefore impossible to make money for nothing in the long term. This general idea is often described as the Efficient Market Hypothesis (Malkiel, 2003). However, against the background of this rather pessimistic outlook, one extremely simple rule of thumb for investment choice might be able to help you: invest in the stocks of the companies that you recognize. Borges et al. (1999) claim that such ‘recognition-based’ investment decisions can lead to much higher returns than from stocks selected by financial experts",
    "chunk_id": "straight_choices;_the_psychology_of_decision_making;_3.json_chunk_20"
  },
  {
    "document_type": "research_paper",
    "title": "Straight Choices; The Psychology of Decision Making; 3",
    "author": "Newell Ben R.",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\straight_choices.pdf",
    "date_published": "2022-03-31",
    "keywords": "",
    "flag": "",
    "chunk_text": ". Borges et al. (1999) claim that such ‘recognition-based’ investment decisions can lead to much higher returns than from stocks selected by financial experts. This ‘stock selection heuristic’ states simply that when picking a subset of stocks from all those available for investment one should choose those objects in the larger set that are highly recognized. Given this formulation, it is clear that the heuristic is only useful for people who recognize some but not all of a given set of stocks. If you do not rcognize any stocks you cannot pick highly recognized ones, and similarly if you are an expert and recognize all stocks the heuristic cannot be used. You need what Ortmann et al. (2008) described as a ‘beneficial degree of ignorance’. 10 Falling Off the Straight and Narrow How well can such a simple rule perform? Borges et al. (1999) put their recognition heuristic to the test in the following way. Germans and Americans were asked to indicate those companies that they recognized from ones listed in the Standard and Poor 500 and from 298 additional stocks trading on German stock exchanges in December 1996. Four categories of participants were interviewed: Munich pedestrians, Chicago pedestrians, University of Munich finance students, and University of Chicago finance students. The former two groups were described as ‘laypersons’, the latter two as ‘experts’. The recognition responses of these four groups were then used to construct stock portfolios of highly recognized companies (those recognized by 90% or more of the participants in a group) for both domestic recognition (companies from the respondents’ own country) and international recognition (foreign companies). This resulted in eight recognition-based portfolios",
    "chunk_id": "straight_choices;_the_psychology_of_decision_making;_3.json_chunk_21"
  },
  {
    "document_type": "research_paper",
    "title": "Straight Choices; The Psychology of Decision Making; 3",
    "author": "Newell Ben R.",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\straight_choices.pdf",
    "date_published": "2022-03-31",
    "keywords": "",
    "flag": "",
    "chunk_text": ". This resulted in eight recognition-based portfolios. Over a six-month period (December 1996 to June 1997), these high recognition portfolios were copared against portfolios of ‘unrecognized’ companies (those recognized by 10% or less of the participants in a group), market indices, mutual funds, and chance portfolios (constructed by selecting companies at random). Figure 1.3 displays the data from the two German groups (experts and laypeople) on the domestic stocks. It can be seen clearly that the portfolios of highly recognized stocks produced much higher returns over the six-month period than those of the unrecognized stocks. Even more impressively, the high recognition companies outperformed the market index and the managed mutual funds. The data for all the groups showed similar patterns – the rcognized stocks always outperformed the unrecognized ones – although rcognition did not outperform the market index or mutual funds for the US domestic recognition markets. 0 10 20 30 40 50 60 Lay people Experts Returns % Highly Recognised Unrecognized Market Index Mutual Fund Chance Portfolio Figure 1.3 Performance of the portfolios by German laypeople and experts in the German domestic market. From data reported in Borges, B., Goldstein, D. G., Ortmann, A., & Gigerenzer, G. (1999). Can ignorance beat the stock market? In G. Gigerenzer, P. M. Todd, & the ABC Research Group (Eds.), Simple heuristics that make us smart (pp. 59–72). New York: Oxford University Press. Copyright 1999 by Oxford University Press. Adapted with permission. Falling Off the Straight and Narrow 11 These results appear to suggest that we can go from ‘recognition to riches’ (Ortmann et al., 2008) and that ignorance can indeed be beneficial (see also Alter & Oppenheimer, 2006, for a related ‘trick’ for beating the stock market using the pronunciation fluency of company names). And, it may not only be in the financial domain that ignorance can be good for you",
    "chunk_id": "straight_choices;_the_psychology_of_decision_making;_3.json_chunk_22"
  },
  {
    "document_type": "research_paper",
    "title": "Straight Choices; The Psychology of Decision Making; 3",
    "author": "Newell Ben R.",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\straight_choices.pdf",
    "date_published": "2022-03-31",
    "keywords": "",
    "flag": "",
    "chunk_text": ". And, it may not only be in the financial domain that ignorance can be good for you. For example, Goldstein and Gigerenzer (2002) reported that German students made slightly more correct inferences about the relative sizes of American cities than US students – despite the US students knowing much more about and recognizing more of the cities. Goldstein and Gigerenzer suggest that this counter-intuitive ‘less-is-more’ effect occurs because the German students were able to rely more often on the recognition heuristic (simply inferring that a recognized city is larger than an unrecognized one) than the US students. The US students, because of their higher rate of recognition, were forced to rely on other knowledge about the cities, which in some instances appeared to lead them to incorrect inferences. We will return to the recognition heuristic in Chapter 3 and scrutinize the claims about the benefits of ignorance, but for now, let us return to the question of what to do with your money. Even if you are not fortunate enough to win the lottery, a financial decision that you will probably have to make at some point in your life is how to save for your retirement. As Benartzi and Thaler (2001, 2002) have noted, there is a growing worldwide trend towards giving individuals some responsibility in making their own asset allocation decisions in defined contribution saving plans. Such devolvement of responsibility raises the question of people’s ability to make these decisions. For example, if you were asked to allocate your contributions among money markets, insurance contracts, bond funds and stock funds, how would you do it? According to Benartzi and Thaler (2001), many investors simply use a ‘1/n strategy’ in which they divide contributions evenly across the funds offered in the plan. In their first experiment, Benartzi and Thaler offered participants a plan with a bond fund and a stock fund and found that the majority of paticipants opted for a 50:50 split between the funds – consistent with the use of a 1/n strategy",
    "chunk_id": "straight_choices;_the_psychology_of_decision_making;_3.json_chunk_23"
  },
  {
    "document_type": "research_paper",
    "title": "Straight Choices; The Psychology of Decision Making; 3",
    "author": "Newell Ben R.",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\straight_choices.pdf",
    "date_published": "2022-03-31",
    "keywords": "",
    "flag": "",
    "chunk_text": ". In a follow-up study, two multiple plans were compared – one with five funds comprising four stock funds and one bond fund, the other also with five but comprising four bond funds and one stock fund. The question was do these different combinations of stock and bond funds lead to different allocations of contributions? In the plan dominated by bond funds, participants allocated 43% of their contributions to the single stock fund. However, in the plan dominated by stock funds, they allocated 68% of their contributions to the stock funds. As the 1/n rule predicts, the total amount allocated to a particular type of fund (stocks) increases when there are more such funds in the portfolio. This result shows that a simple change in the composition of the two plans gives rise to a 25% shift in the amount allocated to the riskier stock funds. Put simply, when more stocks funds were offered, more of the available rsources were allocated to them. The result implies that participants’ attitudes to 12 Falling Off the Straight and Narrow risk (i.e., exposure to fluctuations in the stock market) are highly contingent on the way in which options are presented (cf., Hilton, 2003, and Chapter 9). The ‘1/n strategy’ is a special case of a more general choice heuristic described by Read and Loewenstein (1995) as the ‘diversification heuristic’. The idea is that when people are asked to make several choices simultneously they tend to diversify rather than selecting the same item several times. Simonson (1990) demonstrated the use of such a heuristic in an eperiment in which he offered students the opportunity to choose three items from a selection of snack foods (chocolate bars, crisps, etc.) to be eaten during class time each week. One group were told at the start of the first class that they had to select snacks in advance for the following three weeks, while another group was given the opportunity to select a snack at the beginning of each class",
    "chunk_id": "straight_choices;_the_psychology_of_decision_making;_3.json_chunk_24"
  },
  {
    "document_type": "research_paper",
    "title": "Straight Choices; The Psychology of Decision Making; 3",
    "author": "Newell Ben R.",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\straight_choices.pdf",
    "date_published": "2022-03-31",
    "keywords": "",
    "flag": "",
    "chunk_text": ". Simonson found that 64% of the participants in the advance choice condition chose three different items, whereas only 9% did so when each choice was made shortly before being consumed. This outcome is consistent with the idea that people seek variety when asked to make advance choices (Read & Loewenstein, 1995) but value variety much less when making choices about immediate consumption. This rather naive diversification strategy might be useful in many cicumstances but is it appropriate for investment decisions? Benartzi and Thaler (2001) conclude that using a diversification heuristic ‘can produce a reasonable portfolio [but] it does not assure sensible or coherent decisiomaking’ (p. 96). For example, an employee with little confidence in his or her ability to invest wisely might assume that an employer has compiled a selection of options that is sensible for his or her plan. However, the plan might offer a large number of higher-risk stock options leading the eployee to invest too aggressively (i.e., too heavily in stocks) which may be inappropriate for that person (Benartzi & Thaler, 2001). Summary The examples drawn from the medical, legal and financial arenas clearly show that our decisions can be greatly influenced by the way in which information is provided. Subtle differences in the way numbers are represented or options displayed can affect the decisions we make – sometimes in ways of which we are completely unaware. As we noted at the start of the chapter, our aim is to illustrate the breadth of situations in which understanding how we make decisions is relevant. The details of why some of these effects arise will be explored in the coming chapters. By investigating, systematically, these types of framing and representational issues and understanding the reasons behind the effects, you will have a better chance of keeping your decision making on ‘the straight and narrow’",
    "chunk_id": "straight_choices;_the_psychology_of_decision_making;_3.json_chunk_25"
  },
  {
    "document_type": "research_paper",
    "title": "Straight Choices; The Psychology of Decision Making; 3",
    "author": "Newell Ben R.",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\straight_choices.pdf",
    "date_published": "2022-03-31",
    "keywords": "",
    "flag": "",
    "chunk_text": ". But what is ‘the straight and narrow’ – what makes a decision correct or incorrect, good or bad? We turn to these questions in Chapter 2. Falling Off the Straight and Narrow 13 Suggested Further Reading • The rest of this book! • Goldstein, D. G., & Gigerenzer, G. (2002). Models of ecological rationality: The recognition heuristic. Psychological Review, 109 , 75–90. A detailed examination of how and when relying on recognition can lead to good decisions. • Lejarraga, T., & Hertwig, R. (2021). How experimental methods shaped views on human competence and rationality. Psychological Bulletin, 147, 535-564 . An interesting review that emphasises the importance of learning for understanding how and why we make judgements and decisions; a view very much in keeping with the themes of this book. • Tversky, A., & Kahneman, D. (1974). Judgement under uncetainty: Heuristics and biases. Science, 185 , 1124–1131. • Tversky, A., & Kahneman, D. (1981). The framing of decisions and the psychology of choice. Science, 211 , 453–458. Two seminal papers outlining how we are influenced by availability, among other biases, and how framing impacts choice. Questions for Discussion • Can you think of a time when a decision you made was affected by the way in which information was presented? Would you have made a different decision if you had known about framing effects? • Are forensic experts aware of the limitations of their testimony and the way in which jurors comprehend information? (see the PCAST Report for suggestions: https://obamawhitehouse.archives.gov/sites/default/files/microsites/ostp/ PCAST/pcast_forensic_science_report_final.pdf). • How robust is name recognition as a stock-picking tool? How would you test it? 14 Falling Off the Straight and Narrow",
    "chunk_id": "straight_choices;_the_psychology_of_decision_making;_3.json_chunk_26"
  },
  {
    "document_type": "research_paper",
    "title": "The Outcome‐Representation Learning Model: A Novel Reinforcement Learning Model of the Iowa Gambling Task",
    "author": "Unknown",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Haines-2018-The-outcomerepresentation-learning-.pdf",
    "date_published": "2018-11-20",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": "Cognitive Science 42 (2018) 2534–2561 © 2018 Cognitive Science Society, Inc. All rights reserved. ISSN: 1551-6709 online DOI: 10.1111/cogs.12688 The Outcome-Representation Learning Model: A Novel Reinforcement Learning Model of the Iowa Gambling Task Nathaniel Haines, a Jasmin Vassileva, b,c Woo-Young Ahn a,d a Department of Psychology, The Ohio State University b Department of Psychiatry, Virginia Commonwealth University c Institute for Drug and Alcohol Studies, Virginia Commonwealth University d Department of Psychology, Seoul National University Received 26 October 2017; received in revised form 23 May 2018; accepted 29 August 2018 Abstract The Iowa Gambling Task (IGT) is widely used to study decision-making within healthy and psychiatric populations. However, the complexity of the IGT makes it difficult to attribute varition in performance to specific cognitive processes. Several cognitive models have been proposed for the IGT in an effort to address this problem, but currently no single model shows optimal peformance for both shorand long-term prediction accuracy and parameter recovery. Here, we prpose the Outcome-Representation Learning (ORL) model, a novel model that provides the best compromise between competing models. We test the performance of the ORL model on 393 sujects’ data collected across multiple research sites, and we show that the ORL reveals distinct paterns of decision-making in substance-using populations. Our work highlights the importance of using multiple model comparison metrics to make valid inference with cognitive models and sheds light on learning mechanisms that play a role in underweighting of rare events. Keywords: Computational modeling; Reinforcement learning; Substance use; Iowa Gambling Task; Bayesian data analysis; Amphetamine; Heroin; Cannabis 1",
    "chunk_id": "the_outcome‐representation_learning_model_a_novel_reinforcement_learning_model_of_the_iowa_gambling_task.json_chunk_1"
  },
  {
    "document_type": "research_paper",
    "title": "The Outcome‐Representation Learning Model: A Novel Reinforcement Learning Model of the Iowa Gambling Task",
    "author": "Unknown",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Haines-2018-The-outcomerepresentation-learning-.pdf",
    "date_published": "2018-11-20",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Keywords: Computational modeling; Reinforcement learning; Substance use; Iowa Gambling Task; Bayesian data analysis; Amphetamine; Heroin; Cannabis 1. Introduction There is a growing interest among researchers to develop and apply computational (i.e., cognitive) models to classical assessment tools to help guide clinical decision-maing (e.g., Ahn & Busemeyer, 2016; Batchelder, 1998; McFall & Townsend, 1998; Correspondence should be sent to Nathaniel Haines, Department of Psychology, The Ohio State Univesity, Columbus, OH 43210. E-mail: haines.175@osu.edu (or) Woo-Young Ahn, Department of Psychology, Seoul National University, Seoul 08826, Korea. E-mail: wahn55@snu.ac.kr Neufeld, Vollick, Carter, Boksman, & Jett e, 2002; Ratcliff, Spieler, & Mckoon, 2000; Treat, McFall, Viken, & Kruschke, 2001; Wallsten, Pleskac, & Lejuez, 2005). Despite this interest, clinical assessment has yet to be influenced by the many computational assays available today (see Ahn & Busemeyer, 2016). There are many potential reasons for this, but two important factors are the lack of (a) precise characterizations of nerocognitive processes and (b) optimal, externally valid paradigms for assessing psychiatric conditions. The Iowa Gambling Task (IGT) is an example, which was successfully used to classify various clinical populations from healthy populations (e.g., Bechara, Damasio, Damasio, & Anderson, 1994; Bechara et al., 2001). Originally developed to detect damage in vetromedial prefrontal brain regions, the IGT has since been used to identify a variety of decision-making deficits across a wide range of clinical populations (e.g., Grant, Cotoreggi, & London, 2000; Shurman, Horan, & Nuechterlein, 2005; Stout, Rodawalt, & Siemers, 2001; Whitlow et al., 2004). While the IGT is highly sensitive to decision-maing deficits, the specific underlying neurocognitive processes that are responsible for these observed deficits are difficult to identify using only behavioral performance data",
    "chunk_id": "the_outcome‐representation_learning_model_a_novel_reinforcement_learning_model_of_the_iowa_gambling_task.json_chunk_2"
  },
  {
    "document_type": "research_paper",
    "title": "The Outcome‐Representation Learning Model: A Novel Reinforcement Learning Model of the Iowa Gambling Task",
    "author": "Unknown",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Haines-2018-The-outcomerepresentation-learning-.pdf",
    "date_published": "2018-11-20",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". To address the lack of specificity provided by the IGT, multiple computational models have been proposed which aim to break down the decision-making process into its coponent parts (d’Acremont, Lu, Li, Van der Linden, & Bechara, 2009; Ahn, Busemeyer, Wagenmakers, & Stout, 2008; Busemeyer & Stout, 2002; Worthy, Pang, & Byrne, 2013b), and the modeling approach has been applied to several clinical populations (for a review, see Ahn, Dai, Vassileva, Busemeyer, & Stout, 2016). In particular, the first cogntive model proposed for the IGT — termed the Expectancy-Valence Learning (EVL) model (Busemeyer & Stout, 2002) — was used to identify differences in cognitive mechanisms between healthy controls and multiple clinical populations ranging from those with sustance use to neuropsychiatric disorders (Yechiam, Busemeyer, Stout, & Bechara, 2005). The EVL led to several new competing models, which capture participants’ decisiomaking behavior more accurately. Specifically, two models show excellent performance: (a) the Prospect Valence Learning model with Delta rule (PVL-Delta) shows excellent long-term prediction accuracy and parameter recovery (Ahn et al., 2008, 2014; Steigroever, Wetzels, & Wagenmakers, 2013, 2014), and (b) the Value-Plus-Perseverance model (VPP) shows excellent short-term prediction accuracy (Ahn et al., 2014; Worthy et al., 2013b). Long-term prediction accuracy (a.k.a., absolute performance; Steingroever, Wetzels, & Wagenmakers, 2014) is defined as how well a model can generate the whole choice patterns when only the fitted parameters are used, and short-term prediction accracy is defined as a measure of model prediction accuracy on one-step-ahead trials using fitted parameters and a history of choices while penalizing model complexity",
    "chunk_id": "the_outcome‐representation_learning_model_a_novel_reinforcement_learning_model_of_the_iowa_gambling_task.json_chunk_3"
  },
  {
    "document_type": "research_paper",
    "title": "The Outcome‐Representation Learning Model: A Novel Reinforcement Learning Model of the Iowa Gambling Task",
    "author": "Unknown",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Haines-2018-The-outcomerepresentation-learning-.pdf",
    "date_published": "2018-11-20",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Parameter recovery performance indicates how well “true” model parameters can be estimated (i.e., recovered) after they are used to simulate behavior, which is essential for making valid inference with model parameters (Donkin, Brown, Heathcote, & Wagenmakers, 2010; Wagenmakers, Van Der Maas, & Grasman, 2007). Because all three of these metrics are important in understanding how well model parameters capture the true cognitive prcesses underlying decision making (see Heathcote, Brown, & Wagenmakers, 2015) and N. Haines, J. Vassileva, W.-Y. Ahn / Cognitive Science 42 (2018) 2535 there is no single model that shows good performance in all three metrics, it is unclear which model should be used to make inference on the IGT. Additionally, no studies to our knowledge have explicitly assessed different models’ performance across the multiple versions of the IGT. While many studies to date have employed the original version of the task developed in 1994 (Bechara et al., 1994), the modified version has a non-stationary payoff structure (see section 2.2) and is widely used in practical applications involving populations with severe decision-making impaiments (e.g., Ahn et al., 2014; Bechara & Damasio, 2002). Importantly, a model that peforms well across both versions of the task would be more generalizable to other experience-based cognitive tasks which are used extensively in the decision-making and cognitive science literature. To develop a new and improved computational model for the IGT, it is necessary to first identify the cognitive strategies that decision makers may engage in during IGT administration. In the sections that follow, we describe four separable cognitive stratgies/effects that are consistently observed in IGT behavioral data, including (a) maximiing long-term expected value, (b) maximizing win frequency, (c) choice perseveration, and (d) reversal learning",
    "chunk_id": "the_outcome‐representation_learning_model_a_novel_reinforcement_learning_model_of_the_iowa_gambling_task.json_chunk_4"
  },
  {
    "document_type": "research_paper",
    "title": "The Outcome‐Representation Learning Model: A Novel Reinforcement Learning Model of the Iowa Gambling Task",
    "author": "Unknown",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Haines-2018-The-outcomerepresentation-learning-.pdf",
    "date_published": "2018-11-20",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". As mentioned previously, the IGT falls under the umbrella of more general experience-based cognitive tasks, so a model that accurately captures these multiple strategies has broad implications for models of decisions from experience. 1.1. Expected value In experience-based cognitive tasks, people typically learn the long-term expected value of choice alternatives across trials and make choices appropriately. The IGT is a specific instantiation of an experienced-based task in which people make decisions based on expected value (e.g., Bechara et al., 1994; Beitz, Salthouse, & Davis, 2014). In fact, the most common metric used to summarize IGT behavioral performance is the difference between the number of “good” versus “bad” decks selected, where good and bad decks are those with positive and negative expected values, respectively. For example, in Bechara et al.’s (1994) original work, the net good minus bad deck selections was used to successfully differentiate healthy controls from individuals with ventromedial prfrontal cortex damage. However, it has since become clear that healthy subjects do not always learn to make optimal selections (see Steingroever, Wetzels, Horstmann, Nemann, & Wagenmakers, 2013b), which is consistent with extant literature on experiencbased tasks (e.g., Erev & Barron, 2005). In extreme cases, healthy controls make decsions similar to that of severely impaired decision makers when evaluated using expected value criterion alone (e.g., Caroselli, Hiscock, Scheibel, & Ingram, 2006). The PVL-Delta and VPP models both assume that decision makers first value the oucomes according to the Prospect Theory utility function (Kahneman & Tversky, 1979), and the resulting subjective utilities are then used to update decision makers’ trial-by-trial expectations using the delta rule (i.e., the simplified Rescorla-Wagner updating rule; see Rescorla & Wagner, 1972)",
    "chunk_id": "the_outcome‐representation_learning_model_a_novel_reinforcement_learning_model_of_the_iowa_gambling_task.json_chunk_5"
  },
  {
    "document_type": "research_paper",
    "title": "The Outcome‐Representation Learning Model: A Novel Reinforcement Learning Model of the Iowa Gambling Task",
    "author": "Unknown",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Haines-2018-The-outcomerepresentation-learning-.pdf",
    "date_published": "2018-11-20",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Together, the Prospect Theory utility shape and loss aversion parameters determine which decks decision makers learn to prefer — holding other 2536 N. Haines, J. Vassileva, W.-Y. Ahn / Cognitive Science 42 (2018) parameters constant, low loss aversion can lead to a preference for disadvantageous decks (i.e., decks A and B) because large losses become discounted, while a shape parameter closer to 0 (and below 1) makes decks with frequent gains more valuable than those with infrequent gains despite having the same objective expected value (see section 2.3; Ahn et al., 2008). Notably, reduced loss aversion on the IGT, but not a difference in utility shape, has been linked to decision-making deficits in multiple clinical populations (Ahn et al., 2014; Vassileva et al., 2013), suggesting that differential valuation of gains versus losses is an individual difference with potential real-world implications. Therefore, a new IGT model should capture differential valuation of gains versus losses. 1.2. Win frequency In experience-based paradigms like the IGT, it is well known that a majority of the individuals have strong preferences for choices (i.e., decks) that win frequently, irrespetive of long-term expected value (e.g., Barron & Erev, 2003; Chiu & Lin, 2007; Chiu et al., 2008; Yechiam et al., 2005). For example, across studies using the IGT, deck B (win frequency = 90%) is often more preferred than deck A (win frequency = 50%) despite the long-term value of the two decks being equivalent (Lin, Chiu, Lee, & Hsieh, 2007; Steingroever et al., 2013b). In fact, this preference is so strong that most healthy subjects fail to make optimal decisions when the IGT task structure is altered so that good and bad decks have low and high win frequency, respectively (Chiu et al., 2008). In principle, decision makers may prefer deck B over more advantageous options because they do not accurately account for rare events (i.e., 1 large loss per 10 trials; see Fig. 1)",
    "chunk_id": "the_outcome‐representation_learning_model_a_novel_reinforcement_learning_model_of_the_iowa_gambling_task.json_chunk_6"
  },
  {
    "document_type": "research_paper",
    "title": "The Outcome‐Representation Learning Model: A Novel Reinforcement Learning Model of the Iowa Gambling Task",
    "author": "Unknown",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Haines-2018-The-outcomerepresentation-learning-.pdf",
    "date_published": "2018-11-20",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". In principle, decision makers may prefer deck B over more advantageous options because they do not accurately account for rare events (i.e., 1 large loss per 10 trials; see Fig. 1). Barron and Erev (2003) describe this general tendency as an underweighting of rare events that may be attributable to multiple cognitive mechanisms, including recency effects, estimation error, and/or reliance on cognitive heuristics (see Hertwig & Erev, 2009). However, it is clear from the IGT literature that recency effects alone cannot account for the observed preferences for decks with high win frequency. For example, Steingroever, Wetzels, and Wagenmakers (2013a) showed that the EVL model (Busmeyer & Stout, 2002) — despite capturing recency effects using the delta learning rule — cannot account for the win frequency effect in the IGT. Conversely, the concave dowward Prospect Theory utility function utilized by the PVL-Delta and VPP allows for both models to implicitly account for win frequency (see section 2.3; Ahn et al., 2008). Futhermore, the structure of the IGT is such that the high win frequency decks (i.e., B and D) each have a single loss, so the loss aversion parameter in both the PVL-Delta and VPP models may directly underweight the rare, negative outcomes in these decks. Therfore, the PVL-Delta and VPP implicitly capture win frequency effects and underweighing of rare events through the Prospect Theory utility function, but their parameters do not dissociate the effects of loss aversion or valuation (i.e., the utility shape) from that of win frequency. Relatedly, the individual posterior distributions of the utility shape paraeter are sometimes not well estimated (e.g., confined around a boundary value), which is problematic from a modeling perspective. This is a potentially important oversight given the centrality of win frequency to healthy participants’ IGT performance, which may N. Haines, J. Vassileva, W.-Y",
    "chunk_id": "the_outcome‐representation_learning_model_a_novel_reinforcement_learning_model_of_the_iowa_gambling_task.json_chunk_7"
  },
  {
    "document_type": "research_paper",
    "title": "The Outcome‐Representation Learning Model: A Novel Reinforcement Learning Model of the Iowa Gambling Task",
    "author": "Unknown",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Haines-2018-The-outcomerepresentation-learning-.pdf",
    "date_published": "2018-11-20",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". This is a potentially important oversight given the centrality of win frequency to healthy participants’ IGT performance, which may N. Haines, J. Vassileva, W.-Y. Ahn / Cognitive Science 42 (2018) 2537 differentiate healthy from clinical samples (see Steingroever et al., 2013b). Moreover, a model that explicitly accounts for win frequency may offer insight into experience-based underweighting of rare events. 1.3. Perseveration A series of studies shows that IGT choice preferences can be explained well by heuritic models of choice perseveration — the tendency to continue selecting an option regarless of the choice value. In particular, Worthy, Hawthorne, and Otto (2013a) showed that win-stay/lose-switch choice strategies exhibit good short-term prediction accuracy relative to typical reinforcement learning models, indicating that many decision makers may Fig. 1. Structure of the original and modified versions of the IGT. Notes. (a) The original version of the Iowa Gambling Task (IGT) maintains a stationary payoff distribution for all 100 trials. Decks A and B are both “bad” decks, each with an expected value of 250 points. In cotrast, decks C and D are both “good” decks, each with an expected value of + 250 points. Additionally, decks B and D both have a 90% chance of gaining points when chosen, whereas decks A and C have only a 50% chance. We present net outcomes here, but during the actual task, participants will see a gain and loss after each selection. Actual gains presented are + 100 and + 50 for the bad and good decks, respectively. Actual losses range in value depending on the deck. (b) Net gains (i.e., sum of actual gain and loss) for the first ten draws from each deck. (c) The modified version of the IGT is equivalent to the original version in all respects but one: the losses in the modified version become more and less severe in the bad and good decks, respectively, resulting in a drifting payoff distribution that makes the good decks easier to identify over time",
    "chunk_id": "the_outcome‐representation_learning_model_a_novel_reinforcement_learning_model_of_the_iowa_gambling_task.json_chunk_8"
  },
  {
    "document_type": "research_paper",
    "title": "The Outcome‐Representation Learning Model: A Novel Reinforcement Learning Model of the Iowa Gambling Task",
    "author": "Unknown",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Haines-2018-The-outcomerepresentation-learning-.pdf",
    "date_published": "2018-11-20",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". The loss values change in a stepwise manner, where they are incremented after every ten draws from a given deck. (d) Net gains for the second set of 10 draws (i.e., draws 11 – 20) from the modified IGT. Note that the first 10 draws are identical to the original version, and that the bad decks have decreased in expected value while the good decks have increased. 2538 N. Haines, J. Vassileva, W.-Y. Ahn / Cognitive Science 42 (2018) engage in simple stay/switch strategies that obfuscate inferences made on their learning processes. Furthermore, decay learning rules (Erev & Roth, 1998) provide better shorterm prediction accuracy than typical updating rules (i.e., the delta rule), which may be because they can mimic choice perseveration heuristics by increasing the probability that recently selected decks are chosen again (Ahn et al., 2008). Finally, despite the IGT being designed to capture the exploration – exploitation trade-off (Bechara et al., 1994), recent studies show that healthy participants fail to show evidence of progressing from a state of exploration to exploitation across trials (Steingroever et al., 2013b). Instead, paticipants’ individual tendencies to perseverate on or frequently switch choices remain reatively stable over time. Therefore, a new IGT model should capture decision makers’ tendencies to stay versus switch decks. Otherwise, other model parameters of theoretical interest (e.g., learning rates, loss aversion, etc.) may become conflated with perseverative tendencies. 1.4. Reversal learning Due to the structure of both the original (Bechara et al., 1994) and modified (Bechara et al., 2001) versions of the IGT (see section 2.2 for the details of the task structure), reversal learning plays a critical role in some people’s decision-making process. For example, deck B appears optimal after its first eight selections ( + 100 point rewards on each selection), but the expected value becomes negative after a large loss ( 1,150 points) on the ninth selection",
    "chunk_id": "the_outcome‐representation_learning_model_a_novel_reinforcement_learning_model_of_the_iowa_gambling_task.json_chunk_9"
  },
  {
    "document_type": "research_paper",
    "title": "The Outcome‐Representation Learning Model: A Novel Reinforcement Learning Model of the Iowa Gambling Task",
    "author": "Unknown",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Haines-2018-The-outcomerepresentation-learning-.pdf",
    "date_published": "2018-11-20",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Because many decision makers begin the IGT with a prnounced preference for deck B, which rapidly declines over the first 20 – 30 trials (see Steingroever et al., 2014), it is crucial that models can quickly reverse the preference for deck B after a large loss is encountered. In fact, participants who show performance defcits on the original version of the IGT become indistinguishable from healthy controls when the deck structure is altered to make the bad decks less appealing during the first few draws, and this increase in performance is strongly predictive of reversal learning abilities (Fellows & Farah, 2005). Neither the PVL-Delta nor the VPP models were developed to account for reversal learning. However, the perseverance heuristic in the VPP can potentially mimic shorterm effects of reversal learning by increasing the probability of selecting the same choice after a gain while increasing the probability of switching choices after a loss (see setion 2.3; Worthy et al., 2013b). Both reversal learning and counter-factual (i.e., fictive) updating models can exhibit this behavior by updating the unchosen option utilities in reerence to the chosen option outcome (e.g., Gl € ascher, Hampton, & O’Doherty, 2009; Lorenz, McCabe, Camerer, & Montague, 2007). Unlike the VPP’s perseverance heuristic, counter-factual updating can speed the learning process itself, which can lead to more rapid, long-term preference reversals. Importantly, reversal learning/counter-factual resoning is a well-replicated behavioral phenomenon (see Roese & Summerville, 2005) and has strong support in the model-based cognitive neuroscience literature in application to reinforcement learning tasks (i.e., experience-based tasks; Gl € ascher et al., 2009; Hampton, Bossaerts, & O’Doherty, 2006). N. Haines, J. Vassileva, W.-Y. Ahn / Cognitive Science 42 (2018) 2539 1.5",
    "chunk_id": "the_outcome‐representation_learning_model_a_novel_reinforcement_learning_model_of_the_iowa_gambling_task.json_chunk_10"
  },
  {
    "document_type": "research_paper",
    "title": "The Outcome‐Representation Learning Model: A Novel Reinforcement Learning Model of the Iowa Gambling Task",
    "author": "Unknown",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Haines-2018-The-outcomerepresentation-learning-.pdf",
    "date_published": "2018-11-20",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". N. Haines, J. Vassileva, W.-Y. Ahn / Cognitive Science 42 (2018) 2539 1.5. The current study In summary, the current state-of-the-art computational models of the IGT do not (a) explicitly account for the various effects observed in behavioral data or (b) provide a compromise between the multiple different model comparison metrics used for model selection (i.e., shorand long-term prediction accuracy and parameter recovery). Here, we present the ORL, a novel reinforcement learning model which explicitly accounts for the effects of expected value, gain – loss frequency, choice perseveration, and reversalearning with only five free parameters. By fitting 393 subjects’ IGT choice data, we show that the ORL model provides good shorand long-term prediction accuracy and parameter recovery in comparison to the PVL-Delta and VPP models. Furthermore, the ORL performs consistently well for both the original and modified version of the IGT and on data collected across multiple different research sites. Finally, we apply the ORL to IGT data collected from amphetamine, heroin, and cannabis users (Ahn et al., 2014; Fridberg et al., 2010), and we show that the ORL identifies theoretically meaningful diferences in decision-making between substance-using groups which are supported by prior studies. 2. Methods 2.1. Participants We used IGT data collected from multiple studies to validate the ORL model, incluing (a) an openly accessible, “many labs” collaboration dataset containing IGT data from 247 healthy participants across eight independent studies (Steingroever et al., 2015); 1 (b) data from Ahn et al. (2014), where 48 healthy controls, and 43 pure heroin and 38 pure amphetamine users in protracted abstinence completed a modified version of the IGT; and (c) data from Fridberg et al. (2010), where 17 chronic cannabis users completed the original version of the IGT. 2 Table 1 summarizes the multiple datasets used in the current study. In total, our study includes data from 393 participants",
    "chunk_id": "the_outcome‐representation_learning_model_a_novel_reinforcement_learning_model_of_the_iowa_gambling_task.json_chunk_11"
  },
  {
    "document_type": "research_paper",
    "title": "The Outcome‐Representation Learning Model: A Novel Reinforcement Learning Model of the Iowa Gambling Task",
    "author": "Unknown",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Haines-2018-The-outcomerepresentation-learning-.pdf",
    "date_published": "2018-11-20",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". 2 Table 1 summarizes the multiple datasets used in the current study. In total, our study includes data from 393 participants. See the cited studies for specific details on the participants included in each dataset. 2.2. Tasks In both versions of the IGT, decks A and B are considered “bad” decks because they have a negative expected value, and decks C and D are “good” decks because they have a positive expected value (Fig. 1a and c). The order of cards within each deck (for both versions) is predetermined so that each subject will experience the same sequence of oucomes when drawing from a given deck (e.g., Fig. 1b and d). The original version of the IGT maintains a stationary payoff distribution throughout the task (Bechara et al., 1994), whereas the payoff distribution of the modified version changes over trials (Bechara 2540 N. Haines, J. Vassileva, W.-Y. Ahn / Cognitive Science 42 (2018) et al., 2001) — the net losses in good and bad decks become less and more extreme, respectively, after every 10 selections made from a given deck (c.f. Fig. 1b to d). 2.3. Reinforcement learning models Prospect Valence Learning model with delta rule (PVL-Delta). The PVL-Delta model (Ahn et al., 2008) uses a prospect theory utility function (Kahneman & Tversky, 1979) to transform realized, objective monetary outcomes into subjective utilities: u ð t Þ 1⁄4 x ð t Þ a ; if x ð t Þ 0 k j x ð t Þj a ; otherwise ð 1 Þ Above, t denotes the trial number, u t ð Þ is the subjective utility of the experienced oucome, x t ð Þ is the experienced net outcome (i.e., the amount won minus amount lost on trial t ), and a ð 0 \\ a \\ 2 Þ and k ð 0 \\ k \\ 10 Þ are free parameters which govern the shape of the utility function and sensitivity to losses relative to gains, respectively. The a paramter in the Prospect Theory utility function can account for the win frequency effect (e.g., Chiu et al., 2008)",
    "chunk_id": "the_outcome‐representation_learning_model_a_novel_reinforcement_learning_model_of_the_iowa_gambling_task.json_chunk_12"
  },
  {
    "document_type": "research_paper",
    "title": "The Outcome‐Representation Learning Model: A Novel Reinforcement Learning Model of the Iowa Gambling Task",
    "author": "Unknown",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Haines-2018-The-outcomerepresentation-learning-.pdf",
    "date_published": "2018-11-20",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". The a paramter in the Prospect Theory utility function can account for the win frequency effect (e.g., Chiu et al., 2008). For example, when a \\ 1, the summed subjective utility of receiving $1 five times is greater than receiving $5 once (i.e., the utility curve is concave for postive outcomes and convex for negative ones), so decision makers with an a below 1 would be expected to prefer decks with high win frequency over objectively equivalent decks which win less often (Ahn et al., 2008). Likewise, if k [ 1, the subjective experence of a given loss is greater in magnitude than an equivalent gain, which captures the idea that “losses loom larger than equivalent gains” (Kahneman & Tversky, 1979) when being subjectively evaluated. Note that when making decisions from experience — as in the IGT — the modal participant does not typically show loss aversion (Erev, Ert, & Yechiam, 2008); instead, participants tend to underweight rare events (e.g., Barron & Erev, 2003; Hertwig, Barron, Weber, & Erev, 2004). Previous modeling analyses with Table 1 Breakdown of datasets used in the current study Dataset N Population IGT Version Study Citation Kjome 19 Healthy Modified Kjome et al. (2010) Premkumar 25 Healthy Modified Premkumar et al. (2008) Wood 153 Healthy Modified Wood et al. (2005) Worthy 35 Healthy Original Worthy et al. (2013b) Ahn 48 Healthy Modified Ahn et al. (2014) Ahn 38 Amphetamine Modified Ahn et al. (2014) Ahn 43 Heroin Modified Ahn et al. (2014) Fridberg 15 Healthy Original Fridberg et al. (2010) Fridberg 17 Cannabis Original Fridberg et al. (2010) N. Haines, J. Vassileva, W.-Y. Ahn / Cognitive Science 42 (2018) 2541 the IGT have exhibited a similar pattern, where group-level loss aversion parameters are mostly below 1 (e.g., Ahn et al., 2014)",
    "chunk_id": "the_outcome‐representation_learning_model_a_novel_reinforcement_learning_model_of_the_iowa_gambling_task.json_chunk_13"
  },
  {
    "document_type": "research_paper",
    "title": "The Outcome‐Representation Learning Model: A Novel Reinforcement Learning Model of the Iowa Gambling Task",
    "author": "Unknown",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Haines-2018-The-outcomerepresentation-learning-.pdf",
    "date_published": "2018-11-20",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Haines, J. Vassileva, W.-Y. Ahn / Cognitive Science 42 (2018) 2541 the IGT have exhibited a similar pattern, where group-level loss aversion parameters are mostly below 1 (e.g., Ahn et al., 2014). The PVL-Delta model assumes that decision makers update their expected values for each deck using a simplified variant of the Rescorla – Wagner rule (i.e., the delta rule; Rescorla & Wagner, 1972): E j ð t þ 1 Þ 1⁄4 E j ð t Þ þ A ð u ð t Þ E j ð t ÞÞ ð 2 Þ Here, E j t ð Þ is the expected value of chosen deck j on trial t , and A ð 0 \\ A \\ 1 Þ is a learning rate controlling how quickly decision makers integrate recent outcomes into their expected value for a given deck. Expected values are entered into a softmax function to generate choice probabilities: Pr 1⁄2 D ð t þ 1 Þ 1⁄4 j 1⁄4 e h E j ð t þ 1 Þ P 4 k 1⁄4 1 e h E k ð t þ 1 Þ ð 3 Þ where D t ð Þ is the chosen deck on trail t , and h is determined by: h 1⁄4 3 c 1 ð 4 Þ Here, c ð 0 \\ c \\ 5 Þ is a free parameter which represents trial-independent choice consitency (Yechiam & Ert, 2007). If c is close to 0 or 5, it indicates that decision makers are responding randomly or (near)deterministically, respectively, with respect to their expected values for each deck. Altogether, the PVL-Delta model contains four free parameters ( A , a , c , k ). Value-Plus-Perseverance model (VPP). The VPP model expands upon the PVL-Delta model by adding an additional term for choice perseverance (Worthy et al., 2013b): P j ð t þ 1 Þ 1⁄4 K P j ð t Þ þ P ; if x ð t Þ 0 K P j ð t Þ þ N ; otherwise ð 5 Þ P j t ð Þ indicates the perseveration value for chosen deck j on trial t , which decays by K ð 0 \\ K \\ 1 Þ on each trial. When chosen, the perseveration value for deck j is updated by ε P (-Inf < ε P < Inf) or ε N (-Inf < ε N < Inf) based on the sign of outcome. Positive values for ε P and ε N indicate tendencies for decision makers to “perseverate” the deck chosen on the previous trial, whereas negative values indicate a switching tendency",
    "chunk_id": "the_outcome‐representation_learning_model_a_novel_reinforcement_learning_model_of_the_iowa_gambling_task.json_chunk_14"
  },
  {
    "document_type": "research_paper",
    "title": "The Outcome‐Representation Learning Model: A Novel Reinforcement Learning Model of the Iowa Gambling Task",
    "author": "Unknown",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Haines-2018-The-outcomerepresentation-learning-.pdf",
    "date_published": "2018-11-20",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Positive values for ε P and ε N indicate tendencies for decision makers to “perseverate” the deck chosen on the previous trial, whereas negative values indicate a switching tendency. The VPP assumes that the expected value (from the PVL-Delta model) and persevertion terms are integrated into a single value signal: V j ð t þ 1 Þ 1⁄4 w E j ð t þ 1 Þ þ ð 1 w Þ P j ð t þ 1 Þ ð 6 Þ where x ð 0 \\ x \\ 1 Þ is a parameter that controls the weight given to the expected value and perseveration signals. As x approaches 0 or 1, the VPP reduces to the perseveration 2542 N. Haines, J. Vassileva, W.-Y. Ahn / Cognitive Science 42 (2018) model or the PVL-Delta model alone, respectively. The VPP uses the same softmax funtion as the PVL-Delta to generate choice probabilities, except that E j t þ 1 ð Þ is replaced with V j t þ 1 ð Þ . Altogether, the VPP contains eight free parameters ( A , a , c , k , ε P , ε N , K , Outcome-Representation Learning model (ORL). Here, we propose the ORL as a novel learning model for the IGT. Unlike the PVL-Delta and VPP models, the ORL assumes that the expected value and win frequency for each deck are tracked separately as opposed to implicitly within the Prospect Theory utility function (Pang, Blanco, Maddox, & Worthy, 2016). 3 Note that separate tracking of expected value and win frequency makes the ORL similar to the class of risk-sensitive reinforcement learning models which forgo maximizing expected value to minimize potential risks (e.g., Mihatsch & Neuneier, 2002). The expected value of a deck is updated with separate learning rates for positive and negative outcomes: EV j ð t þ 1 Þ 1⁄4 EV j ð t Þ þ A rew ð x ð t Þ EV j ð t ÞÞ ; if x ð t Þ 0 EV j ð t Þ þ A pun ð x ð t Þ EV j ð t ÞÞ ; otherwise ð 7 Þ where EV j t ð Þ denotes the expected value of chosen deck j on trial t , and A rew ð 0 \\ A rew \\ 1 Þ and A pun ð 0 \\ A pun \\ 1 Þ are learning rates which are used to update expectations after reward (i.e., positive) and punishment (i.e., negative) outcomes, respetively",
    "chunk_id": "the_outcome‐representation_learning_model_a_novel_reinforcement_learning_model_of_the_iowa_gambling_task.json_chunk_15"
  },
  {
    "document_type": "research_paper",
    "title": "The Outcome‐Representation Learning Model: A Novel Reinforcement Learning Model of the Iowa Gambling Task",
    "author": "Unknown",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Haines-2018-The-outcomerepresentation-learning-.pdf",
    "date_published": "2018-11-20",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Unlike the PVL-Delta and VPP models, the ORL is updating expected values using the objective outcome x t ð Þ , not the subjective utility u t ð Þ . The use of separate learning rates for positive versus negative outcomes allows for the ORL model to account for oveand undersensitivity to losses and gains, similar to the loss aversion parameter shared by the PVL-Delta and VPP. Specifically, the larger the difference is between the positive and negative learning rates, the more learning is domnated by either positive or negative outcomes. We used separate learning rates, as opposed to a loss-aversion parameterization, because there is strong neurobiological and behavioral evidence for learning models with separate learning rates for positive versus negative outcomes (e.g., Doll, Jacobs, Sanfey, & Frank, 2009; Gershman, 2015). For example, Parkinson’s patients learn more quickly from negative compared to positive oucomes, and dopamine medication reverses this bias (Frank, Seeberger, & O’Reilly, 2004). Additionally, positive and negative learning rates are modulated by genes that are patially responsible for striatal dopamine functioning (Frank, Moustafa, Haughey, Curran, & Hutchison, 2007), and more recent evidence implicates striatal D1 and D2 receptor stimlation in learning from positive and negative outcomes, respectively (Cox et al., 2015). To account for the win frequency effect, the ORL separately tracks win frequency as follows: EF j ð t þ 1 Þ 1⁄4 EF j ð t Þ þ A rew ð sgn ð x ð t ÞÞÞ EF j ð t ÞÞ ; if x ð t Þ 0 EF j ð t Þ þ A pun ð sgn ð x ð t ÞÞ EF j ð t ÞÞ ; otherwise ð 8 Þ N. Haines, J. Vassileva, W.-Y. Ahn / Cognitive Science 42 (2018) 2543 where EF j t ð Þ denotes the “expected outcome frequency,” A rew ð 0 \\ A rew \\ 1 Þ and A pun ð 0 \\ A pun \\ 1 Þ are learning rates shared with the expected value learning rule, and sgn x t ð Þ ð Þ returns 1, 0, or 1 for positive, 0, or negative outcome values on trial t , respetively. The ORL model also includes a reversal-learning component for EF j t ð Þ",
    "chunk_id": "the_outcome‐representation_learning_model_a_novel_reinforcement_learning_model_of_the_iowa_gambling_task.json_chunk_16"
  },
  {
    "document_type": "research_paper",
    "title": "The Outcome‐Representation Learning Model: A Novel Reinforcement Learning Model of the Iowa Gambling Task",
    "author": "Unknown",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Haines-2018-The-outcomerepresentation-learning-.pdf",
    "date_published": "2018-11-20",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". The ORL model also includes a reversal-learning component for EF j t ð Þ . EF j 0 t ð Þ refers to the expected outcome frequency of all unchosen decks j 0 on trial t : EF j 0 ð t þ 1 Þ 1⁄4 EF j 0 ð t Þ þ A pun ð sgn ð x ð t ÞÞ C EF j 0 ð t ÞÞ ; if x ð t Þ 0 EF j 0 ð t Þ þ A rew ð sgn ð x ð t ÞÞ C EF j 0 ð t ÞÞ ; otherwise ð 9 Þ Here, the learning rates are shared from the expected value learning rule, and C is the number of possible alternative choices for the chosen deck j . Note that when updating unchosen decks j 0 , the reward learning rate is used if the chosen outcome was negative and the punishment learning rate is used if the chosen outcome was positive. Because there are four possible choices in both versions of the IGT, there are always three possble alternative choices. Therefore, C is set to three in the current study. Note that if there were only a single alternative choice (e.g., simple two-choice tasks), C would be set to 1 and the frequency heuristic would reduce to a “double-updating” rule often used to model choice behavior in probabilistic reversal learning tasks (e.g., Gl € ascher et al., 2009). 4 The ORL model also employs a simple choice perseverance model to capture decision makers’ tendencies to stay or switch decks, irrespective of the outcome: PS j ð t þ 1 Þ 1⁄4 1 1 þ K ; if D ð t Þ 1⁄4 j PS j ð t Þ 1 þ K ; otherwise ð 10 Þ where K is determined by: K 1⁄4 3 K 0 1 ð 11 Þ Here, PS j t ð Þ is the perseverance weight of deck j on trial t , and K is a decay parameter controlling how quickly decision makers forget their past deck choices. K 0 is estimated 2 0 ; 5 1⁄2 , therefore, K 2 0 ; 242 1⁄2 (see Eq. 11). The above model implies that the perseveance weight of the chosen deck is set to 1 on each trial, and subsequently all perseveance weights decay exponentially before a choice is made on the next trial. We used this parameterization because it showed the best performance for estimating K compared to other parameterizations (e.g., PS j t þ 1 ð Þ 1⁄4 PS j t ð Þ K )",
    "chunk_id": "the_outcome‐representation_learning_model_a_novel_reinforcement_learning_model_of_the_iowa_gambling_task.json_chunk_17"
  },
  {
    "document_type": "research_paper",
    "title": "The Outcome‐Representation Learning Model: A Novel Reinforcement Learning Model of the Iowa Gambling Task",
    "author": "Unknown",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Haines-2018-The-outcomerepresentation-learning-.pdf",
    "date_published": "2018-11-20",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". We used this parameterization because it showed the best performance for estimating K compared to other parameterizations (e.g., PS j t þ 1 ð Þ 1⁄4 PS j t ð Þ K ). Low or high values for K suggest that decision makers remember long or short histories of their own deck selections, respectively. The ORL model assumes that value, frequency, and perseverance signals are integrated in a linear fashion to generate a single value signal for each deck: 2544 N. Haines, J. Vassileva, W.-Y. Ahn / Cognitive Science 42 (2018) V j ð t þ 1 Þ 1⁄4 EV j ð t þ 1 Þ þ EF j ð t þ 1 Þ b F þ PS j ð t þ 1 Þ b P ð 12 Þ Here, b F ð1 \\ b F \\ 1Þ and b P ð1 \\ b P \\ 1Þ are weights which reflect the effect of outcome frequency and perseverance on total value with respect to the expected value of each deck. Therefore, values for b F less than or greater than 0 indicate that decision maers prefer decks with low or high win frequency, respectively. Additionally, values for b P less than or greater than 0 indicate that decision makers prefer to switch or stay with recently chosen decks, respectively. Note that the expected value ( EV ) is a reference point which frequency and perseverance effects are evaluated against, so the ORL assumes that the “weight” of EV is equal to 1. The ORL uses the same softmax function as the VPP to generate choice probabilities, except that the choice consistency/inverse temperature parameter ( h ) is set to 1. We do not estimate choice consistency for the ORL due to parameter identifiability problems between h , b F , and b P . Altogether, the ORL contains five free parameters ( A rew , A pun , K , b F , b P ). 5 The ORL model will be added to hBayesDM , an easy-to-use R toolbox for computtional modeling of a variety of different reinforcement learning and decision-making models using hierarchical Bayesian analysis (Ahn, Haines, & Zhang, 2017)",
    "chunk_id": "the_outcome‐representation_learning_model_a_novel_reinforcement_learning_model_of_the_iowa_gambling_task.json_chunk_18"
  },
  {
    "document_type": "research_paper",
    "title": "The Outcome‐Representation Learning Model: A Novel Reinforcement Learning Model of the Iowa Gambling Task",
    "author": "Unknown",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Haines-2018-The-outcomerepresentation-learning-.pdf",
    "date_published": "2018-11-20",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Additionally, all R codes used to preprocess, fit, simulate, and plot our results will be uploaded to our GitHub repository upon publication of this manuscript (https://github.com/CCS-Lab). 2.4. Hierarchical Bayesian analysis We used hierarchical Bayesian analysis (HBA) to estimate free parameters for each model (Kruschke, 2015; Lee, 2011; Lee & Wagenmakers, 2011; Rouder & Lu, 2005; Shiffrin, Lee, Kim, & Wagenmakers, 2008). HBA offers many benefits over more coventional approaches (i.e., maximum likelihood estimation), including (a) modeling of individual differences with shrinkage (i.e., pooling) across subjects, and (b) computation of posterior distributions as opposed to point estimates. Previous studies show that HBA leads to more accurate individual-level parameter recovery than the individual MLE approach (e.g., Ahn, Krawitz, Kim, Busemeyer, & Brown, 2011). The HBA was conducted using Stan (version 2.15.1), a probabilistic programming laguage which uses Hamiltonian Monte Carlo (HMC), a variant of Markov Chain Monte Carlo (MCMC), to efficiently sample from high-dimensional probabilistic models as speified by the user (Carpenter, Gelman, Hoffman, & Lee, 2016). For each dataset used in the current study, we assumed that individual-level parameters were drawn from groulevel distributions. Group-level distributions were assumed to be normally distributed, where the priors for locations (i.e., means) and scales (i.e., standard deviations) were assigned normal distributions. Additionally, we used non-centered parameterizations to minimize the dependence between group-level location and scale parameters (Betancourt & Girolami, 2013). Bounded parameters (e.g., learning rates 2 0 ; 1 ð Þ ) were estimated in N. Haines, J. Vassileva, W.-Y. Ahn / Cognitive Science 42 (2018) 2545 an unconstrained space and then probit-transformed to the constrained space — and scaled if necessary — to maximize MCMC efficiency within the parameter space (Ahn et al., 2014, 2017; Wetzels, Vandekerckhove, Tuerlinckx, & Wagenmakers, 2010)",
    "chunk_id": "the_outcome‐representation_learning_model_a_novel_reinforcement_learning_model_of_the_iowa_gambling_task.json_chunk_19"
  },
  {
    "document_type": "research_paper",
    "title": "The Outcome‐Representation Learning Model: A Novel Reinforcement Learning Model of the Iowa Gambling Task",
    "author": "Unknown",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Haines-2018-The-outcomerepresentation-learning-.pdf",
    "date_published": "2018-11-20",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Using the reward learning rate A rew from the ORL model as an example, formal specification of the bounded parameters followed the form: l A rew Normal ð 0 ; 1 Þ r A rew Normal ð 0 ; 0 : 2 Þ A rew 0 Normal(0,1) A rew 1⁄4 Probit ð l A rew þ r A rew A rew 0 Þ ð 13 Þ where l Arew and r Arew are the location and scale parameters for the group-level distribtion, A rew 0 is a vector of individual-level parameters on the unconstrained space, A rew is a vector of individual-level parameters after they have been probit-transformed back to the constrained space, and Probit x ð Þ is the inverse cumulative distribution function of the standard normal distribution. This parameterization ensures that after being probit-tranformed, the hyper prior distribution over the subject-level parameters is (near)uniform between the parameter bounds. For parameters bounded 2 0 ; upper ð Þ (e.g., K ), we used the same parameterization as above but scaled to the upper bound accordingly: K 1⁄4 Probit ð l K þ r K K 0 Þ 5 ð 14 Þ For unbounded parameters (e.g., b F ), we used the same parameterization outline in Eq. 13 except we set the hyper standard deviation to a half-Cauchy 0 ; 1 ð Þ . All models were sampled for 4,000 iterations, with the first 1,500 as warmup (i.e., burn-in), across four sampling chains for a total of 10,000 posterior samples for each parameter. Convegence to target distributions was checked visually by observing trace-plots and numercally by computing Gelman – Rubin — also known as ^ R — statistics for each parameter (Gelman & Rubin, 1992). ^ R values for all models were below 1.1, suggesting that the variance between chains did not outweigh variance within chains. 2.5. Model comparison: Leave-one-out information criterion We used the leave-one-out information criterion (LOOIC) to compare one-step-ahead prediction accuracy across models",
    "chunk_id": "the_outcome‐representation_learning_model_a_novel_reinforcement_learning_model_of_the_iowa_gambling_task.json_chunk_20"
  },
  {
    "document_type": "research_paper",
    "title": "The Outcome‐Representation Learning Model: A Novel Reinforcement Learning Model of the Iowa Gambling Task",
    "author": "Unknown",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Haines-2018-The-outcomerepresentation-learning-.pdf",
    "date_published": "2018-11-20",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". 2.5. Model comparison: Leave-one-out information criterion We used the leave-one-out information criterion (LOOIC) to compare one-step-ahead prediction accuracy across models. LOOIC is an approximation to full leave-one-out prdiction accuracy that can be computed using the log pointwise posterior predictive density (lpd) of observed data (Vehtari, Gelman, & Gabry, 2017). Here, we computed the lpd by taking the log likelihood of each subject’s actual choice on trial t þ 1 conditional on their parameter estimates and choices from trials 2 1 ; 2 ; ; t f g . This procedure is iterated for all trials and for each posterior sample. Log likelihoods are then summed across trials within subjects. This summation results in an N S lpd matrix, where N is the number of subjects and S is the number of posterior samples. We used the loo R package (Vehtari 2546 N. Haines, J. Vassileva, W.-Y. Ahn / Cognitive Science 42 (2018) et al., 2017) to estimate the LOOIC from the lpd matrix. LOOIC is on the deviance scale, where lower values indicate better model fits. 2.6. Model comparison: Choice simulation We used the simulation method to compare long-term prediction accuracy across moels (Ahn et al., 2008; Steingroever et al., 2014). The simulation method involves two steps: (a) models are fit to each group’s data, and (b) fitted model parameters from step 1 are used to simulate subjects’ choice behavior given the task payoff structure. Simulated and true choice patterns are then compared to determine how well the model parameters capture subjects’ choice behavior. In the current study, we employ a fully Bayesian simlation method, which takes random draws from each subject’s joint posterior distribution across fitted model parameters to simulate choice data (Steingroever et al., 2013a, 2014). We iterated this procedure 1,000 times for each subject (i.e., 1,000 draws from indiviual-level, joint posteriors), and choice probabilities for each deck were stored for each iteration",
    "chunk_id": "the_outcome‐representation_learning_model_a_novel_reinforcement_learning_model_of_the_iowa_gambling_task.json_chunk_21"
  },
  {
    "document_type": "research_paper",
    "title": "The Outcome‐Representation Learning Model: A Novel Reinforcement Learning Model of the Iowa Gambling Task",
    "author": "Unknown",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Haines-2018-The-outcomerepresentation-learning-.pdf",
    "date_published": "2018-11-20",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". We iterated this procedure 1,000 times for each subject (i.e., 1,000 draws from indiviual-level, joint posteriors), and choice probabilities for each deck were stored for each iteration. We then averaged the choice probabilities for each deck across iterations and then subjects. Finally, we computed the mean squared deviation (MSD) between the experimental and simulated choice probabilities as follows: MSD 1⁄4 1 4 n n t 1⁄4 1 4 j 1⁄4 1 ð D exp j ð t Þ D sim j ð t ÞÞ 2 ð 15 Þ where n is the number of trials, t is the trial number, j is the deck number, is the average across-subject probability of choosing deck j on trial t , and is the average across-subject simulated probability (across 1,000 iterations as described above) of selecting deck j on trial t . Before computing MSD scores, we smoothed the experimental data (i.e., D exp ð t Þ ) with a moving average of window size 7 (Ahn et al., 2008). Note that this method is diferent from a posterior predictive check because it does not condition on observed response data (Gelman, Hwang, & Vehtari, 2013). 2.7. Model comparison: Parameter recovery Parameter recovery is a method used to determine how well a model can estimate (i.e., recover) known parameter values, and it typically follows two steps: (a) choice data are simulated using a set of true parameters for a given model and task structure, and (b) the model is fit to the simulated choice data and the recovered parameter estimates are copared to the true parameters (e.g., Ahn et al., 2011; Donkin et al., 2010; Wagenmakers et al., 2007). We used the same set of parameters to simulate choices from the modified and original IGT task structure. We generated the parameter set by taking the means of the individual-level posterior distributions of each model fit to the 48 control subjects’ data from Ahn et al. (2014) to ensure that the true parameter values were reasonably ditributed and representative of human decision makers for each model. N. Haines, J. Vassileva, W.-Y",
    "chunk_id": "the_outcome‐representation_learning_model_a_novel_reinforcement_learning_model_of_the_iowa_gambling_task.json_chunk_22"
  },
  {
    "document_type": "research_paper",
    "title": "The Outcome‐Representation Learning Model: A Novel Reinforcement Learning Model of the Iowa Gambling Task",
    "author": "Unknown",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Haines-2018-The-outcomerepresentation-learning-.pdf",
    "date_published": "2018-11-20",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". (2014) to ensure that the true parameter values were reasonably ditributed and representative of human decision makers for each model. N. Haines, J. Vassileva, W.-Y. Ahn / Cognitive Science 42 (2018) 2547 We used two different parameter recovery methods. First, we compared the means of the posterior distributions for each individual-level parameter, and for each model, to the true parameters by plotting all the parameter values in a standardized space. We tranformed parameters by z-scoring the recovered posterior means of each parameter by the mean and standard deviation of true parameters (i.e., the parameter set used to simulate choices) across individual-level parameters, which allowed us to determine how well the location of true parameters was recovered for each parameter and model. Second, we compared each of the true parameters to the entire posterior distribution of the respective recovered parameter by computing rank-ordered (i.e., Spearman’s ) correlations between the true and recovered parameter values across individual-level parameters. We iterated this procedure over each sample from the joint posterior distribution to estimate how well the rank-order between true parameters could be recovered for each parameter and model. The rank-order is particularly important for making inferences on relative parameter diferences between subjects. Together, the parameter recovery methods we used here allowed us to infer how well each model could recover parameters in an absolute and reative sense. 3. Results 3.1. Model comparison: Leave-one-out information criterion Fig. 2 shows the one-step-ahead leave-one-out information criterion (LOOIC) perfomance for each model and datasets used in the current study. As seen in the graphs, while the ORL and VPP outperform the PVL-Delta, they show similar performance to one another. Notably, the ORL outperformed the VPP in all three substance-using groups, albeit by only a negligible amount in heroin users",
    "chunk_id": "the_outcome‐representation_learning_model_a_novel_reinforcement_learning_model_of_the_iowa_gambling_task.json_chunk_23"
  },
  {
    "document_type": "research_paper",
    "title": "The Outcome‐Representation Learning Model: A Novel Reinforcement Learning Model of the Iowa Gambling Task",
    "author": "Unknown",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Haines-2018-The-outcomerepresentation-learning-.pdf",
    "date_published": "2018-11-20",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Notably, the ORL outperformed the VPP in all three substance-using groups, albeit by only a negligible amount in heroin users. Altogether, the LOOIC comparisons suggest that the ORL shows similar short-term prediction performance to the VPP (i.e., better than the PVL-Delta) across both versions of the IGT and across multiple popultions with different decision-making strategies although the ORL has three fewer paramters than the VPP (5 vs. 8). 3.2. Model comparison: Choice simulation The raw choice data and choice simulations for each dataset are depicted in Fig. 3, and the mean squared deviations (MSDs) are shown in Table 2. Similarly to previous analyses (Ahn et al., 2014; Steingroever et al., 2013a), the PVL-Delta showed good simulation peformance for both modified and original IGT versions in both healthy control and sustance-using groups. Unlike previous analyses (Ahn et al., 2014; but see Worthy et al., 2013b), the VPP showed similar performance to the PVL-Delta across datasets. 6 Altogether, the simulation results are less clear on which of the models performs best for long-term prdiction accuracy. In fact, the variation in performance between datasets is much greater than the variation in performance between models within each dataset (see Table 2) . 2548 N. Haines, J. Vassileva, W.-Y. Ahn / Cognitive Science 42 (2018) 3.3. Model comparison: Parameter recovery Parameter recovery results for both versions of the IGT are shown in Fig. 4. For the modified IGT, the PVL-Delta and ORL both show good parameter recovery across model parameters while the VPP performs poorly. For the VPP, the recovered posterior means were systematically higher than the true parameters for the learning rate ( A ), and systematically lower for the choice consistency ( c ) and reinforcement weight ( x ). For the PVL-Delta and ORL, recovered posterior means were well-distributed around the true parameter means",
    "chunk_id": "the_outcome‐representation_learning_model_a_novel_reinforcement_learning_model_of_the_iowa_gambling_task.json_chunk_24"
  },
  {
    "document_type": "research_paper",
    "title": "The Outcome‐Representation Learning Model: A Novel Reinforcement Learning Model of the Iowa Gambling Task",
    "author": "Unknown",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Haines-2018-The-outcomerepresentation-learning-.pdf",
    "date_published": "2018-11-20",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". For the PVL-Delta and ORL, recovered posterior means were well-distributed around the true parameter means. Additionally, the full posterior recovery results for the VPP showed much more variable correlations between true parameters and the recovered posteriors compared to the PVL-Delta and ORL, suggesting that the PVL-Delta and ORL provide more precise posterior estimates and better capture the variance between individual-level parameter estimates (i.e., “subjects”) compared to the VPP. For the original IGT, paramter recovery results were similar. While the VPP showed slightly better performance in the original IGT, still the posterior means for x and c were systematically lower and Fig. 2. Post hoc model fits across models and datasets. Notes. Results of the leave-one-out information criterion (LOOIC) model comparison on one-step-ahead (i.e., short-term) prediction accuracy for each of the datasets analyzed in the current study. Lower LOOIC values indicate better model performance. LOOIC values were baselined by the best model in each comparison. The dashed line represents the zero point (i.e., best model LOOIC = 0), and any deviations from the zero point represent competing model LOOIC values. Error bars represent two standard errors on the difference between the best model and the respective competing model. N. Haines, J. Vassileva, W.-Y. Ahn / Cognitive Science 42 (2018) 2549 Fig. 3. True versus simulated choice proportions across time. Notes. Behavioral and simulation performance for the healthy control data for each of the datasets in the current study. Choice behavior is summarized per block, where blocks were constructed by calculating the proportion of choices made from each deck, across subjects, in 20-trial increments (i.e., block 1 = trials 1 – 20, block 2 = trials 21 – 40, etc.). Choice proportions across subjects are represented by points, and gray ribbons indicate 1 standard error",
    "chunk_id": "the_outcome‐representation_learning_model_a_novel_reinforcement_learning_model_of_the_iowa_gambling_task.json_chunk_25"
  },
  {
    "document_type": "research_paper",
    "title": "The Outcome‐Representation Learning Model: A Novel Reinforcement Learning Model of the Iowa Gambling Task",
    "author": "Unknown",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Haines-2018-The-outcomerepresentation-learning-.pdf",
    "date_published": "2018-11-20",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Choice proportions across subjects are represented by points, and gray ribbons indicate 1 standard error. In general, subjects begin with a preference for deck B, but they learn to prefer deck D as they progress through the task. Additionally, subjects show a clear preference for decks with high win frequency (b and d) over alternatives. Simulation performance is summarized per trial, across subjects within each dataset. The grey ribbons represent 1 standard error across subjects’ averaged simulated choice probabilities. 2550 N. Haines, J. Vassileva, W.-Y. Ahn / Cognitive Science 42 (2018) posterior means for A were systematically higher than their true values. Together, the parameter recovery results suggest that both the PVL-Delta and ORL provide more accrate and precise parameter estimates than the VPP for both versions of the IGT. 3.4. Applications to substance users Because the ORL consistently performed as well or better than competing models across all groups in the current study, we used the ORL to examine group differences in model parameters. Note that we only compared substance-using groups to the healthy control groups within the same studies to minimize any potential between-study effects. Fig. 5 and Fig. 6 show the posterior estimates and differences in posterior estimates for each group, respectively. Below, we use the term “strong evidence” to refer to group differences where the 95% highest density interval (HDI) excludes 0 (Kruschke, 2015). We do not endorse binary interpretations of significant differences using this threshold, and we refer readers to the graphical comparisons (Fig. 6) to judge parameters for meaningful differences. Within the dataset from Ahn et al. (2014), the heroin-using group showed strong evidence of lower punishment learning rates than healthy controls (95% HDI = [0.003, 0.04])",
    "chunk_id": "the_outcome‐representation_learning_model_a_novel_reinforcement_learning_model_of_the_iowa_gambling_task.json_chunk_26"
  },
  {
    "document_type": "research_paper",
    "title": "The Outcome‐Representation Learning Model: A Novel Reinforcement Learning Model of the Iowa Gambling Task",
    "author": "Unknown",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Haines-2018-The-outcomerepresentation-learning-.pdf",
    "date_published": "2018-11-20",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Within the dataset from Ahn et al. (2014), the heroin-using group showed strong evidence of lower punishment learning rates than healthy controls (95% HDI = [0.003, 0.04]). A low punisment learning rate indicates less updating of expectations after experiencing a loss, a finding which is consistent with prior studies showing that heroin users have lower loss-aversion than controls (Ahn et al., 2014). We did not find strong evidence of differences between amphetamine and heroin users. However, there was some evidence (see Fig. 6) that amphtamine users had more negative perseverance weights than heroin users (95% HDI = [ 2.67, 0.79]). Within the dataset from Fridberg et al. (2010), chronic cannabis users showed strong evidence of greater reward learning rates (95% HDI = [ 0.23, 0.05]) and some evidence of lower punishment learning rates (95% HDI = [ 0.001, 0.04]) compared to healthy controls, which is consistent with a previous analysis of this dataset using the PVL-Delta model showing that cannabis users were more sensitive to rewards and less sesitive to losses compared to healthy controls (Fridberg et al., 2010). Lastly, cannabis users showed strong evidence for more negative perseverance weights than healthy controls (95% HDI = [0.004, 4.09]), indicating a strong preference toward switching, as opposed to persverating on, choices irrespective to the expected value of each deck. Table 2 Mean squared deviations of true from simulated choice probabilities Dataset Model 1 2 3 4 5 6 7 8 9 ORL 41.6 20.3 6.9 23.4 7.4 15.4 9.7 81.5 25.1 PVL-Delta 44.9 20.6 4.4 17.3 8.5 12.9 7.7 72.8 18.8 VPP 44.7 20.9 6.0 16.9 8.8 15.0 9.0 85.5 20.6 Notes. 1 = Kjome; 2 = Premkumar; 3 = Wood; 4 = Worthy; 5 = Ahn (Healthy); 6 = Ahn (Amphetmine); 7 = Ahn (Heroin); 8 = Fridberg (Healthy); 9 = Fridberg (Cannabis). The lowest mean squared devation (MSD) is bolded within each dataset. N. Haines, J. Vassileva, W.-Y. Ahn / Cognitive Science 42 (2018) 2551 4",
    "chunk_id": "the_outcome‐representation_learning_model_a_novel_reinforcement_learning_model_of_the_iowa_gambling_task.json_chunk_27"
  },
  {
    "document_type": "research_paper",
    "title": "The Outcome‐Representation Learning Model: A Novel Reinforcement Learning Model of the Iowa Gambling Task",
    "author": "Unknown",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Haines-2018-The-outcomerepresentation-learning-.pdf",
    "date_published": "2018-11-20",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". The lowest mean squared devation (MSD) is bolded within each dataset. N. Haines, J. Vassileva, W.-Y. Ahn / Cognitive Science 42 (2018) 2551 4. Discussion We present a novel cognitive model (the ORL) for the IGT which shows excellent shorand long-term prediction accuracy across both versions of the task and across an array of different clinical populations. The ORL explicitly models the four most consitent trends found in IGT behavioral data, including long-term expected value, gain – loss frequency, perseverance, and reversal-learning. Overall, we showed that the ORL outpeformed or showed comparable performance to competing models in all three model Fig. 4. Parameter recovery results across models and versions of the IGT. Notes. Parameter recovery results for the modified and original IGT tasks. Each task structure was simulated for each model using the same set of 48 individual-level parameter sets across modified and original task structures. Posterior mean results show comparisons of the true parameters with the means of the posterior distributions of the recovered parameters after being standardized. We standardized parameters by z-scoring the true and recovered posterior means by the mean and standard deviation of each of the 48 true parameter sets. This method allowed us to visualize the bias in recovered posterior means, where any values falling above or below the solid diagonal line indicate higher or lower recovered means in reference to the true parameters, respectively. Dashed and dotted lines reflect 1 and 2 standard deviations in the standardized space, respectively. Note that some parameter values fell outside of the graphs (particularly for the VPP), but zooming out further obfuscates the results. Full posterior recovery results were generated by computing a Spearman’s rank-order correlation between each set of individual-level true parameters and the respective set of individual-level recovered parameters for each sample in the recovered posterior distribution",
    "chunk_id": "the_outcome‐representation_learning_model_a_novel_reinforcement_learning_model_of_the_iowa_gambling_task.json_chunk_28"
  },
  {
    "document_type": "research_paper",
    "title": "The Outcome‐Representation Learning Model: A Novel Reinforcement Learning Model of the Iowa Gambling Task",
    "author": "Unknown",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Haines-2018-The-outcomerepresentation-learning-.pdf",
    "date_published": "2018-11-20",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Full posterior recovery results, therefore, represent the uncertainty in recovering the relative positions of the true parameters across all individual-level parameters (i.e., across all “subjects”). Distributions with mass closer to 1 indicate that the order between true parameters is recovered well for a given parameter and model. Dotted lines reprsent 2.5% and 97.5% quantiles, dashed lines represent 25% and 75% quantiles, and the solid line represents the median. Quantiles were calculated across all parameters. 2552 N. Haines, J. Vassileva, W.-Y. Ahn / Cognitive Science 42 (2018) comparison indices, including post hoc test (LOOIC), simulation performance, and parameter recovery. The results suggest that future research using the IGT should cosider the ORL a top choice for cognitive modeling analyses. Consistent with prior studies, our model comparison results suggest that any single measure used to compare models might not be sufficient (Ahn et al., 2008, 2014; Steigroever et al., 2014; Yechiam & Ert, 2007). For example, we found that the ORL consitently outperformed the VPP using parameter recovery metrics yet performed similarly to the VPP in shorand long-term prediction accuracy. Our results underscore the impotance of using many model comparison metrics in deciding between competing cognitive models (Heathcote et al., 2015; Palminteri, Wyart, & Koechlin, 2017). Many studies use only information criteria such as LOOIC (e.g., Akaike or Bayesian information criteria) Fig. 5. Group-level ORL parameters across healthy and substance-using groups. Notes. (a) Group-level parameter distributions for the healthy controls, amphetamine users, and heroin users who underwent the modified IGT. (b) Group-level parameter distributions for the healthy controls and chronic cannabis users who underwent the original IGT. N. Haines, J. Vassileva, W.-Y. Ahn / Cognitive Science 42 (2018) 2553 when choosing one among many cognitive models, and our results suggest that this may lead to imprecise inferences",
    "chunk_id": "the_outcome‐representation_learning_model_a_novel_reinforcement_learning_model_of_the_iowa_gambling_task.json_chunk_29"
  },
  {
    "document_type": "research_paper",
    "title": "The Outcome‐Representation Learning Model: A Novel Reinforcement Learning Model of the Iowa Gambling Task",
    "author": "Unknown",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Haines-2018-The-outcomerepresentation-learning-.pdf",
    "date_published": "2018-11-20",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". N. Haines, J. Vassileva, W.-Y. Ahn / Cognitive Science 42 (2018) 2553 when choosing one among many cognitive models, and our results suggest that this may lead to imprecise inferences. Indeed, despite the VPP performing excellently when assessed using information criteria alone (i.e. LOOIC), the parameter recovery results indicate that multiple VPP model parameters might be imprecise at the subject level and biased at the group level (see Fig. 4). For cognitive models to be useful in identifying individual differences (e.g., for clinical decision making), it is crucial that future studies conduct parameter recovery tests to ensure that parameter interpretations are valid. When applied to IGT performance of pure substance users, the ORL revealed that heoin users in protracted abstinence were less sensitive to punishments (i.e., lower punisment learning rates) compared to healthy controls. The finding of lower punishment sensitivity in the heroin-using group is consistent with Ahn et al. (2014), where heroin users showed lower loss aversion (i.e., k from the VPP) than healthy controls. We also found some evidence that amphetamine users engaged in more switching behavior than heroin users (see b P in Fig. 5 and 6). Although weak in comparison to other reported diferences, this finding is consistent with a previous study showing that high levels of Fig. 6. Differences in group-level ORL parameters between healthy and substance-using groups. Notes. Differences in group-level parameter distributions (for the ORL) between healthy controls and sustance-using groups. Solid red lines highlight the 95% highest posterior density interval (HDI), and dashed red lines reflect the 0 point. Values on the left and right sides of each graph represent the proportion of each distribution falling below and above the 0 point, respectively. Note that groups were compared within studies to minimize any confounding effects of task implementation, study design, and other site-specific experimetal details. 2554 N. Haines, J",
    "chunk_id": "the_outcome‐representation_learning_model_a_novel_reinforcement_learning_model_of_the_iowa_gambling_task.json_chunk_30"
  },
  {
    "document_type": "research_paper",
    "title": "The Outcome‐Representation Learning Model: A Novel Reinforcement Learning Model of the Iowa Gambling Task",
    "author": "Unknown",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Haines-2018-The-outcomerepresentation-learning-.pdf",
    "date_published": "2018-11-20",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Note that groups were compared within studies to minimize any confounding effects of task implementation, study design, and other site-specific experimetal details. 2554 N. Haines, J. Vassileva, W.-Y. Ahn / Cognitive Science 42 (2018) experience-seeking traits are positively and negatively predictive of amphetamine and heoin users, respectively (Ahn & Vassileva, 2016). Notably, behavioral summaries of the amphetamine and heroin user’s choice preferences were indistinguishable (see Ahn et al., 2014). Additionally, the ORL revealed that chronic cannabis users were more sensitive to rewards (i.e., higher reward learning rates) and more likely to engage in exploratory behavior (i.e., more negative perseveration weight) than healthy controls. These findings converge with previous modeling results using the PVL-Delta (Fridberg et al., 2010) and with pharmacological studies showing that cannabis administration can increase sensitivity to rewards (and not punishments), which in turn may lead to more risk-taking behaviors (Lane, 2002; Lane, Cherek, Tcheremissine, Lieving, & Pietras, 2005). Importantly, our finding that chronic cannabis users tend to engage in exploratory behavior — irrespective to the value of each deck — suggests that the high levels of risk-taking induced by acute canabis consumption may have long-lasting effects that influence not only sensitivity to rewards but also the tendency to seek out novel stimuli. Future studies may further clarify the temporal relationship between reward sensitivity and sensation seeking in cannabis users by applying the ORL to cross-sectional or longitudinal samples. Finally, research by our own and other groups consistently reveals that computational model parameters are more sensitive to dissociating substance-specific and disorder-specific neurocognitive prfiles than standard neurobehavioral performance indices (see Ahn et al., 2016 for a review)",
    "chunk_id": "the_outcome‐representation_learning_model_a_novel_reinforcement_learning_model_of_the_iowa_gambling_task.json_chunk_31"
  },
  {
    "document_type": "research_paper",
    "title": "The Outcome‐Representation Learning Model: A Novel Reinforcement Learning Model of the Iowa Gambling Task",
    "author": "Unknown",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Haines-2018-The-outcomerepresentation-learning-.pdf",
    "date_published": "2018-11-20",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Such parameters show significant potential as novel computational markers for addiction and other forms of psychopathology, which could help refine neurocognitive phenotypes and develop more rigorous mechanistic models of psychiatric disorders (Ahn & Busemeyer, 2016). Our results have implications for a wide range of cognitive tasks that involve learning from experience. In particular, our finding that differential learning rates for positive and negative outcomes can capture the same behavioral patterns that have previously been attributed to a loss aversion parameter (cf. controls vs. heroin users in Fig. 5 to findings published in Ahn et al., [2014]) suggests that the underweighting of rare events that is observed in experience-based tasks may arise from learning, rather than valuation mechnisms (e.g., Barron & Erev, 2003; Hertwig et al., 2004). While the ORL limits this underweighting to tasks including outcomes in both gain and loss domains, future studies may extend the model to capture decisions in purely gain or loss domains by modifying the function that codes outcomes as gains versus losses (see equations 7 – 9). One potetial solution could be to code outcomes as gains versus losses based on the sign of the prediction error rather than the objective outcome; in fact, cognitive models utilizing searate learning rates for positive versus negative prediction errors are gaining popularity in the decision sciences due to their theoretical and empirical support (e.g., Gershman, 2015). Conflict of interest The authors declare no competing financial interests. N. Haines, J. Vassileva, W.-Y. Ahn / Cognitive Science 42 (2018) 2555 Acknowledgments Some of the data in this study were collected with financial support from the National Institute on Drug Abuse and Fogarty International Center (award number: R01DA021421). Notes 1. We only included data from Steingroever et al. (2015), where participants undewent either the original or modified versions of the IGT as described in Fig. 1",
    "chunk_id": "the_outcome‐representation_learning_model_a_novel_reinforcement_learning_model_of_the_iowa_gambling_task.json_chunk_32"
  },
  {
    "document_type": "research_paper",
    "title": "The Outcome‐Representation Learning Model: A Novel Reinforcement Learning Model of the Iowa Gambling Task",
    "author": "Unknown",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Haines-2018-The-outcomerepresentation-learning-.pdf",
    "date_published": "2018-11-20",
    "keywords": "Unavailable",
    "flag": "",
    "chunk_text": ". Notes 1. We only included data from Steingroever et al. (2015), where participants undewent either the original or modified versions of the IGT as described in Fig. 1. This criterion excluded any datasets where the order of cards in each deck was randoized or where participants were required to complete other tasks (i.e., introspective judgements) throughout IGT administration. 2. Healthy controls from Fridberg et al. (2010) are included in the many labs dataset from Steingroever et al. (2015). 3. Pang, B., Byrne, K., A., Worthy, D., A. (unpublished). When more is less: working memory load reduces reliance on a frequency heuristic during decision-making. 4. We tried various versions of the reversal learning process (e.g., reversal learning on EV j ( t ) or both EV j ( t ) and EF j ( t )) and versions of the model without the revesal learning component, but the version we report in this paper showed the best model fit. 5. Note that we tried various other models from the reinforcement learning literature, including: variants with the Pearce-Hall updating rule (Pearce & Hall, 1980), woring memory models (Collins, Albrecht, Waltz, Gold, & Frank, 2017), and risk avesion models (d’Acremont et al., 2009). However, none of these models provided an improved fit of the data and we do not report them for brevity. 6. Note that an error was discovered in simulation code used for the VPP in Ahn et al. (2014), which may partially account for the previous finding that the VPP exhibited poor simulation performance.",
    "chunk_id": "the_outcome‐representation_learning_model_a_novel_reinforcement_learning_model_of_the_iowa_gambling_task.json_chunk_33"
  },
  {
    "document_type": "online_article",
    "title": "Understanding the beta distribution (using baseball statistics)",
    "author": "David Robinson",
    "source": "http://varianceexplained.org/statistics/beta_distribution_and_baseball/",
    "date_published": "December 20, 2014",
    "flag": "",
    "chunk_text": "Director of Engineering at Contentsquare Note: I originally published a version of this post as an answer tothis Cross Validated question. Some distributions, like the normal, the binomial, and the uniform, are described in statistics education alongside their real world interpretations and applications, which means beginner statisticians usually gain a solid understanding of them. But I’ve found that thebeta distributionis rarely explained in these intuitive termif its usefulness is addressed at all, it’s often with dense terms like “conjugate prior and “order statistic.” This is a shame, because the intuition behind the beta is pretty cool. In short, the beta distribution can be understood as representing a probability distributionof probabilitiethat is, it represents all the possible values of a probability when we don’t know what that probability is. Here is my favorite explanation of this: Anyone who follows baseball is familiar withbatting averagesimply the number of times a player gets a base hit divided by the number of times he goes up at bat (so it’s just a percentage between 0 and 1). .266 is in general considered an average batting average, while .300 is considered an excellent one. Imagine we have a baseball player, and we want to predict what his season-long batting average will be. You might say we can just use his batting average so fabut this will be a very poor measure at the start of a season! If a player goes up to bat once and gets a single, his batting average is briefly 1.000, while if he strikes out or walks, his batting average is 0.000. It doesn’t get much better if you go up to bat five or six timeyou could get a lucky streak and get an average of 1.000, or an unlucky streak and get an average of 0, neither of which are a remotely good predictor of how you will bat that season",
    "chunk_id": "understanding_the_beta_distribution_(using_baseball_statistics).json_chunk_1"
  },
  {
    "document_type": "online_article",
    "title": "Understanding the beta distribution (using baseball statistics)",
    "author": "David Robinson",
    "source": "http://varianceexplained.org/statistics/beta_distribution_and_baseball/",
    "date_published": "December 20, 2014",
    "flag": "",
    "chunk_text": ". Why is your batting average in the first few hits not a good predictor of your eventual batting average? When a player’s first at-bat is a strikeout, why does no one predict that he’ll never get a hit all season? Because we’re going in withprior expectations.We know that in history, most batting averages over a season have hovered between something like .215 and .360, with some extremely rare exceptions on either side. We know that if a player gets a few strikeouts in a row at the start, that might indicate he’ll end up a bit worse than average, but we know he probably won’t deviate from that range. Given our batting average problem, which can be represented with abinomial distribution(a series of successes and failures), the best way to represent these prior expectations (what we in statistics just call aprior) is with the beta distributioit’s saying, before we’ve seen the player take his first swing, what we roughly expect his batting average to be. The domain of the beta distribution is \\((0, 1)\\), just like a probability, so we already know we’re on the right tracbut the appropriateness of the beta for this task goes far beyond that. We expect that the player’s season-long batting average will be most likely around .27, but that it could reasonably range from .21 to .35. This can be represented with a beta distribution with parameters \\(\\alpha=81\\) and \\(\\beta=219\\): I came up with these parameters for two reasons: You asked what the x axis represents in a beta distribution density plohere it represents his batting average. Thus notice that in this case, not only is the y-axis a probability (or more precisely a probability density), but the x-axis is as well (batting average is just a probability of a hit, after all)! The beta distribution is representing a probability distributionof probabilities. But here’s why the beta distribution is so appropriate. Imagine the player gets a single hit",
    "chunk_id": "understanding_the_beta_distribution_(using_baseball_statistics).json_chunk_2"
  },
  {
    "document_type": "online_article",
    "title": "Understanding the beta distribution (using baseball statistics)",
    "author": "David Robinson",
    "source": "http://varianceexplained.org/statistics/beta_distribution_and_baseball/",
    "date_published": "December 20, 2014",
    "flag": "",
    "chunk_text": ". But here’s why the beta distribution is so appropriate. Imagine the player gets a single hit. His record for the season is now “1 hit; 1 at bat.” We have to thenupdateour probabilitiewe want to shift this entire curve over just a bit to reflect our new information. While the math for proving this is a bit involved (it’s shown here), the result isvery simple. The new beta distribution will be: Where \\(\\alpha_0\\) and \\(\\beta_0\\) are the parameters we started witthat is, 81 and 219. Thus, in this case, \\(\\alpha\\) has increased by 1 (his one hit), while \\(\\beta\\) has not increased at all (no misses yet). That means our new distribution is \\(\\mbox{Beta}(81+1, 219)\\). Let’s compare that to the original: Notice that it has barely changed at althe change is indeed invisible to the naked eye! (That’s because one hit doesn’t really mean anything). However, the more the player hits over the course of the season, the more the curve will shift to accommodate the new evidence, and furthermore the more it will narrow based on the fact that we have more proof. Let’s say halfway through the season he has been up to bat 300 times, hitting 100 out of those times. The new distribution would be \\(\\mbox{beta}(81+100, 219+200)\\): Notice the curve is now both thinner and shifted to the right (higher batting average) than it used to bwe have a better sense of what the player’s batting average is. One of the most interesting outputs of this formula is the expected value of the resulting beta distribution, which is basically your new estimate. Recall that the expected value of the beta distribution is \\(\\frac{\\alpha}{\\alpha+\\beta}\\). Thus, after 100 hits of 300realat-bats, the expected value of the new beta distribution is \\(\\frac{82+100}{82+100+219+200}=.303\\)- notice that it is lower than the naive estimate of \\(\\frac{100}{100+200}=.333\\), but higher than the estimate you started the season with (\\(\\frac{81}{81+219}=.270\\))",
    "chunk_id": "understanding_the_beta_distribution_(using_baseball_statistics).json_chunk_3"
  },
  {
    "document_type": "online_article",
    "title": "Understanding the beta distribution (using baseball statistics)",
    "author": "David Robinson",
    "source": "http://varianceexplained.org/statistics/beta_distribution_and_baseball/",
    "date_published": "December 20, 2014",
    "flag": "",
    "chunk_text": ". You might notice that this formula is equivalent to adding a “head start” to the number of hits and non-hits of a playeyou’re saying “start him off in the season with 81 hits and 219 non hits on his record”). Thus, the beta distribution is best for representing a probabilistic distributionof probabilitiethe case where we don’t know what a probability is in advance, but we have some reasonable guesses. Director of Engineering at Contentsquare Understanding the beta distribution (using baseball statistics)was published onDecember 20, 2014.",
    "chunk_id": "understanding_the_beta_distribution_(using_baseball_statistics).json_chunk_4"
  },
  {
    "document_type": "research_paper",
    "title": "Validating the PVL-Delta model for the Iowa gambling task",
    "author": "Helen Steingroever",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Steingroever-2013-Validating-the-pvl-delta-model-for-.pdf",
    "date_published": "2013-11-26",
    "keywords": "reinforcement learning, expectancy valence model, prospect valence model, test of selective influence, parameter space partitioning",
    "flag": "",
    "chunk_text": "Validating the PVL-Delta model for the Iowa gambling task Helen Steingroever 1 *, Ruud Wetzels 2,3 and Eric-Jan Wagenmakers 1 1 Psychological Methods, Department of Psychology, University of Amsterdam, Amsterdam, Netherlands 2 Informatics Institute, University of Amsterdam, Amsterdam, Netherlands 3 Spinoza Centre for Neuroimaging, Amsterdam, Netherlands Edited by: Ching-Hung Lin, Kaohsiung Medical University, Taiwan Reviewed by: Jan Glaescher, University of Hamburg, Germany Shunsuke Kobayashi, Fukushima Medical University, Japan *Correspondence: Helen Steingroever, Psychological Methods, Department of Psychology, University of Amsterdam, Weesperplein 4, 1018 XA Amsterdam, Netherlands e-mail: helen.steingroever@ gmail.com Decision-making deficits in clinical populations are often assessed with the Iowa gambling task (IGT). Performance on this task is driven by latent psychological processes, the assessment of which requires an analysis using cognitive models. Two popular examples of such models are the Expectancy Valence (EV) and Prospect Valence Learning (PVL) models. These models have recently been subjected to sophisticated procedures of model checking, spawning a hybrid version of the EV and PVL models—the PVL-Delta model. In order to test the validity of the PVL-Delta model we present a parameter space partitioning (PSP) study and a test of selective influence. The PSP study allows one to assess the choice patterns that the PVL-Delta model generates across its entire parameter space. The PSP study revealed that the model accounts for empirical choice patterns featuring a preference for the good decks or the decks with infrequent losses; however, the model fails to account for empirical choice patterns featuring a preference for the bad decks. The test of selective influence investigates the effectiveness of experimental manipulations designed to target only a single model parameter. This test showed that the manipulations were successful for all but one parameter",
    "chunk_id": "validating_the_pvl-delta_model_for_the_iowa_gambling_task.json_chunk_1"
  },
  {
    "document_type": "research_paper",
    "title": "Validating the PVL-Delta model for the Iowa gambling task",
    "author": "Helen Steingroever",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Steingroever-2013-Validating-the-pvl-delta-model-for-.pdf",
    "date_published": "2013-11-26",
    "keywords": "reinforcement learning, expectancy valence model, prospect valence model, test of selective influence, parameter space partitioning",
    "flag": "",
    "chunk_text": ". This test showed that the manipulations were successful for all but one parameter. To conclude, despite a few shortcomings, the PVL-Delta model seems to be a better IGT model than the popular EV and PVL models. Keywords: reinforcement learning, expectancy valence model, prospect valence model, test of selective influence, parameter space partitioning 1. INTRODUCTION The Iowa gambling task (IGT; Bechara et al., 1994 ) is arguably the most popular neuropsychological paradigm to assess decisiomaking deficits in clinical populations. In order to isolate and identify the psychological processes that drive performance on the IGT, behavioral analyses of IGT data are insufficient. A promising alternative analysis approach is to use cognitive process models. The IGT imposes high demands on these models because it is a complex task producing various types of choice patterns that a good model should be able to generate ( Steingroever et al., 2013a,b ). In addition, the models should also account for indiviual differences and for participants’ switch behavior on the task (e.g., Zhao and Costello, 2007; Steingroever et al., 2013b ). Despite the high demands, some plausible and elegant IGT models have been proposed. Two of the most frequently used representatives include the Expectancy Valence model (EV; see Steingroever et al., 2013b , for references), and the Prospect Valence Learning model (PVL; see Steingroever et al., 2013b , for references and a detailed description of the models). The parameters of these models corespond to distinct psychological processes such as motivation, learning/memory, and response consistency ( Busemeyer et al., in press ). Since the development of the EV model in 2002, reinforcement-learning (RL) models for IGT data have been subjected to sophisticated procedures of model checking (e.g., Busemeyer and Stout, 2002; Yechiam and Busemeyer, 2005; Yechiam and Ert, 2007; Ahn et al., 2008; Yechiam and Busemeyer, 2008; Fridberg et al., 2010; Steingroever et al., 2013b )",
    "chunk_id": "validating_the_pvl-delta_model_for_the_iowa_gambling_task.json_chunk_2"
  },
  {
    "document_type": "research_paper",
    "title": "Validating the PVL-Delta model for the Iowa gambling task",
    "author": "Helen Steingroever",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Steingroever-2013-Validating-the-pvl-delta-model-for-.pdf",
    "date_published": "2013-11-26",
    "keywords": "reinforcement learning, expectancy valence model, prospect valence model, test of selective influence, parameter space partitioning",
    "flag": "",
    "chunk_text": ". These model comparison efforts spawned a hybrid version of the EV and PVL models—the PVL-Delta model ( Ahn et al., 2008; Fridberg et al., 2010; Steingroever et al., in press ; see next section for a detailed description of the PVL-Delta model and recent model comparison efforts). This model seems to be promising for IGT data because it can generate a variety of empirical choice patterns better than its competitors ( Steingroever et al., in press ). Whereas previous procedures of model checking focused mostly on relative comparisons of different RL models for IGT data, no efforts have been carried out to validate the PVL-Delta model (i.e., assess its adequacy in isolation). Here, we focus on two different ways of validating the PVL-Delta model: first, we conduct a parameter space partitioning (PSP) study that sytematically assesses which choice patterns the PVL-Delta model generates across its entire parameter space. Thus, with this first validity check we aim to answer the question: can the PVL-Delta model generate typical empirical choice patterns over a wide range of parameter settings? Second, we conduct a test of seletive influence that investigates the effectiveness of experimental manipulations designed to target only one of the model paraeters. Thus, with this second validity check we aim to answer the question: do the parameters of the PVL-Delta model indeed correspond to the proposed psychological processes? The outline of this article is as follows. In the first section, we explain the IGT, outline the PVL-Delta model, and review prevous efforts to compare RL models for IGT data. In the second and third section, we present the PSP study and the test of selective influence. In the last section, we summarize our findings and dicuss their ramifications",
    "chunk_id": "validating_the_pvl-delta_model_for_the_iowa_gambling_task.json_chunk_3"
  },
  {
    "document_type": "research_paper",
    "title": "Validating the PVL-Delta model for the Iowa gambling task",
    "author": "Helen Steingroever",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Steingroever-2013-Validating-the-pvl-delta-model-for-.pdf",
    "date_published": "2013-11-26",
    "keywords": "reinforcement learning, expectancy valence model, prospect valence model, test of selective influence, parameter space partitioning",
    "flag": "",
    "chunk_text": ". In the second and third section, we present the PSP study and the test of selective influence. In the last section, we summarize our findings and dicuss their ramifications. To anticipate our results, our PSP study shows that the PVL-Delta model can account for empirical choice patterns featuring a preference for the good decks or the decks with infrequent losses; however, the model fails to account for empirical choice patterns featuring a preference for the bad decks. Our test of selective influence shows that the manipulations were successful for all but one parameter. 2. THE IOWA GAMBLING TASK AND THE PVL-DELTA MODEL 2.1. THE IOWA GAMBLING TASK In this section we describe the IGT (see also Steingroever et al., 2013b, in press ). The purpose of the IGT is to measure decision-making deficits of clinical populations in an expeimental setting. In the traditional IGT, participants are intially given $2000 facsimile money and are presented with four decks of cards. Participants are instructed to choose cards in order to maximize their long-term net outcome ( Bechara et al., 1994, 1997 ). Unbeknownst to the partiipants, the task typically contains 100 trials. After each choice, participants receive feedback on the rewards and the losses (if any) associated with that card, and the running tally. The task aims to determine whether participants learn to prfer the good, safe decks over the bad, risky decks because this is the only choice pattern that maximizes the long-term net outcomes. The good, safe decks are typically labeled C and D, whereas the bad, risky decks are labeled A and B. Table 1 presents the tradtional payoff scheme as developed by Bechara et al. (1994) . This table illustrates that decks A and B yield high immediate, costant rewards, but even higher unpredictable, occasional losses: hence, the long-term net outcome is negative. Decks C and D, on the other hand, yield low immediate, constant rewards, but even lower unpredictable, occasional losses: hence, the long-term net outcome is positive",
    "chunk_id": "validating_the_pvl-delta_model_for_the_iowa_gambling_task.json_chunk_4"
  },
  {
    "document_type": "research_paper",
    "title": "Validating the PVL-Delta model for the Iowa gambling task",
    "author": "Helen Steingroever",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Steingroever-2013-Validating-the-pvl-delta-model-for-.pdf",
    "date_published": "2013-11-26",
    "keywords": "reinforcement learning, expectancy valence model, prospect valence model, test of selective influence, parameter space partitioning",
    "flag": "",
    "chunk_text": ". Decks C and D, on the other hand, yield low immediate, constant rewards, but even lower unpredictable, occasional losses: hence, the long-term net outcome is positive. In addition to the different payoff manitudes, the decks also differ in the frequency of losses: two decks yield frequent losses (decks A and C) and two decks yield infrequent losses (decks B and D). 2.2. THE PVL-DELTA MODEL In this section, we describe the PVL-Delta model in detail. The model formalizes participants’ performance on the IGT through the interaction of four model parameters that represent distinct psychological processes ( Ahn et al., 2008; Fridberg et al., 2010; Steingroever et al., in press ). The first model assumption is that after choosing a card from deck k ∈{ 1 , 2 , 3 , 4 } on trial t , participants evaluate the net outcome associated with the just-chosen card by means of a non-linear utility function from Prospect theory ( Tversky and Kahneman, 1992 )—the Prospect Utility function: u k ( t ) = X ( t ) A if X ( t ) ≥ 0 − w · | X ( t ) | A if X ( t ) < 0 . (1) Here X ( t ) represents the net outcome on trial t , that is, the sum of the experienced reward and loss (i.e., X ( t ) = W ( t ) − | L ( t ) | ). The Prospect Utility function contains the first two model parameters—the shape parameter A ∈[ 0 , 1 ] , that determines the shape of the utility function, and the loss aversion parameter w ∈[ 0 , 5 ] . As A approaches zero, the shape of the utility funtion approaches a step function. The implication of such a step function is that given a positive net outcome X ( t ) , all utilities are similar because they approach one, and given a negative net oucome X ( t ) , all utilities are also similar because they approach − w . On the other hand, as A approaches one, the subjective utility u k ( t ) increases in direct proportion to the net outcome, X ( t )",
    "chunk_id": "validating_the_pvl-delta_model_for_the_iowa_gambling_task.json_chunk_5"
  },
  {
    "document_type": "research_paper",
    "title": "Validating the PVL-Delta model for the Iowa gambling task",
    "author": "Helen Steingroever",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Steingroever-2013-Validating-the-pvl-delta-model-for-.pdf",
    "date_published": "2013-11-26",
    "keywords": "reinforcement learning, expectancy valence model, prospect valence model, test of selective influence, parameter space partitioning",
    "flag": "",
    "chunk_text": ". On the other hand, as A approaches one, the subjective utility u k ( t ) increases in direct proportion to the net outcome, X ( t ) . A value of w larger than one indicates a larger impact of negtive net outcomes than positive net outcomes on the subjective utility, whereas a value of w approaching one indicates identical impact of negative net outcomes and positive net outcomes. As w approaches zero, the model predicts that negative net outcomes will be neglected. The PVL-Delta model further assumes that, after having formed the utility of the just chosen deck through Equation 1, decision makers update their expected utility of the just chsen deck, while keeping the expected utilities of the remaining decks unchanged. This updating process is described by the Delta learning rule: Ev k ( t ) = Ev k ( t − 1 ) + a · ( u k ( t ) − Ev k ( t − 1 )). (2) The Delta learning rule states that the expected utility of the chsen deck k is adjusted upward if the experienced utility u k ( t ) is higher than expected. If the experienced utility u k ( t ) is lower than expected, the expected utility of deck k is adjusted dowward 1 . This updating process is influenced by the third model parameter—the updating parameter a ∈[ 0 , 1 ] . This parameter quantifies the memory for rewards and losses. A value of a close to zero indicates slow forgetting and weak recency effects, whereas a value of a close to one indicates rapid forgetting and strong recency effects. 1 We initialized the expectancies of each deck k to zero, Ev k ( 0 ) = 0. Table 1 | Payoff scheme of the traditional IGT as developed by Bechara et al. (1994)",
    "chunk_id": "validating_the_pvl-delta_model_for_the_iowa_gambling_task.json_chunk_6"
  },
  {
    "document_type": "research_paper",
    "title": "Validating the PVL-Delta model for the Iowa gambling task",
    "author": "Helen Steingroever",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Steingroever-2013-Validating-the-pvl-delta-model-for-.pdf",
    "date_published": "2013-11-26",
    "keywords": "reinforcement learning, expectancy valence model, prospect valence model, test of selective influence, parameter space partitioning",
    "flag": "",
    "chunk_text": ". 1 We initialized the expectancies of each deck k to zero, Ev k ( 0 ) = 0. Table 1 | Payoff scheme of the traditional IGT as developed by Bechara et al. (1994) . Deck A Deck B Deck C Deck D Bad deck with Bad deck with Good deck with Good deck with frequent losses infrequent losses frequent losses infrequent losses Reward/trial 100 100 50 50 Number of losses/10 cards 5 1 5 1 Loss/10 cards − 1250 − 1250 − 250 − 250 Net outcome/10 cards − 250 − 250 250 250 In the next step, the model assumes that the expected utilities of each deck guide participants’ choices on the next trial t + 1. This assumption is formalized by the softmax choice rule, also known as the ratio-of-strength choice rule. The PVL-Delta model uses this rule to compute the probability of choosing each deck on each trial ( Luce, 1959 ; Equation 3). This rule contains a sensitivity parameter θ that indexes the extent to which trial-by-trial choices match the expected deck utilities. Values of θ close to zero indicate random choice behavior (i.e., strong exploration), whereas large values of θ indicate choice behavior that is strongly determined by the expected utilities (i.e., strong exploitation). P [ S k ( t + 1 ) ] = e θ · Ev k ( t ) 4 j = 1 e θ · Ev j ( t ) (3) The PVL-Delta model assumes a trial-independent sensitivity parameter θ , which depends on the final model parameter: the response consistency c ∈[ 0 , 5 ] (Equation 4). Small values of c cause a random choice pattern, whereas large values of c cause a deterministic choice pattern. θ = 3 c − 1 (4) In sum, the PVL-Delta model has four parameters: (1) The shape parameter A , which determines the shape of the utility function, (2) the loss aversion parameter w , which quantifies the weight of net losses over net rewards, (3) the updating parameter a , which determines the memory for past expectancies, and (4) the response consistency parameter c , which determines the amount of exploitation vs. exploration. 2.3",
    "chunk_id": "validating_the_pvl-delta_model_for_the_iowa_gambling_task.json_chunk_7"
  },
  {
    "document_type": "research_paper",
    "title": "Validating the PVL-Delta model for the Iowa gambling task",
    "author": "Helen Steingroever",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Steingroever-2013-Validating-the-pvl-delta-model-for-.pdf",
    "date_published": "2013-11-26",
    "keywords": "reinforcement learning, expectancy valence model, prospect valence model, test of selective influence, parameter space partitioning",
    "flag": "",
    "chunk_text": ". exploration. 2.3. PREVIOUS COMPARISONS OF RL MODELS This section reviews previous model comparison studies. These studies compared the EV model, PVL model, and alternative RL models using a large variety of methods, for instance: the post hoc fit criterion (i.e., Busemeyer and Stout, 2002; Yechiam and Busemeyer, 2005; Yechiam and Ert, 2007; Ahn et al., 2008; Yechiam and Busemeyer, 2008; Fridberg et al., 2010 ), 2 the siulation method (i.e., Ahn et al., 2008; Fridberg et al., 2010; Steingroever et al., in press; Worthy et al., 2013 ), tests of genealizability (i.e., Yechiam and Busemeyer, 2005; Yechiam and Ert, 2007; Ahn et al., 2008; Yechiam and Busemeyer, 2008 ), tests of parameter consistency (i.e., Yechiam and Busemeyer, 2008 ), and PSP (i.e., Steingroever et al., 2013b ) 3 . The above model comparison studies revealed many positive properties of RL models: first, RL models predict the choices on the next trial better than a Bernoulli baseline model ( Busemeyer and Stout, 2002; Yechiam and Busemeyer, 2005; Yechiam and Ert, 2007; Ahn et al., 2008; Yechiam and Busemeyer, 2008, 2 The post hoc fit criterion is also known as the one-step-ahead prediction method. 3 Note that the PSP study of Steingroever et al. (2013b) did not focus on the PVL-Delta model, but on the EV model, the PVL model, and another hybrid model: the EV model with the Prospect Utility function. Fridberg et al., 2010 ) 4 . Second, parameters from the RL models estimated from one RL task can be used to predict performance on a different RL task ( Yechiam and Busemeyer, 2005; Yechiam and Ert, 2007; Ahn et al., 2008; Yechiam and Busemeyer, 2008 ). Third, the loss aversion parameter and the updating parameter of the EV model are stable across different tasks ( Yechiam and Busemeyer, 2008 ). Fourth, the estimated model parameters can be used to improve the prediction of group membership (i.e., chronic cannabis users vs. healthy controls; Fridberg et al., 2010 )",
    "chunk_id": "validating_the_pvl-delta_model_for_the_iowa_gambling_task.json_chunk_8"
  },
  {
    "document_type": "research_paper",
    "title": "Validating the PVL-Delta model for the Iowa gambling task",
    "author": "Helen Steingroever",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Steingroever-2013-Validating-the-pvl-delta-model-for-.pdf",
    "date_published": "2013-11-26",
    "keywords": "reinforcement learning, expectancy valence model, prospect valence model, test of selective influence, parameter space partitioning",
    "flag": "",
    "chunk_text": ". Fourth, the estimated model parameters can be used to improve the prediction of group membership (i.e., chronic cannabis users vs. healthy controls; Fridberg et al., 2010 ). These positive properties confirm that cognitive modeling analyses are indeed useful to learn more about the psychological processes that drive performance on the IGT. However, previous model comparison studies also revealed that, even though the EV and PVL models are frequently used, they fail to outperform their competitors consistently. It appears that the performance of the RL models depends on the data set and the method used to assess model performance (i.e., fit performance vs. simulation performance; see Steingroever et al., in press , for a more detailed discussion on previous comparisons of RL models). Instead of accepting the EV and PVL models as default models to describe IGT data, there is growing evidence that the PVDelta model may be a promising alternative IGT model: first, Ahn et al. (2008) showed that the PVL-Delta model results in the best simulation performance (i.e., prediction of the entire sequence of choices on the IGT under a new, unobserved payoff sequence) among the EV model, PVL model, and any combination of the components of the two models. Second, Fridberg et al. (2010) showed that, in two data sets, the PVL-Delta model outperforms the EV model in terms of post hoc fit and simulation performance. Third, Steingroever et al. (in press) showed that, among the EV, PVL, and PVL-Delta models, the PVL-Delta model is the only model that adequately generated the choice patterns shown by seven IGT data sets. Even though the PVL-Delta model has recently come to the fore as a promising model for IGT data, it has not yet been suficiently validated. Our goal here is to pursue two methods of validating the PVL-Delta model: a PSP study and a test of selective influence. 3. PARAMETER SPACE PARTITIONING 3.1",
    "chunk_id": "validating_the_pvl-delta_model_for_the_iowa_gambling_task.json_chunk_9"
  },
  {
    "document_type": "research_paper",
    "title": "Validating the PVL-Delta model for the Iowa gambling task",
    "author": "Helen Steingroever",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Steingroever-2013-Validating-the-pvl-delta-model-for-.pdf",
    "date_published": "2013-11-26",
    "keywords": "reinforcement learning, expectancy valence model, prospect valence model, test of selective influence, parameter space partitioning",
    "flag": "",
    "chunk_text": ". Our goal here is to pursue two methods of validating the PVL-Delta model: a PSP study and a test of selective influence. 3. PARAMETER SPACE PARTITIONING 3.1. METHODS We performed a PSP study to evaluate the flexibility of the PVDelta model ( Pitt et al., 2006 , Pitt et al., 2008 ; see also Steingroever et al., 2013b , who performed a PSP study of the EV model, PVL model, and another hybrid model: the EV model with Prospect Utility function). The PSP method systematically assesses the choice patterns predicted by the PVL-Delta model across its entire parameter space. A model is overly flexible when it can geneate not only all choice patterns that are observed empirically, but also choice patterns that are logically possible, but never observed. Instead, one should prefer a less flexible, parsimonious model that—ideally—only generates choice patterns that are also frequently observed in experiments ( Pitt et al., 2006, 2008 ). 4 The Bernoulli baseline model assumes that a participant’s probability of choosing a given deck on a given trial equals the overall proportion of choices the participant actually made from that deck. Note that PSP is a global method (i.e., the full range of paraeter values is considered), whereas the other methods that were used to compare RL models are local (i.e., assessment at a partiular point in the model’s parameter space; for instance, post hoc fit criterion, simulation method, tests of generalizability, and tests of parameter consistency). The advantage of global methods is that they enable one to assess the full range of choice patterns a model can generate, whereas the results of local methods always depend on the idiosyncrasies of any single data set ( Pitt et al., 2006, 2008 ). Pitt et al. (2006) describe a new search algorithm to implement PSP",
    "chunk_id": "validating_the_pvl-delta_model_for_the_iowa_gambling_task.json_chunk_10"
  },
  {
    "document_type": "research_paper",
    "title": "Validating the PVL-Delta model for the Iowa gambling task",
    "author": "Helen Steingroever",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Steingroever-2013-Validating-the-pvl-delta-model-for-.pdf",
    "date_published": "2013-11-26",
    "keywords": "reinforcement learning, expectancy valence model, prospect valence model, test of selective influence, parameter space partitioning",
    "flag": "",
    "chunk_text": ". Pitt et al. (2006) describe a new search algorithm to implement PSP. In our implementation we did not use their sophisticated search algorithm, but followed the conceptual idea of PSP, and used a grid search that works as follows (see also Steingroever et al., 2013b ): for each parameter of the PVL-Delta model, we chose 60 values that were equally spaced over the corresponding parameter range. Each combination of these parameter values was used to generate data for 100 synthetic participants completing a 100-trial IGT. For all analyses in this paper, we scaled the tradtional payoffs of the IGT as presented in Table 1 by dividing by 100 (cf. Ahn et al., 2011 ). The generated data were used to analyze which choice patterns the PVL-Delta model can generate across its entire parameter space. Such analysis naturally requires a definition of choice patterns. Here we used two different definitions—the “broad deinition of choice patterns” and the “restricted definition of choice patterns.” These definitions are the same as used by Steingroever et al. (2013b) . 3.1.1. Broad definition of choice patterns The “broad definition of choice patterns” is intended to provide a general idea of which choice patterns the PVL-Delta model can generate. Following Steingroever et al. (2013b) , we defined five possible choice patterns: (1) Preference for the good decks over bad decks (i.e., { C , D } ≻{ A , B }), (2) preference for the bad decks over good decks (i.e., { A , B } ≻{ C , D } ), (3) preference for the decks with infrequent losses over decks with frequent losses (i.e., { B , D } ≻{ A , C }), (4) preference for the decks with frequent losses over decks with infrequent losses (i.e., { A , C } ≻{ B , D } ), and (5) remaining choice patterns. For each parameter combnation, we computed the proportion of choices from each deck averaged across all 100 trials and all 100 repeated data generations",
    "chunk_id": "validating_the_pvl-delta_model_for_the_iowa_gambling_task.json_chunk_11"
  },
  {
    "document_type": "research_paper",
    "title": "Validating the PVL-Delta model for the Iowa gambling task",
    "author": "Helen Steingroever",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Steingroever-2013-Validating-the-pvl-delta-model-for-.pdf",
    "date_published": "2013-11-26",
    "keywords": "reinforcement learning, expectancy valence model, prospect valence model, test of selective influence, parameter space partitioning",
    "flag": "",
    "chunk_text": ". For each parameter combnation, we computed the proportion of choices from each deck averaged across all 100 trials and all 100 repeated data generations. These average choice proportions were then sorted to determine the generated rank order of deck preferences for each parameter combination. Finally, we computed the proportion of the entire parameter space occupied by each of the defined choice patterns. Even though we defined five possible types of choice patterns, we assume based on the theory underlying the IGT ( Bechara et al., 1994, 1997 ) and our IGT review ( Steingroever et al., 2013a ) that a good model for IGT data should only generate the first three types of choice patterns. 3.1.2. Restricted definition of choice patterns Note that the broad definition of choice patterns only consiers the rank order of the overall proportions of choices from each deck averaged over 100 repeated data generations with the same parameter combination. This means that it does not matter whether the PVL-Delta model generated, for example, a very strong or a very weak preference for the good decks over the bad decks. Both generated choice patterns are classified as the choice pattern “good decks over bad decks” (i.e., { C , D } ≻ { A , B }). To go beyond this coarse classification, we also analyzed the model’s behavior when confronted with pronounced deck preferences. To get an indication of pronounced deck preferences shown by healthy participants on the IGT, we used Steingroever et al. (2013b) ’s definition of pronounced deck preferences: speciically, Steingroever et al. (2013b) searched their IGT data pool ( N = 394; Steingroever et al., 2013a ) for healthy participants that chose at least 65% cards from either the good decks (i.e., ( C + D ) ≥ 0 . 65), the bad decks (i.e., ( A + B ) ≥ 0 . 65), or the decks with infrequent losses (i.e., ( B + D ) ≥ 0 . 65). By using the 0.65-criterion, Steingroever et al",
    "chunk_id": "validating_the_pvl-delta_model_for_the_iowa_gambling_task.json_chunk_12"
  },
  {
    "document_type": "research_paper",
    "title": "Validating the PVL-Delta model for the Iowa gambling task",
    "author": "Helen Steingroever",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Steingroever-2013-Validating-the-pvl-delta-model-for-.pdf",
    "date_published": "2013-11-26",
    "keywords": "reinforcement learning, expectancy valence model, prospect valence model, test of selective influence, parameter space partitioning",
    "flag": "",
    "chunk_text": ". 65), the bad decks (i.e., ( A + B ) ≥ 0 . 65), or the decks with infrequent losses (i.e., ( B + D ) ≥ 0 . 65). By using the 0.65-criterion, Steingroever et al. (2013b) included healthy paticipants with pronounced deck preferences and excluded healthy participants with random choice behaviors. For each of these three groups, Steingroever et al. (2013b) computed the mean prportions of choices from each deck (as shown in Table 2 ). For instance, participants classified to the group “pronounced preerence for the good decks” chose on average 36 cards from deck C and 40 cards from deck D. Note that 53.6% of all participants in the Steingroever et al. (2013a) data pool showed a pronounced deck preference by making at least 65% choices from the two most Table 2 | Mean proportions of choices from each deck and mean proportions of switches during the last 50 trials of healthy participants showing a pronounced deck preference [see Table 4 in Steingroever et al. (2013b) ]. Choice pattern N Deck A Deck B Deck C Deck D Switches during [sd] [sd] [sd] [sd] the last 50 trials [25%, 75% quantile] (min, max) ( C + D ) ≥ 0 . 65 54 0.10 [0.05] 0.14 [0.05] 0.36 [0.17] 0.40 [0.14] 0.35 [0.08, 0.52] (0.00, 0.96) ( A + B ) ≥ 0 . 65 18 0.25 [0.07] 0.52 [0.11] 0.11 [0.05] 0.12 [0.06] 0.43 [0.31, 0.58] (0.10, 0.86) ( B + D ) ≥ 0 . 65 139 0.12 [0.05] 0.37 [0.12] 0.13 [0.05] 0.39 [0.12] 0.47 [0.28, 0.66] (0.02, 1.00) Healthy participants are selected from the Steingroever et al. (2013a) data pool (N = 394). preferred decks. This empirical popularity of pronounced deck preferences underscores how important it is that a RL model for the IGT is able to produce such choice patterns. Table 2 thus provides an indication of pronounced deck preerences shown by healthy participants on the IGT. We used the mean proportion of choices from these three constructed groups for our second, restricted definition of choice patterns",
    "chunk_id": "validating_the_pvl-delta_model_for_the_iowa_gambling_task.json_chunk_13"
  },
  {
    "document_type": "research_paper",
    "title": "Validating the PVL-Delta model for the Iowa gambling task",
    "author": "Helen Steingroever",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Steingroever-2013-Validating-the-pvl-delta-model-for-.pdf",
    "date_published": "2013-11-26",
    "keywords": "reinforcement learning, expectancy valence model, prospect valence model, test of selective influence, parameter space partitioning",
    "flag": "",
    "chunk_text": ". We used the mean proportion of choices from these three constructed groups for our second, restricted definition of choice patterns. Specifically, we define a pronounced preference for the good decks as at least 36 and 40 choices from decks C and D, respetively; we define a pronounced preference for the bad decks as at least 25 and 52 choices from decks A and B, respectively; and we define a pronounced preference for the decks with infrquent losses as at least 37 and 39 choices from decks B and D, respectively. Based on our simulations, we then determined the proportion of the parameter space of the PVL-Delta model that produced choice patterns that satisfy this second, restricted definition. 3.1.3. Switch behavior Finally, a good RL model for the IGT should also capture the switches participants make on the IGT ( Zhao and Costello, 2007 ). Steingroever et al. (2013b) therefore determined the mean prportion of switches during the last 50 trials for the three groups of healthy participants showing pronounced decks preferences (revisited here in the last column of Table 2 ). The table cotains for each of the three groups of healthy participants with pronounced choice patterns the mean proportion of switches during the last 50 trials and statistics quantifying the distribtion of switch proportions (i.e., the interquartile range and the minimum and maximum switch proportions during the last 50 trials). This information is visualized by the boxplots shown in the left column of Figure 1 . From Table 2 and Figure 1 it is evident that, in general, in all three groups participants switch frequently. However, the interquartile ranges and the minimum and maxmum proportion of switches during the last 50 trials also indicate that there is large variability in the proportion of switches, such that the switch behavior of healthy participants varies between no switches at all to switches on every trial",
    "chunk_id": "validating_the_pvl-delta_model_for_the_iowa_gambling_task.json_chunk_14"
  },
  {
    "document_type": "research_paper",
    "title": "Validating the PVL-Delta model for the Iowa gambling task",
    "author": "Helen Steingroever",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Steingroever-2013-Validating-the-pvl-delta-model-for-.pdf",
    "date_published": "2013-11-26",
    "keywords": "reinforcement learning, expectancy valence model, prospect valence model, test of selective influence, parameter space partitioning",
    "flag": "",
    "chunk_text": ". This tendency to switch frequently, but also the large individual differences in the switch behavior of healthy participants are illustrated by Figures 2 , 4 , 6 (see also Figures 3, 7, 10 in Steingroever et al., 2013b ) which show the trial-by-trial choices (i.e., deck selection profiles) of representative healthy participants with a pronounced preference for the good decks, bad decks, and decks with infrequent losses, respectively 5 . We investigated whether the PVL-Delta model captures the empirical switch behavior by comparing the empirical and geerated mean proportions of switches during the last 50 trials. Specifically, the generated mean proportions of switches were obtained by determining the mean proportions of switches duing the last 50 trials for all parameter combinations that produced pronounced deck preferences. The code for the PSP study is available on www . helensteingroever . com. 5 See Steingroever et al. (2013b) for the deck selection profiles of all healthy participants that showed a pronounced deck preference (i.e., at least 65% choices from the two most preferred decks). FIGURE 1 | Boxplots of observed and generated proportions of switches during the last 50 trials, given a pronounced deck preference. Each row presents the results for different pronounced choice patterns: First row: Pronounced preference for the good decks; Second row: Pronounced preference for the bad decks; Third row: Pronounced preference for the decks with infrequent losses. The first column presents the switches of 211 healthy participants selected from the Steingroever et al. (2013a) data pool (cf. Table 2 ). The second column presents the switches generated by the PVL-Delta model (cf. Table 4 ). 3.2. RESULTS 3.2.1. Broad definition of choice patterns Table 3 presents the proportion of the parameter space of the PVL-Delta model occupied by each of the five different types of choice patterns. From this table, it is evident that the PVDelta model can generate all five different types of choice patterns",
    "chunk_id": "validating_the_pvl-delta_model_for_the_iowa_gambling_task.json_chunk_15"
  },
  {
    "document_type": "research_paper",
    "title": "Validating the PVL-Delta model for the Iowa gambling task",
    "author": "Helen Steingroever",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Steingroever-2013-Validating-the-pvl-delta-model-for-.pdf",
    "date_published": "2013-11-26",
    "keywords": "reinforcement learning, expectancy valence model, prospect valence model, test of selective influence, parameter space partitioning",
    "flag": "",
    "chunk_text": ". From this table, it is evident that the PVDelta model can generate all five different types of choice patterns. However, if we consider its partitioned parameter space more closely, we detect substantial differences between the populaity of the different choice patterns: the choice pattern “good decks over bad decks” is the most central to the model’s oveall performance, as this choice pattern occupies the largest part of the model’s parameter space. The second and third largest part of its parameter space are occupied by the choice patterns “remaining” and “infrequent losses over frequent losses.” It is thus evident that choice patterns that are typically shown by healthy participants—the choice patterns “good decks over bad decks” and “infrequent losses over frequent losses” ( Steingroever FIGURE 2 | Deck selection profiles of four healthy participants showing a pronounced preference for the good decks. The filled dots indicate the occurrence of rewards and losses together; the empty dots indicate the occurrence of only rewards. Table 3 | Proportions of choice patterns generated by the PVL-Delta model. Choice pattern Proportion of all choice patterns Good ≻ bad decks { C , D } ≻{ A , B } 0.596 Bad ≻ good decks { A , B } ≻{ C , D } 0.006 Infr. ≻ frequent losses { B , D } ≻{ A , C } 0.118 Frequent ≻ infr. losses { A , C } ≻{ B , D } 0.005 Remaining 0.274 et al., 2013a )—occupy a major part of the model’s parameter space. Table 3 also shows that the choice pattern “bad decks over good decks” is only generated over a minor part of the model’s parameter space. We have therefore grounds to conclude that this choice pattern is uncharacteristic of the PVL-Delta model, and is thus almost irrelevant to its overall performance ( Pitt et al., 2006 ). This finding is important because the choice pattern “bad decks over good decks” is considered characteristic for particpants with decision-making deficits (e.g., patients with lesions to the ventromedial prefrontal cortex; Bechara et al., 1994, 1997 )",
    "chunk_id": "validating_the_pvl-delta_model_for_the_iowa_gambling_task.json_chunk_16"
  },
  {
    "document_type": "research_paper",
    "title": "Validating the PVL-Delta model for the Iowa gambling task",
    "author": "Helen Steingroever",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Steingroever-2013-Validating-the-pvl-delta-model-for-.pdf",
    "date_published": "2013-11-26",
    "keywords": "reinforcement learning, expectancy valence model, prospect valence model, test of selective influence, parameter space partitioning",
    "flag": "",
    "chunk_text": ". These patients are thought to display decision-making deficits on the IGT because their inability to foresee the long-term consquences of their choice behavior leads them to only focus on the immediate rewards. 3.2.2. Restricted definition of choice patterns Table 4 presents the proportion of all choice patterns generated by the PVL-Delta model that satisfy the restricted definition of choice patterns. The table also presents the mean and standard FIGURE 3 | Deck selection profiles of four synthetic participants showing a pronounced preference for the good decks (generated by the PVL-Delta model; A = 0 . 88 , w = 0 . 68 , a = 0 . 25 , c = 1 . 27). deviation of the parameter combinations that generated these pronounced deck preferences. The table shows that only minor parts of the parameter space of the PVL-Delta model are occpied by the three types of pronounced choice patterns, even though these patterns are frequently observed in experiments. For instance, 139 healthy participants from the Steingroever et al. (2013a) data pool (35.3%) show a pronounced preference for the decks with infrequent losses (i.e., ( B + D ) ≥ 0 . 65). However, the PVL-Delta model only generates this choice pattern over 1.6% of its parameter space. 3.2.3. Switch behavior In addition to the generated choice proportions, we also detemined the generated proportion of switches during the last 50 trials for all parameter combination that satisfy the restricted defnition of choice patterns (Columns 2 − 6 of Table 4 ). We averaged these generated switch proportions separately for each of the three types of pronounced deck preferences (last column of Table 4 ). The table also contains statistics quantifying the distribution of the generated switch proportions, that is, the interquartile range and the minimum and maximum proportion of switches duing the last 50 trials. This information is visualized by the right column of Figure 1",
    "chunk_id": "validating_the_pvl-delta_model_for_the_iowa_gambling_task.json_chunk_17"
  },
  {
    "document_type": "research_paper",
    "title": "Validating the PVL-Delta model for the Iowa gambling task",
    "author": "Helen Steingroever",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Steingroever-2013-Validating-the-pvl-delta-model-for-.pdf",
    "date_published": "2013-11-26",
    "keywords": "reinforcement learning, expectancy valence model, prospect valence model, test of selective influence, parameter space partitioning",
    "flag": "",
    "chunk_text": ". This information is visualized by the right column of Figure 1 . When comparing the generated and observed mean propotion of switches during the last 50 trials given pronounced deck preferences, it is apparent that the PVL-Delta model underetimates the observed switch proportions, that is, the generated mean proportion of switches equals or falls below 0.07 for all geerated pronounced choice patterns, whereas the observed mean proportion of switches equals or exceeds 0.35 for all observed pronounced choice patterns ( Tables 2 , 4 ). In addition, for all three types of pronounced choice patterns, the interquartile range of the observed proportion of switches exceeds the interquartile range of the model-generated proportion of switches ( Figure 1 , Table 4 | Proportion of choice patterns generated by the PVL-Delta model that satisfy the restricted definition of choice patterns. Choice pattern Proportion A [sd] w [sd] a [sd] c [sd] Switches during of all choice the last 50 trials patterns [25%, 75% quantile] (min, max) C ≥ 0 . 36 , D ≥ 0 . 40 0.0084 0.66 [0.21] 0.62 [0.38] 0.30 [0.21] 3.49 [0.98] 0.0571 [0.0014, 0.0558] (0.00, 0.5724) A ≥ 0 . 25 , B ≥ 0 . 52 0.0000028 0.92 [0.09] 0.02 [0.03] 0.06 [0.03] 3.07 [0.40] 0.0043 [0.0003, 0.0055] (0.00, 0.0210) B ≥ 0 . 37 , D ≥ 0 . 39 0.0162 0.27 [0.24] 0.34 [0.39] 0.43 [0.27] 2.80 [0.88] 0.0705 [0.0034, 0.0918] (0.00, 0.6450) Note that this definition is only based on the mean proportion of choices of the two strongest preferred decks (first column). For the selected choice patterns, the corresponding mean and standard deviation of the model parameters, and the mean proportion of switches during the last 50 trials are presented. FIGURE 4 | Deck selection profiles of four healthy participants showing a pronounced preference for the bad decks. Tables 2 , 4 )",
    "chunk_id": "validating_the_pvl-delta_model_for_the_iowa_gambling_task.json_chunk_18"
  },
  {
    "document_type": "research_paper",
    "title": "Validating the PVL-Delta model for the Iowa gambling task",
    "author": "Helen Steingroever",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Steingroever-2013-Validating-the-pvl-delta-model-for-.pdf",
    "date_published": "2013-11-26",
    "keywords": "reinforcement learning, expectancy valence model, prospect valence model, test of selective influence, parameter space partitioning",
    "flag": "",
    "chunk_text": ". FIGURE 4 | Deck selection profiles of four healthy participants showing a pronounced preference for the bad decks. Tables 2 , 4 ). However, the largest generated switch proportion given a pronounced preference for the good decks and the decks with infrequent losses, respectively, lie within the corresponing interquartile ranges of the observed switch proportions. This suggests that for a few parameter combinations, the PVL-Delta model meets both empirical regularities—pronounced deck preerences and a tendency to switch frequently. To illustrate the differences and commonalities between the data and the predictions, we plot in Figures 2 – 7 observed and generated deck selection profiles. Figures 2 , 4 , 6 show the deck selection profiles of representative healthy participants with a prnounced preference for the good decks, bad decks, and decks with infrequent losses, respectively. Figures 3 , 5 , 7 show the deck selection profiles that were generated with those parameter FIGURE 5 | Deck selection profiles of four synthetic participants showing a pronounced preference for the bad decks (generated by the PVL-Delta model; A = 1 . 00 , w = 0 . 08 , a = 0 . 05 , c = 2 . 71). combinations that resulted in a pronounced preference for the good decks, bad decks, and decks with infrequent losses, respetively, and the maximum number of switches during the last 50 trials. From the figures it is evident that there are large discrepancies between the observed and generated deck seletion profiles in the case of the pronounced preference for the bad decks: The PVL-Delta model generates a few switches in the beginning of the IGT and then exploitation of a single deck, even though healthy participants keep switching across the entire IGT. However, the observed and generated deck seletion profiles look very similar in the case of the pronounced preference for the good decks and the decks with infrequent losses",
    "chunk_id": "validating_the_pvl-delta_model_for_the_iowa_gambling_task.json_chunk_19"
  },
  {
    "document_type": "research_paper",
    "title": "Validating the PVL-Delta model for the Iowa gambling task",
    "author": "Helen Steingroever",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Steingroever-2013-Validating-the-pvl-delta-model-for-.pdf",
    "date_published": "2013-11-26",
    "keywords": "reinforcement learning, expectancy valence model, prospect valence model, test of selective influence, parameter space partitioning",
    "flag": "",
    "chunk_text": ". However, the observed and generated deck seletion profiles look very similar in the case of the pronounced preference for the good decks and the decks with infrequent losses. FIGURE 6 | Deck selection profiles of four healthy participants showing a pronounced preference for the decks with infrequent losses. To conclude, many healthy participants from the Steingroever et al. (2013a) data pool (53.6%) showed pronounced deck preerences, that is, a pronounced preference for the good decks ( ( C + D ) ≥ 0 . 65), a pronounced preference for the bad decks ( ( A + B ) ≥ 0 . 65), or a pronounced preference for the decks with infrequent losses ( ( B + D ) ≥ 0 . 65) ( Table 2 ). This empiical popularity of pronounced deck preferences is only partly reflected by the PVL-Delta model; the model produces choice patterns that satisfy the restricted definition of choice patterns only within minor parts of its parameter space ( Table 4 ). In addtion, healthy participants in general show many switches during the last 50 trials. However, the PVL-Delta model in general prdicts that participants who show pronounced deck preferences switch rarely during the last 50 trials; all generated mean prportion of switches during the last 50 trials equal or fall below 0.07 whereas the observed mean proportions of switches lie around 0.40. But compared to the popular EV and PVL moels ( Steingroever et al., 2013b ), the PVL-Delta model performs better: the PVL-Delta model generates higher mean proportions of switches than its two competitors for almost all pronounced choice patterns; the only exception is that the EV model geneates a higher mean proportion of switches for the choice pattern featuring a pronounced preference for the bad decks than the PVL-Delta model. Moreover, healthy participants show large individual differences in the proportion of switches during the last 50 trials, such that their switch behavior varies between no switches at all to switches on every trial",
    "chunk_id": "validating_the_pvl-delta_model_for_the_iowa_gambling_task.json_chunk_20"
  },
  {
    "document_type": "research_paper",
    "title": "Validating the PVL-Delta model for the Iowa gambling task",
    "author": "Helen Steingroever",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Steingroever-2013-Validating-the-pvl-delta-model-for-.pdf",
    "date_published": "2013-11-26",
    "keywords": "reinforcement learning, expectancy valence model, prospect valence model, test of selective influence, parameter space partitioning",
    "flag": "",
    "chunk_text": ". However, the PVL-Delta model tends to generate very few switches, given pronounced deck preferences, and fails to generate large proportion of switches (i.e., switch proportions higher than 0.65). But compared to the popular EV and PVL models ( Steingroever et al., 2013b ), the PVL-Delta model again performs better because the EV and PVL FIGURE 7 | Deck selection profiles of four synthetic participants showing a pronounced preference for the decks with infrequent losses (generated by the PVL-Delta model; A = 0 . 00, w = 0 . 00, a = 0 . 42, c = 1 . 19). model’s failure to generate large proportions of switches, given a pronounced choice pattern, is even stronger: Given a pronounced choice pattern, the EV and PVL models fail to generate switch proportions higher than 0.35 and 0.46, respectively. Despite these discrepancies between the empirical and the generated switch behavior, we showed that—given a pronounced preference for the good decks or the decks with infrequent losses and those parameter combinations that yielded the maximum number of switches during the last 50 trials—the PVL-Delta model can produce choice patterns that strongly resemble the empirical choice patterns of healthy participants. 4. TEST OF SELECTIVE INFLUENCE In this section we investigate whether the parameters of the PVL-Delta model indeed correspond to distinct psychological processes. We will therefore carry out a test of selective inflence for the PVL-Delta model. This means that we fit the model to data collected from the standard IGT, but also from condtions that were designed to affect selectively one of the model parameters. These data were collected by Wetzels et al. (2010) , and their experiment was originally designed as a test of selective influence for the EV model. However, the experimental maniulations that were intended to affect the parameters of the EV model should also be reflected by the parameters of the PVDelta model because of the high similarity between the two models. 4.1",
    "chunk_id": "validating_the_pvl-delta_model_for_the_iowa_gambling_task.json_chunk_21"
  },
  {
    "document_type": "research_paper",
    "title": "Validating the PVL-Delta model for the Iowa gambling task",
    "author": "Helen Steingroever",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Steingroever-2013-Validating-the-pvl-delta-model-for-.pdf",
    "date_published": "2013-11-26",
    "keywords": "reinforcement learning, expectancy valence model, prospect valence model, test of selective influence, parameter space partitioning",
    "flag": "",
    "chunk_text": ". 4.1. METHODS We fit the PVL-Delta model separately to four data sets reported by Wetzels et al. (2010) . Specifically, Wetzels et al. (2010) coducted an experiment with a standard condition and three addtional conditions that were designed to affect selectively one of the model parameters: 6 In the “standard condition”, 19 participants completed a 150-trial IGT under the standard administration. In the “rewards condition”, 20 participants completed a 150-trial IGT under the instruction to pay more attention to rewards and to consider losses as less important. We expected this manipulation to decrease the loss aversion parameter w . In the “updating condition”, 19 participants completed a 150- trial IGT under the standard administration. However, each choice was followed by a on-screen presentation of five nubers that the participants had to remember because, after the next choice, participants were asked about the relative position of one of the numbers. We expected this manipulation to increase the updating parameter a . In the “consistency condition”, 16 participants completed a 150-trial IGT under the standard administration. However, they were told that after every 10 trials the payoff schemes for the decks could have changed. We expected this manipulation to decrease the consistency parameter c . To fit the PVL-Delta model, we used a Bayesian hierarchical approach detailed in the next section. This estimation procdure has been consistently shown to outperform alternatives such as maximum likelihood estimation and Bayesian individual estimation ( Ahn et al., 2011; Wetzels et al., 2010 ). To assess whether the chains of all parameters had converged successfully from their starting values to their stationary distribtions, we visually inspected the Hamiltonian Monte Carlo (HMC) chains and used the ˆ R statistic ( Gelman and Rubin, 1992 ). The ˆ R statistic is a formal diagnostic measure of convergence that compares the between-chain variability to the within-chain varability. Values close to 1",
    "chunk_id": "validating_the_pvl-delta_model_for_the_iowa_gambling_task.json_chunk_22"
  },
  {
    "document_type": "research_paper",
    "title": "Validating the PVL-Delta model for the Iowa gambling task",
    "author": "Helen Steingroever",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Steingroever-2013-Validating-the-pvl-delta-model-for-.pdf",
    "date_published": "2013-11-26",
    "keywords": "reinforcement learning, expectancy valence model, prospect valence model, test of selective influence, parameter space partitioning",
    "flag": "",
    "chunk_text": ". The ˆ R statistic is a formal diagnostic measure of convergence that compares the between-chain variability to the within-chain varability. Values close to 1 . 0 indicate convergence to the stationary distribution, whereas values greater than 1 . 1 indicate inadequate convergence. To assess model performance in absolute terms, we used two different methods: the post hoc absolute fit method and the siulation method (see also Steingroever et al., in press ). These two methods allow us to assess the model’s ability to fit and generate the choice patterns present in each of the four condtions. Our implementation of both methods relies on visually contrasting—separately for each deck as a function of 15 bins each containing 10 trials—the observed mean choice proportions from the experiment against the mean choice probabilities from the model. Both methods start by sampling parameter values from the joint posterior distributions over the individual-level parameters (hereafter individual-level joint posteriors). In the case of the post hoc absolute fit method, the model is provided with the sampled parameter values, but also with the actual choices and payoffs of each participant. The post hoc absolute fit method computes the probability of choosing each deck on the next trial based on the information on the observed choices and payoffs up to 6 Note that we use the data sets that Wetzels et al. (2010) obtained after having eliminated two sources of contamination. Specifically, Wetzels et al. (2010) removed participants for whom one or more of the maximum likelihood point estimates were located on the boundary of the parameter space, and participants for whom the Bernoulli baseline model outperformed the EV model. and including the current trial. The simulation method, on the other hand, is only provided with the sampled parameter values, and relies on generating choices for another sequence of paoffs that could have been observed 7",
    "chunk_id": "validating_the_pvl-delta_model_for_the_iowa_gambling_task.json_chunk_23"
  },
  {
    "document_type": "research_paper",
    "title": "Validating the PVL-Delta model for the Iowa gambling task",
    "author": "Helen Steingroever",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Steingroever-2013-Validating-the-pvl-delta-model-for-.pdf",
    "date_published": "2013-11-26",
    "keywords": "reinforcement learning, expectancy valence model, prospect valence model, test of selective influence, parameter space partitioning",
    "flag": "",
    "chunk_text": ". The simulation method, on the other hand, is only provided with the sampled parameter values, and relies on generating choices for another sequence of paoffs that could have been observed 7 . In particular, on each trial, the simulation method generates a choice based on the predicted choice probabilities. For both methods and for each participant, we repeated the process of obtaining the predicted choice proabilities 100 times to account for uncertainty in the individualevel joint posteriors (for detailed recipes see Steingroever et al., in press ) 8 . To investigate the effect of the experimental manipulations, we visually compared the posterior distributions of the group-level parameters of all four conditions. 4.1.1. Bayesian hierarchical estimation procedure To fit the PVL-Delta model to the data of the four experimental conditions, we used a Bayesian hierarchical estimation procedure (see Wetzels et al. (2010) for the same model specification in the case of the EV model). The Bayesian graphical PVL-Delta model for a hierarchical analysis is shown in Figure 8 . This figure shows that the graphical model consists of two plates: The inner plate expresses the replications of the choices on t = 1 , , T trals of the IGT, and the outer plate expresses the replications for i = 1 , , N participants. For the sake of clarity, we omitted the notation that indexes the deck number k . The quantities W i , t (rewards of participant i on trial t ), L i , t (losses of participant i on trial t ), and Ch i , t + 1 (choice of participant i on trial t + 1) can directly be obtained from the data. The quantities u i , t , Ev i , t + 1 , and θ i are deterministic because they can be calculated from Equations 1, 2, and 4. All individual-level parameters z i , that is, { A i , w i , a i , c i } , are also deterministic because instead of modeling the individual-level parameters directly, we modeled their respetive probit transformations z ′ i , that is, { A ′ i , w ′ i , a ′ i , c ′ i }",
    "chunk_id": "validating_the_pvl-delta_model_for_the_iowa_gambling_task.json_chunk_24"
  },
  {
    "document_type": "research_paper",
    "title": "Validating the PVL-Delta model for the Iowa gambling task",
    "author": "Helen Steingroever",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Steingroever-2013-Validating-the-pvl-delta-model-for-.pdf",
    "date_published": "2013-11-26",
    "keywords": "reinforcement learning, expectancy valence model, prospect valence model, test of selective influence, parameter space partitioning",
    "flag": "",
    "chunk_text": ". This means that the parameters z ′ i lie on the probit scale covering the entire real line. The probit transformation is the inverse of the cumultive standard normal distribution function. The parameters z ′ i are assumed to be drawn from group-level normal distributions with mean μ z ′ and standard deviation σ z ′ . Only after the analysis was complete, we transformed the parameters μ z ′ and z ′ i back to the original scale. The model specification requires a definition of priors for the group-level means and standard deviations. We assigned a nomal prior to the group-level means, μ z ′ ∼ N ( 0 , 1 ) , and a uniform prior to the group-level standard deviations, σ z ′ ∼ U ( 0 , 1 . 5 ) . We implemented the PVL-Delta model in Stan ( Hoffman and Gelman, 2011; Stan Development Team, 2013a,b ). The code to fit the PVL-Delta model in Stan is available on http:// www . helensteingroever . com. To confirm that we correctly implmented the PVL-Delta model, we ran several parameter-recovery 7 Note that we used the same payoff schedule as in the corresponding experiment. 8 For completeness, we also produced predicted choices based on the joint poterior of the group-level parameters (hereafter group-level joint posterior); that is, we generated data with 1000 parameter values that were randomly drawn from the group-level joint posterior. There are slight differences between the two types of posterior predictives, but the general conclusions are the same (see Appendix for further details). FIGURE 8 | Bayesian graphical PVL-Delta model for a hierarchical analysis. () is the cumulative standard normal distribution function. studies. The results of two such studies are presented in the Appendix. For each parameter, we ran three HMC chains simultanously. The fitting procedure consisted of two steps: First, we initialized all chains with randomly generated starting values. We collected 1000 samples of each chain after having discarded the first 9000 samples of each chain as burn-in",
    "chunk_id": "validating_the_pvl-delta_model_for_the_iowa_gambling_task.json_chunk_25"
  },
  {
    "document_type": "research_paper",
    "title": "Validating the PVL-Delta model for the Iowa gambling task",
    "author": "Helen Steingroever",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Steingroever-2013-Validating-the-pvl-delta-model-for-.pdf",
    "date_published": "2013-11-26",
    "keywords": "reinforcement learning, expectancy valence model, prospect valence model, test of selective influence, parameter space partitioning",
    "flag": "",
    "chunk_text": ". We collected 1000 samples of each chain after having discarded the first 9000 samples of each chain as burn-in. However, this procedure did not result in successful convergence of the HMC chains of all parameters: for instance, for some parameters, two chains may appear to have converged to their stationary distributions and looked like “hairy caterpillars” that are radomly intermixed, whereas the third chain behaved differently and producing an inferior goodness of fit (GOF). Therefore, in a second step, we again ran three HCM chains for each parameter, but this time, we initialized all chains with paramter values close to the mean of the HCM chain that produced the best GOF in the first step. However, even this procedure resulted in convergence problems for a few participants (e.g., bimodal posterior distributions). We therefore excluded partiipants with such convergence issues and repeated the first and second step. This explains why the sample sizes presented in Table 5 are slightly smaller than those reported by Wetzels et al. (2010) . Table 5 also presents, for each data set separately, the number of burn-in samples and posterior samples that we collected for each chain. These specifications differ across data sets to ensure that all chains reached convergence. We based our inferences on these posterior samples. Table 5 | Sample size of the four data sets and number of burn-in samples and posterior samples that we collected for each chain. Experimental Sample Burn-in Posterior condition size samples samples Standard 17 37,000 3000 Rewards 19 30,000 3000 Update 16 23,000 1500 Consistency 15 18,000 2000 4.2. RESULTS In this section, we discuss the results of the test of selective inflence. We first focus on the behavioral level by describing the choice patterns observed in the four experimental conditions",
    "chunk_id": "validating_the_pvl-delta_model_for_the_iowa_gambling_task.json_chunk_26"
  },
  {
    "document_type": "research_paper",
    "title": "Validating the PVL-Delta model for the Iowa gambling task",
    "author": "Helen Steingroever",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Steingroever-2013-Validating-the-pvl-delta-model-for-.pdf",
    "date_published": "2013-11-26",
    "keywords": "reinforcement learning, expectancy valence model, prospect valence model, test of selective influence, parameter space partitioning",
    "flag": "",
    "chunk_text": ". We first focus on the behavioral level by describing the choice patterns observed in the four experimental conditions. Second, we focus on the level of the cognitive modeling analses; we describe tests confirming that the posterior distributions converged successfully from their starting values to their statioary distributions. In addition, we show that the PVL-Delta model results in a satisfactory fit performance and simulation perfomance for the four conditions. Finally, we visually compare the posterior distributions of the group-level parameters of all four conditions to draw inferences about the effect of the experimental manipulations. 4.2.1. Behavioral data The mean proportion of choices from each deck within 15 blocks each containing 10 trials as observed in the four experimental conditions reported by Wetzels et al. (2010) are presented in the first column of Figure 9 . In the standard condition, participants learned to prefer good deck C over all remaining decks; however, participants failed to learn that deck D is also a good deck. In the rewards condition (i.e., participants were instructed to pay more attention to rewards and to consider losses as less important), participants learned to prefer bad deck B over all remaining decks. Note that even though bad decks A and B both yield high immediate rewards on every trial, participants did not learn to select deck A more often than good decks C and D. This may suggest that the experimental manipulation was only partly successful. In the updating condition (i.e., each choice was followed by a on-screen presentation of five numbers that participants had to remember because, after the next choice, they were asked about the relative position of one of the numbers), participants show a very weak learning curve; they only learned to avoid deck A",
    "chunk_id": "validating_the_pvl-delta_model_for_the_iowa_gambling_task.json_chunk_27"
  },
  {
    "document_type": "research_paper",
    "title": "Validating the PVL-Delta model for the Iowa gambling task",
    "author": "Helen Steingroever",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Steingroever-2013-Validating-the-pvl-delta-model-for-.pdf",
    "date_published": "2013-11-26",
    "keywords": "reinforcement learning, expectancy valence model, prospect valence model, test of selective influence, parameter space partitioning",
    "flag": "",
    "chunk_text": ". In the consistency condition (i.e., participants were told that after every 10 trials the payoff schemes for the decks could have changed), participants—in contrast to the intention of the expeimental manipulation—did not evenly explore all decks across the entire 100 trials. Instead participants learned to prefer decks B and C over the remaining decks. It seems that participants prefer bad deck B because it yields high immediate rewards on the majority of the trials; however, participants prefer good deck C because it never yields a net loss and is therefore a safe option. 4.2.2. Convergence checks Visual inspection of the HMC chains and consideration of the ˆ R statistics for all parameters (all parameters had ˆ R values below 1.045) suggest that all chains have converged successfully. FIGURE 9 | Observed choice behavior and assessment of absolute model performance. The first column shows the mean proportion of choices from each deck within 15 blocks as observed in the four experimental conditions reported by Wetzels et al. (2010) . Each block contains 10 trials. The second and third column show the fit performance and simulation performance, respectively, for each of the four conditions. Fit performance and simulation performance are based on random draws from the individual-level joint posteriors. To illustrate how we visually assessed convergence, we show the chains of one individual-level parameter in the Appendix. From the figure it is evident that the chains have converged successfully from their starting values to their stationary ditribution, looking like “hairy caterpillars” that are randomly intermixed. 4.2.3. Absolute model performance To assess the absolute model performance of the PVL-Delta model with respect to the four experimental conditions, the seond and third column of Figure 9 show the fit performance and simulation performance, respectively. Fit performance and simulation performance are based on random draws from the individual-level joint posterior",
    "chunk_id": "validating_the_pvl-delta_model_for_the_iowa_gambling_task.json_chunk_28"
  },
  {
    "document_type": "research_paper",
    "title": "Validating the PVL-Delta model for the Iowa gambling task",
    "author": "Helen Steingroever",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Steingroever-2013-Validating-the-pvl-delta-model-for-.pdf",
    "date_published": "2013-11-26",
    "keywords": "reinforcement learning, expectancy valence model, prospect valence model, test of selective influence, parameter space partitioning",
    "flag": "",
    "chunk_text": ". Fit performance and simulation performance are based on random draws from the individual-level joint posterior. From the second column of the figure it is evident that the PVL-Delta model provides a good fit to the data of all four conditions (i.e., the model makes accrate one-step-ahead predictions when provided with access to the observed sequence of choices and payoffs). In addition, the third column of Figure 9 illustrates that the PVL-Delta model adquately generates the choice pattern shown by the standard and update conditions. In the case of the rewards and consistency coditions, the simulation performance of the PVL-Delta model is acceptable; the model correctly predicts the most preferred deck, but fails to account for the rank order of the remaining three decks: in the reward condition, the model predicts that deck D is preferred over decks A and C even though the participants chose these three decks about equally often. In the consistency condition, the model predicts that deck D is preferred over deck C even though the participants showed the reverse pattern. To sum up, the PVL-Delta model captures the global patterns in the data providing an acceptable fit and simulation performance with respect to the four data sets at hand; this allows us to meaningfully compare the group-level parameters of the four conditions. 4.2.4. Test of selective influence Figure 10 presents the posterior distributions of the group-level parameters of all four conditions. It is evident that the expermental manipulation is successfully reflected in the loss aversion parameter and the consistency parameter: first, compared to paticipants that received the standard instruction, participants who were instructed to focus on rewards (i.e., the rewards condition) had lower values for the loss aversion parameter indicating that they were indeed more reward-seeking",
    "chunk_id": "validating_the_pvl-delta_model_for_the_iowa_gambling_task.json_chunk_29"
  },
  {
    "document_type": "research_paper",
    "title": "Validating the PVL-Delta model for the Iowa gambling task",
    "author": "Helen Steingroever",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Steingroever-2013-Validating-the-pvl-delta-model-for-.pdf",
    "date_published": "2013-11-26",
    "keywords": "reinforcement learning, expectancy valence model, prospect valence model, test of selective influence, parameter space partitioning",
    "flag": "",
    "chunk_text": ". Second, fitting the PVDelta model to data of participants that were told that after every 10 trials the payoff schemes for the decks could have changed (i.e., the consistency condition) resulted in a smaller consistency parameter (i.e., a more random choice behavior) than fitting the PVL-Delta model to data of participants that received the stadard instructions. However, in the update condition is no clear effect on the updating parameter. Yet, it is evident that the consitency parameter in the update condition is noticeably lower than in the standard condition (i.e., a more random choice behavior); this is consistent with the choice pattern shown by the update condition; participants only learned to avoid deck A, but show a completely indistinguishable preference for the remaining three decks. FIGURE 10 | Posterior distributions for the group-level parameters of the PVL-Delta model in the four experimental conditions. 5. DISCUSSION In this article, we conducted two tests to validate the PVL-Delta model: a parameter space partitioning study and a test of seletive influence. Applying PSP to the PVL-Delta model, we have obtained a deeper understanding of the model’s behavior. We used two different definitions of choice patterns; the broad deinition allowed us to get an indication of how central each of the choice patterns are to the model’s overall performance, and the restricted definition allowed us to assess the model’s data-fitting potential when confronted with data featuring pronounced deck preferences. Using the broad definition of choice patterns, the PSP study revealed that the PVL-Delta model can generate all typical empiical choice patterns. However, the PVL-Delta model generates the choice pattern featuring a preference for the bad decks only over a minor part of its parameter space suggesting that this choice pattern is virtually irrelevant to the model’s overall performance",
    "chunk_id": "validating_the_pvl-delta_model_for_the_iowa_gambling_task.json_chunk_30"
  },
  {
    "document_type": "research_paper",
    "title": "Validating the PVL-Delta model for the Iowa gambling task",
    "author": "Helen Steingroever",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Steingroever-2013-Validating-the-pvl-delta-model-for-.pdf",
    "date_published": "2013-11-26",
    "keywords": "reinforcement learning, expectancy valence model, prospect valence model, test of selective influence, parameter space partitioning",
    "flag": "",
    "chunk_text": ". Using the restricted definition of choice patterns, the PSP study revealed that the PVL-Delta model can still generate all pronounced empirical choice patterns over a minor part of its parameter space. But for these pronounced choice patterns, the PVL-Delta model generally underestimates the empirical switch proportions during the last 50 trials. In particular, given prnounced preferences for the bad decks, the PVL-Delta model fails to account for the empirical switch behavior. This faiure seems to be caused by the Prospect Utility function of the PVL-Delta model: in a previous PSP study, Steingroever et al. ( 2013b ) showed that this failure is also present in the PVL and EV-PU model (i.e., models with the Prospect Utility function), but not in the EV model (i.e., a model without the Prospect Utility function). However, in the case of the other two pronounced choice patterns—the choice patterns favoing decks with high expected value or low loss frequency— we showed that the PVL-Delta model provides a good account for the empirical switch behavior for some parameter combinations. The results of the PSP study for the PVL-Delta model and the earlier PSP studies for the EV and PVL models ( Steingroever et al., 2013b ) suggest that the PVL-Delta model outperforms its two competitors. The EV model fails to generate a pronounced preerence for the decks with infrequent losses; the PVL model is able to generate pronounced decks preferences, but underestimates the switch proportions even more strongly than the PVL-Delta model. This superiority of the PVL-Delta model is in line with the posterior predictive checks reported by Steingroever et al. (in press) . An important advantage of PSP is that it is a global analysis technique augmenting local methods that have previously been used to compare RL models ( Pitt et al., 2006, 2008 )",
    "chunk_id": "validating_the_pvl-delta_model_for_the_iowa_gambling_task.json_chunk_31"
  },
  {
    "document_type": "research_paper",
    "title": "Validating the PVL-Delta model for the Iowa gambling task",
    "author": "Helen Steingroever",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Steingroever-2013-Validating-the-pvl-delta-model-for-.pdf",
    "date_published": "2013-11-26",
    "keywords": "reinforcement learning, expectancy valence model, prospect valence model, test of selective influence, parameter space partitioning",
    "flag": "",
    "chunk_text": ". (in press) . An important advantage of PSP is that it is a global analysis technique augmenting local methods that have previously been used to compare RL models ( Pitt et al., 2006, 2008 ). Whereas local methods, such as the post hoc fit criterion or the generalization criterion, evaluate a model’s performance at a single point of a model’s parameter space, global methods such as PSP help us to determine the full range of choice patterns that a model can geerate by varying its parameter values (see also Vanpaemel, 2009 ). This means that we can obtain a global perspective on the datfitting potential of the PVL-Delta model. Thus, if researches wish to apply the PVL-Delta model to IGT data, they can decide based on the behavioral results whether it is appropriate to apply the PVL-Delta model or not. The PSP results of this paper should be interpreted with care. PSP gives an indication of how central choice patterns are to the overall performance of the model. However, it is premture to conclude that the PVL-Delta model cannot generate the choice pattern “bad decks over goods decks” at all, soley because the model generates this choice pattern over a small part of the parameter space. Instead, we can only conclude that this choice pattern is not central to the model’s overall performance. It should also be noted that the inferences drawn from the PSP study strongly depend on our definitions of choice patterns. The restricted definition of choice patterns was based on IGT peformance of healthy participants ( Steingroever et al., 2013b ). We could thus detect inconsistencies between the empirical populaity of each pronounced choice pattern in the Steingroever et al. (2013a) data pool and the frequency predicted by the PVL-Delta model. It is troubling that the PVL-Delta model fails to generate a pronounced preference for the bad decks with many switches. But it should be acknowledged that this choice pattern is not cetral in healthy participants’ IGT performance: in the Steingroever et al",
    "chunk_id": "validating_the_pvl-delta_model_for_the_iowa_gambling_task.json_chunk_32"
  },
  {
    "document_type": "research_paper",
    "title": "Validating the PVL-Delta model for the Iowa gambling task",
    "author": "Helen Steingroever",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Steingroever-2013-Validating-the-pvl-delta-model-for-.pdf",
    "date_published": "2013-11-26",
    "keywords": "reinforcement learning, expectancy valence model, prospect valence model, test of selective influence, parameter space partitioning",
    "flag": "",
    "chunk_text": ". But it should be acknowledged that this choice pattern is not cetral in healthy participants’ IGT performance: in the Steingroever et al. (2013a) data pool, only 5% ( N = 18) of the healthy paticipants showed this choice pattern ( Table 2 ). Still, this choice pattern is assumed to be characteristic for patients with decisiomaking deficits ( Bechara et al., 1994, 1997 ), but a better empirical foundation (e.g., a literature review on the IGT performance of clinical groups) is required to accurately judge the gravity of the PVL-Delta model’s failure to generate a pronounced preference for the bad decks with many switches. The test of selective influence revealed that the experimetal manipulations had a noticeable effect on the loss aversion parameter and consistency parameter, but not on the updating parameter. However, it is premature to conclude that the updaing parameter does not correspond to memory processes. It may be that the experimental manipulation did not work out properly. In addition, one should bear in mind that every data set is chaacterized by its own idiosyncrasies. IGT data generally are highly idiosyncratic—possibly because the IGT is a very complex task ( Steingroever et al., 2013a ). In order to be able to draw more accrate conclusions on whether the parameters represent distinct psychological processes, independent repetitions of the test of selective influence and even different experimental manipulations are necessary. The results of this article confirm that the PVL-Delta model is an attractive alternative to the popular EV and PVL moels. However, the PVL-Delta model is also characterized by a few shortcomings because it underrepresents the choice pattern featuring a preference for the bad decks. Nevertheless, we recomend that researchers use the PVL-Delta model to disentangle psychological processes underlying IGT performance, provided that they rigorously assess absolute model performance before interpreting the model parameters ( Steingroever et al., in press )",
    "chunk_id": "validating_the_pvl-delta_model_for_the_iowa_gambling_task.json_chunk_33"
  },
  {
    "document_type": "research_paper",
    "title": "Validating the PVL-Delta model for the Iowa gambling task",
    "author": "Helen Steingroever",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Steingroever-2013-Validating-the-pvl-delta-model-for-.pdf",
    "date_published": "2013-11-26",
    "keywords": "reinforcement learning, expectancy valence model, prospect valence model, test of selective influence, parameter space partitioning",
    "flag": "",
    "chunk_text": ". ACKNOWLEDGMENTS This publication was supported by the Dutch national program COMMIT and by an Open Access grant from NWO. REFERENCES Ahn, W.-Y., Busemeyer, J. R., Wagenmakers, E.-J., and Stout, J. C. (2008). Comparison of decision learning models using the generalization criterion method. Cogn. Sci. 32, 1376–1402. doi: 10.1080/03640210802352992 Ahn, W.-Y., Krawitz, A., Kim, W., Busemeyer, J. R., and Brown, J. W. (2011). A model-based fMRI analysis with hierarchical Bayesian parameter estimation. J. Neurosci. Psychol. Econ. 4, 95–110. doi: 10.1037/a0020684 Bechara, A., Damasio, A. R., Damasio, H., and Anderson, S. W. (1994). Insensitivity to future consequences following damage to human prefrontal cortex. Cognition 50, 7–15. doi: 10.1016/0010-0277(94)90018-3 Bechara, A., Damasio, H., Tranel, D., and Damasio, A. R. (1997). Deciding advantgeously before knowing the advantageous strategy. Science 275, 1293–1295. doi: 10.1126/science.275.5304.1293 Busemeyer, J. R., and Stout, J. C. (2002). A contribution of cognitive decision moels to clinical assessment: Decomposing performance on the Bechara gambling task. Psychol. Assess. 14, 253–262. doi: 10.1037/1040-3590.14.3.253 Busemeyer, J. R., Stout, J., and Finn, P. (in press). “Using computational models to help explain decision making processes of substance abusers,” in Cognitive and Affective Neuroscience of Psychopathology , ed D. Barch (New York, NY: Oxford University Press). Fridberg, D. J., Queller, S., Ahn, W.-Y., Kim, W., Bishara, A. J., Busemeyer, J. R., et al. (2010). Cognitive mechanisms underlying risky decision-making in chronic cannabis users. J. Math. Psychol. 54, 28–38. doi: 10.1016/j.jmp.2009.10.002 Gelman, A., and Rubin, D. (1992). Inference from iterative simulation using multiple sequences. Stat. Sci. 7, 457–472. doi: 10.1214/ss/1177011136 Hoffman, M. D., and Gelman, A. (2011). The no-U-turn sampler: adaptively setting path lengths in Hamiltonian Monte Carlo. Arxiv preprint arXiv:1111.4246. Luce, R. (1959). Individual Choice Behavior",
    "chunk_id": "validating_the_pvl-delta_model_for_the_iowa_gambling_task.json_chunk_34"
  },
  {
    "document_type": "research_paper",
    "title": "Validating the PVL-Delta model for the Iowa gambling task",
    "author": "Helen Steingroever",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Steingroever-2013-Validating-the-pvl-delta-model-for-.pdf",
    "date_published": "2013-11-26",
    "keywords": "reinforcement learning, expectancy valence model, prospect valence model, test of selective influence, parameter space partitioning",
    "flag": "",
    "chunk_text": ". D., and Gelman, A. (2011). The no-U-turn sampler: adaptively setting path lengths in Hamiltonian Monte Carlo. Arxiv preprint arXiv:1111.4246. Luce, R. (1959). Individual Choice Behavior . New York, NY: Wiley. Pitt, M., Kim, W., Navarro, D., and Myung, J. (2006). Global model analysis by parameter space partitioning. Psychol. Rev. 113, 57–83. doi: 10.1037/0033- 295X.113.1.57 Pitt, M., Myung, J., Montenegro, M., and Pooley, J. (2008). Measuring model flexibility with parameter space partitioning: an introduction and application example. Cogn. Sci. 32, 1285–1303. doi: 10.1080/03640210802477534 Stan Development Team. (2013a). Stan: A C++ Library for Probability and Sampling, Version 2.0. Available online at: http://mc-stan . org/ Stan Development Team. (2013b). Stan Modeling Language User’s Guide and Reference Manual, Version 2.0 . Available online at: http://mc-stan . org/ Steingroever, H., Wetzels, R., Horstmann, A., Neumann, J., and Wagenmakers, E.-J. (2013a). Performance of healthy participants on the Iowa gambling task. Psychol. Assess. 25, 180–193. doi: 10.1037/a0029929 Steingroever, H., Wetzels, R., and Wagenmakers, E.-J. (2013b). A comparison of reinforcement-learning models for the Iowa gambling task using parameter space partitioning. J. Prob. Solv. 5:2. doi: 10.7771/1932-6246.1150 Steingroever, H., Wetzels, R., and Wagenmakers, E.-J. (in press). Absolute perfomance of reinforcement-learning models for the Iowa gambling task. Decision . Tversky, A., and Kahneman, D. (1992). Advances in prospect theory: cumlative representation of uncertainty. J. Risk Uncertain. 5, 297–323. doi: 10.1007/BF00122574 Vanpaemel, W. (2009). “Measuring model complexity with the prior predictive,” in Advances in Neural Information Processing Systems 22 , eds Y. Bengio, D. Schuurmans, J. Lafferty, C. K. I. Williams, and A. Culotta, 1919–1927 (Red Hook, NY: Curran Associates Inc.). Wetzels, R., Vandekerckhove, J., Tuerlinckx, F., and Wagenmakers, E.-J. (2010)",
    "chunk_id": "validating_the_pvl-delta_model_for_the_iowa_gambling_task.json_chunk_35"
  },
  {
    "document_type": "research_paper",
    "title": "Validating the PVL-Delta model for the Iowa gambling task",
    "author": "Helen Steingroever",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Steingroever-2013-Validating-the-pvl-delta-model-for-.pdf",
    "date_published": "2013-11-26",
    "keywords": "reinforcement learning, expectancy valence model, prospect valence model, test of selective influence, parameter space partitioning",
    "flag": "",
    "chunk_text": ". Schuurmans, J. Lafferty, C. K. I. Williams, and A. Culotta, 1919–1927 (Red Hook, NY: Curran Associates Inc.). Wetzels, R., Vandekerckhove, J., Tuerlinckx, F., and Wagenmakers, E.-J. (2010). Bayesian parameter estimation in the Expectancy Valence model of the Iowa gambling task. J. Math. Psychol. 54, 14–27. doi: 10.1016/j.jmp.2008.12.001 Worthy, D. A., Hawthorne, M. J., and Otto, A. R. (2013). Heterogeneity of strategy use in the Iowa gambling task: a comparison of win-stay/lose-shift and reinforcement learning models. Psychon. Bull. Rev. 20, 364–371. doi: 10.3758/s13423-012-0324-9 Yechiam, E., and Busemeyer, J. (2005). Comparison of basic assumptions embeded in learning models for experience-based decision making. Psychon. Bull. Rev. 12, 387–402. doi: 10.3758/BF03193783 Yechiam, E., and Busemeyer, J. R. (2008). Evaluating generalizability and paraeter consistency in learning models. Games Econ. Behav. 63, 370–394. doi: 10.1016/j.geb.2007.08.011 Yechiam, E., and Ert, E. (2007). Evaluating the reliance on past choices in adaptive learning models. J. Math. Psychol. 51, 75–84. doi: 10.1016/j.jmp.2006.11.002 Zhao, J., and Costello, F. (2007). Computational modelling of switching behaviour in repeated gambles. Artif. Intell. Rev. 27, 209–222. doi: 10.1007/s10462-008- 9083-4 Conflict of Interest Statement: The authors declare that the research was coducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest. Received: 28 June 2013; accepted: 14 November 2013; published online: 03 December 2013. Citation: Steingroever H, Wetzels R and Wagenmakers E-J (2013) Validating the PVDelta model for the Iowa gambling task. Front. Psychol. 4 :898. doi: 10.3389/fpsyg. 2013.00898 This article was submitted to Decision Neuroscience, a section of the journal Frontiers in Psychology. Copyright © 2013 Steingroever, Wetzels and Wagenmakers. This is an open-access article distributed under the terms of the Creative Commons Attribution License (CC BY)",
    "chunk_id": "validating_the_pvl-delta_model_for_the_iowa_gambling_task.json_chunk_36"
  },
  {
    "document_type": "research_paper",
    "title": "Validating the PVL-Delta model for the Iowa gambling task",
    "author": "Helen Steingroever",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Steingroever-2013-Validating-the-pvl-delta-model-for-.pdf",
    "date_published": "2013-11-26",
    "keywords": "reinforcement learning, expectancy valence model, prospect valence model, test of selective influence, parameter space partitioning",
    "flag": "",
    "chunk_text": ". Copyright © 2013 Steingroever, Wetzels and Wagenmakers. This is an open-access article distributed under the terms of the Creative Commons Attribution License (CC BY). The use, distribution or reproduction in other forums is permitted, provided the original author(s) or licensor are credited and that the original publication in this journal is cited, in accordance with accepted academic practice. No use, distribution or reproduction is permitted which does not comply with these terms. APPENDIX In this appendix, we present how we visually assessed convegence, additional absolute model performance checks and the results of two parameter-recovery studies that confirm that we correctly implemented the PVL-Delta model. For the parameterecovery studies, we used two synthetic data sets that were geneated with the PVL-Delta model. The data-generating parameters correspond to the medians of the individual-level joint posterors that were obtained by fitting the PVL-Delta model to two real data sets. Figure A1 shows the HMC chains of one individual-level parameter. From the figure it is evident that the chains have coverged successfully from their starting values to their stationary distribution, looking like “hairy caterpillars” that are randomly intermixed. We inspected this type of plot for every parameter to visually assess convergence in addition to the formal diagnostic measure of convergence ˆ R . Figure A2 presents the fit performance and simulation perfomance of the PVL-Delta model that was obtained with random draws from the joint posterior distributions over the groulevel parameters (hereafter group-level joint posteriors). Note that Figure 9 presents the fit performance and simulation peformance based on the individual-level joint posteriors. A coparison of both figures reveals that the fit performance based FIGURE A1 | HCM chains of the individual-level consistency parameter c of the third participant in the consistency condition",
    "chunk_id": "validating_the_pvl-delta_model_for_the_iowa_gambling_task.json_chunk_37"
  },
  {
    "document_type": "research_paper",
    "title": "Validating the PVL-Delta model for the Iowa gambling task",
    "author": "Helen Steingroever",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Steingroever-2013-Validating-the-pvl-delta-model-for-.pdf",
    "date_published": "2013-11-26",
    "keywords": "reinforcement learning, expectancy valence model, prospect valence model, test of selective influence, parameter space partitioning",
    "flag": "",
    "chunk_text": ". A coparison of both figures reveals that the fit performance based FIGURE A1 | HCM chains of the individual-level consistency parameter c of the third participant in the consistency condition. In addition to the formal diagnostic measure of convergence ˆ R , we inspected this type of plot for every parameter to visually assess convergence. on the group-level joint posteriors ( Figure A2 ) closely matches the fit performance based on the individual-level joint posteriors ( Figure 9 ). However, there are a few discrepancies in the case of the simulation performance: from Figures 9 , A2 it is evident that the simulation performance based on the group-level joint postriors is more extreme, that is, the most preferred deck is preferred even stronger, whereas the least preferred deck is avoided even stronger. However, it is evident that in general Figure A2 mirrors the conclusion drawn from Figure 9 . Figure A3 presents the results of the first recovery study. This data set contains 18 synthetic participants. The figure contains four panels; each panel illustrates the recovery of one of the four model parameters. In each panel, the mode of the group-level posterior is represented by the dotted line, whereas the solid line represents the true group-level parameter. In addition, the paels can also be used to assess the individual-level recovery: the unfilled dots represent the modes of the individual-level postriors, whereas the filled dots represent the true individual-level parameters. Note that the individual-level posterior distributions are not sorted by the subject ID; in order to visualize the degree of individual differences in each model parameter, we sorted the individual-level posterior distributions by the true individualevel parameters. From Figure A3 it is evident that the group-level updaing parameter is slightly underestimated, but the remaining group-level parameters are recovered very accurately. However, the recovery of the individual-level parameters is less accrate",
    "chunk_id": "validating_the_pvl-delta_model_for_the_iowa_gambling_task.json_chunk_38"
  },
  {
    "document_type": "research_paper",
    "title": "Validating the PVL-Delta model for the Iowa gambling task",
    "author": "Helen Steingroever",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Steingroever-2013-Validating-the-pvl-delta-model-for-.pdf",
    "date_published": "2013-11-26",
    "keywords": "reinforcement learning, expectancy valence model, prospect valence model, test of selective influence, parameter space partitioning",
    "flag": "",
    "chunk_text": ". However, the recovery of the individual-level parameters is less accrate. Especially in the case of the shape parameter, most of the individual-level modes differ from the true individual-level parameters by regressing to the mode of the group-level paramter (i.e., shrinkage); small deviations are noticeable in the case of the individual-level loss aversion parameters and the individualevel updating parameter. Yet, in the case of the consistency parameter, most individual-level parameters are recovered very accurately. Figure A4 presents the results of the second recovery study. This data set contains 30 synthetic participants. It is evident that all group-level parameters are recovered very accurately. However, the recovery of the individual-level parameters is less accurate. Especially in the case of the individual-level shape parameters and the individual-level loss aversion parameters, it is evident that the individual-level modes differ from the true individualevel parameters. Yet, the recovery of the individual-level updating parameters and the individual-level consistency parameters is adequate. FIGURE A2 | Observed choice behavior and assessment of absolute model performance. The first column shows the mean proportion of choices from each deck within 15 blocks as observed in the four experimental conditions reported by Wetzels et al. (2010) . Each block contains 10 trials. The second and third column show the fit performance and simulation performance, respectively, for each of the four conditions. Fit performance and simulation performance are based on random draws from the Fit performance and simulation performance are based -level joint posteriors. FIGURE A3 | Recovery of individual and group-level parameters of the PVL-Delta model. Data of 18 participants completing a 100-trial IGT. The dotted lines represent the modes of the group-level posteriors and the unfilled dots the modes of the group-level posterior. FIGURE A4 | Recovery of individual and group-level parameters of the PVL-Delta model",
    "chunk_id": "validating_the_pvl-delta_model_for_the_iowa_gambling_task.json_chunk_39"
  },
  {
    "document_type": "research_paper",
    "title": "Validating the PVL-Delta model for the Iowa gambling task",
    "author": "Helen Steingroever",
    "source": "raw_syllabi\\master_courses\\Decision_making\\pdf_material\\Steingroever-2013-Validating-the-pvl-delta-model-for-.pdf",
    "date_published": "2013-11-26",
    "keywords": "reinforcement learning, expectancy valence model, prospect valence model, test of selective influence, parameter space partitioning",
    "flag": "",
    "chunk_text": ". FIGURE A4 | Recovery of individual and group-level parameters of the PVL-Delta model. Data of 30 participants completing a 100-trial IGT. The dotted lines represent the modes of the group-level posteriors and the unfilled dots the modes of the individual-level posteriors.",
    "chunk_id": "validating_the_pvl-delta_model_for_the_iowa_gambling_task.json_chunk_40"
  }
]